{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IBM Machine Learning\n",
    "## Course 5: Deep Learning\n",
    "## Topic: English Handwritten Characters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Introduction\n",
    "\n",
    "We will work on the handwritten English dataset, which consists of 3410 images. The characters include 0-9, A-Z and a-z, 62 classes in total and each image is map to only one label.\n",
    "The objective is to classify the images to the correct label.\n",
    "The dataset can be found in this link: https://www.kaggle.com/dhruvildave/english-handwritten-characters-dataset?select=Img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 import the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import the library\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load the data label\n",
    "df=pd.read_csv(\"data/english.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Img/img001-001.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Img/img001-002.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Img/img001-003.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Img/img001-004.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Img/img001-005.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                image label\n",
       "0  Img/img001-001.png     0\n",
       "1  Img/img001-002.png     0\n",
       "2  Img/img001-003.png     0\n",
       "3  Img/img001-004.png     0\n",
       "4  Img/img001-005.png     0"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## the first 5 rows in the label file\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3410 entries, 0 to 3409\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   image   3410 non-null   object\n",
      " 1   label   3410 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 53.4+ KB\n"
     ]
    }
   ],
   "source": [
    "## As describe in introduction, there 3410 records.\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       img001-001.png\n",
       "1       img001-002.png\n",
       "2       img001-003.png\n",
       "3       img001-004.png\n",
       "4       img001-005.png\n",
       "             ...      \n",
       "3405    img062-051.png\n",
       "3406    img062-052.png\n",
       "3407    img062-053.png\n",
       "3408    img062-054.png\n",
       "3409    img062-055.png\n",
       "Name: image, Length: 3410, dtype: object"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Process the image column\n",
    "df['image']=df['image'].str.split('/').str[1]\n",
    "df['image']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x3dc0ab70>"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## check the image and corresponding label\n",
    "img=mpimg.imread('data/'+df['image'][0])\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0'"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 convert each image to 2D array\n",
    "\n",
    "From the image we can see that each image have 900 pixels in height and 1200 pixels in width. We have 3409 iamges. If we use the original dimension, it will need a few GB memory. we will compress and convert each image to an array of size(30, 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# before resize\n",
    "image=Image.open('data/'+df['image'][0]).convert('L')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "(1200, 900)\n",
      "L\n"
     ]
    }
   ],
   "source": [
    "print(image.format)\n",
    "print(image.size)\n",
    "print(image.mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x3d9586a0>"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# after resize\n",
    "new_image=image.resize((40,30))\n",
    "plt.imshow(new_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 40)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the size \n",
    "np.asarray(new_image).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the dataset for the pixel value of each image\n",
    "L=[]\n",
    "for image in df['image']:\n",
    "    rawData=np.asarray(Image.open('data/'+image).convert('L').resize((40,30)))\n",
    "    L.append(rawData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3410, 30, 40)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert to numpy array\n",
    "len(L)\n",
    "X=np.array(L)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the data for label \n",
    "y=df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating instance of labelencoder\n",
    "labelencoder = LabelEncoder()\n",
    "\n",
    "# Assigning numerical values \n",
    "y=labelencoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 Data preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's make everything float and scale\n",
    "X=X.astype('float32')\n",
    "X/=255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4 Data splitted into training and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    stratify=y, \n",
    "                                                    test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2557, 30, 40)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Build Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Get a baseline performance using Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "## flatten our data\n",
    "x_train_flat=x_train.reshape(len(x_train), -1)\n",
    "x_test_flat=x_test.reshape(len(x_test), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train_flat shape: (2557, 1200)\n"
     ]
    }
   ],
   "source": [
    "## the size of training \n",
    "print('x_train_flat shape:', x_train_flat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_test_flat shape: (853, 1200)\n"
     ]
    }
   ],
   "source": [
    "## the size of testing\n",
    "print('x_test_flat shape:', x_test_flat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "#used to help some of the timing functions\n",
    "now = datetime.datetime.now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 0:00:02.186125\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, precision_recall_curve, roc_auc_score, roc_curve, accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "## Train the RF Model\n",
    "t = now()\n",
    "rf_model = RandomForestClassifier(n_estimators=200)\n",
    "rf_model.fit(x_train_flat, y_train)\n",
    "print('Training time: %s' % (now() - t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.449\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test set - both \"hard\" predictions, and the scores (percent of trees voting yes)\n",
    "y_pred_class_rf = rf_model.predict(x_test_flat)\n",
    "y_pred_prob_rf = rf_model.predict_proba(x_test_flat)\n",
    "\n",
    "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_rf)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4,  0,  0, ...,  0,  0,  0],\n",
       "       [ 0, 10,  0, ...,  0,  0,  0],\n",
       "       [ 0,  0, 10, ...,  0,  0,  0],\n",
       "       ...,\n",
       "       [ 0,  0,  0, ...,  4,  0,  1],\n",
       "       [ 0,  0,  0, ...,  1,  5,  0],\n",
       "       [ 0,  0,  1, ...,  1,  0,  5]], dtype=int64)"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test,y_pred_class_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see above, the training time is long and the accuracy is quite low(less than 50%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Build a full connected neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(set(y))\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1=Sequential()\n",
    "model_1.add(Dense(100,input_shape=(1200,), activation='sigmoid'))\n",
    "model_1.add(Dense(62,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_10 (Dense)             (None, 100)               120100    \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 62)                6262      \n",
      "=================================================================\n",
      "Total params: 126,362\n",
      "Trainable params: 126,362\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 4.1787 - accuracy: 0.0160 - val_loss: 4.1254 - val_accuracy: 0.0211\n",
      "Epoch 2/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.1243 - accuracy: 0.0235 - val_loss: 4.1042 - val_accuracy: 0.0457\n",
      "Epoch 3/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 4.0929 - accuracy: 0.0305 - val_loss: 4.0581 - val_accuracy: 0.0352\n",
      "Epoch 4/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 4.0302 - accuracy: 0.0372 - val_loss: 4.0225 - val_accuracy: 0.0399\n",
      "Epoch 5/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 3.9689 - accuracy: 0.0571 - val_loss: 3.9600 - val_accuracy: 0.0715\n",
      "Epoch 6/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 3.9033 - accuracy: 0.0755 - val_loss: 3.9012 - val_accuracy: 0.0680\n",
      "Epoch 7/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 3.8296 - accuracy: 0.1060 - val_loss: 3.8459 - val_accuracy: 0.0797\n",
      "Epoch 8/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.7624 - accuracy: 0.1279 - val_loss: 3.7920 - val_accuracy: 0.1020\n",
      "Epoch 9/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.6869 - accuracy: 0.1486 - val_loss: 3.7252 - val_accuracy: 0.1313\n",
      "Epoch 10/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 3.6252 - accuracy: 0.1658 - val_loss: 3.6671 - val_accuracy: 0.1348\n",
      "Epoch 11/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 3.5523 - accuracy: 0.1979 - val_loss: 3.6011 - val_accuracy: 0.1676\n",
      "Epoch 12/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 3.4790 - accuracy: 0.2081 - val_loss: 3.5393 - val_accuracy: 0.1524\n",
      "Epoch 13/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 3.4214 - accuracy: 0.2276 - val_loss: 3.4947 - val_accuracy: 0.1981\n",
      "Epoch 14/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 3.3563 - accuracy: 0.2464 - val_loss: 3.4636 - val_accuracy: 0.1676\n",
      "Epoch 15/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 3.2975 - accuracy: 0.2538 - val_loss: 3.4078 - val_accuracy: 0.2286\n",
      "Epoch 16/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 3.2486 - accuracy: 0.2663 - val_loss: 3.3633 - val_accuracy: 0.2005\n",
      "Epoch 17/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 3.1863 - accuracy: 0.2914 - val_loss: 3.3248 - val_accuracy: 0.2169\n",
      "Epoch 18/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 3.1430 - accuracy: 0.2804 - val_loss: 3.2714 - val_accuracy: 0.2450\n",
      "Epoch 19/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 3.0859 - accuracy: 0.3125 - val_loss: 3.2537 - val_accuracy: 0.2392\n",
      "Epoch 20/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 3.0384 - accuracy: 0.3269 - val_loss: 3.2062 - val_accuracy: 0.2579\n",
      "Epoch 21/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 3.0062 - accuracy: 0.3273 - val_loss: 3.1845 - val_accuracy: 0.2567\n",
      "Epoch 22/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.9514 - accuracy: 0.3359 - val_loss: 3.1596 - val_accuracy: 0.2521\n",
      "Epoch 23/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.9149 - accuracy: 0.3465 - val_loss: 3.1335 - val_accuracy: 0.2403\n",
      "Epoch 24/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.8736 - accuracy: 0.3531 - val_loss: 3.0901 - val_accuracy: 0.2755\n",
      "Epoch 25/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.8418 - accuracy: 0.3559 - val_loss: 3.0683 - val_accuracy: 0.2755\n",
      "Epoch 26/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.8027 - accuracy: 0.3582 - val_loss: 3.0699 - val_accuracy: 0.2767\n",
      "Epoch 27/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.7672 - accuracy: 0.3696 - val_loss: 3.0457 - val_accuracy: 0.2614\n",
      "Epoch 28/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.7379 - accuracy: 0.3766 - val_loss: 3.0259 - val_accuracy: 0.2532\n",
      "Epoch 29/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.7097 - accuracy: 0.3817 - val_loss: 2.9494 - val_accuracy: 0.3118\n",
      "Epoch 30/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.6711 - accuracy: 0.3817 - val_loss: 2.9578 - val_accuracy: 0.2884\n",
      "Epoch 31/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.6403 - accuracy: 0.3954 - val_loss: 2.9805 - val_accuracy: 0.2755\n",
      "Epoch 32/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.6155 - accuracy: 0.3989 - val_loss: 2.9317 - val_accuracy: 0.3107\n",
      "Epoch 33/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.5904 - accuracy: 0.4048 - val_loss: 2.8948 - val_accuracy: 0.3025\n",
      "Epoch 34/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.5607 - accuracy: 0.4095 - val_loss: 2.8858 - val_accuracy: 0.3036\n",
      "Epoch 35/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.5370 - accuracy: 0.3989 - val_loss: 2.8850 - val_accuracy: 0.3154\n",
      "Epoch 36/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.5103 - accuracy: 0.4247 - val_loss: 2.8791 - val_accuracy: 0.3025\n",
      "Epoch 37/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.4762 - accuracy: 0.4204 - val_loss: 2.8483 - val_accuracy: 0.3200\n",
      "Epoch 38/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.4574 - accuracy: 0.4251 - val_loss: 2.8944 - val_accuracy: 0.2814\n",
      "Epoch 39/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.4368 - accuracy: 0.4216 - val_loss: 2.8132 - val_accuracy: 0.3236\n",
      "Epoch 40/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.4204 - accuracy: 0.4357 - val_loss: 2.8085 - val_accuracy: 0.3294\n",
      "Epoch 41/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.3908 - accuracy: 0.4341 - val_loss: 2.8282 - val_accuracy: 0.3212\n",
      "Epoch 42/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.3757 - accuracy: 0.4361 - val_loss: 2.7758 - val_accuracy: 0.3283\n",
      "Epoch 43/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.3523 - accuracy: 0.4501 - val_loss: 2.7997 - val_accuracy: 0.3212\n",
      "Epoch 44/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.3358 - accuracy: 0.4505 - val_loss: 2.7751 - val_accuracy: 0.3306\n",
      "Epoch 45/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.3184 - accuracy: 0.4580 - val_loss: 2.7678 - val_accuracy: 0.3236\n",
      "Epoch 46/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.2922 - accuracy: 0.4564 - val_loss: 2.7532 - val_accuracy: 0.3411\n",
      "Epoch 47/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.2790 - accuracy: 0.4540 - val_loss: 2.7757 - val_accuracy: 0.3294\n",
      "Epoch 48/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.2617 - accuracy: 0.4627 - val_loss: 2.7255 - val_accuracy: 0.3306\n",
      "Epoch 49/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.2471 - accuracy: 0.4724 - val_loss: 2.7612 - val_accuracy: 0.3306\n",
      "Epoch 50/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.2327 - accuracy: 0.4685 - val_loss: 2.7286 - val_accuracy: 0.3341\n",
      "Epoch 51/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.2081 - accuracy: 0.4732 - val_loss: 2.7543 - val_accuracy: 0.3318\n",
      "Epoch 52/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.1967 - accuracy: 0.4767 - val_loss: 2.6864 - val_accuracy: 0.3494\n",
      "Epoch 53/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.1778 - accuracy: 0.4814 - val_loss: 2.6680 - val_accuracy: 0.3646\n",
      "Epoch 54/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.1605 - accuracy: 0.4842 - val_loss: 2.6784 - val_accuracy: 0.3458\n",
      "Epoch 55/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.1482 - accuracy: 0.4869 - val_loss: 2.6778 - val_accuracy: 0.3458\n",
      "Epoch 56/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.1289 - accuracy: 0.4842 - val_loss: 2.6863 - val_accuracy: 0.3505\n",
      "Epoch 57/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.1158 - accuracy: 0.4955 - val_loss: 2.7195 - val_accuracy: 0.3376\n",
      "Epoch 58/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.0992 - accuracy: 0.5025 - val_loss: 2.6999 - val_accuracy: 0.3505\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.0808 - accuracy: 0.4963 - val_loss: 2.6564 - val_accuracy: 0.3669\n",
      "Epoch 60/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.0723 - accuracy: 0.5057 - val_loss: 2.6330 - val_accuracy: 0.3646\n",
      "Epoch 61/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.0624 - accuracy: 0.5053 - val_loss: 2.6518 - val_accuracy: 0.3623\n",
      "Epoch 62/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.0498 - accuracy: 0.5158 - val_loss: 2.6741 - val_accuracy: 0.3540\n",
      "Epoch 63/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.0339 - accuracy: 0.5029 - val_loss: 2.6312 - val_accuracy: 0.3681\n",
      "Epoch 64/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.0186 - accuracy: 0.5123 - val_loss: 2.6320 - val_accuracy: 0.3587\n",
      "Epoch 65/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.0082 - accuracy: 0.5151 - val_loss: 2.6527 - val_accuracy: 0.3599\n",
      "Epoch 66/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.0041 - accuracy: 0.5139 - val_loss: 2.6225 - val_accuracy: 0.3517\n",
      "Epoch 67/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9797 - accuracy: 0.5209 - val_loss: 2.6221 - val_accuracy: 0.3740\n",
      "Epoch 68/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.9757 - accuracy: 0.5162 - val_loss: 2.6333 - val_accuracy: 0.3447\n",
      "Epoch 69/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.9567 - accuracy: 0.5276 - val_loss: 2.6780 - val_accuracy: 0.3552\n",
      "Epoch 70/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.9378 - accuracy: 0.5420 - val_loss: 2.6214 - val_accuracy: 0.3634\n",
      "Epoch 71/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.9349 - accuracy: 0.5264 - val_loss: 2.5941 - val_accuracy: 0.3693\n",
      "Epoch 72/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.9199 - accuracy: 0.5330 - val_loss: 2.6288 - val_accuracy: 0.3634\n",
      "Epoch 73/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.9074 - accuracy: 0.5385 - val_loss: 2.6420 - val_accuracy: 0.3564\n",
      "Epoch 74/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.8956 - accuracy: 0.5440 - val_loss: 2.5801 - val_accuracy: 0.3787\n",
      "Epoch 75/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.8769 - accuracy: 0.5460 - val_loss: 2.6222 - val_accuracy: 0.3693\n",
      "Epoch 76/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.8714 - accuracy: 0.5397 - val_loss: 2.6009 - val_accuracy: 0.3623\n",
      "Epoch 77/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.8620 - accuracy: 0.5460 - val_loss: 2.6238 - val_accuracy: 0.3599\n",
      "Epoch 78/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.8504 - accuracy: 0.5460 - val_loss: 2.5777 - val_accuracy: 0.3740\n",
      "Epoch 79/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.8367 - accuracy: 0.5573 - val_loss: 2.5973 - val_accuracy: 0.3693\n",
      "Epoch 80/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.8248 - accuracy: 0.5581 - val_loss: 2.5970 - val_accuracy: 0.3540\n",
      "Epoch 81/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.8114 - accuracy: 0.5522 - val_loss: 2.5441 - val_accuracy: 0.3857\n",
      "Epoch 82/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.8101 - accuracy: 0.5632 - val_loss: 2.5790 - val_accuracy: 0.3822\n",
      "Epoch 83/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.7915 - accuracy: 0.5620 - val_loss: 2.5928 - val_accuracy: 0.3646\n",
      "Epoch 84/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.7851 - accuracy: 0.5702 - val_loss: 2.5718 - val_accuracy: 0.3646\n",
      "Epoch 85/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.7765 - accuracy: 0.5667 - val_loss: 2.5987 - val_accuracy: 0.3658\n",
      "Epoch 86/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.7607 - accuracy: 0.5643 - val_loss: 2.5907 - val_accuracy: 0.3611\n",
      "Epoch 87/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.7473 - accuracy: 0.5710 - val_loss: 2.6001 - val_accuracy: 0.3669\n",
      "Epoch 88/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.7334 - accuracy: 0.5765 - val_loss: 2.5699 - val_accuracy: 0.3669\n",
      "Epoch 89/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.7341 - accuracy: 0.5772 - val_loss: 2.5240 - val_accuracy: 0.3810\n",
      "Epoch 90/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.7235 - accuracy: 0.5788 - val_loss: 2.5802 - val_accuracy: 0.3705\n",
      "Epoch 91/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.7164 - accuracy: 0.5827 - val_loss: 2.5749 - val_accuracy: 0.3599\n",
      "Epoch 92/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.7023 - accuracy: 0.5804 - val_loss: 2.5802 - val_accuracy: 0.3763\n",
      "Epoch 93/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.6890 - accuracy: 0.5886 - val_loss: 2.5524 - val_accuracy: 0.3669\n",
      "Epoch 94/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.6822 - accuracy: 0.5925 - val_loss: 2.5769 - val_accuracy: 0.3834\n",
      "Epoch 95/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.6709 - accuracy: 0.5866 - val_loss: 2.5459 - val_accuracy: 0.3751\n",
      "Epoch 96/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.6635 - accuracy: 0.5964 - val_loss: 2.5385 - val_accuracy: 0.3728\n",
      "Epoch 97/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.6551 - accuracy: 0.5925 - val_loss: 2.5906 - val_accuracy: 0.3705\n",
      "Epoch 98/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.6472 - accuracy: 0.6023 - val_loss: 2.5407 - val_accuracy: 0.3763\n",
      "Epoch 99/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.6306 - accuracy: 0.6105 - val_loss: 2.5412 - val_accuracy: 0.3716\n",
      "Epoch 100/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.6195 - accuracy: 0.6050 - val_loss: 2.5366 - val_accuracy: 0.4021\n",
      "Epoch 101/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.6143 - accuracy: 0.6089 - val_loss: 2.5119 - val_accuracy: 0.3880\n",
      "Epoch 102/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.6029 - accuracy: 0.6120 - val_loss: 2.6120 - val_accuracy: 0.3576\n",
      "Epoch 103/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.6026 - accuracy: 0.6124 - val_loss: 2.5839 - val_accuracy: 0.3623\n",
      "Epoch 104/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.5811 - accuracy: 0.6179 - val_loss: 2.5457 - val_accuracy: 0.3705\n",
      "Epoch 105/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.5757 - accuracy: 0.6089 - val_loss: 2.5536 - val_accuracy: 0.3658\n",
      "Epoch 106/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.5715 - accuracy: 0.6289 - val_loss: 2.5222 - val_accuracy: 0.3892\n",
      "Epoch 107/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.5649 - accuracy: 0.6253 - val_loss: 2.5622 - val_accuracy: 0.3669\n",
      "Epoch 108/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.5454 - accuracy: 0.6203 - val_loss: 2.5417 - val_accuracy: 0.3751\n",
      "Epoch 109/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.5352 - accuracy: 0.6300 - val_loss: 2.5308 - val_accuracy: 0.3857\n",
      "Epoch 110/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.5322 - accuracy: 0.6226 - val_loss: 2.5482 - val_accuracy: 0.3822\n",
      "Epoch 111/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.5233 - accuracy: 0.6312 - val_loss: 2.5157 - val_accuracy: 0.3904\n",
      "Epoch 112/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.5130 - accuracy: 0.6328 - val_loss: 2.5743 - val_accuracy: 0.3646\n",
      "Epoch 113/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.5093 - accuracy: 0.6379 - val_loss: 2.5326 - val_accuracy: 0.3880\n",
      "Epoch 114/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.4987 - accuracy: 0.6339 - val_loss: 2.5051 - val_accuracy: 0.3810\n",
      "Epoch 115/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.4848 - accuracy: 0.6394 - val_loss: 2.5515 - val_accuracy: 0.3763\n",
      "Epoch 116/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 0s 1ms/step - loss: 1.4801 - accuracy: 0.6390 - val_loss: 2.5525 - val_accuracy: 0.3705\n",
      "Epoch 117/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.4696 - accuracy: 0.6414 - val_loss: 2.5132 - val_accuracy: 0.3892\n",
      "Epoch 118/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.4585 - accuracy: 0.6437 - val_loss: 2.5079 - val_accuracy: 0.3740\n",
      "Epoch 119/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.4584 - accuracy: 0.6476 - val_loss: 2.5949 - val_accuracy: 0.3693\n",
      "Epoch 120/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.4416 - accuracy: 0.6469 - val_loss: 2.5203 - val_accuracy: 0.3927\n",
      "Epoch 121/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.4348 - accuracy: 0.6461 - val_loss: 2.5352 - val_accuracy: 0.3834\n",
      "Epoch 122/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.4263 - accuracy: 0.6562 - val_loss: 2.5212 - val_accuracy: 0.3857\n",
      "Epoch 123/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.4208 - accuracy: 0.6547 - val_loss: 2.5371 - val_accuracy: 0.3751\n",
      "Epoch 124/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.4085 - accuracy: 0.6598 - val_loss: 2.5558 - val_accuracy: 0.3763\n",
      "Epoch 125/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.4007 - accuracy: 0.6551 - val_loss: 2.5634 - val_accuracy: 0.3693\n",
      "Epoch 126/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.3936 - accuracy: 0.6539 - val_loss: 2.5465 - val_accuracy: 0.3834\n",
      "Epoch 127/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.3893 - accuracy: 0.6637 - val_loss: 2.5137 - val_accuracy: 0.3986\n",
      "Epoch 128/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.3758 - accuracy: 0.6578 - val_loss: 2.5291 - val_accuracy: 0.3857\n",
      "Epoch 129/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.3705 - accuracy: 0.6727 - val_loss: 2.5856 - val_accuracy: 0.3693\n",
      "Epoch 130/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.3553 - accuracy: 0.6734 - val_loss: 2.5105 - val_accuracy: 0.3962\n",
      "Epoch 131/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.3559 - accuracy: 0.6754 - val_loss: 2.5299 - val_accuracy: 0.3939\n",
      "Epoch 132/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.3464 - accuracy: 0.6762 - val_loss: 2.5134 - val_accuracy: 0.3892\n",
      "Epoch 133/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.3378 - accuracy: 0.6750 - val_loss: 2.5776 - val_accuracy: 0.3646\n",
      "Epoch 134/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.3289 - accuracy: 0.6864 - val_loss: 2.5083 - val_accuracy: 0.3857\n",
      "Epoch 135/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.3194 - accuracy: 0.6699 - val_loss: 2.5229 - val_accuracy: 0.3904\n",
      "Epoch 136/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.3125 - accuracy: 0.6727 - val_loss: 2.5014 - val_accuracy: 0.3974\n",
      "Epoch 137/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.3076 - accuracy: 0.6871 - val_loss: 2.5368 - val_accuracy: 0.3880\n",
      "Epoch 138/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.3011 - accuracy: 0.6934 - val_loss: 2.4971 - val_accuracy: 0.3962\n",
      "Epoch 139/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.2844 - accuracy: 0.6852 - val_loss: 2.5610 - val_accuracy: 0.3892\n",
      "Epoch 140/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.2846 - accuracy: 0.6887 - val_loss: 2.5355 - val_accuracy: 0.3880\n",
      "Epoch 141/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.2700 - accuracy: 0.6993 - val_loss: 2.5672 - val_accuracy: 0.3787\n",
      "Epoch 142/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.2615 - accuracy: 0.6973 - val_loss: 2.5386 - val_accuracy: 0.3728\n",
      "Epoch 143/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.2654 - accuracy: 0.6981 - val_loss: 2.5273 - val_accuracy: 0.3880\n",
      "Epoch 144/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.2464 - accuracy: 0.7008 - val_loss: 2.5610 - val_accuracy: 0.3834\n",
      "Epoch 145/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.2480 - accuracy: 0.7114 - val_loss: 2.5013 - val_accuracy: 0.3857\n",
      "Epoch 146/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.2270 - accuracy: 0.7141 - val_loss: 2.5328 - val_accuracy: 0.3810\n",
      "Epoch 147/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.2249 - accuracy: 0.7063 - val_loss: 2.5879 - val_accuracy: 0.3728\n",
      "Epoch 148/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.2207 - accuracy: 0.7008 - val_loss: 2.5851 - val_accuracy: 0.3763\n",
      "Epoch 149/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.2160 - accuracy: 0.7114 - val_loss: 2.5429 - val_accuracy: 0.3892\n",
      "Epoch 150/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.2077 - accuracy: 0.7165 - val_loss: 2.5850 - val_accuracy: 0.3857\n",
      "Epoch 151/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.1970 - accuracy: 0.7188 - val_loss: 2.5580 - val_accuracy: 0.3927\n",
      "Epoch 152/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.1888 - accuracy: 0.7176 - val_loss: 2.5282 - val_accuracy: 0.3810\n",
      "Epoch 153/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.1853 - accuracy: 0.7180 - val_loss: 2.5706 - val_accuracy: 0.3869\n",
      "Epoch 154/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.1767 - accuracy: 0.7290 - val_loss: 2.5489 - val_accuracy: 0.3892\n",
      "Epoch 155/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.1679 - accuracy: 0.7270 - val_loss: 2.5322 - val_accuracy: 0.3892\n",
      "Epoch 156/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.1627 - accuracy: 0.7313 - val_loss: 2.5590 - val_accuracy: 0.3916\n",
      "Epoch 157/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.1512 - accuracy: 0.7259 - val_loss: 2.5295 - val_accuracy: 0.3892\n",
      "Epoch 158/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.1476 - accuracy: 0.7309 - val_loss: 2.5387 - val_accuracy: 0.3892\n",
      "Epoch 159/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.1422 - accuracy: 0.7345 - val_loss: 2.5820 - val_accuracy: 0.3763\n",
      "Epoch 160/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.1343 - accuracy: 0.7341 - val_loss: 2.5123 - val_accuracy: 0.4045\n",
      "Epoch 161/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.1263 - accuracy: 0.7333 - val_loss: 2.5070 - val_accuracy: 0.4033\n",
      "Epoch 162/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.1129 - accuracy: 0.7415 - val_loss: 2.5600 - val_accuracy: 0.3880\n",
      "Epoch 163/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.1134 - accuracy: 0.7384 - val_loss: 2.5449 - val_accuracy: 0.3904\n",
      "Epoch 164/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.1056 - accuracy: 0.7391 - val_loss: 2.5383 - val_accuracy: 0.3857\n",
      "Epoch 165/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.0944 - accuracy: 0.7481 - val_loss: 2.5108 - val_accuracy: 0.3916\n",
      "Epoch 166/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.0922 - accuracy: 0.7442 - val_loss: 2.5450 - val_accuracy: 0.3751\n",
      "Epoch 167/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.0899 - accuracy: 0.7419 - val_loss: 2.5546 - val_accuracy: 0.3869\n",
      "Epoch 168/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.0757 - accuracy: 0.7497 - val_loss: 2.5651 - val_accuracy: 0.3927\n",
      "Epoch 169/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.0661 - accuracy: 0.7560 - val_loss: 2.5570 - val_accuracy: 0.3869\n",
      "Epoch 170/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.0634 - accuracy: 0.7446 - val_loss: 2.5231 - val_accuracy: 0.3775\n",
      "Epoch 171/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.0578 - accuracy: 0.7595 - val_loss: 2.5231 - val_accuracy: 0.3916\n",
      "Epoch 172/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.0505 - accuracy: 0.7548 - val_loss: 2.5450 - val_accuracy: 0.3810\n",
      "Epoch 173/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 0s 1ms/step - loss: 1.0443 - accuracy: 0.7575 - val_loss: 2.5473 - val_accuracy: 0.3810\n",
      "Epoch 174/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.0376 - accuracy: 0.7689 - val_loss: 2.5653 - val_accuracy: 0.3845\n",
      "Epoch 175/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.0343 - accuracy: 0.7654 - val_loss: 2.5836 - val_accuracy: 0.3939\n",
      "Epoch 176/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.0191 - accuracy: 0.7673 - val_loss: 2.5516 - val_accuracy: 0.3857\n",
      "Epoch 177/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.0131 - accuracy: 0.7669 - val_loss: 2.5816 - val_accuracy: 0.3927\n",
      "Epoch 178/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.0061 - accuracy: 0.7689 - val_loss: 2.5957 - val_accuracy: 0.3810\n",
      "Epoch 179/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.0087 - accuracy: 0.7646 - val_loss: 2.6407 - val_accuracy: 0.3916\n",
      "Epoch 180/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.9983 - accuracy: 0.7740 - val_loss: 2.5784 - val_accuracy: 0.3798\n",
      "Epoch 181/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.9932 - accuracy: 0.7646 - val_loss: 2.5488 - val_accuracy: 0.3951\n",
      "Epoch 182/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.9794 - accuracy: 0.7818 - val_loss: 2.6057 - val_accuracy: 0.3939\n",
      "Epoch 183/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.9812 - accuracy: 0.7724 - val_loss: 2.6079 - val_accuracy: 0.3728\n",
      "Epoch 184/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.9730 - accuracy: 0.7775 - val_loss: 2.5540 - val_accuracy: 0.3705\n",
      "Epoch 185/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.9612 - accuracy: 0.7794 - val_loss: 2.5599 - val_accuracy: 0.3716\n",
      "Epoch 186/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.9566 - accuracy: 0.7826 - val_loss: 2.5842 - val_accuracy: 0.3845\n",
      "Epoch 187/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.9557 - accuracy: 0.7826 - val_loss: 2.5804 - val_accuracy: 0.3810\n",
      "Epoch 188/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.9509 - accuracy: 0.7849 - val_loss: 2.5698 - val_accuracy: 0.3845\n",
      "Epoch 189/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.9424 - accuracy: 0.7763 - val_loss: 2.5667 - val_accuracy: 0.3822\n",
      "Epoch 190/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.9376 - accuracy: 0.7970 - val_loss: 2.5728 - val_accuracy: 0.3869\n",
      "Epoch 191/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.9295 - accuracy: 0.7951 - val_loss: 2.5632 - val_accuracy: 0.3822\n",
      "Epoch 192/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.9199 - accuracy: 0.7916 - val_loss: 2.6095 - val_accuracy: 0.3951\n",
      "Epoch 193/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.9162 - accuracy: 0.7861 - val_loss: 2.5975 - val_accuracy: 0.3728\n",
      "Epoch 194/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.9039 - accuracy: 0.7974 - val_loss: 2.6058 - val_accuracy: 0.3751\n",
      "Epoch 195/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.8992 - accuracy: 0.8029 - val_loss: 2.6099 - val_accuracy: 0.3939\n",
      "Epoch 196/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.8963 - accuracy: 0.7986 - val_loss: 2.5966 - val_accuracy: 0.3834\n",
      "Epoch 197/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.8909 - accuracy: 0.8025 - val_loss: 2.6315 - val_accuracy: 0.3763\n",
      "Epoch 198/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.8753 - accuracy: 0.8099 - val_loss: 2.6533 - val_accuracy: 0.3775\n",
      "Epoch 199/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.8857 - accuracy: 0.8041 - val_loss: 2.5433 - val_accuracy: 0.3939\n",
      "Epoch 200/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.8709 - accuracy: 0.8103 - val_loss: 2.6049 - val_accuracy: 0.3822\n",
      "Training time: 0:00:23.531346\n"
     ]
    }
   ],
   "source": [
    "t = now()\n",
    "\n",
    "# Compile the model with Optimizer, Loss Function and Metrics\n",
    "opt_1 = keras.optimizers.RMSprop(lr=0.0005)\n",
    "\n",
    "model_1.compile(optimizer=opt_1, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "run_hist_1 = model_1.fit(x_train_flat, y_train, validation_data=(x_test_flat, y_test), epochs=200)\n",
    "\n",
    "print('Training time: %s' % (now() - t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 2.60488224029541\n",
      "Test accuracy: 0.3821805417537689\n"
     ]
    }
   ],
   "source": [
    "score = model_1.evaluate(x_test_flat, y_test, verbose=0)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The full connection neural network perform no better than random forest. The accuray is similar to random forest. We can increase the hidden layers and number of epochs, however the time will increase too."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3 Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set some parameters\n",
    "img_rows, img_cols=x_train.shape[1:]\n",
    "input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "filters = 32\n",
    "pool_size = 2\n",
    "kernel_size = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 40, 1)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = Sequential()\n",
    "\n",
    "model_2.add(Conv2D(32, (3, 4), padding='same',\n",
    "                 input_shape=input_shape))\n",
    "model_2.add(Activation('relu'))\n",
    "model_2.add(Conv2D(32, (3, 4), padding='same',\n",
    "                 input_shape=input_shape))\n",
    "model_2.add(Activation('relu'))\n",
    "model_2.add(MaxPooling2D(pool_size=(3, 4)))\n",
    "model_2.add(Dropout(0.25))\n",
    "\n",
    "model_2.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model_2.add(Activation('relu'))\n",
    "model_2.add(Conv2D(64, (3, 3)))\n",
    "model_2.add(Activation('relu'))\n",
    "model_2.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_2.add(Dropout(0.25))\n",
    "\n",
    "model_2.add(Flatten())\n",
    "model_2.add(Dense(512))\n",
    "model_2.add(Activation('relu'))\n",
    "model_2.add(Dropout(0.5))\n",
    "model_2.add(Dense(num_classes))\n",
    "model_2.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_15 (Conv2D)           (None, 30, 40, 32)        416       \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 30, 40, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 30, 40, 32)        12320     \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 30, 40, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 10, 10, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 10, 10, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 10, 10, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 10, 10, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 8, 8, 64)          36928     \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 62)                31806     \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 62)                0         \n",
      "=================================================================\n",
      "Total params: 624,766\n",
      "Trainable params: 624,766\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "# initiate RMSprop optimizer\n",
    "opt_2 = keras.optimizers.RMSprop(lr=0.0005)\n",
    "\n",
    "# Let's train the model using RMSprop\n",
    "model_2.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt_2,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=x_train.reshape((x_train.shape[0],)+input_shape)\n",
    "x_test=x_test.reshape((x_test.shape[0],)+input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "80/80 [==============================] - 6s 70ms/step - loss: 1.2305 - accuracy: 0.6277 - val_loss: 1.1017 - val_accuracy: 0.6917\n",
      "Epoch 2/30\n",
      "80/80 [==============================] - 5s 67ms/step - loss: 1.1552 - accuracy: 0.6461 - val_loss: 1.0788 - val_accuracy: 0.6917\n",
      "Epoch 3/30\n",
      "80/80 [==============================] - 5s 67ms/step - loss: 1.0053 - accuracy: 0.6899 - val_loss: 1.0149 - val_accuracy: 0.7069\n",
      "Epoch 4/30\n",
      "80/80 [==============================] - 5s 68ms/step - loss: 0.9632 - accuracy: 0.7004 - val_loss: 0.9579 - val_accuracy: 0.7128\n",
      "Epoch 5/30\n",
      "80/80 [==============================] - 6s 72ms/step - loss: 0.8756 - accuracy: 0.7223 - val_loss: 0.9342 - val_accuracy: 0.7280\n",
      "Epoch 6/30\n",
      "80/80 [==============================] - 5s 69ms/step - loss: 0.8299 - accuracy: 0.7368 - val_loss: 0.9239 - val_accuracy: 0.7245\n",
      "Epoch 7/30\n",
      "80/80 [==============================] - 5s 68ms/step - loss: 0.7681 - accuracy: 0.7450 - val_loss: 0.8713 - val_accuracy: 0.7351\n",
      "Epoch 8/30\n",
      "80/80 [==============================] - 5s 69ms/step - loss: 0.7284 - accuracy: 0.7673 - val_loss: 0.8935 - val_accuracy: 0.7444\n",
      "Epoch 9/30\n",
      "80/80 [==============================] - 5s 68ms/step - loss: 0.6816 - accuracy: 0.7888 - val_loss: 0.8722 - val_accuracy: 0.7515\n",
      "Epoch 10/30\n",
      "80/80 [==============================] - 6s 70ms/step - loss: 0.6348 - accuracy: 0.8045 - val_loss: 0.8240 - val_accuracy: 0.7597\n",
      "Epoch 11/30\n",
      "80/80 [==============================] - 6s 71ms/step - loss: 0.5816 - accuracy: 0.8080 - val_loss: 0.9016 - val_accuracy: 0.7339\n",
      "Epoch 12/30\n",
      "80/80 [==============================] - 6s 71ms/step - loss: 0.5470 - accuracy: 0.8162 - val_loss: 0.8006 - val_accuracy: 0.7655\n",
      "Epoch 13/30\n",
      "80/80 [==============================] - 5s 67ms/step - loss: 0.5308 - accuracy: 0.8314 - val_loss: 0.8131 - val_accuracy: 0.7620\n",
      "Epoch 14/30\n",
      "80/80 [==============================] - 5s 68ms/step - loss: 0.5298 - accuracy: 0.8197 - val_loss: 0.7980 - val_accuracy: 0.7585\n",
      "Epoch 15/30\n",
      "80/80 [==============================] - 5s 68ms/step - loss: 0.4866 - accuracy: 0.8346 - val_loss: 0.7957 - val_accuracy: 0.7655\n",
      "Epoch 16/30\n",
      "80/80 [==============================] - 5s 68ms/step - loss: 0.4581 - accuracy: 0.8479 - val_loss: 0.8082 - val_accuracy: 0.7796\n",
      "Epoch 17/30\n",
      "80/80 [==============================] - 5s 68ms/step - loss: 0.4099 - accuracy: 0.8612 - val_loss: 0.8022 - val_accuracy: 0.7644\n",
      "Epoch 18/30\n",
      "80/80 [==============================] - 5s 68ms/step - loss: 0.4255 - accuracy: 0.8557 - val_loss: 0.8055 - val_accuracy: 0.7691\n",
      "Epoch 19/30\n",
      "80/80 [==============================] - 5s 69ms/step - loss: 0.3849 - accuracy: 0.8686 - val_loss: 0.7738 - val_accuracy: 0.7855\n",
      "Epoch 20/30\n",
      "80/80 [==============================] - 5s 68ms/step - loss: 0.3844 - accuracy: 0.8580 - val_loss: 0.7779 - val_accuracy: 0.7737\n",
      "Epoch 21/30\n",
      "80/80 [==============================] - 5s 68ms/step - loss: 0.3500 - accuracy: 0.8827 - val_loss: 0.7604 - val_accuracy: 0.7831\n",
      "Epoch 22/30\n",
      "80/80 [==============================] - 6s 71ms/step - loss: 0.3509 - accuracy: 0.8819 - val_loss: 0.8023 - val_accuracy: 0.7761\n",
      "Epoch 23/30\n",
      "80/80 [==============================] - 6s 70ms/step - loss: 0.3437 - accuracy: 0.8827 - val_loss: 0.7478 - val_accuracy: 0.7878\n",
      "Epoch 24/30\n",
      "80/80 [==============================] - 6s 70ms/step - loss: 0.3078 - accuracy: 0.8882 - val_loss: 0.7946 - val_accuracy: 0.7866\n",
      "Epoch 25/30\n",
      "80/80 [==============================] - 5s 68ms/step - loss: 0.3084 - accuracy: 0.8901 - val_loss: 0.8030 - val_accuracy: 0.7843\n",
      "Epoch 26/30\n",
      "80/80 [==============================] - 6s 69ms/step - loss: 0.2950 - accuracy: 0.8921 - val_loss: 0.8147 - val_accuracy: 0.7691\n",
      "Epoch 27/30\n",
      "80/80 [==============================] - 6s 70ms/step - loss: 0.2802 - accuracy: 0.9042 - val_loss: 0.7880 - val_accuracy: 0.7749\n",
      "Epoch 28/30\n",
      "80/80 [==============================] - 5s 68ms/step - loss: 0.2687 - accuracy: 0.9034 - val_loss: 0.8032 - val_accuracy: 0.7866\n",
      "Epoch 29/30\n",
      "80/80 [==============================] - 5s 69ms/step - loss: 0.2654 - accuracy: 0.9147 - val_loss: 0.8331 - val_accuracy: 0.7866\n",
      "Epoch 30/30\n",
      "80/80 [==============================] - 5s 68ms/step - loss: 0.2674 - accuracy: 0.9081 - val_loss: 0.8297 - val_accuracy: 0.7937\n",
      "Training time: 0:02:47.210564\n"
     ]
    }
   ],
   "source": [
    "t = now()\n",
    "model_2.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=30,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True)\n",
    "print('Training time: %s' % (now() - t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 0.8297411799430847\n",
      "Test accuracy: 0.7936694025993347\n"
     ]
    }
   ],
   "source": [
    "score = model_2.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This task involves in recognizing hand wirtten english characters. There are more than 60 categories. We know that it is more difficult compared to MNIST digit data classification. For example, z may look like 2 or B may look like 8 and so on. \n",
    "From the analysis above, we found that convolution neural network can achieve very high accuracy for image classification. Each pixel can be treated as one feature. The relative location and value of each pixel is very important for image. The final accuracy in test set is close to 80% while the training accuracy is 90%. It indicates there may be some overfitting. This model is still very simple, using deep neural network to build more layers and using dropout regularization may help to achieve higher accuracy.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this course, we learn different deep learning architecture. They are suitable for different task. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
