{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Foundation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras Intro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Keras to build and train neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attributes: (all numeric-valued)\n",
    "   1. Number of times pregnant\n",
    "   2. Plasma glucose concentration a 2 hours in an oral glucose tolerance test\n",
    "   3. Diastolic blood pressure (mm Hg)\n",
    "   4. Triceps skin fold thickness (mm)\n",
    "   5. 2-Hour serum insulin (mu U/ml)\n",
    "   6. Body mass index (weight in kg/(height in m)^2)\n",
    "   7. Diabetes pedigree function\n",
    "   8. Age (years)\n",
    "   9. Class variable (0 or 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_curve,roc_auc_score, roc_curve, accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import Keras objects for Deep Learning\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam,SGD,RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>times_pregnant</th>\n",
       "      <th>glucose_tolerance_test</th>\n",
       "      <th>blood_pressure</th>\n",
       "      <th>skin_thickness</th>\n",
       "      <th>insulin</th>\n",
       "      <th>bmi</th>\n",
       "      <th>pedigree_function</th>\n",
       "      <th>age</th>\n",
       "      <th>has_diabetes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   times_pregnant  glucose_tolerance_test  blood_pressure  skin_thickness  \\\n",
       "0               6                     148              72              35   \n",
       "1               1                      85              66              29   \n",
       "2               8                     183              64               0   \n",
       "3               1                      89              66              23   \n",
       "4               0                     137              40              35   \n",
       "\n",
       "   insulin   bmi  pedigree_function  age  has_diabetes  \n",
       "0        0  33.6              0.627   50             1  \n",
       "1        0  26.6              0.351   31             0  \n",
       "2        0  23.3              0.672   32             1  \n",
       "3       94  28.1              0.167   21             0  \n",
       "4      168  43.1              2.288   33             1  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Load in th data set\n",
    "names = [\"times_pregnant\", \"glucose_tolerance_test\", \"blood_pressure\", \"skin_thickness\", \"insulin\", \n",
    "         \"bmi\", \"pedigree_function\", \"age\", \"has_diabetes\"]\n",
    "\n",
    "diabetes_df=pd.read_csv('data/diabetes.csv', names=names,header=0)\n",
    "diabetes_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768, 9)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=diabetes_df.iloc[:,:-1].values\n",
    "y=diabetes_df['has_diabetes'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train and test(75% and 25%)\n",
    "X_train, X_test, y_train, y_test=train_test_split(X, y, \n",
    "                                                  test_size=0.25,\n",
    "                                                 random_state=11111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3489583333333333"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is about 35% of the patients in this dataset have diabetes, while 65% do not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get baseline performance using Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Train rf model\n",
    "rf_model =RandomForestClassifier(n_estimators=200)\n",
    "rf_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.755\n",
      "roc-auc is 0.828\n"
     ]
    }
   ],
   "source": [
    "## Make prediction on the test set\n",
    "## both \"hard\" prediction and the scores\n",
    "## (percent of trees voting yes)\n",
    "y_pred_class_rf=rf_model.predict(X_test)\n",
    "y_pred_prob_rf=rf_model.predict_proba(X_test)\n",
    "\n",
    "print(\"accuracy is {:.3f}\".format(accuracy_score(y_test, y_pred_class_rf)))\n",
    "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_rf[:,1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_roc(y_test, y_pred, model_name):\n",
    "    fpr, tpr, thr=roc_curve(y_test, y_pred)\n",
    "    fig, ax=plt.subplots(figsize=(8,8))\n",
    "    ax.plot(fpr, tpr, 'k-')\n",
    "    ax.plot([0,1], [0,1], 'k--', linewidth=.5)\n",
    "    ax.grid(True)\n",
    "    ax.set(title='ROC curve for {} on PIMA diabetes problem'.format(model_name),\n",
    "          xlim=[-0.01, 1.01], ylim=[-0.01, 1.01])\n",
    "\n",
    "plot_roc(y_test, y_pred_prob_rf[:,1], 'RF')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a single hidden layer neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the Sequential model to quickly build a neural network.  Our first network will be a single layer network.  We have 8 variables, so we set the input shape to 8.  Let's start by having a single hidden layer with 12 nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "## we normalize the data first\n",
    "## it will aid the numerical stability\n",
    "\n",
    "normalizer=StandardScaler()\n",
    "X_train_norm=normalizer.fit_transform(X_train)\n",
    "X_test_norm=normalizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "## define model\n",
    "## input size is 8dimensional\n",
    "## 1 hidden layer , 12 hidden nodes sigmoid activation\n",
    "## final layer has one node with a sigmoid activation\n",
    "\n",
    "model_1=Sequential()\n",
    "model_1.add(Dense(12, input_shape=(8,), activation='sigmoid'))\n",
    "model_1.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 12)                108       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 121\n",
      "Trainable params: 121\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 576 samples, validate on 192 samples\n",
      "WARNING:tensorflow:From D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/200\n",
      "576/576 [==============================] - 1s 1ms/sample - loss: 0.6524 - acc: 0.6545 - val_loss: 0.6628 - val_acc: 0.6406\n",
      "Epoch 2/200\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.6513 - acc: 0.6545 - val_loss: 0.6616 - val_acc: 0.6406\n",
      "Epoch 3/200\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.6502 - acc: 0.6545 - val_loss: 0.6604 - val_acc: 0.6406\n",
      "Epoch 4/200\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.6492 - acc: 0.6545 - val_loss: 0.6592 - val_acc: 0.6406\n",
      "Epoch 5/200\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.6482 - acc: 0.6545 - val_loss: 0.6580 - val_acc: 0.6406\n",
      "Epoch 6/200\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.6471 - acc: 0.6545 - val_loss: 0.6569 - val_acc: 0.6406\n",
      "Epoch 7/200\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.6461 - acc: 0.6545 - val_loss: 0.6558 - val_acc: 0.6406\n",
      "Epoch 8/200\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.6451 - acc: 0.6545 - val_loss: 0.6547 - val_acc: 0.6406\n",
      "Epoch 9/200\n",
      "576/576 [==============================] - 0s 31us/sample - loss: 0.6441 - acc: 0.6545 - val_loss: 0.6536 - val_acc: 0.6406\n",
      "Epoch 10/200\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.6432 - acc: 0.6545 - val_loss: 0.6526 - val_acc: 0.6406\n",
      "Epoch 11/200\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.6422 - acc: 0.6545 - val_loss: 0.6515 - val_acc: 0.6406\n",
      "Epoch 12/200\n",
      "576/576 [==============================] - 0s 31us/sample - loss: 0.6413 - acc: 0.6545 - val_loss: 0.6505 - val_acc: 0.6406\n",
      "Epoch 13/200\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.6404 - acc: 0.6545 - val_loss: 0.6495 - val_acc: 0.6406\n",
      "Epoch 14/200\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.6395 - acc: 0.6545 - val_loss: 0.6485 - val_acc: 0.6406\n",
      "Epoch 15/200\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.6386 - acc: 0.6545 - val_loss: 0.6475 - val_acc: 0.6406\n",
      "Epoch 16/200\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.6377 - acc: 0.6545 - val_loss: 0.6465 - val_acc: 0.6406\n",
      "Epoch 17/200\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.6368 - acc: 0.6545 - val_loss: 0.6456 - val_acc: 0.6406\n",
      "Epoch 18/200\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.6359 - acc: 0.6545 - val_loss: 0.6446 - val_acc: 0.6406\n",
      "Epoch 19/200\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.6351 - acc: 0.6545 - val_loss: 0.6437 - val_acc: 0.6406\n",
      "Epoch 20/200\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.6342 - acc: 0.6545 - val_loss: 0.6428 - val_acc: 0.6406\n",
      "Epoch 21/200\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.6334 - acc: 0.6545 - val_loss: 0.6419 - val_acc: 0.6406\n",
      "Epoch 22/200\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.6326 - acc: 0.6545 - val_loss: 0.6410 - val_acc: 0.6406\n",
      "Epoch 23/200\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.6317 - acc: 0.6545 - val_loss: 0.6401 - val_acc: 0.6406\n",
      "Epoch 24/200\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.6309 - acc: 0.6545 - val_loss: 0.6392 - val_acc: 0.6406\n",
      "Epoch 25/200\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.6301 - acc: 0.6545 - val_loss: 0.6383 - val_acc: 0.6406\n",
      "Epoch 26/200\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.6293 - acc: 0.6545 - val_loss: 0.6375 - val_acc: 0.6406\n",
      "Epoch 27/200\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.6285 - acc: 0.6545 - val_loss: 0.6366 - val_acc: 0.6406\n",
      "Epoch 28/200\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.6277 - acc: 0.6545 - val_loss: 0.6358 - val_acc: 0.6406\n",
      "Epoch 29/200\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.6269 - acc: 0.6545 - val_loss: 0.6349 - val_acc: 0.6406\n",
      "Epoch 30/200\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.6261 - acc: 0.6545 - val_loss: 0.6341 - val_acc: 0.6406\n",
      "Epoch 31/200\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.6253 - acc: 0.6545 - val_loss: 0.6333 - val_acc: 0.6406\n",
      "Epoch 32/200\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.6246 - acc: 0.6545 - val_loss: 0.6325 - val_acc: 0.6406\n",
      "Epoch 33/200\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.6238 - acc: 0.6545 - val_loss: 0.6317 - val_acc: 0.6406\n",
      "Epoch 34/200\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.5972 - acc: 0.687 - 0s 30us/sample - loss: 0.6230 - acc: 0.6545 - val_loss: 0.6309 - val_acc: 0.6406\n",
      "Epoch 35/200\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.6223 - acc: 0.6545 - val_loss: 0.6301 - val_acc: 0.6406\n",
      "Epoch 36/200\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.6215 - acc: 0.6545 - val_loss: 0.6293 - val_acc: 0.6406\n",
      "Epoch 37/200\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.6208 - acc: 0.6545 - val_loss: 0.6285 - val_acc: 0.6406\n",
      "Epoch 38/200\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.6200 - acc: 0.6545 - val_loss: 0.6277 - val_acc: 0.6406\n",
      "Epoch 39/200\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.6193 - acc: 0.6545 - val_loss: 0.6269 - val_acc: 0.6406\n",
      "Epoch 40/200\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.6186 - acc: 0.6545 - val_loss: 0.6262 - val_acc: 0.6406\n",
      "Epoch 41/200\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.6179 - acc: 0.6545 - val_loss: 0.6254 - val_acc: 0.6406\n",
      "Epoch 42/200\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.6171 - acc: 0.6545 - val_loss: 0.6247 - val_acc: 0.6406\n",
      "Epoch 43/200\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.6164 - acc: 0.6545 - val_loss: 0.6239 - val_acc: 0.6406\n",
      "Epoch 44/200\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.6157 - acc: 0.6545 - val_loss: 0.6232 - val_acc: 0.6406\n",
      "Epoch 45/200\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.6150 - acc: 0.6545 - val_loss: 0.6224 - val_acc: 0.6406\n",
      "Epoch 46/200\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.6143 - acc: 0.6545 - val_loss: 0.6217 - val_acc: 0.6406\n",
      "Epoch 47/200\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.6136 - acc: 0.6545 - val_loss: 0.6210 - val_acc: 0.6406\n",
      "Epoch 48/200\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.6129 - acc: 0.6545 - val_loss: 0.6202 - val_acc: 0.6406\n",
      "Epoch 49/200\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.6123 - acc: 0.6545 - val_loss: 0.6195 - val_acc: 0.6406\n",
      "Epoch 50/200\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.6116 - acc: 0.6545 - val_loss: 0.6188 - val_acc: 0.6406\n",
      "Epoch 51/200\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.6109 - acc: 0.6545 - val_loss: 0.6181 - val_acc: 0.6406\n",
      "Epoch 52/200\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.6102 - acc: 0.6545 - val_loss: 0.6174 - val_acc: 0.6406\n",
      "Epoch 53/200\n",
      "576/576 [==============================] - 0s 31us/sample - loss: 0.6096 - acc: 0.6545 - val_loss: 0.6167 - val_acc: 0.6406\n",
      "Epoch 54/200\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.6088 - acc: 0.6545 - val_loss: 0.6160 - val_acc: 0.6406\n",
      "Epoch 55/200\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.6082 - acc: 0.6545 - val_loss: 0.6153 - val_acc: 0.6406\n",
      "Epoch 56/200\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.6075 - acc: 0.6545 - val_loss: 0.6146 - val_acc: 0.6406\n",
      "Epoch 57/200\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.6069 - acc: 0.6545 - val_loss: 0.6140 - val_acc: 0.6406\n",
      "Epoch 58/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 24us/sample - loss: 0.6062 - acc: 0.6545 - val_loss: 0.6133 - val_acc: 0.6406\n",
      "Epoch 59/200\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.6056 - acc: 0.6545 - val_loss: 0.6126 - val_acc: 0.6406\n",
      "Epoch 60/200\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.6050 - acc: 0.6545 - val_loss: 0.6119 - val_acc: 0.6406\n",
      "Epoch 61/200\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.6043 - acc: 0.6545 - val_loss: 0.6113 - val_acc: 0.6406\n",
      "Epoch 62/200\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.6036 - acc: 0.6545 - val_loss: 0.6106 - val_acc: 0.6406\n",
      "Epoch 63/200\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.6030 - acc: 0.6545 - val_loss: 0.6100 - val_acc: 0.6406\n",
      "Epoch 64/200\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.6024 - acc: 0.6545 - val_loss: 0.6093 - val_acc: 0.6406\n",
      "Epoch 65/200\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.6018 - acc: 0.6545 - val_loss: 0.6087 - val_acc: 0.6406\n",
      "Epoch 66/200\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.6011 - acc: 0.6545 - val_loss: 0.6080 - val_acc: 0.6406\n",
      "Epoch 67/200\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.6005 - acc: 0.6545 - val_loss: 0.6074 - val_acc: 0.6406\n",
      "Epoch 68/200\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.5999 - acc: 0.6545 - val_loss: 0.6067 - val_acc: 0.6406\n",
      "Epoch 69/200\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.5993 - acc: 0.6562 - val_loss: 0.6061 - val_acc: 0.6406\n",
      "Epoch 70/200\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.5987 - acc: 0.6562 - val_loss: 0.6055 - val_acc: 0.6406\n",
      "Epoch 71/200\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.5981 - acc: 0.6562 - val_loss: 0.6049 - val_acc: 0.6406\n",
      "Epoch 72/200\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.5975 - acc: 0.6562 - val_loss: 0.6042 - val_acc: 0.6406\n",
      "Epoch 73/200\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.5968 - acc: 0.6562 - val_loss: 0.6036 - val_acc: 0.6406\n",
      "Epoch 74/200\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.5963 - acc: 0.6580 - val_loss: 0.6030 - val_acc: 0.6406\n",
      "Epoch 75/200\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.5957 - acc: 0.6580 - val_loss: 0.6024 - val_acc: 0.6406\n",
      "Epoch 76/200\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.5951 - acc: 0.6597 - val_loss: 0.6018 - val_acc: 0.6406\n",
      "Epoch 77/200\n",
      "576/576 [==============================] - 0s 31us/sample - loss: 0.5945 - acc: 0.6580 - val_loss: 0.6012 - val_acc: 0.6406\n",
      "Epoch 78/200\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.5939 - acc: 0.6597 - val_loss: 0.6006 - val_acc: 0.6406\n",
      "Epoch 79/200\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.5933 - acc: 0.6597 - val_loss: 0.6000 - val_acc: 0.6406\n",
      "Epoch 80/200\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.5927 - acc: 0.6597 - val_loss: 0.5994 - val_acc: 0.6406\n",
      "Epoch 81/200\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.5922 - acc: 0.6597 - val_loss: 0.5988 - val_acc: 0.6406\n",
      "Epoch 82/200\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.5916 - acc: 0.6597 - val_loss: 0.5982 - val_acc: 0.6406\n",
      "Epoch 83/200\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.5911 - acc: 0.6597 - val_loss: 0.5976 - val_acc: 0.6406\n",
      "Epoch 84/200\n",
      "576/576 [==============================] - 0s 31us/sample - loss: 0.5905 - acc: 0.6597 - val_loss: 0.5971 - val_acc: 0.6406\n",
      "Epoch 85/200\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.5899 - acc: 0.6615 - val_loss: 0.5965 - val_acc: 0.6354\n",
      "Epoch 86/200\n",
      "576/576 [==============================] - 0s 35us/sample - loss: 0.5893 - acc: 0.6615 - val_loss: 0.5959 - val_acc: 0.6354\n",
      "Epoch 87/200\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.5888 - acc: 0.6632 - val_loss: 0.5953 - val_acc: 0.6354\n",
      "Epoch 88/200\n",
      "576/576 [==============================] - 0s 36us/sample - loss: 0.5882 - acc: 0.6632 - val_loss: 0.5948 - val_acc: 0.6354\n",
      "Epoch 89/200\n",
      "576/576 [==============================] - 0s 31us/sample - loss: 0.5877 - acc: 0.6632 - val_loss: 0.5942 - val_acc: 0.6354\n",
      "Epoch 90/200\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.5871 - acc: 0.6632 - val_loss: 0.5937 - val_acc: 0.6354\n",
      "Epoch 91/200\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.5866 - acc: 0.6649 - val_loss: 0.5931 - val_acc: 0.6354\n",
      "Epoch 92/200\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.5860 - acc: 0.6684 - val_loss: 0.5925 - val_acc: 0.6406\n",
      "Epoch 93/200\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.5855 - acc: 0.6684 - val_loss: 0.5920 - val_acc: 0.6406\n",
      "Epoch 94/200\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.5850 - acc: 0.6684 - val_loss: 0.5914 - val_acc: 0.6406\n",
      "Epoch 95/200\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.5844 - acc: 0.6684 - val_loss: 0.5909 - val_acc: 0.6458\n",
      "Epoch 96/200\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.5839 - acc: 0.6701 - val_loss: 0.5904 - val_acc: 0.6458\n",
      "Epoch 97/200\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.5834 - acc: 0.6701 - val_loss: 0.5898 - val_acc: 0.6458\n",
      "Epoch 98/200\n",
      "576/576 [==============================] - 0s 23us/sample - loss: 0.5828 - acc: 0.6701 - val_loss: 0.5893 - val_acc: 0.6458\n",
      "Epoch 99/200\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.5823 - acc: 0.6719 - val_loss: 0.5887 - val_acc: 0.6458\n",
      "Epoch 100/200\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.5818 - acc: 0.6701 - val_loss: 0.5882 - val_acc: 0.6458\n",
      "Epoch 101/200\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.5812 - acc: 0.6701 - val_loss: 0.5877 - val_acc: 0.6458\n",
      "Epoch 102/200\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.5807 - acc: 0.6719 - val_loss: 0.5872 - val_acc: 0.6615\n",
      "Epoch 103/200\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.5802 - acc: 0.6736 - val_loss: 0.5866 - val_acc: 0.6615\n",
      "Epoch 104/200\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.5797 - acc: 0.6736 - val_loss: 0.5861 - val_acc: 0.6615\n",
      "Epoch 105/200\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.5792 - acc: 0.6753 - val_loss: 0.5856 - val_acc: 0.6771\n",
      "Epoch 106/200\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.5787 - acc: 0.6771 - val_loss: 0.5851 - val_acc: 0.6771\n",
      "Epoch 107/200\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.5782 - acc: 0.6771 - val_loss: 0.5846 - val_acc: 0.6771\n",
      "Epoch 108/200\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.5777 - acc: 0.6788 - val_loss: 0.5841 - val_acc: 0.6771\n",
      "Epoch 109/200\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.5772 - acc: 0.6771 - val_loss: 0.5835 - val_acc: 0.6823\n",
      "Epoch 110/200\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.5767 - acc: 0.6771 - val_loss: 0.5830 - val_acc: 0.6823\n",
      "Epoch 111/200\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.5762 - acc: 0.6788 - val_loss: 0.5825 - val_acc: 0.6823\n",
      "Epoch 112/200\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.5757 - acc: 0.6788 - val_loss: 0.5820 - val_acc: 0.6823\n",
      "Epoch 113/200\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.5752 - acc: 0.6806 - val_loss: 0.5815 - val_acc: 0.6823\n",
      "Epoch 114/200\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.5747 - acc: 0.6806 - val_loss: 0.5810 - val_acc: 0.6823\n",
      "Epoch 115/200\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.5742 - acc: 0.6823 - val_loss: 0.5806 - val_acc: 0.6823\n",
      "Epoch 116/200\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.5737 - acc: 0.6823 - val_loss: 0.5801 - val_acc: 0.6875\n",
      "Epoch 117/200\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.5733 - acc: 0.6840 - val_loss: 0.5796 - val_acc: 0.6875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 118/200\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.5728 - acc: 0.6892 - val_loss: 0.5791 - val_acc: 0.6875\n",
      "Epoch 119/200\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.5723 - acc: 0.6927 - val_loss: 0.5786 - val_acc: 0.6875\n",
      "Epoch 120/200\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.5718 - acc: 0.6962 - val_loss: 0.5781 - val_acc: 0.6875\n",
      "Epoch 121/200\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.5714 - acc: 0.6979 - val_loss: 0.5777 - val_acc: 0.6875\n",
      "Epoch 122/200\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.5709 - acc: 0.6979 - val_loss: 0.5772 - val_acc: 0.6875\n",
      "Epoch 123/200\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.5704 - acc: 0.6962 - val_loss: 0.5767 - val_acc: 0.6875\n",
      "Epoch 124/200\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.5700 - acc: 0.6944 - val_loss: 0.5762 - val_acc: 0.6875\n",
      "Epoch 125/200\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.5695 - acc: 0.6944 - val_loss: 0.5758 - val_acc: 0.6875\n",
      "Epoch 126/200\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.5690 - acc: 0.6944 - val_loss: 0.5753 - val_acc: 0.6979\n",
      "Epoch 127/200\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.5686 - acc: 0.6944 - val_loss: 0.5748 - val_acc: 0.6979\n",
      "Epoch 128/200\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.5681 - acc: 0.6944 - val_loss: 0.5744 - val_acc: 0.6979\n",
      "Epoch 129/200\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.5676 - acc: 0.6944 - val_loss: 0.5739 - val_acc: 0.6979\n",
      "Epoch 130/200\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.5672 - acc: 0.6944 - val_loss: 0.5735 - val_acc: 0.6979\n",
      "Epoch 131/200\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.5667 - acc: 0.6944 - val_loss: 0.5730 - val_acc: 0.6979\n",
      "Epoch 132/200\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.5663 - acc: 0.6927 - val_loss: 0.5726 - val_acc: 0.7031\n",
      "Epoch 133/200\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.5659 - acc: 0.6979 - val_loss: 0.5721 - val_acc: 0.7031\n",
      "Epoch 134/200\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.5654 - acc: 0.6979 - val_loss: 0.5717 - val_acc: 0.7031\n",
      "Epoch 135/200\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.5650 - acc: 0.6997 - val_loss: 0.5712 - val_acc: 0.7031\n",
      "Epoch 136/200\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.5645 - acc: 0.7049 - val_loss: 0.5708 - val_acc: 0.7031\n",
      "Epoch 137/200\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.5641 - acc: 0.7066 - val_loss: 0.5703 - val_acc: 0.7031\n",
      "Epoch 138/200\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.5637 - acc: 0.7066 - val_loss: 0.5699 - val_acc: 0.6979\n",
      "Epoch 139/200\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.5632 - acc: 0.7066 - val_loss: 0.5695 - val_acc: 0.7031\n",
      "Epoch 140/200\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.5628 - acc: 0.7083 - val_loss: 0.5690 - val_acc: 0.7031\n",
      "Epoch 141/200\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.5624 - acc: 0.7083 - val_loss: 0.5686 - val_acc: 0.7135\n",
      "Epoch 142/200\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.5620 - acc: 0.7083 - val_loss: 0.5682 - val_acc: 0.7135\n",
      "Epoch 143/200\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.5615 - acc: 0.7083 - val_loss: 0.5678 - val_acc: 0.7135\n",
      "Epoch 144/200\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.5611 - acc: 0.7083 - val_loss: 0.5673 - val_acc: 0.7135\n",
      "Epoch 145/200\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.5606 - acc: 0.7083 - val_loss: 0.5669 - val_acc: 0.7135\n",
      "Epoch 146/200\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.5602 - acc: 0.7083 - val_loss: 0.5665 - val_acc: 0.7188\n",
      "Epoch 147/200\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.5598 - acc: 0.7083 - val_loss: 0.5661 - val_acc: 0.7188\n",
      "Epoch 148/200\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.5594 - acc: 0.7083 - val_loss: 0.5657 - val_acc: 0.7188\n",
      "Epoch 149/200\n",
      "576/576 [==============================] - 0s 31us/sample - loss: 0.5590 - acc: 0.7101 - val_loss: 0.5652 - val_acc: 0.7188\n",
      "Epoch 150/200\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.5585 - acc: 0.7101 - val_loss: 0.5648 - val_acc: 0.7188\n",
      "Epoch 151/200\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.5581 - acc: 0.7101 - val_loss: 0.5644 - val_acc: 0.7188\n",
      "Epoch 152/200\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.5577 - acc: 0.7118 - val_loss: 0.5640 - val_acc: 0.7188\n",
      "Epoch 153/200\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.5573 - acc: 0.7118 - val_loss: 0.5636 - val_acc: 0.7188\n",
      "Epoch 154/200\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.5569 - acc: 0.7101 - val_loss: 0.5632 - val_acc: 0.7188\n",
      "Epoch 155/200\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.5565 - acc: 0.7101 - val_loss: 0.5628 - val_acc: 0.7188\n",
      "Epoch 156/200\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.5561 - acc: 0.7101 - val_loss: 0.5624 - val_acc: 0.7188\n",
      "Epoch 157/200\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.5557 - acc: 0.7118 - val_loss: 0.5620 - val_acc: 0.7135\n",
      "Epoch 158/200\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.5553 - acc: 0.7135 - val_loss: 0.5616 - val_acc: 0.7135\n",
      "Epoch 159/200\n",
      "576/576 [==============================] - 0s 23us/sample - loss: 0.5549 - acc: 0.7135 - val_loss: 0.5612 - val_acc: 0.7135\n",
      "Epoch 160/200\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.5545 - acc: 0.7153 - val_loss: 0.5608 - val_acc: 0.7135\n",
      "Epoch 161/200\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.5541 - acc: 0.7170 - val_loss: 0.5604 - val_acc: 0.7188\n",
      "Epoch 162/200\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.5537 - acc: 0.7153 - val_loss: 0.5600 - val_acc: 0.7188\n",
      "Epoch 163/200\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.5533 - acc: 0.7153 - val_loss: 0.5597 - val_acc: 0.7188\n",
      "Epoch 164/200\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.5529 - acc: 0.7153 - val_loss: 0.5593 - val_acc: 0.7188\n",
      "Epoch 165/200\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.5526 - acc: 0.7205 - val_loss: 0.5589 - val_acc: 0.7188\n",
      "Epoch 166/200\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.5522 - acc: 0.7170 - val_loss: 0.5585 - val_acc: 0.7240\n",
      "Epoch 167/200\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.5518 - acc: 0.7170 - val_loss: 0.5581 - val_acc: 0.7240\n",
      "Epoch 168/200\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.5514 - acc: 0.7170 - val_loss: 0.5578 - val_acc: 0.7240\n",
      "Epoch 169/200\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.5510 - acc: 0.7153 - val_loss: 0.5574 - val_acc: 0.7240\n",
      "Epoch 170/200\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.5507 - acc: 0.7153 - val_loss: 0.5570 - val_acc: 0.7240\n",
      "Epoch 171/200\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.5503 - acc: 0.7153 - val_loss: 0.5566 - val_acc: 0.7240\n",
      "Epoch 172/200\n",
      "576/576 [==============================] - 0s 23us/sample - loss: 0.5499 - acc: 0.7153 - val_loss: 0.5563 - val_acc: 0.7240\n",
      "Epoch 173/200\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.5495 - acc: 0.7153 - val_loss: 0.5559 - val_acc: 0.7240\n",
      "Epoch 174/200\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.5491 - acc: 0.7135 - val_loss: 0.5555 - val_acc: 0.7240\n",
      "Epoch 175/200\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.5488 - acc: 0.7135 - val_loss: 0.5552 - val_acc: 0.7240\n",
      "Epoch 176/200\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.5484 - acc: 0.7135 - val_loss: 0.5548 - val_acc: 0.7240\n",
      "Epoch 177/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 24us/sample - loss: 0.5480 - acc: 0.7135 - val_loss: 0.5545 - val_acc: 0.7240\n",
      "Epoch 178/200\n",
      "576/576 [==============================] - 0s 23us/sample - loss: 0.5477 - acc: 0.7188 - val_loss: 0.5541 - val_acc: 0.7240\n",
      "Epoch 179/200\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.5473 - acc: 0.7188 - val_loss: 0.5537 - val_acc: 0.7240\n",
      "Epoch 180/200\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.5470 - acc: 0.7205 - val_loss: 0.5534 - val_acc: 0.7240\n",
      "Epoch 181/200\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.5466 - acc: 0.7205 - val_loss: 0.5530 - val_acc: 0.7240\n",
      "Epoch 182/200\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.5462 - acc: 0.7205 - val_loss: 0.5527 - val_acc: 0.7240\n",
      "Epoch 183/200\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.5459 - acc: 0.7222 - val_loss: 0.5523 - val_acc: 0.7240\n",
      "Epoch 184/200\n",
      "576/576 [==============================] - 0s 23us/sample - loss: 0.5455 - acc: 0.7222 - val_loss: 0.5520 - val_acc: 0.7240\n",
      "Epoch 185/200\n",
      "576/576 [==============================] - 0s 23us/sample - loss: 0.5452 - acc: 0.7222 - val_loss: 0.5516 - val_acc: 0.7240\n",
      "Epoch 186/200\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.5448 - acc: 0.7222 - val_loss: 0.5513 - val_acc: 0.7240\n",
      "Epoch 187/200\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.5444 - acc: 0.7240 - val_loss: 0.5510 - val_acc: 0.7240\n",
      "Epoch 188/200\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.5441 - acc: 0.7240 - val_loss: 0.5506 - val_acc: 0.7292\n",
      "Epoch 189/200\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.5438 - acc: 0.7240 - val_loss: 0.5503 - val_acc: 0.7292\n",
      "Epoch 190/200\n",
      "576/576 [==============================] - 0s 23us/sample - loss: 0.5434 - acc: 0.7257 - val_loss: 0.5499 - val_acc: 0.7292\n",
      "Epoch 191/200\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.5430 - acc: 0.7274 - val_loss: 0.5496 - val_acc: 0.7344\n",
      "Epoch 192/200\n",
      "576/576 [==============================] - 0s 23us/sample - loss: 0.5427 - acc: 0.7257 - val_loss: 0.5493 - val_acc: 0.7344\n",
      "Epoch 193/200\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.5424 - acc: 0.7257 - val_loss: 0.5489 - val_acc: 0.7344\n",
      "Epoch 194/200\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.5420 - acc: 0.7257 - val_loss: 0.5486 - val_acc: 0.7344\n",
      "Epoch 195/200\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.5417 - acc: 0.7257 - val_loss: 0.5483 - val_acc: 0.7344\n",
      "Epoch 196/200\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.5413 - acc: 0.7257 - val_loss: 0.5480 - val_acc: 0.7344\n",
      "Epoch 197/200\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.5410 - acc: 0.7257 - val_loss: 0.5476 - val_acc: 0.7396\n",
      "Epoch 198/200\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.5407 - acc: 0.7257 - val_loss: 0.5473 - val_acc: 0.7396\n",
      "Epoch 199/200\n",
      "576/576 [==============================] - 0s 23us/sample - loss: 0.5403 - acc: 0.7257 - val_loss: 0.5470 - val_acc: 0.7500\n",
      "Epoch 200/200\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.5400 - acc: 0.7292 - val_loss: 0.5467 - val_acc: 0.7500\n"
     ]
    }
   ],
   "source": [
    "## Fit the model\n",
    "model_1.compile(SGD(lr=.003), \"binary_crossentropy\", \n",
    "                 metrics=[\"accuracy\"])\n",
    "run_hist_1=model_1.fit(X_train_norm, y_train, \n",
    "                       validation_data=(X_test_norm, y_test),\n",
    "                      epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Like we did for the Random Forest, we generate two kinds of prediction\n",
    "## One is hard prediction\n",
    "## the other is a probabilstic score\n",
    "\n",
    "y_pred_class_nn_1=model_1.predict_classes(X_test_norm)\n",
    "y_pred_prob_nn_1=model_1.predict(X_test_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_class_nn_1[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.37534937],\n",
       "       [0.5007908 ],\n",
       "       [0.27101666],\n",
       "       [0.2614464 ],\n",
       "       [0.24968278],\n",
       "       [0.4893297 ],\n",
       "       [0.22519344],\n",
       "       [0.298941  ],\n",
       "       [0.5698062 ],\n",
       "       [0.32869005]], dtype=float32)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_prob_nn_1[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.750\n",
      "roc-auc is 0.811\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print model performance and plot the roc curve\n",
    "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_nn_1)))\n",
    "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_nn_1)))\n",
    "\n",
    "plot_roc(y_test, y_pred_prob_nn_1, 'NN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'acc', 'val_loss', 'val_acc'])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_hist_1.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x19c37588>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(run_hist_1.history[\"loss\"],'r', marker='.', label=\"Train Loss\")\n",
    "ax.plot(run_hist_1.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 576 samples, validate on 192 samples\n",
      "Epoch 1/1000\n",
      "576/576 [==============================] - 0s 61us/sample - loss: 0.5397 - acc: 0.7326 - val_loss: 0.5463 - val_acc: 0.7500\n",
      "Epoch 2/1000\n",
      "576/576 [==============================] - 0s 35us/sample - loss: 0.5394 - acc: 0.7344 - val_loss: 0.5460 - val_acc: 0.7500\n",
      "Epoch 3/1000\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.5390 - acc: 0.7344 - val_loss: 0.5457 - val_acc: 0.7500\n",
      "Epoch 4/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.5387 - acc: 0.7344 - val_loss: 0.5454 - val_acc: 0.7448\n",
      "Epoch 5/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.5384 - acc: 0.7344 - val_loss: 0.5451 - val_acc: 0.7448\n",
      "Epoch 6/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.5380 - acc: 0.7361 - val_loss: 0.5448 - val_acc: 0.7500\n",
      "Epoch 7/1000\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.5377 - acc: 0.7361 - val_loss: 0.5445 - val_acc: 0.7500\n",
      "Epoch 8/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.5374 - acc: 0.7361 - val_loss: 0.5441 - val_acc: 0.7552\n",
      "Epoch 9/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.5371 - acc: 0.7396 - val_loss: 0.5438 - val_acc: 0.7552\n",
      "Epoch 10/1000\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.5368 - acc: 0.7396 - val_loss: 0.5435 - val_acc: 0.7552\n",
      "Epoch 11/1000\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.5364 - acc: 0.7396 - val_loss: 0.5432 - val_acc: 0.7552\n",
      "Epoch 12/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.5361 - acc: 0.7396 - val_loss: 0.5429 - val_acc: 0.7552\n",
      "Epoch 13/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.5358 - acc: 0.7396 - val_loss: 0.5426 - val_acc: 0.7552\n",
      "Epoch 14/1000\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.5355 - acc: 0.7396 - val_loss: 0.5423 - val_acc: 0.7552\n",
      "Epoch 15/1000\n",
      "576/576 [==============================] - 0s 31us/sample - loss: 0.5352 - acc: 0.7396 - val_loss: 0.5420 - val_acc: 0.7552\n",
      "Epoch 16/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.5349 - acc: 0.7396 - val_loss: 0.5417 - val_acc: 0.7552\n",
      "Epoch 17/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.5346 - acc: 0.7396 - val_loss: 0.5414 - val_acc: 0.7552\n",
      "Epoch 18/1000\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.5342 - acc: 0.7396 - val_loss: 0.5411 - val_acc: 0.7552\n",
      "Epoch 19/1000\n",
      "576/576 [==============================] - 0s 31us/sample - loss: 0.5340 - acc: 0.7396 - val_loss: 0.5409 - val_acc: 0.7552\n",
      "Epoch 20/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.5336 - acc: 0.7396 - val_loss: 0.5406 - val_acc: 0.7552\n",
      "Epoch 21/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.5333 - acc: 0.7396 - val_loss: 0.5403 - val_acc: 0.7552\n",
      "Epoch 22/1000\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.5330 - acc: 0.7396 - val_loss: 0.5400 - val_acc: 0.7552\n",
      "Epoch 23/1000\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.5327 - acc: 0.7396 - val_loss: 0.5397 - val_acc: 0.7552\n",
      "Epoch 24/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.5324 - acc: 0.7413 - val_loss: 0.5394 - val_acc: 0.7552\n",
      "Epoch 25/1000\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.5321 - acc: 0.7431 - val_loss: 0.5391 - val_acc: 0.7552\n",
      "Epoch 26/1000\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.5318 - acc: 0.7448 - val_loss: 0.5389 - val_acc: 0.7552\n",
      "Epoch 27/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.5315 - acc: 0.7483 - val_loss: 0.5386 - val_acc: 0.7552\n",
      "Epoch 28/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.5312 - acc: 0.7483 - val_loss: 0.5383 - val_acc: 0.7604\n",
      "Epoch 29/1000\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.5309 - acc: 0.7465 - val_loss: 0.5380 - val_acc: 0.7604\n",
      "Epoch 30/1000\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.5307 - acc: 0.7465 - val_loss: 0.5377 - val_acc: 0.7604\n",
      "Epoch 31/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.5304 - acc: 0.7465 - val_loss: 0.5375 - val_acc: 0.7604\n",
      "Epoch 32/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.5301 - acc: 0.7483 - val_loss: 0.5372 - val_acc: 0.7656\n",
      "Epoch 33/1000\n",
      "576/576 [==============================] - 0s 33us/sample - loss: 0.5298 - acc: 0.7465 - val_loss: 0.5369 - val_acc: 0.7656\n",
      "Epoch 34/1000\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.5295 - acc: 0.7483 - val_loss: 0.5366 - val_acc: 0.7656\n",
      "Epoch 35/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.5292 - acc: 0.7483 - val_loss: 0.5364 - val_acc: 0.7656\n",
      "Epoch 36/1000\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.5289 - acc: 0.7483 - val_loss: 0.5361 - val_acc: 0.7656\n",
      "Epoch 37/1000\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.5286 - acc: 0.7500 - val_loss: 0.5358 - val_acc: 0.7656\n",
      "Epoch 38/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.5283 - acc: 0.7517 - val_loss: 0.5356 - val_acc: 0.7656\n",
      "Epoch 39/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.5281 - acc: 0.7517 - val_loss: 0.5353 - val_acc: 0.7656\n",
      "Epoch 40/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.5278 - acc: 0.7517 - val_loss: 0.5351 - val_acc: 0.7656\n",
      "Epoch 41/1000\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.5275 - acc: 0.7500 - val_loss: 0.5348 - val_acc: 0.7604\n",
      "Epoch 42/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.5272 - acc: 0.7517 - val_loss: 0.5345 - val_acc: 0.7604\n",
      "Epoch 43/1000\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.5270 - acc: 0.7517 - val_loss: 0.5343 - val_acc: 0.7604\n",
      "Epoch 44/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.5267 - acc: 0.7517 - val_loss: 0.5340 - val_acc: 0.7604\n",
      "Epoch 45/1000\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.5264 - acc: 0.7517 - val_loss: 0.5338 - val_acc: 0.7604\n",
      "Epoch 46/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.5261 - acc: 0.7517 - val_loss: 0.5335 - val_acc: 0.7656\n",
      "Epoch 47/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.5259 - acc: 0.7517 - val_loss: 0.5333 - val_acc: 0.7656\n",
      "Epoch 48/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.5256 - acc: 0.7517 - val_loss: 0.5330 - val_acc: 0.7656\n",
      "Epoch 49/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.5253 - acc: 0.7500 - val_loss: 0.5327 - val_acc: 0.7656\n",
      "Epoch 50/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.5250 - acc: 0.7500 - val_loss: 0.5325 - val_acc: 0.7656\n",
      "Epoch 51/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.5248 - acc: 0.7500 - val_loss: 0.5322 - val_acc: 0.7656\n",
      "Epoch 52/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.5245 - acc: 0.7500 - val_loss: 0.5320 - val_acc: 0.7656\n",
      "Epoch 53/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.5242 - acc: 0.7500 - val_loss: 0.5318 - val_acc: 0.7656\n",
      "Epoch 54/1000\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.5240 - acc: 0.7500 - val_loss: 0.5315 - val_acc: 0.7656\n",
      "Epoch 55/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.5237 - acc: 0.7517 - val_loss: 0.5313 - val_acc: 0.7708\n",
      "Epoch 56/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.5234 - acc: 0.7517 - val_loss: 0.5310 - val_acc: 0.7708\n",
      "Epoch 57/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.5232 - acc: 0.7517 - val_loss: 0.5308 - val_acc: 0.7708\n",
      "Epoch 58/1000\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.5229 - acc: 0.7500 - val_loss: 0.5305 - val_acc: 0.7708\n",
      "Epoch 59/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.5227 - acc: 0.7517 - val_loss: 0.5303 - val_acc: 0.7708\n",
      "Epoch 60/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 30us/sample - loss: 0.5224 - acc: 0.7535 - val_loss: 0.5301 - val_acc: 0.7708\n",
      "Epoch 61/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.5221 - acc: 0.7500 - val_loss: 0.5298 - val_acc: 0.7708\n",
      "Epoch 62/1000\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.5219 - acc: 0.7535 - val_loss: 0.5296 - val_acc: 0.7708\n",
      "Epoch 63/1000\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.5216 - acc: 0.7535 - val_loss: 0.5294 - val_acc: 0.7708\n",
      "Epoch 64/1000\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.5214 - acc: 0.7535 - val_loss: 0.5291 - val_acc: 0.7760\n",
      "Epoch 65/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.5211 - acc: 0.7535 - val_loss: 0.5289 - val_acc: 0.7760\n",
      "Epoch 66/1000\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.5209 - acc: 0.7535 - val_loss: 0.5287 - val_acc: 0.7760\n",
      "Epoch 67/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.5206 - acc: 0.7535 - val_loss: 0.5284 - val_acc: 0.7760\n",
      "Epoch 68/1000\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.5204 - acc: 0.7517 - val_loss: 0.5282 - val_acc: 0.7760\n",
      "Epoch 69/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.5201 - acc: 0.7552 - val_loss: 0.5280 - val_acc: 0.7760\n",
      "Epoch 70/1000\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.5199 - acc: 0.7552 - val_loss: 0.5278 - val_acc: 0.7760\n",
      "Epoch 71/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.5196 - acc: 0.7552 - val_loss: 0.5275 - val_acc: 0.7760\n",
      "Epoch 72/1000\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.5194 - acc: 0.7535 - val_loss: 0.5273 - val_acc: 0.7760\n",
      "Epoch 73/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.5191 - acc: 0.7535 - val_loss: 0.5271 - val_acc: 0.7760\n",
      "Epoch 74/1000\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.5189 - acc: 0.7535 - val_loss: 0.5269 - val_acc: 0.7760\n",
      "Epoch 75/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.5186 - acc: 0.7552 - val_loss: 0.5266 - val_acc: 0.7760\n",
      "Epoch 76/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.5184 - acc: 0.7552 - val_loss: 0.5264 - val_acc: 0.7760\n",
      "Epoch 77/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.5182 - acc: 0.7552 - val_loss: 0.5262 - val_acc: 0.7760\n",
      "Epoch 78/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.5179 - acc: 0.7552 - val_loss: 0.5260 - val_acc: 0.7760\n",
      "Epoch 79/1000\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.5177 - acc: 0.7569 - val_loss: 0.5258 - val_acc: 0.7760\n",
      "Epoch 80/1000\n",
      "576/576 [==============================] - 0s 23us/sample - loss: 0.5175 - acc: 0.7587 - val_loss: 0.5256 - val_acc: 0.7760\n",
      "Epoch 81/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.5172 - acc: 0.7552 - val_loss: 0.5254 - val_acc: 0.7760\n",
      "Epoch 82/1000\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.5170 - acc: 0.7587 - val_loss: 0.5251 - val_acc: 0.7760\n",
      "Epoch 83/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.5168 - acc: 0.7587 - val_loss: 0.5249 - val_acc: 0.7812\n",
      "Epoch 84/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.5165 - acc: 0.7587 - val_loss: 0.5247 - val_acc: 0.7812\n",
      "Epoch 85/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.5163 - acc: 0.7587 - val_loss: 0.5245 - val_acc: 0.7812\n",
      "Epoch 86/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.5160 - acc: 0.7587 - val_loss: 0.5243 - val_acc: 0.7812\n",
      "Epoch 87/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.5158 - acc: 0.7569 - val_loss: 0.5241 - val_acc: 0.7865\n",
      "Epoch 88/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.5156 - acc: 0.7587 - val_loss: 0.5239 - val_acc: 0.7865\n",
      "Epoch 89/1000\n",
      "576/576 [==============================] - 0s 23us/sample - loss: 0.5153 - acc: 0.7569 - val_loss: 0.5237 - val_acc: 0.7812\n",
      "Epoch 90/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.5151 - acc: 0.7587 - val_loss: 0.5235 - val_acc: 0.7812\n",
      "Epoch 91/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.5149 - acc: 0.7552 - val_loss: 0.5233 - val_acc: 0.7812\n",
      "Epoch 92/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.5147 - acc: 0.7569 - val_loss: 0.5231 - val_acc: 0.7812\n",
      "Epoch 93/1000\n",
      "576/576 [==============================] - 0s 31us/sample - loss: 0.5144 - acc: 0.7569 - val_loss: 0.5229 - val_acc: 0.7812\n",
      "Epoch 94/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.5142 - acc: 0.7569 - val_loss: 0.5227 - val_acc: 0.7760\n",
      "Epoch 95/1000\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.5140 - acc: 0.7569 - val_loss: 0.5225 - val_acc: 0.7760\n",
      "Epoch 96/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.5138 - acc: 0.7569 - val_loss: 0.5223 - val_acc: 0.7760\n",
      "Epoch 97/1000\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.5135 - acc: 0.7569 - val_loss: 0.5221 - val_acc: 0.7760\n",
      "Epoch 98/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.5134 - acc: 0.7569 - val_loss: 0.5219 - val_acc: 0.7760\n",
      "Epoch 99/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.5131 - acc: 0.7569 - val_loss: 0.5217 - val_acc: 0.7760\n",
      "Epoch 100/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.5129 - acc: 0.7569 - val_loss: 0.5215 - val_acc: 0.7760\n",
      "Epoch 101/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.5127 - acc: 0.7569 - val_loss: 0.5213 - val_acc: 0.7760\n",
      "Epoch 102/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.5125 - acc: 0.7569 - val_loss: 0.5211 - val_acc: 0.7760\n",
      "Epoch 103/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.5122 - acc: 0.7569 - val_loss: 0.5209 - val_acc: 0.7760\n",
      "Epoch 104/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.5120 - acc: 0.7552 - val_loss: 0.5207 - val_acc: 0.7812\n",
      "Epoch 105/1000\n",
      "576/576 [==============================] - 0s 23us/sample - loss: 0.5118 - acc: 0.7552 - val_loss: 0.5205 - val_acc: 0.7812\n",
      "Epoch 106/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.5116 - acc: 0.7552 - val_loss: 0.5204 - val_acc: 0.7812\n",
      "Epoch 107/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.5114 - acc: 0.7552 - val_loss: 0.5202 - val_acc: 0.7812\n",
      "Epoch 108/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.5112 - acc: 0.7552 - val_loss: 0.5200 - val_acc: 0.7812\n",
      "Epoch 109/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.5109 - acc: 0.7552 - val_loss: 0.5198 - val_acc: 0.7812\n",
      "Epoch 110/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.5107 - acc: 0.7552 - val_loss: 0.5196 - val_acc: 0.7812\n",
      "Epoch 111/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.5105 - acc: 0.7552 - val_loss: 0.5194 - val_acc: 0.7812\n",
      "Epoch 112/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.5103 - acc: 0.7552 - val_loss: 0.5192 - val_acc: 0.7812\n",
      "Epoch 113/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.5101 - acc: 0.7552 - val_loss: 0.5191 - val_acc: 0.7812\n",
      "Epoch 114/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.5099 - acc: 0.7569 - val_loss: 0.5189 - val_acc: 0.7812\n",
      "Epoch 115/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.5097 - acc: 0.7569 - val_loss: 0.5187 - val_acc: 0.7812\n",
      "Epoch 116/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.5095 - acc: 0.7552 - val_loss: 0.5185 - val_acc: 0.7812\n",
      "Epoch 117/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.5093 - acc: 0.7552 - val_loss: 0.5184 - val_acc: 0.7812\n",
      "Epoch 118/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.5091 - acc: 0.7552 - val_loss: 0.5182 - val_acc: 0.7812\n",
      "Epoch 119/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 24us/sample - loss: 0.5089 - acc: 0.7587 - val_loss: 0.5180 - val_acc: 0.7812\n",
      "Epoch 120/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.5087 - acc: 0.7587 - val_loss: 0.5178 - val_acc: 0.7812\n",
      "Epoch 121/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.5085 - acc: 0.7587 - val_loss: 0.5177 - val_acc: 0.7812\n",
      "Epoch 122/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.5083 - acc: 0.7587 - val_loss: 0.5175 - val_acc: 0.7812\n",
      "Epoch 123/1000\n",
      "576/576 [==============================] - 0s 23us/sample - loss: 0.5081 - acc: 0.7604 - val_loss: 0.5173 - val_acc: 0.7812\n",
      "Epoch 124/1000\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.5079 - acc: 0.7587 - val_loss: 0.5171 - val_acc: 0.7812\n",
      "Epoch 125/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.5077 - acc: 0.7604 - val_loss: 0.5170 - val_acc: 0.7812\n",
      "Epoch 126/1000\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.5075 - acc: 0.7604 - val_loss: 0.5168 - val_acc: 0.7812\n",
      "Epoch 127/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.5073 - acc: 0.7604 - val_loss: 0.5166 - val_acc: 0.7812\n",
      "Epoch 128/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.5071 - acc: 0.7587 - val_loss: 0.5165 - val_acc: 0.7812\n",
      "Epoch 129/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.5069 - acc: 0.7587 - val_loss: 0.5163 - val_acc: 0.7812\n",
      "Epoch 130/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.5067 - acc: 0.7587 - val_loss: 0.5161 - val_acc: 0.7812\n",
      "Epoch 131/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.5065 - acc: 0.7587 - val_loss: 0.5160 - val_acc: 0.7812\n",
      "Epoch 132/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.5063 - acc: 0.7604 - val_loss: 0.5158 - val_acc: 0.7812\n",
      "Epoch 133/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.5061 - acc: 0.7587 - val_loss: 0.5156 - val_acc: 0.7865\n",
      "Epoch 134/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.5059 - acc: 0.7604 - val_loss: 0.5155 - val_acc: 0.7865\n",
      "Epoch 135/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.5057 - acc: 0.7604 - val_loss: 0.5153 - val_acc: 0.7865\n",
      "Epoch 136/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.5055 - acc: 0.7604 - val_loss: 0.5152 - val_acc: 0.7865\n",
      "Epoch 137/1000\n",
      "576/576 [==============================] - 0s 23us/sample - loss: 0.5053 - acc: 0.7604 - val_loss: 0.5150 - val_acc: 0.7865\n",
      "Epoch 138/1000\n",
      "576/576 [==============================] - 0s 23us/sample - loss: 0.5052 - acc: 0.7604 - val_loss: 0.5148 - val_acc: 0.7865\n",
      "Epoch 139/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.5050 - acc: 0.7604 - val_loss: 0.5147 - val_acc: 0.7865\n",
      "Epoch 140/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.5048 - acc: 0.7604 - val_loss: 0.5145 - val_acc: 0.7865\n",
      "Epoch 141/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.5046 - acc: 0.7604 - val_loss: 0.5144 - val_acc: 0.7865\n",
      "Epoch 142/1000\n",
      "576/576 [==============================] - 0s 23us/sample - loss: 0.5044 - acc: 0.7604 - val_loss: 0.5142 - val_acc: 0.7865\n",
      "Epoch 143/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.5042 - acc: 0.7604 - val_loss: 0.5140 - val_acc: 0.7865\n",
      "Epoch 144/1000\n",
      "576/576 [==============================] - 0s 23us/sample - loss: 0.5040 - acc: 0.7604 - val_loss: 0.5139 - val_acc: 0.7865\n",
      "Epoch 145/1000\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.5039 - acc: 0.7622 - val_loss: 0.5137 - val_acc: 0.7865\n",
      "Epoch 146/1000\n",
      "576/576 [==============================] - 0s 23us/sample - loss: 0.5037 - acc: 0.7604 - val_loss: 0.5136 - val_acc: 0.7865\n",
      "Epoch 147/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.5035 - acc: 0.7622 - val_loss: 0.5134 - val_acc: 0.7865\n",
      "Epoch 148/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.5033 - acc: 0.7622 - val_loss: 0.5133 - val_acc: 0.7865\n",
      "Epoch 149/1000\n",
      "576/576 [==============================] - 0s 23us/sample - loss: 0.5031 - acc: 0.7622 - val_loss: 0.5131 - val_acc: 0.7865\n",
      "Epoch 150/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.5030 - acc: 0.7622 - val_loss: 0.5130 - val_acc: 0.7865\n",
      "Epoch 151/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.5028 - acc: 0.7622 - val_loss: 0.5128 - val_acc: 0.7865\n",
      "Epoch 152/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.5026 - acc: 0.7604 - val_loss: 0.5127 - val_acc: 0.7865\n",
      "Epoch 153/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.5024 - acc: 0.7622 - val_loss: 0.5125 - val_acc: 0.7865\n",
      "Epoch 154/1000\n",
      "576/576 [==============================] - 0s 35us/sample - loss: 0.5023 - acc: 0.7622 - val_loss: 0.5124 - val_acc: 0.7865\n",
      "Epoch 155/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.5021 - acc: 0.7604 - val_loss: 0.5122 - val_acc: 0.7865\n",
      "Epoch 156/1000\n",
      "576/576 [==============================] - 0s 23us/sample - loss: 0.5019 - acc: 0.7604 - val_loss: 0.5121 - val_acc: 0.7865\n",
      "Epoch 157/1000\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.5017 - acc: 0.7604 - val_loss: 0.5120 - val_acc: 0.7917\n",
      "Epoch 158/1000\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.5015 - acc: 0.7604 - val_loss: 0.5118 - val_acc: 0.7917\n",
      "Epoch 159/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.5014 - acc: 0.7604 - val_loss: 0.5117 - val_acc: 0.7917\n",
      "Epoch 160/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.5012 - acc: 0.7604 - val_loss: 0.5115 - val_acc: 0.7917\n",
      "Epoch 161/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.5010 - acc: 0.7604 - val_loss: 0.5114 - val_acc: 0.7917\n",
      "Epoch 162/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.5009 - acc: 0.7604 - val_loss: 0.5113 - val_acc: 0.7917\n",
      "Epoch 163/1000\n",
      "576/576 [==============================] - 0s 23us/sample - loss: 0.5007 - acc: 0.7604 - val_loss: 0.5111 - val_acc: 0.7917\n",
      "Epoch 164/1000\n",
      "576/576 [==============================] - 0s 23us/sample - loss: 0.5005 - acc: 0.7604 - val_loss: 0.5110 - val_acc: 0.7917\n",
      "Epoch 165/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.5003 - acc: 0.7604 - val_loss: 0.5108 - val_acc: 0.7917\n",
      "Epoch 166/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.5002 - acc: 0.7604 - val_loss: 0.5107 - val_acc: 0.7917\n",
      "Epoch 167/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.5000 - acc: 0.7604 - val_loss: 0.5106 - val_acc: 0.7917\n",
      "Epoch 168/1000\n",
      "576/576 [==============================] - 0s 23us/sample - loss: 0.4999 - acc: 0.7604 - val_loss: 0.5104 - val_acc: 0.7917\n",
      "Epoch 169/1000\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4997 - acc: 0.7604 - val_loss: 0.5103 - val_acc: 0.7917\n",
      "Epoch 170/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4995 - acc: 0.7604 - val_loss: 0.5102 - val_acc: 0.7917\n",
      "Epoch 171/1000\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4993 - acc: 0.7622 - val_loss: 0.5100 - val_acc: 0.7917\n",
      "Epoch 172/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4992 - acc: 0.7622 - val_loss: 0.5099 - val_acc: 0.7865\n",
      "Epoch 173/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4990 - acc: 0.7622 - val_loss: 0.5098 - val_acc: 0.7865\n",
      "Epoch 174/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4989 - acc: 0.7622 - val_loss: 0.5096 - val_acc: 0.7865\n",
      "Epoch 175/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4987 - acc: 0.7622 - val_loss: 0.5095 - val_acc: 0.7865\n",
      "Epoch 176/1000\n",
      "576/576 [==============================] - 0s 23us/sample - loss: 0.4985 - acc: 0.7622 - val_loss: 0.5094 - val_acc: 0.7865\n",
      "Epoch 177/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4984 - acc: 0.7622 - val_loss: 0.5092 - val_acc: 0.7865\n",
      "Epoch 178/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 23us/sample - loss: 0.4982 - acc: 0.7622 - val_loss: 0.5091 - val_acc: 0.7865\n",
      "Epoch 179/1000\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4981 - acc: 0.7622 - val_loss: 0.5090 - val_acc: 0.7865\n",
      "Epoch 180/1000\n",
      "576/576 [==============================] - 0s 23us/sample - loss: 0.4979 - acc: 0.7622 - val_loss: 0.5088 - val_acc: 0.7865\n",
      "Epoch 181/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4977 - acc: 0.7622 - val_loss: 0.5087 - val_acc: 0.7865\n",
      "Epoch 182/1000\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4976 - acc: 0.7622 - val_loss: 0.5086 - val_acc: 0.7865\n",
      "Epoch 183/1000\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4974 - acc: 0.7639 - val_loss: 0.5085 - val_acc: 0.7865\n",
      "Epoch 184/1000\n",
      "576/576 [==============================] - 0s 23us/sample - loss: 0.4973 - acc: 0.7656 - val_loss: 0.5083 - val_acc: 0.7865\n",
      "Epoch 185/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4971 - acc: 0.7656 - val_loss: 0.5082 - val_acc: 0.7865\n",
      "Epoch 186/1000\n",
      "576/576 [==============================] - 0s 23us/sample - loss: 0.4969 - acc: 0.7656 - val_loss: 0.5081 - val_acc: 0.7865\n",
      "Epoch 187/1000\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4968 - acc: 0.7639 - val_loss: 0.5080 - val_acc: 0.7865\n",
      "Epoch 188/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4966 - acc: 0.7674 - val_loss: 0.5078 - val_acc: 0.7865\n",
      "Epoch 189/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4965 - acc: 0.7674 - val_loss: 0.5077 - val_acc: 0.7865\n",
      "Epoch 190/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4964 - acc: 0.7674 - val_loss: 0.5076 - val_acc: 0.7865\n",
      "Epoch 191/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4962 - acc: 0.7674 - val_loss: 0.5075 - val_acc: 0.7865\n",
      "Epoch 192/1000\n",
      "576/576 [==============================] - 0s 23us/sample - loss: 0.4960 - acc: 0.7674 - val_loss: 0.5074 - val_acc: 0.7865\n",
      "Epoch 193/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4959 - acc: 0.7674 - val_loss: 0.5072 - val_acc: 0.7812\n",
      "Epoch 194/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4957 - acc: 0.7691 - val_loss: 0.5071 - val_acc: 0.7812\n",
      "Epoch 195/1000\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4956 - acc: 0.7691 - val_loss: 0.5070 - val_acc: 0.7812\n",
      "Epoch 196/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4954 - acc: 0.7691 - val_loss: 0.5069 - val_acc: 0.7812\n",
      "Epoch 197/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4953 - acc: 0.7691 - val_loss: 0.5068 - val_acc: 0.7812\n",
      "Epoch 198/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4951 - acc: 0.7691 - val_loss: 0.5066 - val_acc: 0.7812\n",
      "Epoch 199/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4950 - acc: 0.7691 - val_loss: 0.5065 - val_acc: 0.7812\n",
      "Epoch 200/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4948 - acc: 0.7691 - val_loss: 0.5064 - val_acc: 0.7812\n",
      "Epoch 201/1000\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4947 - acc: 0.7708 - val_loss: 0.5063 - val_acc: 0.7812\n",
      "Epoch 202/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4945 - acc: 0.7708 - val_loss: 0.5062 - val_acc: 0.7812\n",
      "Epoch 203/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4944 - acc: 0.7708 - val_loss: 0.5061 - val_acc: 0.7812\n",
      "Epoch 204/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4942 - acc: 0.7708 - val_loss: 0.5060 - val_acc: 0.7812\n",
      "Epoch 205/1000\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4941 - acc: 0.7708 - val_loss: 0.5059 - val_acc: 0.7812\n",
      "Epoch 206/1000\n",
      "576/576 [==============================] - 0s 23us/sample - loss: 0.4940 - acc: 0.7708 - val_loss: 0.5057 - val_acc: 0.7812\n",
      "Epoch 207/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4938 - acc: 0.7708 - val_loss: 0.5056 - val_acc: 0.7812\n",
      "Epoch 208/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4937 - acc: 0.7708 - val_loss: 0.5055 - val_acc: 0.7812\n",
      "Epoch 209/1000\n",
      "576/576 [==============================] - 0s 31us/sample - loss: 0.4935 - acc: 0.7708 - val_loss: 0.5054 - val_acc: 0.7812\n",
      "Epoch 210/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4934 - acc: 0.7708 - val_loss: 0.5053 - val_acc: 0.7812\n",
      "Epoch 211/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4932 - acc: 0.7708 - val_loss: 0.5052 - val_acc: 0.7812\n",
      "Epoch 212/1000\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4931 - acc: 0.7708 - val_loss: 0.5051 - val_acc: 0.7865\n",
      "Epoch 213/1000\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4930 - acc: 0.7726 - val_loss: 0.5050 - val_acc: 0.7865\n",
      "Epoch 214/1000\n",
      "576/576 [==============================] - 0s 35us/sample - loss: 0.4928 - acc: 0.7726 - val_loss: 0.5049 - val_acc: 0.7865\n",
      "Epoch 215/1000\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4927 - acc: 0.7726 - val_loss: 0.5048 - val_acc: 0.7865\n",
      "Epoch 216/1000\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4926 - acc: 0.7726 - val_loss: 0.5047 - val_acc: 0.7865\n",
      "Epoch 217/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4924 - acc: 0.7726 - val_loss: 0.5045 - val_acc: 0.7865\n",
      "Epoch 218/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4923 - acc: 0.7726 - val_loss: 0.5044 - val_acc: 0.7865\n",
      "Epoch 219/1000\n",
      "576/576 [==============================] - 0s 23us/sample - loss: 0.4921 - acc: 0.7726 - val_loss: 0.5043 - val_acc: 0.7865\n",
      "Epoch 220/1000\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4920 - acc: 0.7726 - val_loss: 0.5042 - val_acc: 0.7865\n",
      "Epoch 221/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4918 - acc: 0.7726 - val_loss: 0.5041 - val_acc: 0.7865\n",
      "Epoch 222/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4917 - acc: 0.7726 - val_loss: 0.5040 - val_acc: 0.7865\n",
      "Epoch 223/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4916 - acc: 0.7726 - val_loss: 0.5039 - val_acc: 0.7865\n",
      "Epoch 224/1000\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4914 - acc: 0.7726 - val_loss: 0.5038 - val_acc: 0.7865\n",
      "Epoch 225/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4913 - acc: 0.7726 - val_loss: 0.5037 - val_acc: 0.7865\n",
      "Epoch 226/1000\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4912 - acc: 0.7726 - val_loss: 0.5036 - val_acc: 0.7865\n",
      "Epoch 227/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4911 - acc: 0.7726 - val_loss: 0.5035 - val_acc: 0.7865\n",
      "Epoch 228/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4909 - acc: 0.7726 - val_loss: 0.5034 - val_acc: 0.7865\n",
      "Epoch 229/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4908 - acc: 0.7726 - val_loss: 0.5033 - val_acc: 0.7865\n",
      "Epoch 230/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4907 - acc: 0.7726 - val_loss: 0.5032 - val_acc: 0.7865\n",
      "Epoch 231/1000\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4905 - acc: 0.7743 - val_loss: 0.5031 - val_acc: 0.7865\n",
      "Epoch 232/1000\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4904 - acc: 0.7743 - val_loss: 0.5030 - val_acc: 0.7865\n",
      "Epoch 233/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4903 - acc: 0.7743 - val_loss: 0.5029 - val_acc: 0.7865\n",
      "Epoch 234/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4901 - acc: 0.7743 - val_loss: 0.5028 - val_acc: 0.7865\n",
      "Epoch 235/1000\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4900 - acc: 0.7726 - val_loss: 0.5027 - val_acc: 0.7865\n",
      "Epoch 236/1000\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4899 - acc: 0.7726 - val_loss: 0.5026 - val_acc: 0.7865\n",
      "Epoch 237/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4898 - acc: 0.7726 - val_loss: 0.5026 - val_acc: 0.7865\n",
      "Epoch 238/1000\n",
      "576/576 [==============================] - 0s 23us/sample - loss: 0.4896 - acc: 0.7726 - val_loss: 0.5025 - val_acc: 0.7865\n",
      "Epoch 239/1000\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4895 - acc: 0.7726 - val_loss: 0.5024 - val_acc: 0.7917\n",
      "Epoch 240/1000\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4894 - acc: 0.7726 - val_loss: 0.5023 - val_acc: 0.7917\n",
      "Epoch 241/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4893 - acc: 0.7726 - val_loss: 0.5022 - val_acc: 0.7917\n",
      "Epoch 242/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4891 - acc: 0.7726 - val_loss: 0.5021 - val_acc: 0.7917\n",
      "Epoch 243/1000\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4890 - acc: 0.7726 - val_loss: 0.5020 - val_acc: 0.7917\n",
      "Epoch 244/1000\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4889 - acc: 0.7726 - val_loss: 0.5019 - val_acc: 0.7917\n",
      "Epoch 245/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4888 - acc: 0.7726 - val_loss: 0.5018 - val_acc: 0.7917\n",
      "Epoch 246/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4886 - acc: 0.7726 - val_loss: 0.5017 - val_acc: 0.7917\n",
      "Epoch 247/1000\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4885 - acc: 0.7726 - val_loss: 0.5016 - val_acc: 0.7917\n",
      "Epoch 248/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4884 - acc: 0.7726 - val_loss: 0.5015 - val_acc: 0.7917\n",
      "Epoch 249/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4883 - acc: 0.7726 - val_loss: 0.5015 - val_acc: 0.7917\n",
      "Epoch 250/1000\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4882 - acc: 0.7726 - val_loss: 0.5014 - val_acc: 0.7917\n",
      "Epoch 251/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4880 - acc: 0.7726 - val_loss: 0.5013 - val_acc: 0.7917\n",
      "Epoch 252/1000\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4879 - acc: 0.7726 - val_loss: 0.5012 - val_acc: 0.7917\n",
      "Epoch 253/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4878 - acc: 0.7726 - val_loss: 0.5011 - val_acc: 0.7917\n",
      "Epoch 254/1000\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4877 - acc: 0.7726 - val_loss: 0.5010 - val_acc: 0.7917\n",
      "Epoch 255/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4876 - acc: 0.7726 - val_loss: 0.5009 - val_acc: 0.7917\n",
      "Epoch 256/1000\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4874 - acc: 0.7726 - val_loss: 0.5008 - val_acc: 0.7917\n",
      "Epoch 257/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4873 - acc: 0.7726 - val_loss: 0.5008 - val_acc: 0.7917\n",
      "Epoch 258/1000\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4872 - acc: 0.7726 - val_loss: 0.5007 - val_acc: 0.7917\n",
      "Epoch 259/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4871 - acc: 0.7726 - val_loss: 0.5006 - val_acc: 0.7865\n",
      "Epoch 260/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4869 - acc: 0.7726 - val_loss: 0.5005 - val_acc: 0.7865\n",
      "Epoch 261/1000\n",
      "576/576 [==============================] - 0s 35us/sample - loss: 0.4868 - acc: 0.7726 - val_loss: 0.5004 - val_acc: 0.7865\n",
      "Epoch 262/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4867 - acc: 0.7726 - val_loss: 0.5003 - val_acc: 0.7865\n",
      "Epoch 263/1000\n",
      "576/576 [==============================] - 0s 23us/sample - loss: 0.4866 - acc: 0.7726 - val_loss: 0.5003 - val_acc: 0.7812\n",
      "Epoch 264/1000\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4865 - acc: 0.7726 - val_loss: 0.5002 - val_acc: 0.7812\n",
      "Epoch 265/1000\n",
      "576/576 [==============================] - 0s 31us/sample - loss: 0.4864 - acc: 0.7726 - val_loss: 0.5001 - val_acc: 0.7812\n",
      "Epoch 266/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4863 - acc: 0.7726 - val_loss: 0.5000 - val_acc: 0.7812\n",
      "Epoch 267/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4862 - acc: 0.7726 - val_loss: 0.4999 - val_acc: 0.7812\n",
      "Epoch 268/1000\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4861 - acc: 0.7726 - val_loss: 0.4998 - val_acc: 0.7812\n",
      "Epoch 269/1000\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4859 - acc: 0.7726 - val_loss: 0.4998 - val_acc: 0.7812\n",
      "Epoch 270/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4858 - acc: 0.7726 - val_loss: 0.4997 - val_acc: 0.7812\n",
      "Epoch 271/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4857 - acc: 0.7726 - val_loss: 0.4996 - val_acc: 0.7812\n",
      "Epoch 272/1000\n",
      "576/576 [==============================] - 0s 35us/sample - loss: 0.4856 - acc: 0.7726 - val_loss: 0.4995 - val_acc: 0.7812\n",
      "Epoch 273/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4855 - acc: 0.7726 - val_loss: 0.4995 - val_acc: 0.7812\n",
      "Epoch 274/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4854 - acc: 0.7726 - val_loss: 0.4994 - val_acc: 0.7812\n",
      "Epoch 275/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4853 - acc: 0.7726 - val_loss: 0.4993 - val_acc: 0.7812\n",
      "Epoch 276/1000\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4852 - acc: 0.7726 - val_loss: 0.4992 - val_acc: 0.7812\n",
      "Epoch 277/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4850 - acc: 0.7726 - val_loss: 0.4991 - val_acc: 0.7760\n",
      "Epoch 278/1000\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4849 - acc: 0.7726 - val_loss: 0.4991 - val_acc: 0.7760\n",
      "Epoch 279/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4848 - acc: 0.7743 - val_loss: 0.4990 - val_acc: 0.7760\n",
      "Epoch 280/1000\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4847 - acc: 0.7726 - val_loss: 0.4989 - val_acc: 0.7760\n",
      "Epoch 281/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4846 - acc: 0.7743 - val_loss: 0.4988 - val_acc: 0.7760\n",
      "Epoch 282/1000\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4845 - acc: 0.7743 - val_loss: 0.4988 - val_acc: 0.7760\n",
      "Epoch 283/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4844 - acc: 0.7743 - val_loss: 0.4987 - val_acc: 0.7760\n",
      "Epoch 284/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4843 - acc: 0.7743 - val_loss: 0.4986 - val_acc: 0.7760\n",
      "Epoch 285/1000\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4842 - acc: 0.7760 - val_loss: 0.4985 - val_acc: 0.7760\n",
      "Epoch 286/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4841 - acc: 0.7760 - val_loss: 0.4985 - val_acc: 0.7760\n",
      "Epoch 287/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4840 - acc: 0.7760 - val_loss: 0.4984 - val_acc: 0.7760\n",
      "Epoch 288/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4839 - acc: 0.7760 - val_loss: 0.4983 - val_acc: 0.7760\n",
      "Epoch 289/1000\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4838 - acc: 0.7760 - val_loss: 0.4983 - val_acc: 0.7760\n",
      "Epoch 290/1000\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4837 - acc: 0.7760 - val_loss: 0.4982 - val_acc: 0.7760\n",
      "Epoch 291/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4836 - acc: 0.7760 - val_loss: 0.4981 - val_acc: 0.7760\n",
      "Epoch 292/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4835 - acc: 0.7760 - val_loss: 0.4980 - val_acc: 0.7760\n",
      "Epoch 293/1000\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4834 - acc: 0.7760 - val_loss: 0.4980 - val_acc: 0.7760\n",
      "Epoch 294/1000\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4832 - acc: 0.7760 - val_loss: 0.4979 - val_acc: 0.7760\n",
      "Epoch 295/1000\n",
      "576/576 [==============================] - 0s 23us/sample - loss: 0.4832 - acc: 0.7760 - val_loss: 0.4978 - val_acc: 0.7760\n",
      "Epoch 296/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4830 - acc: 0.7760 - val_loss: 0.4978 - val_acc: 0.7760\n",
      "Epoch 297/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4829 - acc: 0.7760 - val_loss: 0.4977 - val_acc: 0.7760\n",
      "Epoch 298/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4828 - acc: 0.7760 - val_loss: 0.4976 - val_acc: 0.7760\n",
      "Epoch 299/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4827 - acc: 0.7760 - val_loss: 0.4976 - val_acc: 0.7760\n",
      "Epoch 300/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4826 - acc: 0.7760 - val_loss: 0.4975 - val_acc: 0.7760\n",
      "Epoch 301/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4826 - acc: 0.7760 - val_loss: 0.4974 - val_acc: 0.7760\n",
      "Epoch 302/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4825 - acc: 0.7760 - val_loss: 0.4974 - val_acc: 0.7760\n",
      "Epoch 303/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4824 - acc: 0.7760 - val_loss: 0.4973 - val_acc: 0.7760\n",
      "Epoch 304/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4822 - acc: 0.7760 - val_loss: 0.4972 - val_acc: 0.7760\n",
      "Epoch 305/1000\n",
      "576/576 [==============================] - 0s 23us/sample - loss: 0.4822 - acc: 0.7760 - val_loss: 0.4972 - val_acc: 0.7760\n",
      "Epoch 306/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4821 - acc: 0.7760 - val_loss: 0.4971 - val_acc: 0.7760\n",
      "Epoch 307/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4820 - acc: 0.7760 - val_loss: 0.4970 - val_acc: 0.7760\n",
      "Epoch 308/1000\n",
      "576/576 [==============================] - 0s 23us/sample - loss: 0.4819 - acc: 0.7760 - val_loss: 0.4970 - val_acc: 0.7760\n",
      "Epoch 309/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4818 - acc: 0.7760 - val_loss: 0.4969 - val_acc: 0.7760\n",
      "Epoch 310/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4817 - acc: 0.7743 - val_loss: 0.4968 - val_acc: 0.7760\n",
      "Epoch 311/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4816 - acc: 0.7743 - val_loss: 0.4968 - val_acc: 0.7760\n",
      "Epoch 312/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4815 - acc: 0.7743 - val_loss: 0.4967 - val_acc: 0.7760\n",
      "Epoch 313/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4814 - acc: 0.7743 - val_loss: 0.4966 - val_acc: 0.7760\n",
      "Epoch 314/1000\n",
      "576/576 [==============================] - 0s 23us/sample - loss: 0.4813 - acc: 0.7743 - val_loss: 0.4966 - val_acc: 0.7760\n",
      "Epoch 315/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4812 - acc: 0.7743 - val_loss: 0.4965 - val_acc: 0.7760\n",
      "Epoch 316/1000\n",
      "576/576 [==============================] - 0s 31us/sample - loss: 0.4811 - acc: 0.7726 - val_loss: 0.4965 - val_acc: 0.7760\n",
      "Epoch 317/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4810 - acc: 0.7743 - val_loss: 0.4964 - val_acc: 0.7760\n",
      "Epoch 318/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4809 - acc: 0.7726 - val_loss: 0.4963 - val_acc: 0.7760\n",
      "Epoch 319/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4808 - acc: 0.7726 - val_loss: 0.4963 - val_acc: 0.7760\n",
      "Epoch 320/1000\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4807 - acc: 0.7708 - val_loss: 0.4962 - val_acc: 0.7760\n",
      "Epoch 321/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4806 - acc: 0.7743 - val_loss: 0.4961 - val_acc: 0.7760\n",
      "Epoch 322/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4805 - acc: 0.7760 - val_loss: 0.4961 - val_acc: 0.7760\n",
      "Epoch 323/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4804 - acc: 0.7726 - val_loss: 0.4960 - val_acc: 0.7760\n",
      "Epoch 324/1000\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4804 - acc: 0.7726 - val_loss: 0.4960 - val_acc: 0.7760\n",
      "Epoch 325/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4803 - acc: 0.7726 - val_loss: 0.4959 - val_acc: 0.7760\n",
      "Epoch 326/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4802 - acc: 0.7726 - val_loss: 0.4958 - val_acc: 0.7760\n",
      "Epoch 327/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4801 - acc: 0.7726 - val_loss: 0.4958 - val_acc: 0.7760\n",
      "Epoch 328/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4800 - acc: 0.7743 - val_loss: 0.4957 - val_acc: 0.7760\n",
      "Epoch 329/1000\n",
      "576/576 [==============================] - 0s 23us/sample - loss: 0.4799 - acc: 0.7726 - val_loss: 0.4957 - val_acc: 0.7760\n",
      "Epoch 330/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4798 - acc: 0.7726 - val_loss: 0.4956 - val_acc: 0.7760\n",
      "Epoch 331/1000\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4797 - acc: 0.7726 - val_loss: 0.4956 - val_acc: 0.7760\n",
      "Epoch 332/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4797 - acc: 0.7726 - val_loss: 0.4955 - val_acc: 0.7760\n",
      "Epoch 333/1000\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4796 - acc: 0.7726 - val_loss: 0.4954 - val_acc: 0.7760\n",
      "Epoch 334/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4795 - acc: 0.7726 - val_loss: 0.4954 - val_acc: 0.7760\n",
      "Epoch 335/1000\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4794 - acc: 0.7726 - val_loss: 0.4953 - val_acc: 0.7708\n",
      "Epoch 336/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4793 - acc: 0.7726 - val_loss: 0.4953 - val_acc: 0.7708\n",
      "Epoch 337/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4792 - acc: 0.7726 - val_loss: 0.4952 - val_acc: 0.7708\n",
      "Epoch 338/1000\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4791 - acc: 0.7726 - val_loss: 0.4952 - val_acc: 0.7708\n",
      "Epoch 339/1000\n",
      "576/576 [==============================] - 0s 23us/sample - loss: 0.4790 - acc: 0.7726 - val_loss: 0.4951 - val_acc: 0.7708\n",
      "Epoch 340/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4789 - acc: 0.7726 - val_loss: 0.4951 - val_acc: 0.7708\n",
      "Epoch 341/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4789 - acc: 0.7726 - val_loss: 0.4950 - val_acc: 0.7708\n",
      "Epoch 342/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4788 - acc: 0.7726 - val_loss: 0.4950 - val_acc: 0.7708\n",
      "Epoch 343/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4787 - acc: 0.7726 - val_loss: 0.4949 - val_acc: 0.7656\n",
      "Epoch 344/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4786 - acc: 0.7726 - val_loss: 0.4948 - val_acc: 0.7656\n",
      "Epoch 345/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4785 - acc: 0.7726 - val_loss: 0.4948 - val_acc: 0.7656\n",
      "Epoch 346/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4784 - acc: 0.7743 - val_loss: 0.4947 - val_acc: 0.7708\n",
      "Epoch 347/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4784 - acc: 0.7743 - val_loss: 0.4947 - val_acc: 0.7708\n",
      "Epoch 348/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4783 - acc: 0.7743 - val_loss: 0.4946 - val_acc: 0.7708\n",
      "Epoch 349/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4782 - acc: 0.7743 - val_loss: 0.4946 - val_acc: 0.7708\n",
      "Epoch 350/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4781 - acc: 0.7743 - val_loss: 0.4945 - val_acc: 0.7708\n",
      "Epoch 351/1000\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4780 - acc: 0.7743 - val_loss: 0.4945 - val_acc: 0.7708\n",
      "Epoch 352/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4779 - acc: 0.7743 - val_loss: 0.4944 - val_acc: 0.7708\n",
      "Epoch 353/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4779 - acc: 0.7743 - val_loss: 0.4944 - val_acc: 0.7708\n",
      "Epoch 354/1000\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4778 - acc: 0.7743 - val_loss: 0.4943 - val_acc: 0.7708\n",
      "Epoch 355/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4777 - acc: 0.7743 - val_loss: 0.4943 - val_acc: 0.7708\n",
      "Epoch 356/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4776 - acc: 0.7743 - val_loss: 0.4942 - val_acc: 0.7708\n",
      "Epoch 357/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4776 - acc: 0.7743 - val_loss: 0.4942 - val_acc: 0.7708\n",
      "Epoch 358/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4775 - acc: 0.7743 - val_loss: 0.4941 - val_acc: 0.7708\n",
      "Epoch 359/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4774 - acc: 0.7743 - val_loss: 0.4941 - val_acc: 0.7656\n",
      "Epoch 360/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4773 - acc: 0.7743 - val_loss: 0.4940 - val_acc: 0.7656\n",
      "Epoch 361/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4772 - acc: 0.7743 - val_loss: 0.4940 - val_acc: 0.7656\n",
      "Epoch 362/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4771 - acc: 0.7743 - val_loss: 0.4939 - val_acc: 0.7656\n",
      "Epoch 363/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4771 - acc: 0.7743 - val_loss: 0.4939 - val_acc: 0.7656\n",
      "Epoch 364/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4770 - acc: 0.7743 - val_loss: 0.4938 - val_acc: 0.7656\n",
      "Epoch 365/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4769 - acc: 0.7743 - val_loss: 0.4938 - val_acc: 0.7656\n",
      "Epoch 366/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4768 - acc: 0.7743 - val_loss: 0.4937 - val_acc: 0.7656\n",
      "Epoch 367/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4768 - acc: 0.7743 - val_loss: 0.4937 - val_acc: 0.7656\n",
      "Epoch 368/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4767 - acc: 0.7743 - val_loss: 0.4936 - val_acc: 0.7656\n",
      "Epoch 369/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4766 - acc: 0.7743 - val_loss: 0.4936 - val_acc: 0.7656\n",
      "Epoch 370/1000\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4765 - acc: 0.7743 - val_loss: 0.4936 - val_acc: 0.7656\n",
      "Epoch 371/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4764 - acc: 0.7743 - val_loss: 0.4935 - val_acc: 0.7656\n",
      "Epoch 372/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4764 - acc: 0.7743 - val_loss: 0.4935 - val_acc: 0.7656\n",
      "Epoch 373/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4763 - acc: 0.7743 - val_loss: 0.4934 - val_acc: 0.7656\n",
      "Epoch 374/1000\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4762 - acc: 0.7743 - val_loss: 0.4934 - val_acc: 0.7656\n",
      "Epoch 375/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4762 - acc: 0.7743 - val_loss: 0.4933 - val_acc: 0.7656\n",
      "Epoch 376/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4761 - acc: 0.7743 - val_loss: 0.4933 - val_acc: 0.7656\n",
      "Epoch 377/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4760 - acc: 0.7743 - val_loss: 0.4932 - val_acc: 0.7656\n",
      "Epoch 378/1000\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4759 - acc: 0.7743 - val_loss: 0.4932 - val_acc: 0.7656\n",
      "Epoch 379/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4758 - acc: 0.7743 - val_loss: 0.4932 - val_acc: 0.7656\n",
      "Epoch 380/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4758 - acc: 0.7743 - val_loss: 0.4931 - val_acc: 0.7656\n",
      "Epoch 381/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4757 - acc: 0.7760 - val_loss: 0.4931 - val_acc: 0.7656\n",
      "Epoch 382/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4756 - acc: 0.7760 - val_loss: 0.4930 - val_acc: 0.7656\n",
      "Epoch 383/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4756 - acc: 0.7760 - val_loss: 0.4930 - val_acc: 0.7656\n",
      "Epoch 384/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4755 - acc: 0.7760 - val_loss: 0.4929 - val_acc: 0.7656\n",
      "Epoch 385/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4754 - acc: 0.7760 - val_loss: 0.4929 - val_acc: 0.7656\n",
      "Epoch 386/1000\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4753 - acc: 0.7760 - val_loss: 0.4929 - val_acc: 0.7656\n",
      "Epoch 387/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4753 - acc: 0.7760 - val_loss: 0.4928 - val_acc: 0.7656\n",
      "Epoch 388/1000\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4752 - acc: 0.7760 - val_loss: 0.4928 - val_acc: 0.7656\n",
      "Epoch 389/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4751 - acc: 0.7760 - val_loss: 0.4927 - val_acc: 0.7656\n",
      "Epoch 390/1000\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4751 - acc: 0.7760 - val_loss: 0.4927 - val_acc: 0.7656\n",
      "Epoch 391/1000\n",
      "576/576 [==============================] - 0s 33us/sample - loss: 0.4750 - acc: 0.7760 - val_loss: 0.4926 - val_acc: 0.7656\n",
      "Epoch 392/1000\n",
      "576/576 [==============================] - 0s 31us/sample - loss: 0.4749 - acc: 0.7760 - val_loss: 0.4926 - val_acc: 0.7656\n",
      "Epoch 393/1000\n",
      "576/576 [==============================] - 0s 23us/sample - loss: 0.4748 - acc: 0.7760 - val_loss: 0.4926 - val_acc: 0.7656\n",
      "Epoch 394/1000\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4747 - acc: 0.7760 - val_loss: 0.4925 - val_acc: 0.7656\n",
      "Epoch 395/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4747 - acc: 0.7760 - val_loss: 0.4925 - val_acc: 0.7656\n",
      "Epoch 396/1000\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4746 - acc: 0.7760 - val_loss: 0.4924 - val_acc: 0.7656\n",
      "Epoch 397/1000\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4746 - acc: 0.7760 - val_loss: 0.4924 - val_acc: 0.7656\n",
      "Epoch 398/1000\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4745 - acc: 0.7760 - val_loss: 0.4924 - val_acc: 0.7656\n",
      "Epoch 399/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4744 - acc: 0.7760 - val_loss: 0.4923 - val_acc: 0.7656\n",
      "Epoch 400/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4744 - acc: 0.7760 - val_loss: 0.4923 - val_acc: 0.7656\n",
      "Epoch 401/1000\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4743 - acc: 0.7760 - val_loss: 0.4922 - val_acc: 0.7656\n",
      "Epoch 402/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4742 - acc: 0.7760 - val_loss: 0.4922 - val_acc: 0.7656\n",
      "Epoch 403/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4741 - acc: 0.7760 - val_loss: 0.4922 - val_acc: 0.7656\n",
      "Epoch 404/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4741 - acc: 0.7760 - val_loss: 0.4921 - val_acc: 0.7656\n",
      "Epoch 405/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4740 - acc: 0.7760 - val_loss: 0.4921 - val_acc: 0.7656\n",
      "Epoch 406/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4739 - acc: 0.7760 - val_loss: 0.4921 - val_acc: 0.7656\n",
      "Epoch 407/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4739 - acc: 0.7778 - val_loss: 0.4920 - val_acc: 0.7656\n",
      "Epoch 408/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4738 - acc: 0.7760 - val_loss: 0.4920 - val_acc: 0.7656\n",
      "Epoch 409/1000\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4737 - acc: 0.7760 - val_loss: 0.4919 - val_acc: 0.7656\n",
      "Epoch 410/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4737 - acc: 0.7778 - val_loss: 0.4919 - val_acc: 0.7656\n",
      "Epoch 411/1000\n",
      "576/576 [==============================] - 0s 23us/sample - loss: 0.4736 - acc: 0.7778 - val_loss: 0.4919 - val_acc: 0.7656\n",
      "Epoch 412/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4735 - acc: 0.7778 - val_loss: 0.4918 - val_acc: 0.7656\n",
      "Epoch 413/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4735 - acc: 0.7778 - val_loss: 0.4918 - val_acc: 0.7656\n",
      "Epoch 414/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4734 - acc: 0.7778 - val_loss: 0.4918 - val_acc: 0.7656\n",
      "Epoch 415/1000\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4734 - acc: 0.7778 - val_loss: 0.4917 - val_acc: 0.7656\n",
      "Epoch 416/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4733 - acc: 0.7778 - val_loss: 0.4917 - val_acc: 0.7656\n",
      "Epoch 417/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4732 - acc: 0.7778 - val_loss: 0.4917 - val_acc: 0.7656\n",
      "Epoch 418/1000\n",
      "576/576 [==============================] - 0s 23us/sample - loss: 0.4731 - acc: 0.7778 - val_loss: 0.4916 - val_acc: 0.7656\n",
      "Epoch 419/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4731 - acc: 0.7778 - val_loss: 0.4916 - val_acc: 0.7656\n",
      "Epoch 420/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4730 - acc: 0.7778 - val_loss: 0.4915 - val_acc: 0.7656\n",
      "Epoch 421/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4730 - acc: 0.7778 - val_loss: 0.4915 - val_acc: 0.7656\n",
      "Epoch 422/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4729 - acc: 0.7778 - val_loss: 0.4915 - val_acc: 0.7656\n",
      "Epoch 423/1000\n",
      "576/576 [==============================] - 0s 23us/sample - loss: 0.4728 - acc: 0.7778 - val_loss: 0.4914 - val_acc: 0.7656\n",
      "Epoch 424/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4728 - acc: 0.7778 - val_loss: 0.4914 - val_acc: 0.7656\n",
      "Epoch 425/1000\n",
      "576/576 [==============================] - 0s 23us/sample - loss: 0.4727 - acc: 0.7778 - val_loss: 0.4914 - val_acc: 0.7656\n",
      "Epoch 426/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4727 - acc: 0.7760 - val_loss: 0.4913 - val_acc: 0.7656\n",
      "Epoch 427/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4726 - acc: 0.7778 - val_loss: 0.4913 - val_acc: 0.7656\n",
      "Epoch 428/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4725 - acc: 0.7778 - val_loss: 0.4913 - val_acc: 0.7656\n",
      "Epoch 429/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4725 - acc: 0.7778 - val_loss: 0.4912 - val_acc: 0.7656\n",
      "Epoch 430/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4724 - acc: 0.7760 - val_loss: 0.4912 - val_acc: 0.7656\n",
      "Epoch 431/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4723 - acc: 0.7760 - val_loss: 0.4912 - val_acc: 0.7656\n",
      "Epoch 432/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4723 - acc: 0.7760 - val_loss: 0.4911 - val_acc: 0.7656\n",
      "Epoch 433/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4722 - acc: 0.7760 - val_loss: 0.4911 - val_acc: 0.7656\n",
      "Epoch 434/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4722 - acc: 0.7760 - val_loss: 0.4911 - val_acc: 0.7656\n",
      "Epoch 435/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4721 - acc: 0.7760 - val_loss: 0.4910 - val_acc: 0.7656\n",
      "Epoch 436/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4721 - acc: 0.7760 - val_loss: 0.4910 - val_acc: 0.7656\n",
      "Epoch 437/1000\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4720 - acc: 0.7778 - val_loss: 0.4910 - val_acc: 0.7656\n",
      "Epoch 438/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4719 - acc: 0.7760 - val_loss: 0.4910 - val_acc: 0.7656\n",
      "Epoch 439/1000\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4719 - acc: 0.7760 - val_loss: 0.4909 - val_acc: 0.7656\n",
      "Epoch 440/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4718 - acc: 0.7778 - val_loss: 0.4909 - val_acc: 0.7656\n",
      "Epoch 441/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4717 - acc: 0.7778 - val_loss: 0.4909 - val_acc: 0.7656\n",
      "Epoch 442/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4717 - acc: 0.7778 - val_loss: 0.4908 - val_acc: 0.7656\n",
      "Epoch 443/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4716 - acc: 0.7778 - val_loss: 0.4908 - val_acc: 0.7656\n",
      "Epoch 444/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4716 - acc: 0.7778 - val_loss: 0.4908 - val_acc: 0.7656\n",
      "Epoch 445/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4715 - acc: 0.7778 - val_loss: 0.4907 - val_acc: 0.7656\n",
      "Epoch 446/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4715 - acc: 0.7778 - val_loss: 0.4907 - val_acc: 0.7656\n",
      "Epoch 447/1000\n",
      "576/576 [==============================] - 0s 23us/sample - loss: 0.4714 - acc: 0.7778 - val_loss: 0.4907 - val_acc: 0.7656\n",
      "Epoch 448/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4713 - acc: 0.7778 - val_loss: 0.4906 - val_acc: 0.7656\n",
      "Epoch 449/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4713 - acc: 0.7778 - val_loss: 0.4906 - val_acc: 0.7656\n",
      "Epoch 450/1000\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4712 - acc: 0.7778 - val_loss: 0.4906 - val_acc: 0.7656\n",
      "Epoch 451/1000\n",
      "576/576 [==============================] - 0s 31us/sample - loss: 0.4712 - acc: 0.7795 - val_loss: 0.4906 - val_acc: 0.7656\n",
      "Epoch 452/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4711 - acc: 0.7795 - val_loss: 0.4905 - val_acc: 0.7656\n",
      "Epoch 453/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4711 - acc: 0.7795 - val_loss: 0.4905 - val_acc: 0.7656\n",
      "Epoch 454/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4710 - acc: 0.7795 - val_loss: 0.4905 - val_acc: 0.7656\n",
      "Epoch 455/1000\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4710 - acc: 0.7795 - val_loss: 0.4904 - val_acc: 0.7656\n",
      "Epoch 456/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4709 - acc: 0.7795 - val_loss: 0.4904 - val_acc: 0.7656\n",
      "Epoch 457/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4709 - acc: 0.7795 - val_loss: 0.4904 - val_acc: 0.7656\n",
      "Epoch 458/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4708 - acc: 0.7795 - val_loss: 0.4904 - val_acc: 0.7656\n",
      "Epoch 459/1000\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4707 - acc: 0.7795 - val_loss: 0.4903 - val_acc: 0.7656\n",
      "Epoch 460/1000\n",
      "576/576 [==============================] - 0s 23us/sample - loss: 0.4707 - acc: 0.7795 - val_loss: 0.4903 - val_acc: 0.7656\n",
      "Epoch 461/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4706 - acc: 0.7795 - val_loss: 0.4903 - val_acc: 0.7656\n",
      "Epoch 462/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4706 - acc: 0.7795 - val_loss: 0.4903 - val_acc: 0.7656\n",
      "Epoch 463/1000\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4705 - acc: 0.7795 - val_loss: 0.4902 - val_acc: 0.7656\n",
      "Epoch 464/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4705 - acc: 0.7795 - val_loss: 0.4902 - val_acc: 0.7656\n",
      "Epoch 465/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4704 - acc: 0.7795 - val_loss: 0.4902 - val_acc: 0.7656\n",
      "Epoch 466/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4704 - acc: 0.7795 - val_loss: 0.4901 - val_acc: 0.7656\n",
      "Epoch 467/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4703 - acc: 0.7795 - val_loss: 0.4901 - val_acc: 0.7656\n",
      "Epoch 468/1000\n",
      "576/576 [==============================] - 0s 23us/sample - loss: 0.4702 - acc: 0.7795 - val_loss: 0.4901 - val_acc: 0.7656\n",
      "Epoch 469/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4702 - acc: 0.7795 - val_loss: 0.4901 - val_acc: 0.7656\n",
      "Epoch 470/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4701 - acc: 0.7778 - val_loss: 0.4900 - val_acc: 0.7656\n",
      "Epoch 471/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4701 - acc: 0.7778 - val_loss: 0.4900 - val_acc: 0.7656\n",
      "Epoch 472/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4700 - acc: 0.7778 - val_loss: 0.4900 - val_acc: 0.7656\n",
      "Epoch 473/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4700 - acc: 0.7778 - val_loss: 0.4900 - val_acc: 0.7656\n",
      "Epoch 474/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4699 - acc: 0.7778 - val_loss: 0.4899 - val_acc: 0.7656\n",
      "Epoch 475/1000\n",
      "576/576 [==============================] - 0s 23us/sample - loss: 0.4699 - acc: 0.7778 - val_loss: 0.4899 - val_acc: 0.7656\n",
      "Epoch 476/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4698 - acc: 0.7778 - val_loss: 0.4899 - val_acc: 0.7656\n",
      "Epoch 477/1000\n",
      "576/576 [==============================] - 0s 23us/sample - loss: 0.4698 - acc: 0.7778 - val_loss: 0.4899 - val_acc: 0.7656\n",
      "Epoch 478/1000\n",
      "576/576 [==============================] - 0s 23us/sample - loss: 0.4697 - acc: 0.7778 - val_loss: 0.4898 - val_acc: 0.7656\n",
      "Epoch 479/1000\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4697 - acc: 0.7778 - val_loss: 0.4898 - val_acc: 0.7656\n",
      "Epoch 480/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4696 - acc: 0.7778 - val_loss: 0.4898 - val_acc: 0.7656\n",
      "Epoch 481/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4696 - acc: 0.7778 - val_loss: 0.4898 - val_acc: 0.7656\n",
      "Epoch 482/1000\n",
      "576/576 [==============================] - 0s 23us/sample - loss: 0.4695 - acc: 0.7778 - val_loss: 0.4897 - val_acc: 0.7656\n",
      "Epoch 483/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4695 - acc: 0.7778 - val_loss: 0.4897 - val_acc: 0.7656\n",
      "Epoch 484/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4694 - acc: 0.7778 - val_loss: 0.4897 - val_acc: 0.7656\n",
      "Epoch 485/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4694 - acc: 0.7778 - val_loss: 0.4897 - val_acc: 0.7656\n",
      "Epoch 486/1000\n",
      "576/576 [==============================] - 0s 23us/sample - loss: 0.4693 - acc: 0.7778 - val_loss: 0.4897 - val_acc: 0.7656\n",
      "Epoch 487/1000\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4693 - acc: 0.7760 - val_loss: 0.4896 - val_acc: 0.7656\n",
      "Epoch 488/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4692 - acc: 0.7778 - val_loss: 0.4896 - val_acc: 0.7656\n",
      "Epoch 489/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4692 - acc: 0.7760 - val_loss: 0.4896 - val_acc: 0.7656\n",
      "Epoch 490/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4691 - acc: 0.7760 - val_loss: 0.4896 - val_acc: 0.7656\n",
      "Epoch 491/1000\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4691 - acc: 0.7760 - val_loss: 0.4895 - val_acc: 0.7656\n",
      "Epoch 492/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4690 - acc: 0.7760 - val_loss: 0.4895 - val_acc: 0.7656\n",
      "Epoch 493/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4690 - acc: 0.7760 - val_loss: 0.4895 - val_acc: 0.7656\n",
      "Epoch 494/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4689 - acc: 0.7760 - val_loss: 0.4895 - val_acc: 0.7656\n",
      "Epoch 495/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4689 - acc: 0.7760 - val_loss: 0.4894 - val_acc: 0.7656\n",
      "Epoch 496/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4688 - acc: 0.7760 - val_loss: 0.4894 - val_acc: 0.7656\n",
      "Epoch 497/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4688 - acc: 0.7760 - val_loss: 0.4894 - val_acc: 0.7656\n",
      "Epoch 498/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4688 - acc: 0.7760 - val_loss: 0.4894 - val_acc: 0.7656\n",
      "Epoch 499/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4687 - acc: 0.7760 - val_loss: 0.4894 - val_acc: 0.7656\n",
      "Epoch 500/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4686 - acc: 0.7760 - val_loss: 0.4893 - val_acc: 0.7656\n",
      "Epoch 501/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4686 - acc: 0.7760 - val_loss: 0.4893 - val_acc: 0.7604\n",
      "Epoch 502/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4686 - acc: 0.7760 - val_loss: 0.4893 - val_acc: 0.7604\n",
      "Epoch 503/1000\n",
      "576/576 [==============================] - 0s 23us/sample - loss: 0.4685 - acc: 0.7760 - val_loss: 0.4893 - val_acc: 0.7604\n",
      "Epoch 504/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4685 - acc: 0.7760 - val_loss: 0.4893 - val_acc: 0.7604\n",
      "Epoch 505/1000\n",
      "576/576 [==============================] - 0s 23us/sample - loss: 0.4684 - acc: 0.7760 - val_loss: 0.4892 - val_acc: 0.7604\n",
      "Epoch 506/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4684 - acc: 0.7760 - val_loss: 0.4892 - val_acc: 0.7604\n",
      "Epoch 507/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4683 - acc: 0.7760 - val_loss: 0.4892 - val_acc: 0.7604\n",
      "Epoch 508/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4683 - acc: 0.7760 - val_loss: 0.4892 - val_acc: 0.7604\n",
      "Epoch 509/1000\n",
      "576/576 [==============================] - 0s 23us/sample - loss: 0.4682 - acc: 0.7743 - val_loss: 0.4891 - val_acc: 0.7604\n",
      "Epoch 510/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4682 - acc: 0.7743 - val_loss: 0.4891 - val_acc: 0.7604\n",
      "Epoch 511/1000\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4681 - acc: 0.7743 - val_loss: 0.4891 - val_acc: 0.7604\n",
      "Epoch 512/1000\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4681 - acc: 0.7760 - val_loss: 0.4891 - val_acc: 0.7604\n",
      "Epoch 513/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4681 - acc: 0.7743 - val_loss: 0.4891 - val_acc: 0.7604\n",
      "Epoch 514/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4680 - acc: 0.7743 - val_loss: 0.4890 - val_acc: 0.7604\n",
      "Epoch 515/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4680 - acc: 0.7760 - val_loss: 0.4890 - val_acc: 0.7604\n",
      "Epoch 516/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4679 - acc: 0.7760 - val_loss: 0.4890 - val_acc: 0.7604\n",
      "Epoch 517/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4679 - acc: 0.7760 - val_loss: 0.4890 - val_acc: 0.7604\n",
      "Epoch 518/1000\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4678 - acc: 0.7760 - val_loss: 0.4890 - val_acc: 0.7604\n",
      "Epoch 519/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4678 - acc: 0.7760 - val_loss: 0.4890 - val_acc: 0.7604\n",
      "Epoch 520/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4677 - acc: 0.7778 - val_loss: 0.4889 - val_acc: 0.7604\n",
      "Epoch 521/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4677 - acc: 0.7760 - val_loss: 0.4889 - val_acc: 0.7604\n",
      "Epoch 522/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4677 - acc: 0.7778 - val_loss: 0.4889 - val_acc: 0.7604\n",
      "Epoch 523/1000\n",
      "576/576 [==============================] - 0s 23us/sample - loss: 0.4676 - acc: 0.7778 - val_loss: 0.4889 - val_acc: 0.7604\n",
      "Epoch 524/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4676 - acc: 0.7778 - val_loss: 0.4889 - val_acc: 0.7604\n",
      "Epoch 525/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4675 - acc: 0.7778 - val_loss: 0.4888 - val_acc: 0.7604\n",
      "Epoch 526/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4675 - acc: 0.7778 - val_loss: 0.4888 - val_acc: 0.7604\n",
      "Epoch 527/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4674 - acc: 0.7778 - val_loss: 0.4888 - val_acc: 0.7604\n",
      "Epoch 528/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4674 - acc: 0.7778 - val_loss: 0.4888 - val_acc: 0.7604\n",
      "Epoch 529/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4674 - acc: 0.7778 - val_loss: 0.4888 - val_acc: 0.7604\n",
      "Epoch 530/1000\n",
      "576/576 [==============================] - 0s 23us/sample - loss: 0.4673 - acc: 0.7778 - val_loss: 0.4887 - val_acc: 0.7604\n",
      "Epoch 531/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4673 - acc: 0.7778 - val_loss: 0.4887 - val_acc: 0.7604\n",
      "Epoch 532/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4672 - acc: 0.7778 - val_loss: 0.4887 - val_acc: 0.7604\n",
      "Epoch 533/1000\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4672 - acc: 0.7778 - val_loss: 0.4887 - val_acc: 0.7604\n",
      "Epoch 534/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4671 - acc: 0.7778 - val_loss: 0.4887 - val_acc: 0.7604\n",
      "Epoch 535/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4671 - acc: 0.7795 - val_loss: 0.4887 - val_acc: 0.7604\n",
      "Epoch 536/1000\n",
      "576/576 [==============================] - 0s 23us/sample - loss: 0.4671 - acc: 0.7778 - val_loss: 0.4886 - val_acc: 0.7604\n",
      "Epoch 537/1000\n",
      "576/576 [==============================] - 0s 23us/sample - loss: 0.4670 - acc: 0.7778 - val_loss: 0.4886 - val_acc: 0.7604\n",
      "Epoch 538/1000\n",
      "576/576 [==============================] - 0s 23us/sample - loss: 0.4670 - acc: 0.7778 - val_loss: 0.4886 - val_acc: 0.7604\n",
      "Epoch 539/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4669 - acc: 0.7778 - val_loss: 0.4886 - val_acc: 0.7604\n",
      "Epoch 540/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4669 - acc: 0.7795 - val_loss: 0.4886 - val_acc: 0.7604\n",
      "Epoch 541/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4669 - acc: 0.7795 - val_loss: 0.4886 - val_acc: 0.7604\n",
      "Epoch 542/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4668 - acc: 0.7795 - val_loss: 0.4885 - val_acc: 0.7604\n",
      "Epoch 543/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4668 - acc: 0.7795 - val_loss: 0.4885 - val_acc: 0.7604\n",
      "Epoch 544/1000\n",
      "576/576 [==============================] - 0s 23us/sample - loss: 0.4667 - acc: 0.7795 - val_loss: 0.4885 - val_acc: 0.7604\n",
      "Epoch 545/1000\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4667 - acc: 0.7795 - val_loss: 0.4885 - val_acc: 0.7604\n",
      "Epoch 546/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4667 - acc: 0.7795 - val_loss: 0.4885 - val_acc: 0.7604\n",
      "Epoch 547/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4666 - acc: 0.7795 - val_loss: 0.4885 - val_acc: 0.7604\n",
      "Epoch 548/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4666 - acc: 0.7795 - val_loss: 0.4884 - val_acc: 0.7604\n",
      "Epoch 549/1000\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4666 - acc: 0.7795 - val_loss: 0.4884 - val_acc: 0.7604\n",
      "Epoch 550/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4665 - acc: 0.7795 - val_loss: 0.4884 - val_acc: 0.7604\n",
      "Epoch 551/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4665 - acc: 0.7795 - val_loss: 0.4884 - val_acc: 0.7604\n",
      "Epoch 552/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4664 - acc: 0.7795 - val_loss: 0.4884 - val_acc: 0.7604\n",
      "Epoch 553/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4664 - acc: 0.7795 - val_loss: 0.4884 - val_acc: 0.7604\n",
      "Epoch 554/1000\n",
      "576/576 [==============================] - 0s 23us/sample - loss: 0.4663 - acc: 0.7795 - val_loss: 0.4884 - val_acc: 0.7604\n",
      "Epoch 555/1000\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4663 - acc: 0.7795 - val_loss: 0.4883 - val_acc: 0.7604\n",
      "Epoch 556/1000\n",
      "576/576 [==============================] - 0s 23us/sample - loss: 0.4663 - acc: 0.7795 - val_loss: 0.4883 - val_acc: 0.7604\n",
      "Epoch 557/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4662 - acc: 0.7795 - val_loss: 0.4883 - val_acc: 0.7604\n",
      "Epoch 558/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4662 - acc: 0.7795 - val_loss: 0.4883 - val_acc: 0.7604\n",
      "Epoch 559/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4661 - acc: 0.7795 - val_loss: 0.4883 - val_acc: 0.7604\n",
      "Epoch 560/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4661 - acc: 0.7795 - val_loss: 0.4883 - val_acc: 0.7604\n",
      "Epoch 561/1000\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4661 - acc: 0.7795 - val_loss: 0.4883 - val_acc: 0.7604\n",
      "Epoch 562/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4660 - acc: 0.7795 - val_loss: 0.4882 - val_acc: 0.7604\n",
      "Epoch 563/1000\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4660 - acc: 0.7795 - val_loss: 0.4882 - val_acc: 0.7604\n",
      "Epoch 564/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4660 - acc: 0.7795 - val_loss: 0.4882 - val_acc: 0.7604\n",
      "Epoch 565/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4659 - acc: 0.7795 - val_loss: 0.4882 - val_acc: 0.7604\n",
      "Epoch 566/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4659 - acc: 0.7812 - val_loss: 0.4882 - val_acc: 0.7604\n",
      "Epoch 567/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4659 - acc: 0.7795 - val_loss: 0.4882 - val_acc: 0.7604\n",
      "Epoch 568/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4658 - acc: 0.7795 - val_loss: 0.4882 - val_acc: 0.7604\n",
      "Epoch 569/1000\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4658 - acc: 0.7795 - val_loss: 0.4881 - val_acc: 0.7604\n",
      "Epoch 570/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4657 - acc: 0.7795 - val_loss: 0.4881 - val_acc: 0.7604\n",
      "Epoch 571/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4657 - acc: 0.7795 - val_loss: 0.4881 - val_acc: 0.7604\n",
      "Epoch 572/1000\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4657 - acc: 0.7812 - val_loss: 0.4881 - val_acc: 0.7604\n",
      "Epoch 573/1000\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4657 - acc: 0.7795 - val_loss: 0.4881 - val_acc: 0.7604\n",
      "Epoch 574/1000\n",
      "576/576 [==============================] - 0s 23us/sample - loss: 0.4656 - acc: 0.7795 - val_loss: 0.4881 - val_acc: 0.7604\n",
      "Epoch 575/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4656 - acc: 0.7795 - val_loss: 0.4881 - val_acc: 0.7604\n",
      "Epoch 576/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4655 - acc: 0.7795 - val_loss: 0.4880 - val_acc: 0.7604\n",
      "Epoch 577/1000\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4655 - acc: 0.7812 - val_loss: 0.4880 - val_acc: 0.7604\n",
      "Epoch 578/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4655 - acc: 0.7830 - val_loss: 0.4880 - val_acc: 0.7604\n",
      "Epoch 579/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4654 - acc: 0.7812 - val_loss: 0.4880 - val_acc: 0.7604\n",
      "Epoch 580/1000\n",
      "576/576 [==============================] - 0s 23us/sample - loss: 0.4654 - acc: 0.7830 - val_loss: 0.4880 - val_acc: 0.7604\n",
      "Epoch 581/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4653 - acc: 0.7812 - val_loss: 0.4880 - val_acc: 0.7604\n",
      "Epoch 582/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4653 - acc: 0.7812 - val_loss: 0.4880 - val_acc: 0.7604\n",
      "Epoch 583/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4653 - acc: 0.7830 - val_loss: 0.4880 - val_acc: 0.7604\n",
      "Epoch 584/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4652 - acc: 0.7812 - val_loss: 0.4879 - val_acc: 0.7604\n",
      "Epoch 585/1000\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4652 - acc: 0.7830 - val_loss: 0.4879 - val_acc: 0.7604\n",
      "Epoch 586/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4652 - acc: 0.7830 - val_loss: 0.4879 - val_acc: 0.7604\n",
      "Epoch 587/1000\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4651 - acc: 0.7812 - val_loss: 0.4879 - val_acc: 0.7604\n",
      "Epoch 588/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4651 - acc: 0.7830 - val_loss: 0.4879 - val_acc: 0.7604\n",
      "Epoch 589/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4651 - acc: 0.7812 - val_loss: 0.4879 - val_acc: 0.7604\n",
      "Epoch 590/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4651 - acc: 0.7812 - val_loss: 0.4879 - val_acc: 0.7604\n",
      "Epoch 591/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4650 - acc: 0.7812 - val_loss: 0.4879 - val_acc: 0.7604\n",
      "Epoch 592/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4650 - acc: 0.7830 - val_loss: 0.4879 - val_acc: 0.7604\n",
      "Epoch 593/1000\n",
      "576/576 [==============================] - 0s 23us/sample - loss: 0.4649 - acc: 0.7812 - val_loss: 0.4878 - val_acc: 0.7604\n",
      "Epoch 594/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4649 - acc: 0.7830 - val_loss: 0.4878 - val_acc: 0.7604\n",
      "Epoch 595/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4649 - acc: 0.7812 - val_loss: 0.4878 - val_acc: 0.7604\n",
      "Epoch 596/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4648 - acc: 0.7812 - val_loss: 0.4878 - val_acc: 0.7604\n",
      "Epoch 597/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4648 - acc: 0.7812 - val_loss: 0.4878 - val_acc: 0.7604\n",
      "Epoch 598/1000\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4648 - acc: 0.7830 - val_loss: 0.4878 - val_acc: 0.7604\n",
      "Epoch 599/1000\n",
      "576/576 [==============================] - 0s 38us/sample - loss: 0.4647 - acc: 0.7812 - val_loss: 0.4878 - val_acc: 0.7604\n",
      "Epoch 600/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4647 - acc: 0.7830 - val_loss: 0.4878 - val_acc: 0.7604\n",
      "Epoch 601/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4647 - acc: 0.7812 - val_loss: 0.4878 - val_acc: 0.7604\n",
      "Epoch 602/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4647 - acc: 0.7812 - val_loss: 0.4877 - val_acc: 0.7604\n",
      "Epoch 603/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4646 - acc: 0.7830 - val_loss: 0.4877 - val_acc: 0.7604\n",
      "Epoch 604/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4646 - acc: 0.7812 - val_loss: 0.4877 - val_acc: 0.7604\n",
      "Epoch 605/1000\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4646 - acc: 0.7812 - val_loss: 0.4877 - val_acc: 0.7604\n",
      "Epoch 606/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4645 - acc: 0.7812 - val_loss: 0.4877 - val_acc: 0.7604\n",
      "Epoch 607/1000\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4645 - acc: 0.7830 - val_loss: 0.4877 - val_acc: 0.7604\n",
      "Epoch 608/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4645 - acc: 0.7812 - val_loss: 0.4877 - val_acc: 0.7604\n",
      "Epoch 609/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4644 - acc: 0.7795 - val_loss: 0.4877 - val_acc: 0.7604\n",
      "Epoch 610/1000\n",
      "576/576 [==============================] - 0s 23us/sample - loss: 0.4644 - acc: 0.7812 - val_loss: 0.4877 - val_acc: 0.7604\n",
      "Epoch 611/1000\n",
      "576/576 [==============================] - 0s 23us/sample - loss: 0.4643 - acc: 0.7812 - val_loss: 0.4876 - val_acc: 0.7604\n",
      "Epoch 612/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4643 - acc: 0.7812 - val_loss: 0.4876 - val_acc: 0.7604\n",
      "Epoch 613/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4643 - acc: 0.7812 - val_loss: 0.4876 - val_acc: 0.7604\n",
      "Epoch 614/1000\n",
      "576/576 [==============================] - 0s 23us/sample - loss: 0.4643 - acc: 0.7812 - val_loss: 0.4876 - val_acc: 0.7604\n",
      "Epoch 615/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4642 - acc: 0.7812 - val_loss: 0.4876 - val_acc: 0.7604\n",
      "Epoch 616/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4642 - acc: 0.7812 - val_loss: 0.4876 - val_acc: 0.7604\n",
      "Epoch 617/1000\n",
      "576/576 [==============================] - 0s 23us/sample - loss: 0.4642 - acc: 0.7812 - val_loss: 0.4876 - val_acc: 0.7604\n",
      "Epoch 618/1000\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4641 - acc: 0.7812 - val_loss: 0.4876 - val_acc: 0.7604\n",
      "Epoch 619/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4641 - acc: 0.7812 - val_loss: 0.4876 - val_acc: 0.7604\n",
      "Epoch 620/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4641 - acc: 0.7812 - val_loss: 0.4876 - val_acc: 0.7604\n",
      "Epoch 621/1000\n",
      "576/576 [==============================] - 0s 23us/sample - loss: 0.4640 - acc: 0.7812 - val_loss: 0.4876 - val_acc: 0.7604\n",
      "Epoch 622/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4640 - acc: 0.7795 - val_loss: 0.4875 - val_acc: 0.7604\n",
      "Epoch 623/1000\n",
      "576/576 [==============================] - 0s 23us/sample - loss: 0.4640 - acc: 0.7795 - val_loss: 0.4875 - val_acc: 0.7604\n",
      "Epoch 624/1000\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4640 - acc: 0.7795 - val_loss: 0.4875 - val_acc: 0.7604\n",
      "Epoch 625/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4639 - acc: 0.7795 - val_loss: 0.4875 - val_acc: 0.7604\n",
      "Epoch 626/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4639 - acc: 0.7795 - val_loss: 0.4875 - val_acc: 0.7604\n",
      "Epoch 627/1000\n",
      "576/576 [==============================] - 0s 23us/sample - loss: 0.4639 - acc: 0.7795 - val_loss: 0.4875 - val_acc: 0.7604\n",
      "Epoch 628/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4638 - acc: 0.7795 - val_loss: 0.4875 - val_acc: 0.7604\n",
      "Epoch 629/1000\n",
      "576/576 [==============================] - 0s 23us/sample - loss: 0.4638 - acc: 0.7795 - val_loss: 0.4875 - val_acc: 0.7604\n",
      "Epoch 630/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4638 - acc: 0.7795 - val_loss: 0.4875 - val_acc: 0.7604\n",
      "Epoch 631/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4637 - acc: 0.7795 - val_loss: 0.4875 - val_acc: 0.7604\n",
      "Epoch 632/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4637 - acc: 0.7795 - val_loss: 0.4875 - val_acc: 0.7604\n",
      "Epoch 633/1000\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4637 - acc: 0.7795 - val_loss: 0.4874 - val_acc: 0.7604\n",
      "Epoch 634/1000\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4637 - acc: 0.7795 - val_loss: 0.4874 - val_acc: 0.7604\n",
      "Epoch 635/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4636 - acc: 0.7795 - val_loss: 0.4874 - val_acc: 0.7604\n",
      "Epoch 636/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4636 - acc: 0.7795 - val_loss: 0.4874 - val_acc: 0.7604\n",
      "Epoch 637/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4636 - acc: 0.7795 - val_loss: 0.4874 - val_acc: 0.7604\n",
      "Epoch 638/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4636 - acc: 0.7795 - val_loss: 0.4874 - val_acc: 0.7604\n",
      "Epoch 639/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4635 - acc: 0.7795 - val_loss: 0.4874 - val_acc: 0.7604\n",
      "Epoch 640/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4635 - acc: 0.7795 - val_loss: 0.4874 - val_acc: 0.7604\n",
      "Epoch 641/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4634 - acc: 0.7795 - val_loss: 0.4874 - val_acc: 0.7604\n",
      "Epoch 642/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4634 - acc: 0.7795 - val_loss: 0.4874 - val_acc: 0.7604\n",
      "Epoch 643/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4634 - acc: 0.7795 - val_loss: 0.4874 - val_acc: 0.7604\n",
      "Epoch 644/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4634 - acc: 0.7795 - val_loss: 0.4874 - val_acc: 0.7604\n",
      "Epoch 645/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4633 - acc: 0.7795 - val_loss: 0.4874 - val_acc: 0.7604\n",
      "Epoch 646/1000\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4633 - acc: 0.7795 - val_loss: 0.4873 - val_acc: 0.7604\n",
      "Epoch 647/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4633 - acc: 0.7795 - val_loss: 0.4873 - val_acc: 0.7604\n",
      "Epoch 648/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4633 - acc: 0.7795 - val_loss: 0.4873 - val_acc: 0.7604\n",
      "Epoch 649/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4632 - acc: 0.7795 - val_loss: 0.4873 - val_acc: 0.7604\n",
      "Epoch 650/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4632 - acc: 0.7778 - val_loss: 0.4873 - val_acc: 0.7604\n",
      "Epoch 651/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4632 - acc: 0.7778 - val_loss: 0.4873 - val_acc: 0.7604\n",
      "Epoch 652/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4632 - acc: 0.7778 - val_loss: 0.4873 - val_acc: 0.7604\n",
      "Epoch 653/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4631 - acc: 0.7778 - val_loss: 0.4873 - val_acc: 0.7604\n",
      "Epoch 654/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4631 - acc: 0.7778 - val_loss: 0.4873 - val_acc: 0.7604\n",
      "Epoch 655/1000\n",
      "576/576 [==============================] - 0s 23us/sample - loss: 0.4631 - acc: 0.7778 - val_loss: 0.4873 - val_acc: 0.7604\n",
      "Epoch 656/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4630 - acc: 0.7778 - val_loss: 0.4873 - val_acc: 0.7604\n",
      "Epoch 657/1000\n",
      "576/576 [==============================] - 0s 23us/sample - loss: 0.4630 - acc: 0.7778 - val_loss: 0.4873 - val_acc: 0.7604\n",
      "Epoch 658/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4630 - acc: 0.7795 - val_loss: 0.4873 - val_acc: 0.7604\n",
      "Epoch 659/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4630 - acc: 0.7795 - val_loss: 0.4873 - val_acc: 0.7604\n",
      "Epoch 660/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4629 - acc: 0.7795 - val_loss: 0.4872 - val_acc: 0.7604\n",
      "Epoch 661/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4629 - acc: 0.7778 - val_loss: 0.4872 - val_acc: 0.7604\n",
      "Epoch 662/1000\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4629 - acc: 0.7778 - val_loss: 0.4872 - val_acc: 0.7604\n",
      "Epoch 663/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4628 - acc: 0.7778 - val_loss: 0.4872 - val_acc: 0.7604\n",
      "Epoch 664/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4628 - acc: 0.7778 - val_loss: 0.4872 - val_acc: 0.7604\n",
      "Epoch 665/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4628 - acc: 0.7795 - val_loss: 0.4872 - val_acc: 0.7604\n",
      "Epoch 666/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4628 - acc: 0.7778 - val_loss: 0.4872 - val_acc: 0.7604\n",
      "Epoch 667/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4628 - acc: 0.7778 - val_loss: 0.4872 - val_acc: 0.7604\n",
      "Epoch 668/1000\n",
      "576/576 [==============================] - 0s 23us/sample - loss: 0.4627 - acc: 0.7778 - val_loss: 0.4872 - val_acc: 0.7604\n",
      "Epoch 669/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4627 - acc: 0.7795 - val_loss: 0.4872 - val_acc: 0.7604\n",
      "Epoch 670/1000\n",
      "576/576 [==============================] - 0s 23us/sample - loss: 0.4627 - acc: 0.7795 - val_loss: 0.4872 - val_acc: 0.7604\n",
      "Epoch 671/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4626 - acc: 0.7795 - val_loss: 0.4872 - val_acc: 0.7604\n",
      "Epoch 672/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4626 - acc: 0.7795 - val_loss: 0.4872 - val_acc: 0.7604\n",
      "Epoch 673/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4626 - acc: 0.7795 - val_loss: 0.4872 - val_acc: 0.7604\n",
      "Epoch 674/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4626 - acc: 0.7795 - val_loss: 0.4872 - val_acc: 0.7604\n",
      "Epoch 675/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4625 - acc: 0.7795 - val_loss: 0.4872 - val_acc: 0.7604\n",
      "Epoch 676/1000\n",
      "576/576 [==============================] - 0s 23us/sample - loss: 0.4625 - acc: 0.7795 - val_loss: 0.4871 - val_acc: 0.7604\n",
      "Epoch 677/1000\n",
      "576/576 [==============================] - 0s 23us/sample - loss: 0.4625 - acc: 0.7795 - val_loss: 0.4871 - val_acc: 0.7604\n",
      "Epoch 678/1000\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4625 - acc: 0.7812 - val_loss: 0.4871 - val_acc: 0.7604\n",
      "Epoch 679/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4625 - acc: 0.7812 - val_loss: 0.4871 - val_acc: 0.7604\n",
      "Epoch 680/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4624 - acc: 0.7812 - val_loss: 0.4871 - val_acc: 0.7604\n",
      "Epoch 681/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4624 - acc: 0.7812 - val_loss: 0.4871 - val_acc: 0.7604\n",
      "Epoch 682/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4624 - acc: 0.7812 - val_loss: 0.4871 - val_acc: 0.7604\n",
      "Epoch 683/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4623 - acc: 0.7812 - val_loss: 0.4871 - val_acc: 0.7604\n",
      "Epoch 684/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4623 - acc: 0.7812 - val_loss: 0.4871 - val_acc: 0.7604\n",
      "Epoch 685/1000\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4623 - acc: 0.7812 - val_loss: 0.4871 - val_acc: 0.7604\n",
      "Epoch 686/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4623 - acc: 0.7812 - val_loss: 0.4871 - val_acc: 0.7604\n",
      "Epoch 687/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4623 - acc: 0.7812 - val_loss: 0.4871 - val_acc: 0.7604\n",
      "Epoch 688/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4622 - acc: 0.7812 - val_loss: 0.4871 - val_acc: 0.7604\n",
      "Epoch 689/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4622 - acc: 0.7812 - val_loss: 0.4871 - val_acc: 0.7604\n",
      "Epoch 690/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4622 - acc: 0.7812 - val_loss: 0.4871 - val_acc: 0.7604\n",
      "Epoch 691/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4622 - acc: 0.7812 - val_loss: 0.4871 - val_acc: 0.7604\n",
      "Epoch 692/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4621 - acc: 0.7812 - val_loss: 0.4871 - val_acc: 0.7604\n",
      "Epoch 693/1000\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4621 - acc: 0.7812 - val_loss: 0.4871 - val_acc: 0.7604\n",
      "Epoch 694/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4621 - acc: 0.7812 - val_loss: 0.4871 - val_acc: 0.7604\n",
      "Epoch 695/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4621 - acc: 0.7812 - val_loss: 0.4871 - val_acc: 0.7604\n",
      "Epoch 696/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4620 - acc: 0.7812 - val_loss: 0.4870 - val_acc: 0.7604\n",
      "Epoch 697/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4620 - acc: 0.7812 - val_loss: 0.4870 - val_acc: 0.7604\n",
      "Epoch 698/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4620 - acc: 0.7812 - val_loss: 0.4870 - val_acc: 0.7604\n",
      "Epoch 699/1000\n",
      "576/576 [==============================] - 0s 23us/sample - loss: 0.4620 - acc: 0.7812 - val_loss: 0.4870 - val_acc: 0.7604\n",
      "Epoch 700/1000\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4619 - acc: 0.7812 - val_loss: 0.4870 - val_acc: 0.7604\n",
      "Epoch 701/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4619 - acc: 0.7812 - val_loss: 0.4870 - val_acc: 0.7604\n",
      "Epoch 702/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4619 - acc: 0.7812 - val_loss: 0.4870 - val_acc: 0.7604\n",
      "Epoch 703/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4619 - acc: 0.7812 - val_loss: 0.4870 - val_acc: 0.7604\n",
      "Epoch 704/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4618 - acc: 0.7812 - val_loss: 0.4870 - val_acc: 0.7604\n",
      "Epoch 705/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4618 - acc: 0.7812 - val_loss: 0.4870 - val_acc: 0.7604\n",
      "Epoch 706/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4618 - acc: 0.7812 - val_loss: 0.4870 - val_acc: 0.7604\n",
      "Epoch 707/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4618 - acc: 0.7812 - val_loss: 0.4870 - val_acc: 0.7604\n",
      "Epoch 708/1000\n",
      "576/576 [==============================] - 0s 23us/sample - loss: 0.4618 - acc: 0.7812 - val_loss: 0.4870 - val_acc: 0.7604\n",
      "Epoch 709/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4617 - acc: 0.7812 - val_loss: 0.4870 - val_acc: 0.7604\n",
      "Epoch 710/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4617 - acc: 0.7812 - val_loss: 0.4870 - val_acc: 0.7604\n",
      "Epoch 711/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4617 - acc: 0.7812 - val_loss: 0.4870 - val_acc: 0.7604\n",
      "Epoch 712/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4617 - acc: 0.7812 - val_loss: 0.4870 - val_acc: 0.7604\n",
      "Epoch 713/1000\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4617 - acc: 0.7812 - val_loss: 0.4870 - val_acc: 0.7604\n",
      "Epoch 714/1000\n",
      "576/576 [==============================] - 0s 23us/sample - loss: 0.4616 - acc: 0.7812 - val_loss: 0.4870 - val_acc: 0.7604\n",
      "Epoch 715/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4616 - acc: 0.7812 - val_loss: 0.4870 - val_acc: 0.7604\n",
      "Epoch 716/1000\n",
      "576/576 [==============================] - 0s 23us/sample - loss: 0.4616 - acc: 0.7812 - val_loss: 0.4870 - val_acc: 0.7604\n",
      "Epoch 717/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4615 - acc: 0.7812 - val_loss: 0.4870 - val_acc: 0.7604\n",
      "Epoch 718/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4615 - acc: 0.7812 - val_loss: 0.4870 - val_acc: 0.7604\n",
      "Epoch 719/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4615 - acc: 0.7812 - val_loss: 0.4869 - val_acc: 0.7604\n",
      "Epoch 720/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4615 - acc: 0.7812 - val_loss: 0.4869 - val_acc: 0.7604\n",
      "Epoch 721/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4615 - acc: 0.7812 - val_loss: 0.4869 - val_acc: 0.7604\n",
      "Epoch 722/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4614 - acc: 0.7812 - val_loss: 0.4869 - val_acc: 0.7604\n",
      "Epoch 723/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4614 - acc: 0.7812 - val_loss: 0.4869 - val_acc: 0.7604\n",
      "Epoch 724/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4614 - acc: 0.7812 - val_loss: 0.4869 - val_acc: 0.7604\n",
      "Epoch 725/1000\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4614 - acc: 0.7812 - val_loss: 0.4869 - val_acc: 0.7604\n",
      "Epoch 726/1000\n",
      "576/576 [==============================] - 0s 23us/sample - loss: 0.4613 - acc: 0.7812 - val_loss: 0.4869 - val_acc: 0.7604\n",
      "Epoch 727/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4613 - acc: 0.7812 - val_loss: 0.4869 - val_acc: 0.7604\n",
      "Epoch 728/1000\n",
      "576/576 [==============================] - 0s 23us/sample - loss: 0.4613 - acc: 0.7812 - val_loss: 0.4869 - val_acc: 0.7604\n",
      "Epoch 729/1000\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4613 - acc: 0.7812 - val_loss: 0.4869 - val_acc: 0.7604\n",
      "Epoch 730/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4613 - acc: 0.7812 - val_loss: 0.4869 - val_acc: 0.7604\n",
      "Epoch 731/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4613 - acc: 0.7812 - val_loss: 0.4869 - val_acc: 0.7604\n",
      "Epoch 732/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4612 - acc: 0.7812 - val_loss: 0.4869 - val_acc: 0.7604\n",
      "Epoch 733/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4612 - acc: 0.7812 - val_loss: 0.4869 - val_acc: 0.7604\n",
      "Epoch 734/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4612 - acc: 0.7812 - val_loss: 0.4869 - val_acc: 0.7604\n",
      "Epoch 735/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4612 - acc: 0.7812 - val_loss: 0.4869 - val_acc: 0.7604\n",
      "Epoch 736/1000\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4612 - acc: 0.7812 - val_loss: 0.4869 - val_acc: 0.7604\n",
      "Epoch 737/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4611 - acc: 0.7812 - val_loss: 0.4869 - val_acc: 0.7604\n",
      "Epoch 738/1000\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4611 - acc: 0.7812 - val_loss: 0.4869 - val_acc: 0.7604\n",
      "Epoch 739/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4611 - acc: 0.7812 - val_loss: 0.4869 - val_acc: 0.7604\n",
      "Epoch 740/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4611 - acc: 0.7795 - val_loss: 0.4869 - val_acc: 0.7604\n",
      "Epoch 741/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4610 - acc: 0.7812 - val_loss: 0.4869 - val_acc: 0.7604\n",
      "Epoch 742/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4610 - acc: 0.7795 - val_loss: 0.4869 - val_acc: 0.7604\n",
      "Epoch 743/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4610 - acc: 0.7795 - val_loss: 0.4869 - val_acc: 0.7604\n",
      "Epoch 744/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4610 - acc: 0.7795 - val_loss: 0.4869 - val_acc: 0.7604\n",
      "Epoch 745/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4610 - acc: 0.7795 - val_loss: 0.4869 - val_acc: 0.7604\n",
      "Epoch 746/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4610 - acc: 0.7795 - val_loss: 0.4869 - val_acc: 0.7604\n",
      "Epoch 747/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4609 - acc: 0.7795 - val_loss: 0.4869 - val_acc: 0.7604\n",
      "Epoch 748/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4609 - acc: 0.7795 - val_loss: 0.4869 - val_acc: 0.7604\n",
      "Epoch 749/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4609 - acc: 0.7795 - val_loss: 0.4869 - val_acc: 0.7604\n",
      "Epoch 750/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4609 - acc: 0.7795 - val_loss: 0.4869 - val_acc: 0.7604\n",
      "Epoch 751/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4609 - acc: 0.7795 - val_loss: 0.4869 - val_acc: 0.7604\n",
      "Epoch 752/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4608 - acc: 0.7795 - val_loss: 0.4869 - val_acc: 0.7604\n",
      "Epoch 753/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4608 - acc: 0.7795 - val_loss: 0.4869 - val_acc: 0.7604\n",
      "Epoch 754/1000\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4608 - acc: 0.7795 - val_loss: 0.4869 - val_acc: 0.7604\n",
      "Epoch 755/1000\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4608 - acc: 0.7795 - val_loss: 0.4868 - val_acc: 0.7604\n",
      "Epoch 756/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4608 - acc: 0.7795 - val_loss: 0.4868 - val_acc: 0.7604\n",
      "Epoch 757/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4608 - acc: 0.7795 - val_loss: 0.4868 - val_acc: 0.7604\n",
      "Epoch 758/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4607 - acc: 0.7795 - val_loss: 0.4868 - val_acc: 0.7604\n",
      "Epoch 759/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4607 - acc: 0.7795 - val_loss: 0.4868 - val_acc: 0.7604\n",
      "Epoch 760/1000\n",
      "576/576 [==============================] - 0s 23us/sample - loss: 0.4607 - acc: 0.7795 - val_loss: 0.4868 - val_acc: 0.7604\n",
      "Epoch 761/1000\n",
      "576/576 [==============================] - 0s 23us/sample - loss: 0.4607 - acc: 0.7795 - val_loss: 0.4868 - val_acc: 0.7604\n",
      "Epoch 762/1000\n",
      "576/576 [==============================] - 0s 23us/sample - loss: 0.4607 - acc: 0.7795 - val_loss: 0.4868 - val_acc: 0.7604\n",
      "Epoch 763/1000\n",
      "576/576 [==============================] - 0s 23us/sample - loss: 0.4606 - acc: 0.7795 - val_loss: 0.4868 - val_acc: 0.7604\n",
      "Epoch 764/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4606 - acc: 0.7795 - val_loss: 0.4868 - val_acc: 0.7604\n",
      "Epoch 765/1000\n",
      "576/576 [==============================] - 0s 23us/sample - loss: 0.4606 - acc: 0.7795 - val_loss: 0.4868 - val_acc: 0.7604\n",
      "Epoch 766/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4605 - acc: 0.7795 - val_loss: 0.4868 - val_acc: 0.7604\n",
      "Epoch 767/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4605 - acc: 0.7795 - val_loss: 0.4868 - val_acc: 0.7604\n",
      "Epoch 768/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4605 - acc: 0.7795 - val_loss: 0.4868 - val_acc: 0.7604\n",
      "Epoch 769/1000\n",
      "576/576 [==============================] - 0s 23us/sample - loss: 0.4605 - acc: 0.7795 - val_loss: 0.4868 - val_acc: 0.7604\n",
      "Epoch 770/1000\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4605 - acc: 0.7795 - val_loss: 0.4868 - val_acc: 0.7604\n",
      "Epoch 771/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4605 - acc: 0.7795 - val_loss: 0.4868 - val_acc: 0.7604\n",
      "Epoch 772/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4604 - acc: 0.7795 - val_loss: 0.4868 - val_acc: 0.7604\n",
      "Epoch 773/1000\n",
      "576/576 [==============================] - 0s 23us/sample - loss: 0.4604 - acc: 0.7795 - val_loss: 0.4868 - val_acc: 0.7604\n",
      "Epoch 774/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4604 - acc: 0.7795 - val_loss: 0.4868 - val_acc: 0.7604\n",
      "Epoch 775/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4604 - acc: 0.7795 - val_loss: 0.4868 - val_acc: 0.7604\n",
      "Epoch 776/1000\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4604 - acc: 0.7795 - val_loss: 0.4868 - val_acc: 0.7604\n",
      "Epoch 777/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4603 - acc: 0.7795 - val_loss: 0.4868 - val_acc: 0.7604\n",
      "Epoch 778/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4603 - acc: 0.7795 - val_loss: 0.4868 - val_acc: 0.7604\n",
      "Epoch 779/1000\n",
      "576/576 [==============================] - 0s 23us/sample - loss: 0.4603 - acc: 0.7795 - val_loss: 0.4868 - val_acc: 0.7604\n",
      "Epoch 780/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4603 - acc: 0.7795 - val_loss: 0.4868 - val_acc: 0.7604\n",
      "Epoch 781/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4603 - acc: 0.7795 - val_loss: 0.4868 - val_acc: 0.7604\n",
      "Epoch 782/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4603 - acc: 0.7795 - val_loss: 0.4868 - val_acc: 0.7604\n",
      "Epoch 783/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4602 - acc: 0.7795 - val_loss: 0.4868 - val_acc: 0.7604\n",
      "Epoch 784/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4602 - acc: 0.7795 - val_loss: 0.4868 - val_acc: 0.7604\n",
      "Epoch 785/1000\n",
      "576/576 [==============================] - 0s 23us/sample - loss: 0.4602 - acc: 0.7795 - val_loss: 0.4868 - val_acc: 0.7604\n",
      "Epoch 786/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4602 - acc: 0.7795 - val_loss: 0.4868 - val_acc: 0.7604\n",
      "Epoch 787/1000\n",
      "576/576 [==============================] - 0s 23us/sample - loss: 0.4602 - acc: 0.7795 - val_loss: 0.4868 - val_acc: 0.7604\n",
      "Epoch 788/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4602 - acc: 0.7795 - val_loss: 0.4868 - val_acc: 0.7604\n",
      "Epoch 789/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4601 - acc: 0.7795 - val_loss: 0.4868 - val_acc: 0.7604\n",
      "Epoch 790/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4601 - acc: 0.7795 - val_loss: 0.4868 - val_acc: 0.7604\n",
      "Epoch 791/1000\n",
      "576/576 [==============================] - 0s 23us/sample - loss: 0.4601 - acc: 0.7795 - val_loss: 0.4868 - val_acc: 0.7604\n",
      "Epoch 792/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4601 - acc: 0.7795 - val_loss: 0.4868 - val_acc: 0.7604\n",
      "Epoch 793/1000\n",
      "576/576 [==============================] - 0s 23us/sample - loss: 0.4601 - acc: 0.7795 - val_loss: 0.4868 - val_acc: 0.7604\n",
      "Epoch 794/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4601 - acc: 0.7795 - val_loss: 0.4868 - val_acc: 0.7604\n",
      "Epoch 795/1000\n",
      "576/576 [==============================] - 0s 23us/sample - loss: 0.4600 - acc: 0.7795 - val_loss: 0.4868 - val_acc: 0.7604\n",
      "Epoch 796/1000\n",
      "576/576 [==============================] - 0s 23us/sample - loss: 0.4600 - acc: 0.7795 - val_loss: 0.4868 - val_acc: 0.7604\n",
      "Epoch 797/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4600 - acc: 0.7795 - val_loss: 0.4868 - val_acc: 0.7604\n",
      "Epoch 798/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4600 - acc: 0.7795 - val_loss: 0.4868 - val_acc: 0.7604\n",
      "Epoch 799/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4600 - acc: 0.7795 - val_loss: 0.4868 - val_acc: 0.7604\n",
      "Epoch 800/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4600 - acc: 0.7795 - val_loss: 0.4868 - val_acc: 0.7604\n",
      "Epoch 801/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4599 - acc: 0.7795 - val_loss: 0.4868 - val_acc: 0.7604\n",
      "Epoch 802/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4599 - acc: 0.7812 - val_loss: 0.4868 - val_acc: 0.7604\n",
      "Epoch 803/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4599 - acc: 0.7795 - val_loss: 0.4868 - val_acc: 0.7604\n",
      "Epoch 804/1000\n",
      "576/576 [==============================] - 0s 23us/sample - loss: 0.4599 - acc: 0.7795 - val_loss: 0.4868 - val_acc: 0.7604\n",
      "Epoch 805/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4599 - acc: 0.7795 - val_loss: 0.4868 - val_acc: 0.7604\n",
      "Epoch 806/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4599 - acc: 0.7812 - val_loss: 0.4868 - val_acc: 0.7604\n",
      "Epoch 807/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4598 - acc: 0.7795 - val_loss: 0.4868 - val_acc: 0.7604\n",
      "Epoch 808/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4598 - acc: 0.7795 - val_loss: 0.4868 - val_acc: 0.7604\n",
      "Epoch 809/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4598 - acc: 0.7795 - val_loss: 0.4868 - val_acc: 0.7604\n",
      "Epoch 810/1000\n",
      "576/576 [==============================] - 0s 23us/sample - loss: 0.4598 - acc: 0.7795 - val_loss: 0.4868 - val_acc: 0.7604\n",
      "Epoch 811/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4598 - acc: 0.7795 - val_loss: 0.4868 - val_acc: 0.7604\n",
      "Epoch 812/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4598 - acc: 0.7812 - val_loss: 0.4868 - val_acc: 0.7604\n",
      "Epoch 813/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4597 - acc: 0.7795 - val_loss: 0.4868 - val_acc: 0.7604\n",
      "Epoch 814/1000\n",
      "576/576 [==============================] - 0s 23us/sample - loss: 0.4597 - acc: 0.7795 - val_loss: 0.4868 - val_acc: 0.7604\n",
      "Epoch 815/1000\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4597 - acc: 0.7812 - val_loss: 0.4868 - val_acc: 0.7604\n",
      "Epoch 816/1000\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4597 - acc: 0.7795 - val_loss: 0.4868 - val_acc: 0.7604\n",
      "Epoch 817/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4597 - acc: 0.7795 - val_loss: 0.4868 - val_acc: 0.7604\n",
      "Epoch 818/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4597 - acc: 0.7812 - val_loss: 0.4868 - val_acc: 0.7604\n",
      "Epoch 819/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4596 - acc: 0.7795 - val_loss: 0.4868 - val_acc: 0.7604\n",
      "Epoch 820/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4596 - acc: 0.7795 - val_loss: 0.4868 - val_acc: 0.7604\n",
      "Epoch 821/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4596 - acc: 0.7812 - val_loss: 0.4868 - val_acc: 0.7604\n",
      "Epoch 822/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4596 - acc: 0.7812 - val_loss: 0.4868 - val_acc: 0.7604\n",
      "Epoch 823/1000\n",
      "576/576 [==============================] - 0s 23us/sample - loss: 0.4596 - acc: 0.7795 - val_loss: 0.4868 - val_acc: 0.7604\n",
      "Epoch 824/1000\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4596 - acc: 0.7795 - val_loss: 0.4868 - val_acc: 0.7604\n",
      "Epoch 825/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4595 - acc: 0.7812 - val_loss: 0.4868 - val_acc: 0.7604\n",
      "Epoch 826/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4595 - acc: 0.7795 - val_loss: 0.4868 - val_acc: 0.7604\n",
      "Epoch 827/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4595 - acc: 0.7812 - val_loss: 0.4868 - val_acc: 0.7604\n",
      "Epoch 828/1000\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4595 - acc: 0.7795 - val_loss: 0.4868 - val_acc: 0.7604\n",
      "Epoch 829/1000\n",
      "576/576 [==============================] - 0s 23us/sample - loss: 0.4595 - acc: 0.7812 - val_loss: 0.4868 - val_acc: 0.7604\n",
      "Epoch 830/1000\n",
      "576/576 [==============================] - 0s 23us/sample - loss: 0.4595 - acc: 0.7795 - val_loss: 0.4868 - val_acc: 0.7604\n",
      "Epoch 831/1000\n",
      "576/576 [==============================] - 0s 23us/sample - loss: 0.4595 - acc: 0.7812 - val_loss: 0.4868 - val_acc: 0.7604\n",
      "Epoch 832/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4594 - acc: 0.7812 - val_loss: 0.4868 - val_acc: 0.7604\n",
      "Epoch 833/1000\n",
      "576/576 [==============================] - 0s 23us/sample - loss: 0.4594 - acc: 0.7812 - val_loss: 0.4868 - val_acc: 0.7604\n",
      "Epoch 834/1000\n",
      "576/576 [==============================] - 0s 23us/sample - loss: 0.4594 - acc: 0.7812 - val_loss: 0.4868 - val_acc: 0.7604\n",
      "Epoch 835/1000\n",
      "576/576 [==============================] - 0s 23us/sample - loss: 0.4594 - acc: 0.7812 - val_loss: 0.4868 - val_acc: 0.7604\n",
      "Epoch 836/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4594 - acc: 0.7812 - val_loss: 0.4868 - val_acc: 0.7656\n",
      "Epoch 837/1000\n",
      "576/576 [==============================] - 0s 23us/sample - loss: 0.4594 - acc: 0.7812 - val_loss: 0.4868 - val_acc: 0.7656\n",
      "Epoch 838/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4594 - acc: 0.7812 - val_loss: 0.4868 - val_acc: 0.7656\n",
      "Epoch 839/1000\n",
      "576/576 [==============================] - 0s 23us/sample - loss: 0.4593 - acc: 0.7812 - val_loss: 0.4868 - val_acc: 0.7656\n",
      "Epoch 840/1000\n",
      "576/576 [==============================] - 0s 23us/sample - loss: 0.4593 - acc: 0.7812 - val_loss: 0.4868 - val_acc: 0.7656\n",
      "Epoch 841/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4593 - acc: 0.7812 - val_loss: 0.4868 - val_acc: 0.7656\n",
      "Epoch 842/1000\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4593 - acc: 0.7812 - val_loss: 0.4868 - val_acc: 0.7656\n",
      "Epoch 843/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4593 - acc: 0.7812 - val_loss: 0.4868 - val_acc: 0.7656\n",
      "Epoch 844/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4592 - acc: 0.7795 - val_loss: 0.4868 - val_acc: 0.7656\n",
      "Epoch 845/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4592 - acc: 0.7812 - val_loss: 0.4868 - val_acc: 0.7656\n",
      "Epoch 846/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4592 - acc: 0.7812 - val_loss: 0.4868 - val_acc: 0.7656\n",
      "Epoch 847/1000\n",
      "576/576 [==============================] - 0s 23us/sample - loss: 0.4592 - acc: 0.7812 - val_loss: 0.4868 - val_acc: 0.7656\n",
      "Epoch 848/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4592 - acc: 0.7812 - val_loss: 0.4868 - val_acc: 0.7656\n",
      "Epoch 849/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4592 - acc: 0.7812 - val_loss: 0.4868 - val_acc: 0.7656\n",
      "Epoch 850/1000\n",
      "576/576 [==============================] - 0s 23us/sample - loss: 0.4592 - acc: 0.7812 - val_loss: 0.4868 - val_acc: 0.7656\n",
      "Epoch 851/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4592 - acc: 0.7812 - val_loss: 0.4868 - val_acc: 0.7656\n",
      "Epoch 852/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4591 - acc: 0.7812 - val_loss: 0.4868 - val_acc: 0.7656\n",
      "Epoch 853/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4591 - acc: 0.7812 - val_loss: 0.4868 - val_acc: 0.7656\n",
      "Epoch 854/1000\n",
      "576/576 [==============================] - 0s 23us/sample - loss: 0.4591 - acc: 0.7812 - val_loss: 0.4868 - val_acc: 0.7656\n",
      "Epoch 855/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4591 - acc: 0.7812 - val_loss: 0.4868 - val_acc: 0.7656\n",
      "Epoch 856/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4591 - acc: 0.7812 - val_loss: 0.4868 - val_acc: 0.7656\n",
      "Epoch 857/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4591 - acc: 0.7812 - val_loss: 0.4868 - val_acc: 0.7656\n",
      "Epoch 858/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4590 - acc: 0.7812 - val_loss: 0.4868 - val_acc: 0.7656\n",
      "Epoch 859/1000\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4590 - acc: 0.7812 - val_loss: 0.4868 - val_acc: 0.7656\n",
      "Epoch 860/1000\n",
      "576/576 [==============================] - 0s 23us/sample - loss: 0.4590 - acc: 0.7812 - val_loss: 0.4868 - val_acc: 0.7656\n",
      "Epoch 861/1000\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4590 - acc: 0.7812 - val_loss: 0.4868 - val_acc: 0.7656\n",
      "Epoch 862/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4590 - acc: 0.7812 - val_loss: 0.4868 - val_acc: 0.7656\n",
      "Epoch 863/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4590 - acc: 0.7812 - val_loss: 0.4868 - val_acc: 0.7656\n",
      "Epoch 864/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4590 - acc: 0.7812 - val_loss: 0.4868 - val_acc: 0.7656\n",
      "Epoch 865/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4590 - acc: 0.7812 - val_loss: 0.4868 - val_acc: 0.7656\n",
      "Epoch 866/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4589 - acc: 0.7812 - val_loss: 0.4868 - val_acc: 0.7656\n",
      "Epoch 867/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4589 - acc: 0.7812 - val_loss: 0.4868 - val_acc: 0.7656\n",
      "Epoch 868/1000\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4589 - acc: 0.7812 - val_loss: 0.4868 - val_acc: 0.7656\n",
      "Epoch 869/1000\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4589 - acc: 0.7812 - val_loss: 0.4868 - val_acc: 0.7656\n",
      "Epoch 870/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4589 - acc: 0.7812 - val_loss: 0.4868 - val_acc: 0.7656\n",
      "Epoch 871/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4589 - acc: 0.7812 - val_loss: 0.4868 - val_acc: 0.7656\n",
      "Epoch 872/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4588 - acc: 0.7812 - val_loss: 0.4868 - val_acc: 0.7656\n",
      "Epoch 873/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4588 - acc: 0.7812 - val_loss: 0.4868 - val_acc: 0.7656\n",
      "Epoch 874/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4588 - acc: 0.7812 - val_loss: 0.4868 - val_acc: 0.7656\n",
      "Epoch 875/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4588 - acc: 0.7812 - val_loss: 0.4868 - val_acc: 0.7656\n",
      "Epoch 876/1000\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4588 - acc: 0.7812 - val_loss: 0.4868 - val_acc: 0.7656\n",
      "Epoch 877/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4588 - acc: 0.7812 - val_loss: 0.4868 - val_acc: 0.7656\n",
      "Epoch 878/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4588 - acc: 0.7812 - val_loss: 0.4868 - val_acc: 0.7656\n",
      "Epoch 879/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4588 - acc: 0.7812 - val_loss: 0.4868 - val_acc: 0.7656\n",
      "Epoch 880/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4587 - acc: 0.7812 - val_loss: 0.4868 - val_acc: 0.7656\n",
      "Epoch 881/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4587 - acc: 0.7812 - val_loss: 0.4868 - val_acc: 0.7656\n",
      "Epoch 882/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4587 - acc: 0.7812 - val_loss: 0.4868 - val_acc: 0.7656\n",
      "Epoch 883/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4587 - acc: 0.7812 - val_loss: 0.4868 - val_acc: 0.7656\n",
      "Epoch 884/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4587 - acc: 0.7812 - val_loss: 0.4868 - val_acc: 0.7656\n",
      "Epoch 885/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4587 - acc: 0.7812 - val_loss: 0.4868 - val_acc: 0.7656\n",
      "Epoch 886/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4587 - acc: 0.7812 - val_loss: 0.4868 - val_acc: 0.7656\n",
      "Epoch 887/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4587 - acc: 0.7812 - val_loss: 0.4868 - val_acc: 0.7656\n",
      "Epoch 888/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4586 - acc: 0.7812 - val_loss: 0.4868 - val_acc: 0.7656\n",
      "Epoch 889/1000\n",
      "576/576 [==============================] - 0s 23us/sample - loss: 0.4587 - acc: 0.7812 - val_loss: 0.4868 - val_acc: 0.7656\n",
      "Epoch 890/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4586 - acc: 0.7812 - val_loss: 0.4868 - val_acc: 0.7656\n",
      "Epoch 891/1000\n",
      "576/576 [==============================] - 0s 23us/sample - loss: 0.4586 - acc: 0.7812 - val_loss: 0.4868 - val_acc: 0.7656\n",
      "Epoch 892/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4586 - acc: 0.7812 - val_loss: 0.4868 - val_acc: 0.7656\n",
      "Epoch 893/1000\n",
      "576/576 [==============================] - 0s 23us/sample - loss: 0.4586 - acc: 0.7812 - val_loss: 0.4868 - val_acc: 0.7656\n",
      "Epoch 894/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4586 - acc: 0.7812 - val_loss: 0.4868 - val_acc: 0.7656\n",
      "Epoch 895/1000\n",
      "576/576 [==============================] - 0s 23us/sample - loss: 0.4586 - acc: 0.7812 - val_loss: 0.4868 - val_acc: 0.7656\n",
      "Epoch 896/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4586 - acc: 0.7795 - val_loss: 0.4868 - val_acc: 0.7656\n",
      "Epoch 897/1000\n",
      "576/576 [==============================] - 0s 23us/sample - loss: 0.4585 - acc: 0.7795 - val_loss: 0.4868 - val_acc: 0.7656\n",
      "Epoch 898/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4585 - acc: 0.7795 - val_loss: 0.4868 - val_acc: 0.7656\n",
      "Epoch 899/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4585 - acc: 0.7795 - val_loss: 0.4868 - val_acc: 0.7656\n",
      "Epoch 900/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4585 - acc: 0.7795 - val_loss: 0.4868 - val_acc: 0.7656\n",
      "Epoch 901/1000\n",
      "576/576 [==============================] - 0s 23us/sample - loss: 0.4585 - acc: 0.7795 - val_loss: 0.4868 - val_acc: 0.7656\n",
      "Epoch 902/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4585 - acc: 0.7795 - val_loss: 0.4868 - val_acc: 0.7656\n",
      "Epoch 903/1000\n",
      "576/576 [==============================] - 0s 23us/sample - loss: 0.4584 - acc: 0.7795 - val_loss: 0.4868 - val_acc: 0.7656\n",
      "Epoch 904/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4584 - acc: 0.7795 - val_loss: 0.4868 - val_acc: 0.7656\n",
      "Epoch 905/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4584 - acc: 0.7795 - val_loss: 0.4868 - val_acc: 0.7656\n",
      "Epoch 906/1000\n",
      "576/576 [==============================] - 0s 23us/sample - loss: 0.4584 - acc: 0.7795 - val_loss: 0.4868 - val_acc: 0.7656\n",
      "Epoch 907/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4584 - acc: 0.7795 - val_loss: 0.4868 - val_acc: 0.7656\n",
      "Epoch 908/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4584 - acc: 0.7795 - val_loss: 0.4868 - val_acc: 0.7656\n",
      "Epoch 909/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4584 - acc: 0.7795 - val_loss: 0.4868 - val_acc: 0.7656\n",
      "Epoch 910/1000\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4584 - acc: 0.7795 - val_loss: 0.4868 - val_acc: 0.7656\n",
      "Epoch 911/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4583 - acc: 0.7795 - val_loss: 0.4868 - val_acc: 0.7656\n",
      "Epoch 912/1000\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4583 - acc: 0.7795 - val_loss: 0.4868 - val_acc: 0.7656\n",
      "Epoch 913/1000\n",
      "576/576 [==============================] - 0s 31us/sample - loss: 0.4583 - acc: 0.7795 - val_loss: 0.4868 - val_acc: 0.7656\n",
      "Epoch 914/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4583 - acc: 0.7795 - val_loss: 0.4869 - val_acc: 0.7656\n",
      "Epoch 915/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4583 - acc: 0.7795 - val_loss: 0.4869 - val_acc: 0.7656\n",
      "Epoch 916/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4583 - acc: 0.7795 - val_loss: 0.4869 - val_acc: 0.7656\n",
      "Epoch 917/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4583 - acc: 0.7795 - val_loss: 0.4869 - val_acc: 0.7656\n",
      "Epoch 918/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4582 - acc: 0.7795 - val_loss: 0.4869 - val_acc: 0.7656\n",
      "Epoch 919/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4583 - acc: 0.7795 - val_loss: 0.4869 - val_acc: 0.7656\n",
      "Epoch 920/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4582 - acc: 0.7795 - val_loss: 0.4869 - val_acc: 0.7656\n",
      "Epoch 921/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4582 - acc: 0.7795 - val_loss: 0.4869 - val_acc: 0.7656\n",
      "Epoch 922/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4582 - acc: 0.7795 - val_loss: 0.4869 - val_acc: 0.7656\n",
      "Epoch 923/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4582 - acc: 0.7795 - val_loss: 0.4869 - val_acc: 0.7656\n",
      "Epoch 924/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4582 - acc: 0.7795 - val_loss: 0.4869 - val_acc: 0.7656\n",
      "Epoch 925/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4582 - acc: 0.7795 - val_loss: 0.4869 - val_acc: 0.7656\n",
      "Epoch 926/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4582 - acc: 0.7795 - val_loss: 0.4869 - val_acc: 0.7656\n",
      "Epoch 927/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4581 - acc: 0.7795 - val_loss: 0.4869 - val_acc: 0.7656\n",
      "Epoch 928/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4581 - acc: 0.7795 - val_loss: 0.4869 - val_acc: 0.7656\n",
      "Epoch 929/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4581 - acc: 0.7795 - val_loss: 0.4869 - val_acc: 0.7656\n",
      "Epoch 930/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4581 - acc: 0.7795 - val_loss: 0.4869 - val_acc: 0.7656\n",
      "Epoch 931/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4581 - acc: 0.7795 - val_loss: 0.4869 - val_acc: 0.7656\n",
      "Epoch 932/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4581 - acc: 0.7795 - val_loss: 0.4869 - val_acc: 0.7656\n",
      "Epoch 933/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4581 - acc: 0.7795 - val_loss: 0.4869 - val_acc: 0.7656\n",
      "Epoch 934/1000\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4581 - acc: 0.7795 - val_loss: 0.4869 - val_acc: 0.7656\n",
      "Epoch 935/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4581 - acc: 0.7795 - val_loss: 0.4869 - val_acc: 0.7656\n",
      "Epoch 936/1000\n",
      "576/576 [==============================] - 0s 23us/sample - loss: 0.4580 - acc: 0.7795 - val_loss: 0.4869 - val_acc: 0.7656\n",
      "Epoch 937/1000\n",
      "576/576 [==============================] - 0s 31us/sample - loss: 0.4580 - acc: 0.7795 - val_loss: 0.4869 - val_acc: 0.7656\n",
      "Epoch 938/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4580 - acc: 0.7795 - val_loss: 0.4869 - val_acc: 0.7656\n",
      "Epoch 939/1000\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4580 - acc: 0.7795 - val_loss: 0.4869 - val_acc: 0.7656\n",
      "Epoch 940/1000\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4580 - acc: 0.7795 - val_loss: 0.4869 - val_acc: 0.7656\n",
      "Epoch 941/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4580 - acc: 0.7795 - val_loss: 0.4869 - val_acc: 0.7656\n",
      "Epoch 942/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4580 - acc: 0.7795 - val_loss: 0.4869 - val_acc: 0.7656\n",
      "Epoch 943/1000\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4580 - acc: 0.7795 - val_loss: 0.4869 - val_acc: 0.7656\n",
      "Epoch 944/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4580 - acc: 0.7795 - val_loss: 0.4869 - val_acc: 0.7656\n",
      "Epoch 945/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4579 - acc: 0.7795 - val_loss: 0.4869 - val_acc: 0.7656\n",
      "Epoch 946/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4579 - acc: 0.7795 - val_loss: 0.4869 - val_acc: 0.7656\n",
      "Epoch 947/1000\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4579 - acc: 0.7795 - val_loss: 0.4869 - val_acc: 0.7656\n",
      "Epoch 948/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4579 - acc: 0.7795 - val_loss: 0.4869 - val_acc: 0.7656\n",
      "Epoch 949/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4579 - acc: 0.7795 - val_loss: 0.4869 - val_acc: 0.7656\n",
      "Epoch 950/1000\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4579 - acc: 0.7795 - val_loss: 0.4869 - val_acc: 0.7656\n",
      "Epoch 951/1000\n",
      "576/576 [==============================] - 0s 23us/sample - loss: 0.4579 - acc: 0.7795 - val_loss: 0.4869 - val_acc: 0.7656\n",
      "Epoch 952/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4579 - acc: 0.7795 - val_loss: 0.4869 - val_acc: 0.7656\n",
      "Epoch 953/1000\n",
      "576/576 [==============================] - 0s 23us/sample - loss: 0.4578 - acc: 0.7795 - val_loss: 0.4869 - val_acc: 0.7656\n",
      "Epoch 954/1000\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4578 - acc: 0.7795 - val_loss: 0.4869 - val_acc: 0.7656\n",
      "Epoch 955/1000\n",
      "576/576 [==============================] - 0s 23us/sample - loss: 0.4578 - acc: 0.7795 - val_loss: 0.4869 - val_acc: 0.7656\n",
      "Epoch 956/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4578 - acc: 0.7795 - val_loss: 0.4869 - val_acc: 0.7656\n",
      "Epoch 957/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4578 - acc: 0.7795 - val_loss: 0.4869 - val_acc: 0.7656\n",
      "Epoch 958/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4578 - acc: 0.7795 - val_loss: 0.4869 - val_acc: 0.7656\n",
      "Epoch 959/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4578 - acc: 0.7795 - val_loss: 0.4869 - val_acc: 0.7656\n",
      "Epoch 960/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4578 - acc: 0.7795 - val_loss: 0.4869 - val_acc: 0.7656\n",
      "Epoch 961/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4578 - acc: 0.7795 - val_loss: 0.4869 - val_acc: 0.7656\n",
      "Epoch 962/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4578 - acc: 0.7795 - val_loss: 0.4869 - val_acc: 0.7656\n",
      "Epoch 963/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4577 - acc: 0.7795 - val_loss: 0.4869 - val_acc: 0.7656\n",
      "Epoch 964/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4577 - acc: 0.7795 - val_loss: 0.4869 - val_acc: 0.7656\n",
      "Epoch 965/1000\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4577 - acc: 0.7795 - val_loss: 0.4869 - val_acc: 0.7656\n",
      "Epoch 966/1000\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4577 - acc: 0.7795 - val_loss: 0.4869 - val_acc: 0.7656\n",
      "Epoch 967/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4577 - acc: 0.7795 - val_loss: 0.4870 - val_acc: 0.7656\n",
      "Epoch 968/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4577 - acc: 0.7795 - val_loss: 0.4870 - val_acc: 0.7656\n",
      "Epoch 969/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4577 - acc: 0.7795 - val_loss: 0.4870 - val_acc: 0.7656\n",
      "Epoch 970/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4577 - acc: 0.7795 - val_loss: 0.4870 - val_acc: 0.7656\n",
      "Epoch 971/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4576 - acc: 0.7795 - val_loss: 0.4870 - val_acc: 0.7656\n",
      "Epoch 972/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4576 - acc: 0.7795 - val_loss: 0.4870 - val_acc: 0.7656\n",
      "Epoch 973/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4576 - acc: 0.7795 - val_loss: 0.4870 - val_acc: 0.7656\n",
      "Epoch 974/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4576 - acc: 0.7795 - val_loss: 0.4870 - val_acc: 0.7656\n",
      "Epoch 975/1000\n",
      "576/576 [==============================] - 0s 23us/sample - loss: 0.4576 - acc: 0.7795 - val_loss: 0.4870 - val_acc: 0.7656\n",
      "Epoch 976/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4576 - acc: 0.7795 - val_loss: 0.4870 - val_acc: 0.7656\n",
      "Epoch 977/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4576 - acc: 0.7795 - val_loss: 0.4870 - val_acc: 0.7656\n",
      "Epoch 978/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4576 - acc: 0.7795 - val_loss: 0.4870 - val_acc: 0.7656\n",
      "Epoch 979/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4576 - acc: 0.7795 - val_loss: 0.4870 - val_acc: 0.7656\n",
      "Epoch 980/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4575 - acc: 0.7795 - val_loss: 0.4870 - val_acc: 0.7656\n",
      "Epoch 981/1000\n",
      "576/576 [==============================] - 0s 23us/sample - loss: 0.4576 - acc: 0.7795 - val_loss: 0.4870 - val_acc: 0.7656\n",
      "Epoch 982/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4575 - acc: 0.7795 - val_loss: 0.4870 - val_acc: 0.7656\n",
      "Epoch 983/1000\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4575 - acc: 0.7795 - val_loss: 0.4870 - val_acc: 0.7656\n",
      "Epoch 984/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4575 - acc: 0.7795 - val_loss: 0.4870 - val_acc: 0.7656\n",
      "Epoch 985/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4575 - acc: 0.7795 - val_loss: 0.4870 - val_acc: 0.7656\n",
      "Epoch 986/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4575 - acc: 0.7795 - val_loss: 0.4870 - val_acc: 0.7656\n",
      "Epoch 987/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4575 - acc: 0.7795 - val_loss: 0.4870 - val_acc: 0.7656\n",
      "Epoch 988/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4575 - acc: 0.7795 - val_loss: 0.4870 - val_acc: 0.7604\n",
      "Epoch 989/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4575 - acc: 0.7795 - val_loss: 0.4870 - val_acc: 0.7604\n",
      "Epoch 990/1000\n",
      "576/576 [==============================] - 0s 23us/sample - loss: 0.4575 - acc: 0.7795 - val_loss: 0.4870 - val_acc: 0.7604\n",
      "Epoch 991/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4574 - acc: 0.7795 - val_loss: 0.4870 - val_acc: 0.7604\n",
      "Epoch 992/1000\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4574 - acc: 0.7795 - val_loss: 0.4870 - val_acc: 0.7604\n",
      "Epoch 993/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4574 - acc: 0.7795 - val_loss: 0.4870 - val_acc: 0.7604\n",
      "Epoch 994/1000\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4574 - acc: 0.7812 - val_loss: 0.4870 - val_acc: 0.7604\n",
      "Epoch 995/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4574 - acc: 0.7795 - val_loss: 0.4870 - val_acc: 0.7604\n",
      "Epoch 996/1000\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4574 - acc: 0.7795 - val_loss: 0.4870 - val_acc: 0.7604\n",
      "Epoch 997/1000\n",
      "576/576 [==============================] - 0s 23us/sample - loss: 0.4574 - acc: 0.7795 - val_loss: 0.4870 - val_acc: 0.7604\n",
      "Epoch 998/1000\n",
      "576/576 [==============================] - 0s 31us/sample - loss: 0.4574 - acc: 0.7795 - val_loss: 0.4870 - val_acc: 0.7604\n",
      "Epoch 999/1000\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4574 - acc: 0.7795 - val_loss: 0.4870 - val_acc: 0.7604\n",
      "Epoch 1000/1000\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4574 - acc: 0.7795 - val_loss: 0.4870 - val_acc: 0.7604\n"
     ]
    }
   ],
   "source": [
    "## we call \"fit\" again\n",
    "run_hist_1b = model_1.fit(X_train_norm, y_train, \n",
    "                          validation_data=(X_test_norm, y_test), \n",
    "                          epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x19edaf98>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = len(run_hist_1.history[\"loss\"])\n",
    "m = len(run_hist_1b.history['loss'])\n",
    "fig, ax = plt.subplots(figsize=(16, 8))\n",
    "\n",
    "ax.plot(range(n), run_hist_1.history[\"loss\"],'r', marker='.', label=\"Train Loss - Run 1\")\n",
    "ax.plot(range(n, n+m), run_hist_1b.history[\"loss\"], 'hotpink', marker='.', label=\"Train Loss - Run 2\")\n",
    "\n",
    "ax.plot(range(n), run_hist_1.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss - Run 1\")\n",
    "ax.plot(range(n, n+m), run_hist_1b.history[\"val_loss\"], 'LightSkyBlue', marker='.',  label=\"Validation Loss - Run 2\")\n",
    "\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Build a model with two hidden layers, each with 6 nodes\n",
    "- Use the \"relu\" activation function for the hidden layers, and \"sigmoid\" for the final layer\n",
    "- Use a learning rate of .003 and train for 1500 epochs\n",
    "- Graph the trajectory of the loss functions, accuracy on both train and test set\n",
    "- Plot the roc curve for the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 6)                 54        \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 6)                 42        \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 7         \n",
      "=================================================================\n",
      "Total params: 103\n",
      "Trainable params: 103\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_2=Sequential()\n",
    "model_2.add(Dense(6, input_shape=(8,), activation='relu'))\n",
    "model_2.add(Dense(6, input_shape=(6,), activation='relu'))\n",
    "model_2.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 576 samples, validate on 192 samples\n",
      "Epoch 1/1500\n",
      "576/576 [==============================] - 0s 326us/sample - loss: 0.7524 - acc: 0.4219 - val_loss: 0.7314 - val_acc: 0.4219\n",
      "Epoch 2/1500\n",
      "576/576 [==============================] - 0s 31us/sample - loss: 0.7446 - acc: 0.4236 - val_loss: 0.7251 - val_acc: 0.4427\n",
      "Epoch 3/1500\n",
      "576/576 [==============================] - 0s 31us/sample - loss: 0.7373 - acc: 0.4219 - val_loss: 0.7191 - val_acc: 0.4635\n",
      "Epoch 4/1500\n",
      "576/576 [==============================] - 0s 35us/sample - loss: 0.7302 - acc: 0.4306 - val_loss: 0.7134 - val_acc: 0.4740\n",
      "Epoch 5/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.7236 - acc: 0.4358 - val_loss: 0.7079 - val_acc: 0.4948\n",
      "Epoch 6/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.7174 - acc: 0.4479 - val_loss: 0.7027 - val_acc: 0.5104\n",
      "Epoch 7/1500\n",
      "576/576 [==============================] - 0s 31us/sample - loss: 0.7115 - acc: 0.4549 - val_loss: 0.6977 - val_acc: 0.5104\n",
      "Epoch 8/1500\n",
      "576/576 [==============================] - 0s 35us/sample - loss: 0.7059 - acc: 0.4618 - val_loss: 0.6931 - val_acc: 0.4948\n",
      "Epoch 9/1500\n",
      "576/576 [==============================] - 0s 31us/sample - loss: 0.7008 - acc: 0.4740 - val_loss: 0.6887 - val_acc: 0.5156\n",
      "Epoch 10/1500\n",
      "576/576 [==============================] - 0s 31us/sample - loss: 0.6958 - acc: 0.4983 - val_loss: 0.6845 - val_acc: 0.5365\n",
      "Epoch 11/1500\n",
      "576/576 [==============================] - 0s 31us/sample - loss: 0.6911 - acc: 0.5208 - val_loss: 0.6806 - val_acc: 0.5729\n",
      "Epoch 12/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.6866 - acc: 0.5312 - val_loss: 0.6768 - val_acc: 0.6042\n",
      "Epoch 13/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.6823 - acc: 0.5556 - val_loss: 0.6732 - val_acc: 0.6146\n",
      "Epoch 14/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.6783 - acc: 0.5851 - val_loss: 0.6698 - val_acc: 0.6250\n",
      "Epoch 15/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.6744 - acc: 0.6111 - val_loss: 0.6665 - val_acc: 0.6562\n",
      "Epoch 16/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.6707 - acc: 0.6319 - val_loss: 0.6634 - val_acc: 0.6771\n",
      "Epoch 17/1500\n",
      "576/576 [==============================] - 0s 31us/sample - loss: 0.6672 - acc: 0.6389 - val_loss: 0.6604 - val_acc: 0.6927\n",
      "Epoch 18/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.6638 - acc: 0.6562 - val_loss: 0.6575 - val_acc: 0.7083\n",
      "Epoch 19/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.6607 - acc: 0.6562 - val_loss: 0.6548 - val_acc: 0.7135\n",
      "Epoch 20/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.6577 - acc: 0.6632 - val_loss: 0.6521 - val_acc: 0.7083\n",
      "Epoch 21/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.6548 - acc: 0.6632 - val_loss: 0.6496 - val_acc: 0.7083\n",
      "Epoch 22/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.6521 - acc: 0.6806 - val_loss: 0.6472 - val_acc: 0.6979\n",
      "Epoch 23/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.6494 - acc: 0.6858 - val_loss: 0.6449 - val_acc: 0.7031\n",
      "Epoch 24/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.6469 - acc: 0.6858 - val_loss: 0.6427 - val_acc: 0.6979\n",
      "Epoch 25/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.6445 - acc: 0.6858 - val_loss: 0.6405 - val_acc: 0.7031\n",
      "Epoch 26/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.6421 - acc: 0.6840 - val_loss: 0.6385 - val_acc: 0.7083\n",
      "Epoch 27/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.6400 - acc: 0.6875 - val_loss: 0.6365 - val_acc: 0.7135\n",
      "Epoch 28/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.6379 - acc: 0.6892 - val_loss: 0.6345 - val_acc: 0.7135\n",
      "Epoch 29/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.6359 - acc: 0.6892 - val_loss: 0.6326 - val_acc: 0.7135\n",
      "Epoch 30/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.6340 - acc: 0.6840 - val_loss: 0.6308 - val_acc: 0.7135\n",
      "Epoch 31/1500\n",
      "576/576 [==============================] - 0s 31us/sample - loss: 0.6321 - acc: 0.6892 - val_loss: 0.6291 - val_acc: 0.7135\n",
      "Epoch 32/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.6304 - acc: 0.6892 - val_loss: 0.6274 - val_acc: 0.7135\n",
      "Epoch 33/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.6287 - acc: 0.6892 - val_loss: 0.6258 - val_acc: 0.7083\n",
      "Epoch 34/1500\n",
      "576/576 [==============================] - 0s 31us/sample - loss: 0.6270 - acc: 0.6910 - val_loss: 0.6243 - val_acc: 0.7135\n",
      "Epoch 35/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.6254 - acc: 0.6910 - val_loss: 0.6227 - val_acc: 0.7240\n",
      "Epoch 36/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.6239 - acc: 0.6858 - val_loss: 0.6212 - val_acc: 0.7240\n",
      "Epoch 37/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.6223 - acc: 0.6892 - val_loss: 0.6197 - val_acc: 0.7292\n",
      "Epoch 38/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.6208 - acc: 0.6892 - val_loss: 0.6183 - val_acc: 0.7344\n",
      "Epoch 39/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.6193 - acc: 0.6892 - val_loss: 0.6169 - val_acc: 0.7344\n",
      "Epoch 40/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.6179 - acc: 0.6927 - val_loss: 0.6155 - val_acc: 0.7344\n",
      "Epoch 41/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.6166 - acc: 0.6927 - val_loss: 0.6142 - val_acc: 0.7292\n",
      "Epoch 42/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.6152 - acc: 0.6944 - val_loss: 0.6128 - val_acc: 0.7292\n",
      "Epoch 43/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.6139 - acc: 0.6944 - val_loss: 0.6115 - val_acc: 0.7292\n",
      "Epoch 44/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.6126 - acc: 0.6962 - val_loss: 0.6103 - val_acc: 0.7292\n",
      "Epoch 45/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.6114 - acc: 0.6979 - val_loss: 0.6090 - val_acc: 0.7240\n",
      "Epoch 46/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.6101 - acc: 0.6979 - val_loss: 0.6078 - val_acc: 0.7240\n",
      "Epoch 47/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.6089 - acc: 0.6962 - val_loss: 0.6065 - val_acc: 0.7240\n",
      "Epoch 48/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.6077 - acc: 0.6979 - val_loss: 0.6053 - val_acc: 0.7240\n",
      "Epoch 49/1500\n",
      "576/576 [==============================] - 0s 31us/sample - loss: 0.6066 - acc: 0.6979 - val_loss: 0.6041 - val_acc: 0.7188\n",
      "Epoch 50/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.6054 - acc: 0.7014 - val_loss: 0.6029 - val_acc: 0.7188\n",
      "Epoch 51/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.6043 - acc: 0.6997 - val_loss: 0.6018 - val_acc: 0.7188\n",
      "Epoch 52/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.6032 - acc: 0.6979 - val_loss: 0.6006 - val_acc: 0.7135\n",
      "Epoch 53/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.6021 - acc: 0.6979 - val_loss: 0.5994 - val_acc: 0.7135\n",
      "Epoch 54/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.6010 - acc: 0.6979 - val_loss: 0.5983 - val_acc: 0.7135\n",
      "Epoch 55/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.6000 - acc: 0.6979 - val_loss: 0.5972 - val_acc: 0.7135\n",
      "Epoch 56/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.5989 - acc: 0.6979 - val_loss: 0.5961 - val_acc: 0.7135\n",
      "Epoch 57/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.5978 - acc: 0.6962 - val_loss: 0.5950 - val_acc: 0.7135\n",
      "Epoch 58/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.5967 - acc: 0.6962 - val_loss: 0.5939 - val_acc: 0.7135\n",
      "Epoch 59/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.5957 - acc: 0.6979 - val_loss: 0.5928 - val_acc: 0.7188\n",
      "Epoch 60/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 28us/sample - loss: 0.5947 - acc: 0.6979 - val_loss: 0.5918 - val_acc: 0.7188\n",
      "Epoch 61/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.5937 - acc: 0.6997 - val_loss: 0.5907 - val_acc: 0.7188\n",
      "Epoch 62/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.5927 - acc: 0.6997 - val_loss: 0.5897 - val_acc: 0.7188\n",
      "Epoch 63/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.5917 - acc: 0.6997 - val_loss: 0.5886 - val_acc: 0.7240\n",
      "Epoch 64/1500\n",
      "576/576 [==============================] - 0s 35us/sample - loss: 0.5906 - acc: 0.7014 - val_loss: 0.5876 - val_acc: 0.7240\n",
      "Epoch 65/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.5897 - acc: 0.7014 - val_loss: 0.5866 - val_acc: 0.7240\n",
      "Epoch 66/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.5887 - acc: 0.6997 - val_loss: 0.5856 - val_acc: 0.7240\n",
      "Epoch 67/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.5878 - acc: 0.7014 - val_loss: 0.5846 - val_acc: 0.7240\n",
      "Epoch 68/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.5868 - acc: 0.7014 - val_loss: 0.5836 - val_acc: 0.7240\n",
      "Epoch 69/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.5858 - acc: 0.7014 - val_loss: 0.5827 - val_acc: 0.7240\n",
      "Epoch 70/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.5848 - acc: 0.7014 - val_loss: 0.5817 - val_acc: 0.7240\n",
      "Epoch 71/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.5839 - acc: 0.6997 - val_loss: 0.5807 - val_acc: 0.7292\n",
      "Epoch 72/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.5830 - acc: 0.7014 - val_loss: 0.5797 - val_acc: 0.7292\n",
      "Epoch 73/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.5820 - acc: 0.7014 - val_loss: 0.5788 - val_acc: 0.7240\n",
      "Epoch 74/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.5811 - acc: 0.7031 - val_loss: 0.5778 - val_acc: 0.7188\n",
      "Epoch 75/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.5802 - acc: 0.7014 - val_loss: 0.5769 - val_acc: 0.7188\n",
      "Epoch 76/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.5792 - acc: 0.7031 - val_loss: 0.5759 - val_acc: 0.7188\n",
      "Epoch 77/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.5784 - acc: 0.7014 - val_loss: 0.5750 - val_acc: 0.7188\n",
      "Epoch 78/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.5775 - acc: 0.7049 - val_loss: 0.5741 - val_acc: 0.7240\n",
      "Epoch 79/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.5765 - acc: 0.7031 - val_loss: 0.5732 - val_acc: 0.7240\n",
      "Epoch 80/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.5756 - acc: 0.7049 - val_loss: 0.5722 - val_acc: 0.7240\n",
      "Epoch 81/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.5747 - acc: 0.7049 - val_loss: 0.5713 - val_acc: 0.7240\n",
      "Epoch 82/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.5738 - acc: 0.7049 - val_loss: 0.5704 - val_acc: 0.7240\n",
      "Epoch 83/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.5729 - acc: 0.7049 - val_loss: 0.5695 - val_acc: 0.7240\n",
      "Epoch 84/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.5720 - acc: 0.7049 - val_loss: 0.5686 - val_acc: 0.7240\n",
      "Epoch 85/1500\n",
      "576/576 [==============================] - 0s 36us/sample - loss: 0.5712 - acc: 0.7049 - val_loss: 0.5677 - val_acc: 0.7240\n",
      "Epoch 86/1500\n",
      "576/576 [==============================] - 0s 35us/sample - loss: 0.5703 - acc: 0.7031 - val_loss: 0.5668 - val_acc: 0.7240\n",
      "Epoch 87/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.5694 - acc: 0.7031 - val_loss: 0.5659 - val_acc: 0.7240\n",
      "Epoch 88/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.5685 - acc: 0.7049 - val_loss: 0.5651 - val_acc: 0.7240\n",
      "Epoch 89/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.5676 - acc: 0.7066 - val_loss: 0.5642 - val_acc: 0.7292\n",
      "Epoch 90/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.5667 - acc: 0.7049 - val_loss: 0.5633 - val_acc: 0.7292\n",
      "Epoch 91/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.5659 - acc: 0.7049 - val_loss: 0.5625 - val_acc: 0.7292\n",
      "Epoch 92/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.5650 - acc: 0.7083 - val_loss: 0.5616 - val_acc: 0.7292\n",
      "Epoch 93/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.5641 - acc: 0.7083 - val_loss: 0.5607 - val_acc: 0.7292\n",
      "Epoch 94/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.5633 - acc: 0.7066 - val_loss: 0.5599 - val_acc: 0.7240\n",
      "Epoch 95/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.5624 - acc: 0.7083 - val_loss: 0.5591 - val_acc: 0.7240\n",
      "Epoch 96/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.5616 - acc: 0.7083 - val_loss: 0.5582 - val_acc: 0.7240\n",
      "Epoch 97/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.5607 - acc: 0.7101 - val_loss: 0.5574 - val_acc: 0.7240\n",
      "Epoch 98/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.5598 - acc: 0.7101 - val_loss: 0.5566 - val_acc: 0.7240\n",
      "Epoch 99/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.5590 - acc: 0.7118 - val_loss: 0.5558 - val_acc: 0.7240\n",
      "Epoch 100/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.5582 - acc: 0.7118 - val_loss: 0.5549 - val_acc: 0.7240\n",
      "Epoch 101/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.5573 - acc: 0.7118 - val_loss: 0.5541 - val_acc: 0.7240\n",
      "Epoch 102/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.5565 - acc: 0.7118 - val_loss: 0.5533 - val_acc: 0.7240\n",
      "Epoch 103/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.5556 - acc: 0.7118 - val_loss: 0.5525 - val_acc: 0.7292\n",
      "Epoch 104/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.5547 - acc: 0.7118 - val_loss: 0.5517 - val_acc: 0.7292\n",
      "Epoch 105/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.5539 - acc: 0.7153 - val_loss: 0.5509 - val_acc: 0.7292\n",
      "Epoch 106/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.5531 - acc: 0.7153 - val_loss: 0.5501 - val_acc: 0.7292\n",
      "Epoch 107/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.5522 - acc: 0.7153 - val_loss: 0.5494 - val_acc: 0.7292\n",
      "Epoch 108/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.5514 - acc: 0.7153 - val_loss: 0.5486 - val_acc: 0.7292\n",
      "Epoch 109/1500\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.5490 - acc: 0.687 - 0s 26us/sample - loss: 0.5506 - acc: 0.7153 - val_loss: 0.5478 - val_acc: 0.7292\n",
      "Epoch 110/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.5497 - acc: 0.7188 - val_loss: 0.5471 - val_acc: 0.7292\n",
      "Epoch 111/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.5489 - acc: 0.7188 - val_loss: 0.5463 - val_acc: 0.7292\n",
      "Epoch 112/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.5480 - acc: 0.7188 - val_loss: 0.5456 - val_acc: 0.7292\n",
      "Epoch 113/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.5473 - acc: 0.7188 - val_loss: 0.5449 - val_acc: 0.7292\n",
      "Epoch 114/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.5464 - acc: 0.7205 - val_loss: 0.5441 - val_acc: 0.7292\n",
      "Epoch 115/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.5456 - acc: 0.7205 - val_loss: 0.5434 - val_acc: 0.7448\n",
      "Epoch 116/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.5447 - acc: 0.7222 - val_loss: 0.5427 - val_acc: 0.7448\n",
      "Epoch 117/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.5439 - acc: 0.7240 - val_loss: 0.5419 - val_acc: 0.7448\n",
      "Epoch 118/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.5431 - acc: 0.7240 - val_loss: 0.5412 - val_acc: 0.7448\n",
      "Epoch 119/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 30us/sample - loss: 0.5423 - acc: 0.7257 - val_loss: 0.5405 - val_acc: 0.7396\n",
      "Epoch 120/1500\n",
      "576/576 [==============================] - 0s 35us/sample - loss: 0.5415 - acc: 0.7257 - val_loss: 0.5398 - val_acc: 0.7396\n",
      "Epoch 121/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.5407 - acc: 0.7257 - val_loss: 0.5391 - val_acc: 0.7396\n",
      "Epoch 122/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.5399 - acc: 0.7274 - val_loss: 0.5384 - val_acc: 0.7396\n",
      "Epoch 123/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.5392 - acc: 0.7274 - val_loss: 0.5377 - val_acc: 0.7344\n",
      "Epoch 124/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.5384 - acc: 0.7309 - val_loss: 0.5370 - val_acc: 0.7344\n",
      "Epoch 125/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.5375 - acc: 0.7309 - val_loss: 0.5364 - val_acc: 0.7396\n",
      "Epoch 126/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.5368 - acc: 0.7309 - val_loss: 0.5357 - val_acc: 0.7448\n",
      "Epoch 127/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.5360 - acc: 0.7292 - val_loss: 0.5350 - val_acc: 0.7448\n",
      "Epoch 128/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.5352 - acc: 0.7274 - val_loss: 0.5343 - val_acc: 0.7448\n",
      "Epoch 129/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.5344 - acc: 0.7292 - val_loss: 0.5337 - val_acc: 0.7448\n",
      "Epoch 130/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.5336 - acc: 0.7292 - val_loss: 0.5330 - val_acc: 0.7448\n",
      "Epoch 131/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.5329 - acc: 0.7309 - val_loss: 0.5324 - val_acc: 0.7448\n",
      "Epoch 132/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.5321 - acc: 0.7292 - val_loss: 0.5317 - val_acc: 0.7448\n",
      "Epoch 133/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.5313 - acc: 0.7292 - val_loss: 0.5311 - val_acc: 0.7448\n",
      "Epoch 134/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.5305 - acc: 0.7292 - val_loss: 0.5304 - val_acc: 0.7448\n",
      "Epoch 135/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.5298 - acc: 0.7309 - val_loss: 0.5298 - val_acc: 0.7448\n",
      "Epoch 136/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.5291 - acc: 0.7309 - val_loss: 0.5292 - val_acc: 0.7448\n",
      "Epoch 137/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.5283 - acc: 0.7326 - val_loss: 0.5286 - val_acc: 0.7448\n",
      "Epoch 138/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.5276 - acc: 0.7326 - val_loss: 0.5280 - val_acc: 0.7448\n",
      "Epoch 139/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.5269 - acc: 0.7326 - val_loss: 0.5274 - val_acc: 0.7448\n",
      "Epoch 140/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.5261 - acc: 0.7344 - val_loss: 0.5268 - val_acc: 0.7448\n",
      "Epoch 141/1500\n",
      "576/576 [==============================] - 0s 31us/sample - loss: 0.5254 - acc: 0.7344 - val_loss: 0.5263 - val_acc: 0.7448\n",
      "Epoch 142/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.5247 - acc: 0.7344 - val_loss: 0.5257 - val_acc: 0.7500\n",
      "Epoch 143/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.5240 - acc: 0.7344 - val_loss: 0.5251 - val_acc: 0.7552\n",
      "Epoch 144/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.5233 - acc: 0.7344 - val_loss: 0.5246 - val_acc: 0.7552\n",
      "Epoch 145/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.5226 - acc: 0.7344 - val_loss: 0.5240 - val_acc: 0.7552\n",
      "Epoch 146/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.5219 - acc: 0.7344 - val_loss: 0.5235 - val_acc: 0.7552\n",
      "Epoch 147/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.5213 - acc: 0.7361 - val_loss: 0.5230 - val_acc: 0.7552\n",
      "Epoch 148/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.5205 - acc: 0.7378 - val_loss: 0.5225 - val_acc: 0.7552\n",
      "Epoch 149/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.5199 - acc: 0.7396 - val_loss: 0.5220 - val_acc: 0.7552\n",
      "Epoch 150/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.5192 - acc: 0.7396 - val_loss: 0.5215 - val_acc: 0.7552\n",
      "Epoch 151/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.5185 - acc: 0.7396 - val_loss: 0.5210 - val_acc: 0.7552\n",
      "Epoch 152/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.5180 - acc: 0.7396 - val_loss: 0.5205 - val_acc: 0.7552\n",
      "Epoch 153/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.5173 - acc: 0.7431 - val_loss: 0.5200 - val_acc: 0.7552\n",
      "Epoch 154/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.5167 - acc: 0.7413 - val_loss: 0.5196 - val_acc: 0.7552\n",
      "Epoch 155/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.5160 - acc: 0.7413 - val_loss: 0.5191 - val_acc: 0.7552\n",
      "Epoch 156/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.5154 - acc: 0.7413 - val_loss: 0.5186 - val_acc: 0.7552\n",
      "Epoch 157/1500\n",
      "576/576 [==============================] - 0s 31us/sample - loss: 0.5148 - acc: 0.7413 - val_loss: 0.5181 - val_acc: 0.7552\n",
      "Epoch 158/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.5141 - acc: 0.7396 - val_loss: 0.5176 - val_acc: 0.7552\n",
      "Epoch 159/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.5135 - acc: 0.7396 - val_loss: 0.5171 - val_acc: 0.7552\n",
      "Epoch 160/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.5129 - acc: 0.7413 - val_loss: 0.5167 - val_acc: 0.7604\n",
      "Epoch 161/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.5123 - acc: 0.7396 - val_loss: 0.5162 - val_acc: 0.7604\n",
      "Epoch 162/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.5116 - acc: 0.7413 - val_loss: 0.5158 - val_acc: 0.7604\n",
      "Epoch 163/1500\n",
      "576/576 [==============================] - 0s 31us/sample - loss: 0.5110 - acc: 0.7413 - val_loss: 0.5153 - val_acc: 0.7604\n",
      "Epoch 164/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.5105 - acc: 0.7431 - val_loss: 0.5149 - val_acc: 0.7552\n",
      "Epoch 165/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.5099 - acc: 0.7431 - val_loss: 0.5145 - val_acc: 0.7552\n",
      "Epoch 166/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.5093 - acc: 0.7431 - val_loss: 0.5141 - val_acc: 0.7552\n",
      "Epoch 167/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.5087 - acc: 0.7431 - val_loss: 0.5136 - val_acc: 0.7552\n",
      "Epoch 168/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.5082 - acc: 0.7448 - val_loss: 0.5132 - val_acc: 0.7552\n",
      "Epoch 169/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.5076 - acc: 0.7448 - val_loss: 0.5129 - val_acc: 0.7604\n",
      "Epoch 170/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.5071 - acc: 0.7465 - val_loss: 0.5125 - val_acc: 0.7604\n",
      "Epoch 171/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.5065 - acc: 0.7465 - val_loss: 0.5121 - val_acc: 0.7604\n",
      "Epoch 172/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.5060 - acc: 0.7465 - val_loss: 0.5117 - val_acc: 0.7656\n",
      "Epoch 173/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.5055 - acc: 0.7448 - val_loss: 0.5113 - val_acc: 0.7656\n",
      "Epoch 174/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.5050 - acc: 0.7465 - val_loss: 0.5110 - val_acc: 0.7656\n",
      "Epoch 175/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.5045 - acc: 0.7517 - val_loss: 0.5106 - val_acc: 0.7656\n",
      "Epoch 176/1500\n",
      "576/576 [==============================] - 0s 50us/sample - loss: 0.5039 - acc: 0.7500 - val_loss: 0.5103 - val_acc: 0.7656\n",
      "Epoch 177/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.5035 - acc: 0.7517 - val_loss: 0.5099 - val_acc: 0.7656\n",
      "Epoch 178/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 26us/sample - loss: 0.5029 - acc: 0.7517 - val_loss: 0.5096 - val_acc: 0.7656\n",
      "Epoch 179/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.5024 - acc: 0.7517 - val_loss: 0.5093 - val_acc: 0.7708\n",
      "Epoch 180/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.5020 - acc: 0.7500 - val_loss: 0.5089 - val_acc: 0.7656\n",
      "Epoch 181/1500\n",
      "576/576 [==============================] - 0s 31us/sample - loss: 0.5015 - acc: 0.7500 - val_loss: 0.5086 - val_acc: 0.7656\n",
      "Epoch 182/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.5010 - acc: 0.7517 - val_loss: 0.5083 - val_acc: 0.7656\n",
      "Epoch 183/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.5005 - acc: 0.7535 - val_loss: 0.5080 - val_acc: 0.7656\n",
      "Epoch 184/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.5000 - acc: 0.7552 - val_loss: 0.5077 - val_acc: 0.7656\n",
      "Epoch 185/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4995 - acc: 0.7552 - val_loss: 0.5074 - val_acc: 0.7656\n",
      "Epoch 186/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4991 - acc: 0.7535 - val_loss: 0.5071 - val_acc: 0.7708\n",
      "Epoch 187/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4987 - acc: 0.7535 - val_loss: 0.5068 - val_acc: 0.7708\n",
      "Epoch 188/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4982 - acc: 0.7535 - val_loss: 0.5065 - val_acc: 0.7708\n",
      "Epoch 189/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4977 - acc: 0.7535 - val_loss: 0.5062 - val_acc: 0.7708\n",
      "Epoch 190/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4973 - acc: 0.7535 - val_loss: 0.5060 - val_acc: 0.7708\n",
      "Epoch 191/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4968 - acc: 0.7535 - val_loss: 0.5057 - val_acc: 0.7708\n",
      "Epoch 192/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4964 - acc: 0.7517 - val_loss: 0.5054 - val_acc: 0.7708\n",
      "Epoch 193/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4959 - acc: 0.7535 - val_loss: 0.5052 - val_acc: 0.7708\n",
      "Epoch 194/1500\n",
      "576/576 [==============================] - 0s 31us/sample - loss: 0.4955 - acc: 0.7517 - val_loss: 0.5049 - val_acc: 0.7708\n",
      "Epoch 195/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4951 - acc: 0.7517 - val_loss: 0.5047 - val_acc: 0.7708\n",
      "Epoch 196/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4946 - acc: 0.7517 - val_loss: 0.5044 - val_acc: 0.7708\n",
      "Epoch 197/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4942 - acc: 0.7517 - val_loss: 0.5042 - val_acc: 0.7708\n",
      "Epoch 198/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4938 - acc: 0.7517 - val_loss: 0.5039 - val_acc: 0.7708\n",
      "Epoch 199/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4934 - acc: 0.7517 - val_loss: 0.5037 - val_acc: 0.7708\n",
      "Epoch 200/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4929 - acc: 0.7517 - val_loss: 0.5035 - val_acc: 0.7708\n",
      "Epoch 201/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4925 - acc: 0.7517 - val_loss: 0.5032 - val_acc: 0.7708\n",
      "Epoch 202/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4922 - acc: 0.7552 - val_loss: 0.5030 - val_acc: 0.7708\n",
      "Epoch 203/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4917 - acc: 0.7569 - val_loss: 0.5028 - val_acc: 0.7656\n",
      "Epoch 204/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4913 - acc: 0.7604 - val_loss: 0.5026 - val_acc: 0.7656\n",
      "Epoch 205/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4910 - acc: 0.7604 - val_loss: 0.5023 - val_acc: 0.7656\n",
      "Epoch 206/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4905 - acc: 0.7604 - val_loss: 0.5021 - val_acc: 0.7656\n",
      "Epoch 207/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4901 - acc: 0.7622 - val_loss: 0.5019 - val_acc: 0.7656\n",
      "Epoch 208/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4898 - acc: 0.7622 - val_loss: 0.5017 - val_acc: 0.7656\n",
      "Epoch 209/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4894 - acc: 0.7639 - val_loss: 0.5015 - val_acc: 0.7656\n",
      "Epoch 210/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4890 - acc: 0.7639 - val_loss: 0.5013 - val_acc: 0.7656\n",
      "Epoch 211/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4887 - acc: 0.7639 - val_loss: 0.5011 - val_acc: 0.7656\n",
      "Epoch 212/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4883 - acc: 0.7639 - val_loss: 0.5009 - val_acc: 0.7656\n",
      "Epoch 213/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4880 - acc: 0.7639 - val_loss: 0.5007 - val_acc: 0.7656\n",
      "Epoch 214/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4876 - acc: 0.7639 - val_loss: 0.5005 - val_acc: 0.7656\n",
      "Epoch 215/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4872 - acc: 0.7639 - val_loss: 0.5004 - val_acc: 0.7656\n",
      "Epoch 216/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4869 - acc: 0.7639 - val_loss: 0.5002 - val_acc: 0.7656\n",
      "Epoch 217/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4865 - acc: 0.7639 - val_loss: 0.5000 - val_acc: 0.7656\n",
      "Epoch 218/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4861 - acc: 0.7639 - val_loss: 0.4999 - val_acc: 0.7656\n",
      "Epoch 219/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4858 - acc: 0.7639 - val_loss: 0.4997 - val_acc: 0.7656\n",
      "Epoch 220/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4854 - acc: 0.7639 - val_loss: 0.4995 - val_acc: 0.7656\n",
      "Epoch 221/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4851 - acc: 0.7639 - val_loss: 0.4994 - val_acc: 0.7656\n",
      "Epoch 222/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4847 - acc: 0.7639 - val_loss: 0.4992 - val_acc: 0.7656\n",
      "Epoch 223/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4843 - acc: 0.7622 - val_loss: 0.4990 - val_acc: 0.7656\n",
      "Epoch 224/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4840 - acc: 0.7622 - val_loss: 0.4989 - val_acc: 0.7656\n",
      "Epoch 225/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4836 - acc: 0.7622 - val_loss: 0.4987 - val_acc: 0.7656\n",
      "Epoch 226/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4833 - acc: 0.7622 - val_loss: 0.4986 - val_acc: 0.7656\n",
      "Epoch 227/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4830 - acc: 0.7622 - val_loss: 0.4984 - val_acc: 0.7656\n",
      "Epoch 228/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4826 - acc: 0.7604 - val_loss: 0.4983 - val_acc: 0.7656\n",
      "Epoch 229/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4823 - acc: 0.7587 - val_loss: 0.4982 - val_acc: 0.7656\n",
      "Epoch 230/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4820 - acc: 0.7622 - val_loss: 0.4980 - val_acc: 0.7656\n",
      "Epoch 231/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4816 - acc: 0.7604 - val_loss: 0.4979 - val_acc: 0.7656\n",
      "Epoch 232/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4813 - acc: 0.7587 - val_loss: 0.4978 - val_acc: 0.7656\n",
      "Epoch 233/1500\n",
      "576/576 [==============================] - 0s 36us/sample - loss: 0.4810 - acc: 0.7587 - val_loss: 0.4976 - val_acc: 0.7656\n",
      "Epoch 234/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4807 - acc: 0.7587 - val_loss: 0.4975 - val_acc: 0.7656\n",
      "Epoch 235/1500\n",
      "576/576 [==============================] - 0s 33us/sample - loss: 0.4803 - acc: 0.7604 - val_loss: 0.4974 - val_acc: 0.7656\n",
      "Epoch 236/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4800 - acc: 0.7604 - val_loss: 0.4973 - val_acc: 0.7656\n",
      "Epoch 237/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4798 - acc: 0.7604 - val_loss: 0.4972 - val_acc: 0.7656\n",
      "Epoch 238/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4794 - acc: 0.7587 - val_loss: 0.4971 - val_acc: 0.7656\n",
      "Epoch 239/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4791 - acc: 0.7587 - val_loss: 0.4970 - val_acc: 0.7656\n",
      "Epoch 240/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4788 - acc: 0.7587 - val_loss: 0.4969 - val_acc: 0.7656\n",
      "Epoch 241/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4785 - acc: 0.7587 - val_loss: 0.4968 - val_acc: 0.7708\n",
      "Epoch 242/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4782 - acc: 0.7587 - val_loss: 0.4967 - val_acc: 0.7708\n",
      "Epoch 243/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4779 - acc: 0.7569 - val_loss: 0.4966 - val_acc: 0.7708\n",
      "Epoch 244/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4776 - acc: 0.7587 - val_loss: 0.4965 - val_acc: 0.7708\n",
      "Epoch 245/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4773 - acc: 0.7604 - val_loss: 0.4964 - val_acc: 0.7708\n",
      "Epoch 246/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4770 - acc: 0.7604 - val_loss: 0.4963 - val_acc: 0.7708\n",
      "Epoch 247/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4767 - acc: 0.7622 - val_loss: 0.4962 - val_acc: 0.7708\n",
      "Epoch 248/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4765 - acc: 0.7622 - val_loss: 0.4961 - val_acc: 0.7708\n",
      "Epoch 249/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4762 - acc: 0.7622 - val_loss: 0.4961 - val_acc: 0.7708\n",
      "Epoch 250/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4759 - acc: 0.7622 - val_loss: 0.4960 - val_acc: 0.7708\n",
      "Epoch 251/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4756 - acc: 0.7639 - val_loss: 0.4959 - val_acc: 0.7708\n",
      "Epoch 252/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4754 - acc: 0.7639 - val_loss: 0.4958 - val_acc: 0.7708\n",
      "Epoch 253/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4751 - acc: 0.7656 - val_loss: 0.4957 - val_acc: 0.7708\n",
      "Epoch 254/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4749 - acc: 0.7639 - val_loss: 0.4956 - val_acc: 0.7708\n",
      "Epoch 255/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4746 - acc: 0.7656 - val_loss: 0.4956 - val_acc: 0.7708\n",
      "Epoch 256/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4744 - acc: 0.7656 - val_loss: 0.4955 - val_acc: 0.7708\n",
      "Epoch 257/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4741 - acc: 0.7656 - val_loss: 0.4954 - val_acc: 0.7708\n",
      "Epoch 258/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4738 - acc: 0.7656 - val_loss: 0.4953 - val_acc: 0.7708\n",
      "Epoch 259/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4736 - acc: 0.7656 - val_loss: 0.4953 - val_acc: 0.7708\n",
      "Epoch 260/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4734 - acc: 0.7622 - val_loss: 0.4952 - val_acc: 0.7708\n",
      "Epoch 261/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4731 - acc: 0.7622 - val_loss: 0.4951 - val_acc: 0.7708\n",
      "Epoch 262/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4729 - acc: 0.7622 - val_loss: 0.4950 - val_acc: 0.7708\n",
      "Epoch 263/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4726 - acc: 0.7622 - val_loss: 0.4950 - val_acc: 0.7708\n",
      "Epoch 264/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4724 - acc: 0.7656 - val_loss: 0.4949 - val_acc: 0.7708\n",
      "Epoch 265/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4722 - acc: 0.7656 - val_loss: 0.4948 - val_acc: 0.7708\n",
      "Epoch 266/1500\n",
      "576/576 [==============================] - 0s 31us/sample - loss: 0.4720 - acc: 0.7656 - val_loss: 0.4948 - val_acc: 0.7708\n",
      "Epoch 267/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4717 - acc: 0.7656 - val_loss: 0.4947 - val_acc: 0.7708\n",
      "Epoch 268/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4715 - acc: 0.7656 - val_loss: 0.4947 - val_acc: 0.7708\n",
      "Epoch 269/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4712 - acc: 0.7639 - val_loss: 0.4946 - val_acc: 0.7708\n",
      "Epoch 270/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4711 - acc: 0.7656 - val_loss: 0.4946 - val_acc: 0.7708\n",
      "Epoch 271/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4708 - acc: 0.7639 - val_loss: 0.4945 - val_acc: 0.7708\n",
      "Epoch 272/1500\n",
      "576/576 [==============================] - 0s 31us/sample - loss: 0.4706 - acc: 0.7639 - val_loss: 0.4945 - val_acc: 0.7708\n",
      "Epoch 273/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4704 - acc: 0.7656 - val_loss: 0.4944 - val_acc: 0.7708\n",
      "Epoch 274/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4701 - acc: 0.7656 - val_loss: 0.4944 - val_acc: 0.7708\n",
      "Epoch 275/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4699 - acc: 0.7656 - val_loss: 0.4943 - val_acc: 0.7708\n",
      "Epoch 276/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4697 - acc: 0.7656 - val_loss: 0.4942 - val_acc: 0.7708\n",
      "Epoch 277/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4695 - acc: 0.7656 - val_loss: 0.4942 - val_acc: 0.7708\n",
      "Epoch 278/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4693 - acc: 0.7656 - val_loss: 0.4941 - val_acc: 0.7708\n",
      "Epoch 279/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4691 - acc: 0.7656 - val_loss: 0.4941 - val_acc: 0.7708\n",
      "Epoch 280/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4688 - acc: 0.7656 - val_loss: 0.4940 - val_acc: 0.7708\n",
      "Epoch 281/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4686 - acc: 0.7656 - val_loss: 0.4940 - val_acc: 0.7708\n",
      "Epoch 282/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4684 - acc: 0.7656 - val_loss: 0.4940 - val_acc: 0.7708\n",
      "Epoch 283/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4683 - acc: 0.7656 - val_loss: 0.4939 - val_acc: 0.7708\n",
      "Epoch 284/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4680 - acc: 0.7656 - val_loss: 0.4939 - val_acc: 0.7708\n",
      "Epoch 285/1500\n",
      "576/576 [==============================] - 0s 31us/sample - loss: 0.4679 - acc: 0.7656 - val_loss: 0.4939 - val_acc: 0.7708\n",
      "Epoch 286/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4676 - acc: 0.7656 - val_loss: 0.4938 - val_acc: 0.7708\n",
      "Epoch 287/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4674 - acc: 0.7656 - val_loss: 0.4938 - val_acc: 0.7708\n",
      "Epoch 288/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4672 - acc: 0.7656 - val_loss: 0.4938 - val_acc: 0.7708\n",
      "Epoch 289/1500\n",
      "576/576 [==============================] - 0s 35us/sample - loss: 0.4671 - acc: 0.7656 - val_loss: 0.4937 - val_acc: 0.7708\n",
      "Epoch 290/1500\n",
      "576/576 [==============================] - 0s 31us/sample - loss: 0.4669 - acc: 0.7656 - val_loss: 0.4937 - val_acc: 0.7708\n",
      "Epoch 291/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4667 - acc: 0.7656 - val_loss: 0.4937 - val_acc: 0.7708\n",
      "Epoch 292/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4665 - acc: 0.7656 - val_loss: 0.4937 - val_acc: 0.7708\n",
      "Epoch 293/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4663 - acc: 0.7656 - val_loss: 0.4937 - val_acc: 0.7708\n",
      "Epoch 294/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4661 - acc: 0.7656 - val_loss: 0.4936 - val_acc: 0.7708\n",
      "Epoch 295/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4660 - acc: 0.7656 - val_loss: 0.4936 - val_acc: 0.7708\n",
      "Epoch 296/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4658 - acc: 0.7639 - val_loss: 0.4936 - val_acc: 0.7708\n",
      "Epoch 297/1500\n",
      "576/576 [==============================] - 0s 31us/sample - loss: 0.4657 - acc: 0.7656 - val_loss: 0.4936 - val_acc: 0.7708\n",
      "Epoch 298/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4655 - acc: 0.7674 - val_loss: 0.4936 - val_acc: 0.7708\n",
      "Epoch 299/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4654 - acc: 0.7639 - val_loss: 0.4935 - val_acc: 0.7708\n",
      "Epoch 300/1500\n",
      "576/576 [==============================] - 0s 31us/sample - loss: 0.4652 - acc: 0.7656 - val_loss: 0.4935 - val_acc: 0.7708\n",
      "Epoch 301/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4650 - acc: 0.7639 - val_loss: 0.4935 - val_acc: 0.7708\n",
      "Epoch 302/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4649 - acc: 0.7656 - val_loss: 0.4935 - val_acc: 0.7708\n",
      "Epoch 303/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4647 - acc: 0.7639 - val_loss: 0.4935 - val_acc: 0.7708\n",
      "Epoch 304/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4646 - acc: 0.7622 - val_loss: 0.4935 - val_acc: 0.7708\n",
      "Epoch 305/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4644 - acc: 0.7639 - val_loss: 0.4935 - val_acc: 0.7708\n",
      "Epoch 306/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4642 - acc: 0.7639 - val_loss: 0.4935 - val_acc: 0.7656\n",
      "Epoch 307/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4641 - acc: 0.7622 - val_loss: 0.4935 - val_acc: 0.7656\n",
      "Epoch 308/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4639 - acc: 0.7604 - val_loss: 0.4935 - val_acc: 0.7656\n",
      "Epoch 309/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4638 - acc: 0.7622 - val_loss: 0.4935 - val_acc: 0.7656\n",
      "Epoch 310/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4637 - acc: 0.7622 - val_loss: 0.4935 - val_acc: 0.7656\n",
      "Epoch 311/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4635 - acc: 0.7639 - val_loss: 0.4935 - val_acc: 0.7656\n",
      "Epoch 312/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4634 - acc: 0.7639 - val_loss: 0.4934 - val_acc: 0.7656\n",
      "Epoch 313/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4632 - acc: 0.7639 - val_loss: 0.4935 - val_acc: 0.7708\n",
      "Epoch 314/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4631 - acc: 0.7656 - val_loss: 0.4934 - val_acc: 0.7708\n",
      "Epoch 315/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4629 - acc: 0.7656 - val_loss: 0.4934 - val_acc: 0.7708\n",
      "Epoch 316/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4629 - acc: 0.7656 - val_loss: 0.4934 - val_acc: 0.7708\n",
      "Epoch 317/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4627 - acc: 0.7656 - val_loss: 0.4934 - val_acc: 0.7708\n",
      "Epoch 318/1500\n",
      "576/576 [==============================] - 0s 31us/sample - loss: 0.4625 - acc: 0.7656 - val_loss: 0.4934 - val_acc: 0.7708\n",
      "Epoch 319/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4625 - acc: 0.7674 - val_loss: 0.4934 - val_acc: 0.7708\n",
      "Epoch 320/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4623 - acc: 0.7656 - val_loss: 0.4934 - val_acc: 0.7708\n",
      "Epoch 321/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4622 - acc: 0.7674 - val_loss: 0.4934 - val_acc: 0.7708\n",
      "Epoch 322/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4621 - acc: 0.7674 - val_loss: 0.4933 - val_acc: 0.7708\n",
      "Epoch 323/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4619 - acc: 0.7691 - val_loss: 0.4933 - val_acc: 0.7708\n",
      "Epoch 324/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4618 - acc: 0.7691 - val_loss: 0.4933 - val_acc: 0.7708\n",
      "Epoch 325/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4617 - acc: 0.7691 - val_loss: 0.4933 - val_acc: 0.7708\n",
      "Epoch 326/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4616 - acc: 0.7691 - val_loss: 0.4933 - val_acc: 0.7708\n",
      "Epoch 327/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4615 - acc: 0.7691 - val_loss: 0.4933 - val_acc: 0.7708\n",
      "Epoch 328/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4614 - acc: 0.7691 - val_loss: 0.4933 - val_acc: 0.7708\n",
      "Epoch 329/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4612 - acc: 0.7691 - val_loss: 0.4933 - val_acc: 0.7708\n",
      "Epoch 330/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4611 - acc: 0.7691 - val_loss: 0.4933 - val_acc: 0.7708\n",
      "Epoch 331/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4611 - acc: 0.7691 - val_loss: 0.4933 - val_acc: 0.7708\n",
      "Epoch 332/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4609 - acc: 0.7674 - val_loss: 0.4933 - val_acc: 0.7708\n",
      "Epoch 333/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4607 - acc: 0.7691 - val_loss: 0.4933 - val_acc: 0.7760\n",
      "Epoch 334/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4606 - acc: 0.7674 - val_loss: 0.4932 - val_acc: 0.7760\n",
      "Epoch 335/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4605 - acc: 0.7691 - val_loss: 0.4932 - val_acc: 0.7760\n",
      "Epoch 336/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4604 - acc: 0.7691 - val_loss: 0.4932 - val_acc: 0.7760\n",
      "Epoch 337/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4603 - acc: 0.7674 - val_loss: 0.4932 - val_acc: 0.7760\n",
      "Epoch 338/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4602 - acc: 0.7674 - val_loss: 0.4932 - val_acc: 0.7760\n",
      "Epoch 339/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4601 - acc: 0.7691 - val_loss: 0.4932 - val_acc: 0.7760\n",
      "Epoch 340/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4600 - acc: 0.7691 - val_loss: 0.4931 - val_acc: 0.7760\n",
      "Epoch 341/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4598 - acc: 0.7674 - val_loss: 0.4931 - val_acc: 0.7760\n",
      "Epoch 342/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4598 - acc: 0.7674 - val_loss: 0.4931 - val_acc: 0.7760\n",
      "Epoch 343/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4597 - acc: 0.7674 - val_loss: 0.4931 - val_acc: 0.7760\n",
      "Epoch 344/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4595 - acc: 0.7674 - val_loss: 0.4931 - val_acc: 0.7760\n",
      "Epoch 345/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4594 - acc: 0.7674 - val_loss: 0.4931 - val_acc: 0.7760\n",
      "Epoch 346/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4593 - acc: 0.7674 - val_loss: 0.4931 - val_acc: 0.7760\n",
      "Epoch 347/1500\n",
      "576/576 [==============================] - 0s 33us/sample - loss: 0.4592 - acc: 0.7674 - val_loss: 0.4930 - val_acc: 0.7760\n",
      "Epoch 348/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4591 - acc: 0.7674 - val_loss: 0.4930 - val_acc: 0.7760\n",
      "Epoch 349/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4590 - acc: 0.7691 - val_loss: 0.4930 - val_acc: 0.7760\n",
      "Epoch 350/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4589 - acc: 0.7674 - val_loss: 0.4930 - val_acc: 0.7760\n",
      "Epoch 351/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4587 - acc: 0.7674 - val_loss: 0.4929 - val_acc: 0.7760\n",
      "Epoch 352/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4586 - acc: 0.7674 - val_loss: 0.4929 - val_acc: 0.7760\n",
      "Epoch 353/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4585 - acc: 0.7674 - val_loss: 0.4929 - val_acc: 0.7760\n",
      "Epoch 354/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4583 - acc: 0.7674 - val_loss: 0.4929 - val_acc: 0.7760\n",
      "Epoch 355/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4582 - acc: 0.7674 - val_loss: 0.4928 - val_acc: 0.7760\n",
      "Epoch 356/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4581 - acc: 0.7674 - val_loss: 0.4928 - val_acc: 0.7760\n",
      "Epoch 357/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4580 - acc: 0.7674 - val_loss: 0.4928 - val_acc: 0.7760\n",
      "Epoch 358/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4579 - acc: 0.7691 - val_loss: 0.4928 - val_acc: 0.7760\n",
      "Epoch 359/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4577 - acc: 0.7674 - val_loss: 0.4927 - val_acc: 0.7760\n",
      "Epoch 360/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4576 - acc: 0.7691 - val_loss: 0.4927 - val_acc: 0.7760\n",
      "Epoch 361/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4575 - acc: 0.7674 - val_loss: 0.4927 - val_acc: 0.7760\n",
      "Epoch 362/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4574 - acc: 0.7691 - val_loss: 0.4927 - val_acc: 0.7760\n",
      "Epoch 363/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4573 - acc: 0.7674 - val_loss: 0.4927 - val_acc: 0.7760\n",
      "Epoch 364/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4572 - acc: 0.7656 - val_loss: 0.4926 - val_acc: 0.7760\n",
      "Epoch 365/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4571 - acc: 0.7656 - val_loss: 0.4926 - val_acc: 0.7812\n",
      "Epoch 366/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4569 - acc: 0.7674 - val_loss: 0.4926 - val_acc: 0.7865\n",
      "Epoch 367/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4569 - acc: 0.7674 - val_loss: 0.4926 - val_acc: 0.7865\n",
      "Epoch 368/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4567 - acc: 0.7674 - val_loss: 0.4925 - val_acc: 0.7865\n",
      "Epoch 369/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4567 - acc: 0.7674 - val_loss: 0.4925 - val_acc: 0.7865\n",
      "Epoch 370/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4565 - acc: 0.7674 - val_loss: 0.4925 - val_acc: 0.7865\n",
      "Epoch 371/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4564 - acc: 0.7691 - val_loss: 0.4925 - val_acc: 0.7865\n",
      "Epoch 372/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4563 - acc: 0.7691 - val_loss: 0.4925 - val_acc: 0.7865\n",
      "Epoch 373/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4561 - acc: 0.7674 - val_loss: 0.4925 - val_acc: 0.7865\n",
      "Epoch 374/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4561 - acc: 0.7691 - val_loss: 0.4924 - val_acc: 0.7865\n",
      "Epoch 375/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4559 - acc: 0.7691 - val_loss: 0.4924 - val_acc: 0.7865\n",
      "Epoch 376/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4558 - acc: 0.7691 - val_loss: 0.4924 - val_acc: 0.7865\n",
      "Epoch 377/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4558 - acc: 0.7691 - val_loss: 0.4924 - val_acc: 0.7865\n",
      "Epoch 378/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4556 - acc: 0.7674 - val_loss: 0.4924 - val_acc: 0.7865\n",
      "Epoch 379/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4555 - acc: 0.7726 - val_loss: 0.4924 - val_acc: 0.7865\n",
      "Epoch 380/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4554 - acc: 0.7708 - val_loss: 0.4923 - val_acc: 0.7865\n",
      "Epoch 381/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4553 - acc: 0.7726 - val_loss: 0.4923 - val_acc: 0.7865\n",
      "Epoch 382/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4552 - acc: 0.7726 - val_loss: 0.4923 - val_acc: 0.7865\n",
      "Epoch 383/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4550 - acc: 0.7726 - val_loss: 0.4923 - val_acc: 0.7865\n",
      "Epoch 384/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4549 - acc: 0.7726 - val_loss: 0.4923 - val_acc: 0.7865\n",
      "Epoch 385/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4548 - acc: 0.7726 - val_loss: 0.4923 - val_acc: 0.7865\n",
      "Epoch 386/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4547 - acc: 0.7726 - val_loss: 0.4923 - val_acc: 0.7865\n",
      "Epoch 387/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4546 - acc: 0.7726 - val_loss: 0.4923 - val_acc: 0.7865\n",
      "Epoch 388/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4545 - acc: 0.7743 - val_loss: 0.4923 - val_acc: 0.7865\n",
      "Epoch 389/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4544 - acc: 0.7726 - val_loss: 0.4923 - val_acc: 0.7865\n",
      "Epoch 390/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4543 - acc: 0.7726 - val_loss: 0.4923 - val_acc: 0.7865\n",
      "Epoch 391/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4542 - acc: 0.7743 - val_loss: 0.4923 - val_acc: 0.7865\n",
      "Epoch 392/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4541 - acc: 0.7760 - val_loss: 0.4923 - val_acc: 0.7865\n",
      "Epoch 393/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4541 - acc: 0.7760 - val_loss: 0.4923 - val_acc: 0.7865\n",
      "Epoch 394/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4539 - acc: 0.7760 - val_loss: 0.4923 - val_acc: 0.7865\n",
      "Epoch 395/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4538 - acc: 0.7760 - val_loss: 0.4923 - val_acc: 0.7865\n",
      "Epoch 396/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4537 - acc: 0.7760 - val_loss: 0.4923 - val_acc: 0.7865\n",
      "Epoch 397/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4536 - acc: 0.7760 - val_loss: 0.4923 - val_acc: 0.7865\n",
      "Epoch 398/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4535 - acc: 0.7760 - val_loss: 0.4923 - val_acc: 0.7865\n",
      "Epoch 399/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4534 - acc: 0.7760 - val_loss: 0.4923 - val_acc: 0.7865\n",
      "Epoch 400/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4534 - acc: 0.7760 - val_loss: 0.4923 - val_acc: 0.7865\n",
      "Epoch 401/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4532 - acc: 0.7760 - val_loss: 0.4923 - val_acc: 0.7865\n",
      "Epoch 402/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4531 - acc: 0.7760 - val_loss: 0.4923 - val_acc: 0.7865\n",
      "Epoch 403/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4530 - acc: 0.7760 - val_loss: 0.4923 - val_acc: 0.7865\n",
      "Epoch 404/1500\n",
      "576/576 [==============================] - 0s 35us/sample - loss: 0.4530 - acc: 0.7760 - val_loss: 0.4923 - val_acc: 0.7865\n",
      "Epoch 405/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4528 - acc: 0.7760 - val_loss: 0.4923 - val_acc: 0.7865\n",
      "Epoch 406/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4527 - acc: 0.7760 - val_loss: 0.4923 - val_acc: 0.7865\n",
      "Epoch 407/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4526 - acc: 0.7760 - val_loss: 0.4923 - val_acc: 0.7865\n",
      "Epoch 408/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4525 - acc: 0.7760 - val_loss: 0.4924 - val_acc: 0.7865\n",
      "Epoch 409/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4524 - acc: 0.7760 - val_loss: 0.4924 - val_acc: 0.7865\n",
      "Epoch 410/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4523 - acc: 0.7760 - val_loss: 0.4923 - val_acc: 0.7865\n",
      "Epoch 411/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4522 - acc: 0.7760 - val_loss: 0.4923 - val_acc: 0.7865\n",
      "Epoch 412/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4521 - acc: 0.7743 - val_loss: 0.4923 - val_acc: 0.7865\n",
      "Epoch 413/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4520 - acc: 0.7743 - val_loss: 0.4923 - val_acc: 0.7865\n",
      "Epoch 414/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4519 - acc: 0.7760 - val_loss: 0.4923 - val_acc: 0.7865\n",
      "Epoch 415/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4518 - acc: 0.7743 - val_loss: 0.4923 - val_acc: 0.7865\n",
      "Epoch 416/1500\n",
      "576/576 [==============================] - 0s 31us/sample - loss: 0.4517 - acc: 0.7743 - val_loss: 0.4923 - val_acc: 0.7865\n",
      "Epoch 417/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4516 - acc: 0.7760 - val_loss: 0.4924 - val_acc: 0.7865\n",
      "Epoch 418/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4515 - acc: 0.7743 - val_loss: 0.4924 - val_acc: 0.7865\n",
      "Epoch 419/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4514 - acc: 0.7760 - val_loss: 0.4924 - val_acc: 0.7865\n",
      "Epoch 420/1500\n",
      "576/576 [==============================] - 0s 31us/sample - loss: 0.4513 - acc: 0.7760 - val_loss: 0.4924 - val_acc: 0.7865\n",
      "Epoch 421/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4512 - acc: 0.7760 - val_loss: 0.4924 - val_acc: 0.7865\n",
      "Epoch 422/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4511 - acc: 0.7760 - val_loss: 0.4924 - val_acc: 0.7865\n",
      "Epoch 423/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4510 - acc: 0.7760 - val_loss: 0.4924 - val_acc: 0.7865\n",
      "Epoch 424/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4509 - acc: 0.7760 - val_loss: 0.4924 - val_acc: 0.7865\n",
      "Epoch 425/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4508 - acc: 0.7760 - val_loss: 0.4924 - val_acc: 0.7865\n",
      "Epoch 426/1500\n",
      "576/576 [==============================] - 0s 31us/sample - loss: 0.4507 - acc: 0.7760 - val_loss: 0.4924 - val_acc: 0.7865\n",
      "Epoch 427/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4506 - acc: 0.7778 - val_loss: 0.4924 - val_acc: 0.7865\n",
      "Epoch 428/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4505 - acc: 0.7778 - val_loss: 0.4924 - val_acc: 0.7865\n",
      "Epoch 429/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4504 - acc: 0.7778 - val_loss: 0.4924 - val_acc: 0.7865\n",
      "Epoch 430/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4503 - acc: 0.7778 - val_loss: 0.4924 - val_acc: 0.7865\n",
      "Epoch 431/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4502 - acc: 0.7778 - val_loss: 0.4924 - val_acc: 0.7865\n",
      "Epoch 432/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4501 - acc: 0.7778 - val_loss: 0.4924 - val_acc: 0.7865\n",
      "Epoch 433/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4500 - acc: 0.7778 - val_loss: 0.4924 - val_acc: 0.7865\n",
      "Epoch 434/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4499 - acc: 0.7778 - val_loss: 0.4924 - val_acc: 0.7865\n",
      "Epoch 435/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4499 - acc: 0.7778 - val_loss: 0.4924 - val_acc: 0.7865\n",
      "Epoch 436/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4497 - acc: 0.7778 - val_loss: 0.4924 - val_acc: 0.7865\n",
      "Epoch 437/1500\n",
      "576/576 [==============================] - 0s 31us/sample - loss: 0.4497 - acc: 0.7778 - val_loss: 0.4924 - val_acc: 0.7865\n",
      "Epoch 438/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4496 - acc: 0.7795 - val_loss: 0.4924 - val_acc: 0.7865\n",
      "Epoch 439/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4495 - acc: 0.7778 - val_loss: 0.4924 - val_acc: 0.7865\n",
      "Epoch 440/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4495 - acc: 0.7760 - val_loss: 0.4924 - val_acc: 0.7865\n",
      "Epoch 441/1500\n",
      "576/576 [==============================] - 0s 31us/sample - loss: 0.4494 - acc: 0.7760 - val_loss: 0.4924 - val_acc: 0.7865\n",
      "Epoch 442/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4493 - acc: 0.7760 - val_loss: 0.4924 - val_acc: 0.7865\n",
      "Epoch 443/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4492 - acc: 0.7760 - val_loss: 0.4924 - val_acc: 0.7865\n",
      "Epoch 444/1500\n",
      "576/576 [==============================] - 0s 31us/sample - loss: 0.4491 - acc: 0.7760 - val_loss: 0.4924 - val_acc: 0.7865\n",
      "Epoch 445/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4490 - acc: 0.7760 - val_loss: 0.4924 - val_acc: 0.7865\n",
      "Epoch 446/1500\n",
      "576/576 [==============================] - 0s 31us/sample - loss: 0.4490 - acc: 0.7760 - val_loss: 0.4924 - val_acc: 0.7917\n",
      "Epoch 447/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4489 - acc: 0.7760 - val_loss: 0.4925 - val_acc: 0.7917\n",
      "Epoch 448/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4488 - acc: 0.7778 - val_loss: 0.4925 - val_acc: 0.7917\n",
      "Epoch 449/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4487 - acc: 0.7778 - val_loss: 0.4925 - val_acc: 0.7917\n",
      "Epoch 450/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4487 - acc: 0.7778 - val_loss: 0.4925 - val_acc: 0.7917\n",
      "Epoch 451/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4486 - acc: 0.7778 - val_loss: 0.4925 - val_acc: 0.7917\n",
      "Epoch 452/1500\n",
      "576/576 [==============================] - 0s 31us/sample - loss: 0.4485 - acc: 0.7778 - val_loss: 0.4925 - val_acc: 0.7917\n",
      "Epoch 453/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4485 - acc: 0.7778 - val_loss: 0.4925 - val_acc: 0.7917\n",
      "Epoch 454/1500\n",
      "576/576 [==============================] - 0s 31us/sample - loss: 0.4484 - acc: 0.7778 - val_loss: 0.4925 - val_acc: 0.7917\n",
      "Epoch 455/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4483 - acc: 0.7778 - val_loss: 0.4925 - val_acc: 0.7917\n",
      "Epoch 456/1500\n",
      "576/576 [==============================] - 0s 33us/sample - loss: 0.4482 - acc: 0.7778 - val_loss: 0.4926 - val_acc: 0.7917\n",
      "Epoch 457/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4482 - acc: 0.7778 - val_loss: 0.4926 - val_acc: 0.7917\n",
      "Epoch 458/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4481 - acc: 0.7778 - val_loss: 0.4926 - val_acc: 0.7917\n",
      "Epoch 459/1500\n",
      "576/576 [==============================] - 0s 35us/sample - loss: 0.4481 - acc: 0.7778 - val_loss: 0.4926 - val_acc: 0.7917\n",
      "Epoch 460/1500\n",
      "576/576 [==============================] - 0s 33us/sample - loss: 0.4480 - acc: 0.7760 - val_loss: 0.4926 - val_acc: 0.7917\n",
      "Epoch 461/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4479 - acc: 0.7778 - val_loss: 0.4926 - val_acc: 0.7917\n",
      "Epoch 462/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4479 - acc: 0.7778 - val_loss: 0.4926 - val_acc: 0.7917\n",
      "Epoch 463/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4478 - acc: 0.7778 - val_loss: 0.4926 - val_acc: 0.7917\n",
      "Epoch 464/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4477 - acc: 0.7778 - val_loss: 0.4927 - val_acc: 0.7917\n",
      "Epoch 465/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4477 - acc: 0.7760 - val_loss: 0.4927 - val_acc: 0.7917\n",
      "Epoch 466/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4476 - acc: 0.7778 - val_loss: 0.4927 - val_acc: 0.7917\n",
      "Epoch 467/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4476 - acc: 0.7760 - val_loss: 0.4927 - val_acc: 0.7917\n",
      "Epoch 468/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4475 - acc: 0.7760 - val_loss: 0.4927 - val_acc: 0.7917\n",
      "Epoch 469/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4475 - acc: 0.7743 - val_loss: 0.4927 - val_acc: 0.7917\n",
      "Epoch 470/1500\n",
      "576/576 [==============================] - 0s 31us/sample - loss: 0.4474 - acc: 0.7743 - val_loss: 0.4927 - val_acc: 0.7917\n",
      "Epoch 471/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4473 - acc: 0.7743 - val_loss: 0.4927 - val_acc: 0.7917\n",
      "Epoch 472/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4473 - acc: 0.7743 - val_loss: 0.4927 - val_acc: 0.7917\n",
      "Epoch 473/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4472 - acc: 0.7743 - val_loss: 0.4927 - val_acc: 0.7917\n",
      "Epoch 474/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4471 - acc: 0.7743 - val_loss: 0.4927 - val_acc: 0.7917\n",
      "Epoch 475/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4470 - acc: 0.7743 - val_loss: 0.4927 - val_acc: 0.7917\n",
      "Epoch 476/1500\n",
      "576/576 [==============================] - 0s 31us/sample - loss: 0.4470 - acc: 0.7743 - val_loss: 0.4927 - val_acc: 0.7917\n",
      "Epoch 477/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4469 - acc: 0.7743 - val_loss: 0.4927 - val_acc: 0.7917\n",
      "Epoch 478/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4469 - acc: 0.7743 - val_loss: 0.4927 - val_acc: 0.7917\n",
      "Epoch 479/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4469 - acc: 0.7743 - val_loss: 0.4927 - val_acc: 0.7917\n",
      "Epoch 480/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4468 - acc: 0.7743 - val_loss: 0.4928 - val_acc: 0.7917\n",
      "Epoch 481/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4468 - acc: 0.7743 - val_loss: 0.4928 - val_acc: 0.7917\n",
      "Epoch 482/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4467 - acc: 0.7743 - val_loss: 0.4928 - val_acc: 0.7917\n",
      "Epoch 483/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4466 - acc: 0.7743 - val_loss: 0.4928 - val_acc: 0.7917\n",
      "Epoch 484/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4465 - acc: 0.7743 - val_loss: 0.4928 - val_acc: 0.7917\n",
      "Epoch 485/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4464 - acc: 0.7760 - val_loss: 0.4928 - val_acc: 0.7917\n",
      "Epoch 486/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4464 - acc: 0.7743 - val_loss: 0.4928 - val_acc: 0.7917\n",
      "Epoch 487/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4464 - acc: 0.7743 - val_loss: 0.4928 - val_acc: 0.7917\n",
      "Epoch 488/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4463 - acc: 0.7743 - val_loss: 0.4928 - val_acc: 0.7917\n",
      "Epoch 489/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4463 - acc: 0.7743 - val_loss: 0.4928 - val_acc: 0.7917\n",
      "Epoch 490/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4462 - acc: 0.7743 - val_loss: 0.4928 - val_acc: 0.7917\n",
      "Epoch 491/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4461 - acc: 0.7743 - val_loss: 0.4928 - val_acc: 0.7917\n",
      "Epoch 492/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4462 - acc: 0.7743 - val_loss: 0.4929 - val_acc: 0.7917\n",
      "Epoch 493/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4461 - acc: 0.7743 - val_loss: 0.4929 - val_acc: 0.7917\n",
      "Epoch 494/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4461 - acc: 0.7743 - val_loss: 0.4929 - val_acc: 0.7917\n",
      "Epoch 495/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4460 - acc: 0.7743 - val_loss: 0.4929 - val_acc: 0.7917\n",
      "Epoch 496/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4459 - acc: 0.7743 - val_loss: 0.4929 - val_acc: 0.7917\n",
      "Epoch 497/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4459 - acc: 0.7743 - val_loss: 0.4929 - val_acc: 0.7917\n",
      "Epoch 498/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4458 - acc: 0.7743 - val_loss: 0.4929 - val_acc: 0.7917\n",
      "Epoch 499/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4458 - acc: 0.7743 - val_loss: 0.4929 - val_acc: 0.7917\n",
      "Epoch 500/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4457 - acc: 0.7743 - val_loss: 0.4930 - val_acc: 0.7917\n",
      "Epoch 501/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4457 - acc: 0.7743 - val_loss: 0.4930 - val_acc: 0.7917\n",
      "Epoch 502/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4456 - acc: 0.7743 - val_loss: 0.4930 - val_acc: 0.7917\n",
      "Epoch 503/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4456 - acc: 0.7743 - val_loss: 0.4930 - val_acc: 0.7917\n",
      "Epoch 504/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4455 - acc: 0.7743 - val_loss: 0.4930 - val_acc: 0.7917\n",
      "Epoch 505/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4455 - acc: 0.7743 - val_loss: 0.4930 - val_acc: 0.7917\n",
      "Epoch 506/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4455 - acc: 0.7743 - val_loss: 0.4930 - val_acc: 0.7917\n",
      "Epoch 507/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4454 - acc: 0.7743 - val_loss: 0.4931 - val_acc: 0.7917\n",
      "Epoch 508/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4453 - acc: 0.7743 - val_loss: 0.4931 - val_acc: 0.7917\n",
      "Epoch 509/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4453 - acc: 0.7743 - val_loss: 0.4931 - val_acc: 0.7917\n",
      "Epoch 510/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4453 - acc: 0.7760 - val_loss: 0.4931 - val_acc: 0.7917\n",
      "Epoch 511/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4452 - acc: 0.7743 - val_loss: 0.4931 - val_acc: 0.7917\n",
      "Epoch 512/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4452 - acc: 0.7743 - val_loss: 0.4931 - val_acc: 0.7917\n",
      "Epoch 513/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4451 - acc: 0.7743 - val_loss: 0.4931 - val_acc: 0.7917\n",
      "Epoch 514/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4450 - acc: 0.7743 - val_loss: 0.4932 - val_acc: 0.7917\n",
      "Epoch 515/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4450 - acc: 0.7760 - val_loss: 0.4932 - val_acc: 0.7917\n",
      "Epoch 516/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4450 - acc: 0.7743 - val_loss: 0.4932 - val_acc: 0.7917\n",
      "Epoch 517/1500\n",
      "576/576 [==============================] - 0s 40us/sample - loss: 0.4449 - acc: 0.7743 - val_loss: 0.4932 - val_acc: 0.7917\n",
      "Epoch 518/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4449 - acc: 0.7743 - val_loss: 0.4932 - val_acc: 0.7917\n",
      "Epoch 519/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4448 - acc: 0.7743 - val_loss: 0.4932 - val_acc: 0.7917\n",
      "Epoch 520/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4448 - acc: 0.7743 - val_loss: 0.4932 - val_acc: 0.7917\n",
      "Epoch 521/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4447 - acc: 0.7743 - val_loss: 0.4932 - val_acc: 0.7865\n",
      "Epoch 522/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4447 - acc: 0.7743 - val_loss: 0.4933 - val_acc: 0.7865\n",
      "Epoch 523/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4447 - acc: 0.7743 - val_loss: 0.4933 - val_acc: 0.7865\n",
      "Epoch 524/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4446 - acc: 0.7743 - val_loss: 0.4933 - val_acc: 0.7865\n",
      "Epoch 525/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4446 - acc: 0.7760 - val_loss: 0.4933 - val_acc: 0.7865\n",
      "Epoch 526/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4445 - acc: 0.7743 - val_loss: 0.4933 - val_acc: 0.7865\n",
      "Epoch 527/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4445 - acc: 0.7726 - val_loss: 0.4933 - val_acc: 0.7865\n",
      "Epoch 528/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4445 - acc: 0.7743 - val_loss: 0.4933 - val_acc: 0.7865\n",
      "Epoch 529/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4444 - acc: 0.7743 - val_loss: 0.4933 - val_acc: 0.7865\n",
      "Epoch 530/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4444 - acc: 0.7743 - val_loss: 0.4933 - val_acc: 0.7865\n",
      "Epoch 531/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4444 - acc: 0.7726 - val_loss: 0.4933 - val_acc: 0.7865\n",
      "Epoch 532/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4443 - acc: 0.7726 - val_loss: 0.4934 - val_acc: 0.7865\n",
      "Epoch 533/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4443 - acc: 0.7760 - val_loss: 0.4934 - val_acc: 0.7865\n",
      "Epoch 534/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4443 - acc: 0.7743 - val_loss: 0.4934 - val_acc: 0.7865\n",
      "Epoch 535/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4442 - acc: 0.7743 - val_loss: 0.4934 - val_acc: 0.7865\n",
      "Epoch 536/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4441 - acc: 0.7743 - val_loss: 0.4934 - val_acc: 0.7865\n",
      "Epoch 537/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4441 - acc: 0.7726 - val_loss: 0.4934 - val_acc: 0.7865\n",
      "Epoch 538/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4441 - acc: 0.7726 - val_loss: 0.4934 - val_acc: 0.7865\n",
      "Epoch 539/1500\n",
      "576/576 [==============================] - 0s 33us/sample - loss: 0.4441 - acc: 0.7726 - val_loss: 0.4935 - val_acc: 0.7812\n",
      "Epoch 540/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4440 - acc: 0.7726 - val_loss: 0.4935 - val_acc: 0.7812\n",
      "Epoch 541/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4440 - acc: 0.7743 - val_loss: 0.4935 - val_acc: 0.7812\n",
      "Epoch 542/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4439 - acc: 0.7726 - val_loss: 0.4935 - val_acc: 0.7812\n",
      "Epoch 543/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4439 - acc: 0.7743 - val_loss: 0.4935 - val_acc: 0.7812\n",
      "Epoch 544/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4438 - acc: 0.7726 - val_loss: 0.4935 - val_acc: 0.7812\n",
      "Epoch 545/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4438 - acc: 0.7726 - val_loss: 0.4935 - val_acc: 0.7812\n",
      "Epoch 546/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4438 - acc: 0.7726 - val_loss: 0.4935 - val_acc: 0.7812\n",
      "Epoch 547/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4438 - acc: 0.7743 - val_loss: 0.4935 - val_acc: 0.7812\n",
      "Epoch 548/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4437 - acc: 0.7743 - val_loss: 0.4935 - val_acc: 0.7812\n",
      "Epoch 549/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4436 - acc: 0.7743 - val_loss: 0.4935 - val_acc: 0.7812\n",
      "Epoch 550/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4436 - acc: 0.7743 - val_loss: 0.4935 - val_acc: 0.7812\n",
      "Epoch 551/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4436 - acc: 0.7760 - val_loss: 0.4936 - val_acc: 0.7812\n",
      "Epoch 552/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4436 - acc: 0.7760 - val_loss: 0.4936 - val_acc: 0.7812\n",
      "Epoch 553/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4436 - acc: 0.7760 - val_loss: 0.4936 - val_acc: 0.7812\n",
      "Epoch 554/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4435 - acc: 0.7743 - val_loss: 0.4936 - val_acc: 0.7760\n",
      "Epoch 555/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4435 - acc: 0.7743 - val_loss: 0.4936 - val_acc: 0.7760\n",
      "Epoch 556/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4434 - acc: 0.7743 - val_loss: 0.4936 - val_acc: 0.7760\n",
      "Epoch 557/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4434 - acc: 0.7743 - val_loss: 0.4936 - val_acc: 0.7760\n",
      "Epoch 558/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4434 - acc: 0.7760 - val_loss: 0.4936 - val_acc: 0.7760\n",
      "Epoch 559/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4433 - acc: 0.7743 - val_loss: 0.4936 - val_acc: 0.7760\n",
      "Epoch 560/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4433 - acc: 0.7743 - val_loss: 0.4936 - val_acc: 0.7760\n",
      "Epoch 561/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4432 - acc: 0.7743 - val_loss: 0.4936 - val_acc: 0.7760\n",
      "Epoch 562/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4432 - acc: 0.7743 - val_loss: 0.4936 - val_acc: 0.7760\n",
      "Epoch 563/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4432 - acc: 0.7743 - val_loss: 0.4936 - val_acc: 0.7760\n",
      "Epoch 564/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4432 - acc: 0.7743 - val_loss: 0.4937 - val_acc: 0.7760\n",
      "Epoch 565/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4431 - acc: 0.7726 - val_loss: 0.4937 - val_acc: 0.7760\n",
      "Epoch 566/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4431 - acc: 0.7760 - val_loss: 0.4937 - val_acc: 0.7760\n",
      "Epoch 567/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4430 - acc: 0.7743 - val_loss: 0.4937 - val_acc: 0.7760\n",
      "Epoch 568/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4430 - acc: 0.7726 - val_loss: 0.4937 - val_acc: 0.7760\n",
      "Epoch 569/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4430 - acc: 0.7778 - val_loss: 0.4937 - val_acc: 0.7760\n",
      "Epoch 570/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4430 - acc: 0.7778 - val_loss: 0.4937 - val_acc: 0.7760\n",
      "Epoch 571/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4429 - acc: 0.7743 - val_loss: 0.4937 - val_acc: 0.7760\n",
      "Epoch 572/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4428 - acc: 0.7743 - val_loss: 0.4937 - val_acc: 0.7760\n",
      "Epoch 573/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4428 - acc: 0.7743 - val_loss: 0.4937 - val_acc: 0.7760\n",
      "Epoch 574/1500\n",
      "576/576 [==============================] - 0s 31us/sample - loss: 0.4428 - acc: 0.7760 - val_loss: 0.4937 - val_acc: 0.7760\n",
      "Epoch 575/1500\n",
      "576/576 [==============================] - 0s 31us/sample - loss: 0.4427 - acc: 0.7760 - val_loss: 0.4938 - val_acc: 0.7760\n",
      "Epoch 576/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4428 - acc: 0.7760 - val_loss: 0.4938 - val_acc: 0.7708\n",
      "Epoch 577/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4427 - acc: 0.7760 - val_loss: 0.4938 - val_acc: 0.7708\n",
      "Epoch 578/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4427 - acc: 0.7760 - val_loss: 0.4938 - val_acc: 0.7708\n",
      "Epoch 579/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4426 - acc: 0.7760 - val_loss: 0.4938 - val_acc: 0.7708\n",
      "Epoch 580/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4425 - acc: 0.7760 - val_loss: 0.4938 - val_acc: 0.7708\n",
      "Epoch 581/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4425 - acc: 0.7778 - val_loss: 0.4938 - val_acc: 0.7708\n",
      "Epoch 582/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4425 - acc: 0.7778 - val_loss: 0.4938 - val_acc: 0.7708\n",
      "Epoch 583/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4424 - acc: 0.7760 - val_loss: 0.4938 - val_acc: 0.7708\n",
      "Epoch 584/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4424 - acc: 0.7778 - val_loss: 0.4938 - val_acc: 0.7708\n",
      "Epoch 585/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4424 - acc: 0.7778 - val_loss: 0.4938 - val_acc: 0.7708\n",
      "Epoch 586/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4423 - acc: 0.7778 - val_loss: 0.4938 - val_acc: 0.7708\n",
      "Epoch 587/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4423 - acc: 0.7778 - val_loss: 0.4938 - val_acc: 0.7708\n",
      "Epoch 588/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4422 - acc: 0.7795 - val_loss: 0.4938 - val_acc: 0.7708\n",
      "Epoch 589/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4422 - acc: 0.7795 - val_loss: 0.4938 - val_acc: 0.7708\n",
      "Epoch 590/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4422 - acc: 0.7760 - val_loss: 0.4939 - val_acc: 0.7708\n",
      "Epoch 591/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4422 - acc: 0.7778 - val_loss: 0.4939 - val_acc: 0.7708\n",
      "Epoch 592/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4421 - acc: 0.7795 - val_loss: 0.4939 - val_acc: 0.7708\n",
      "Epoch 593/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4421 - acc: 0.7778 - val_loss: 0.4939 - val_acc: 0.7708\n",
      "Epoch 594/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4420 - acc: 0.7778 - val_loss: 0.4939 - val_acc: 0.7708\n",
      "Epoch 595/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4421 - acc: 0.7760 - val_loss: 0.4940 - val_acc: 0.7708\n",
      "Epoch 596/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4420 - acc: 0.7778 - val_loss: 0.4940 - val_acc: 0.7708\n",
      "Epoch 597/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4420 - acc: 0.7778 - val_loss: 0.4940 - val_acc: 0.7708\n",
      "Epoch 598/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4419 - acc: 0.7795 - val_loss: 0.4940 - val_acc: 0.7708\n",
      "Epoch 599/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4419 - acc: 0.7778 - val_loss: 0.4940 - val_acc: 0.7708\n",
      "Epoch 600/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4418 - acc: 0.7778 - val_loss: 0.4940 - val_acc: 0.7708\n",
      "Epoch 601/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4419 - acc: 0.7795 - val_loss: 0.4940 - val_acc: 0.7708\n",
      "Epoch 602/1500\n",
      "576/576 [==============================] - 0s 31us/sample - loss: 0.4418 - acc: 0.7778 - val_loss: 0.4940 - val_acc: 0.7708\n",
      "Epoch 603/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4417 - acc: 0.7778 - val_loss: 0.4940 - val_acc: 0.7708\n",
      "Epoch 604/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4418 - acc: 0.7795 - val_loss: 0.4941 - val_acc: 0.7708\n",
      "Epoch 605/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4417 - acc: 0.7778 - val_loss: 0.4941 - val_acc: 0.7708\n",
      "Epoch 606/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4417 - acc: 0.7778 - val_loss: 0.4941 - val_acc: 0.7708\n",
      "Epoch 607/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4416 - acc: 0.7778 - val_loss: 0.4941 - val_acc: 0.7708\n",
      "Epoch 608/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4416 - acc: 0.7778 - val_loss: 0.4941 - val_acc: 0.7708\n",
      "Epoch 609/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4416 - acc: 0.7778 - val_loss: 0.4941 - val_acc: 0.7708\n",
      "Epoch 610/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4415 - acc: 0.7778 - val_loss: 0.4941 - val_acc: 0.7708\n",
      "Epoch 611/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4415 - acc: 0.7778 - val_loss: 0.4941 - val_acc: 0.7708\n",
      "Epoch 612/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4415 - acc: 0.7778 - val_loss: 0.4942 - val_acc: 0.7708\n",
      "Epoch 613/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4414 - acc: 0.7778 - val_loss: 0.4942 - val_acc: 0.7708\n",
      "Epoch 614/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4414 - acc: 0.7760 - val_loss: 0.4942 - val_acc: 0.7708\n",
      "Epoch 615/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4414 - acc: 0.7778 - val_loss: 0.4942 - val_acc: 0.7708\n",
      "Epoch 616/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4413 - acc: 0.7778 - val_loss: 0.4942 - val_acc: 0.7708\n",
      "Epoch 617/1500\n",
      "576/576 [==============================] - 0s 31us/sample - loss: 0.4412 - acc: 0.7778 - val_loss: 0.4942 - val_acc: 0.7708\n",
      "Epoch 618/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4413 - acc: 0.7778 - val_loss: 0.4942 - val_acc: 0.7708\n",
      "Epoch 619/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4412 - acc: 0.7778 - val_loss: 0.4942 - val_acc: 0.7708\n",
      "Epoch 620/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4412 - acc: 0.7778 - val_loss: 0.4943 - val_acc: 0.7708\n",
      "Epoch 621/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4412 - acc: 0.7778 - val_loss: 0.4943 - val_acc: 0.7708\n",
      "Epoch 622/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4411 - acc: 0.7778 - val_loss: 0.4943 - val_acc: 0.7708\n",
      "Epoch 623/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4411 - acc: 0.7778 - val_loss: 0.4943 - val_acc: 0.7708\n",
      "Epoch 624/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4411 - acc: 0.7778 - val_loss: 0.4943 - val_acc: 0.7708\n",
      "Epoch 625/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4411 - acc: 0.7778 - val_loss: 0.4943 - val_acc: 0.7708\n",
      "Epoch 626/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4410 - acc: 0.7778 - val_loss: 0.4943 - val_acc: 0.7708\n",
      "Epoch 627/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4410 - acc: 0.7795 - val_loss: 0.4943 - val_acc: 0.7708\n",
      "Epoch 628/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4410 - acc: 0.7778 - val_loss: 0.4944 - val_acc: 0.7708\n",
      "Epoch 629/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4410 - acc: 0.7795 - val_loss: 0.4944 - val_acc: 0.7708\n",
      "Epoch 630/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4409 - acc: 0.7795 - val_loss: 0.4944 - val_acc: 0.7708\n",
      "Epoch 631/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4409 - acc: 0.7778 - val_loss: 0.4944 - val_acc: 0.7708\n",
      "Epoch 632/1500\n",
      "576/576 [==============================] - 0s 40us/sample - loss: 0.4408 - acc: 0.7795 - val_loss: 0.4944 - val_acc: 0.7708\n",
      "Epoch 633/1500\n",
      "576/576 [==============================] - 0s 31us/sample - loss: 0.4409 - acc: 0.7778 - val_loss: 0.4944 - val_acc: 0.7708\n",
      "Epoch 634/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4408 - acc: 0.7795 - val_loss: 0.4944 - val_acc: 0.7708\n",
      "Epoch 635/1500\n",
      "576/576 [==============================] - 0s 35us/sample - loss: 0.4408 - acc: 0.7795 - val_loss: 0.4944 - val_acc: 0.7708\n",
      "Epoch 636/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4408 - acc: 0.7795 - val_loss: 0.4945 - val_acc: 0.7656\n",
      "Epoch 637/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4407 - acc: 0.7778 - val_loss: 0.4945 - val_acc: 0.7656\n",
      "Epoch 638/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4407 - acc: 0.7795 - val_loss: 0.4945 - val_acc: 0.7656\n",
      "Epoch 639/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4407 - acc: 0.7795 - val_loss: 0.4945 - val_acc: 0.7656\n",
      "Epoch 640/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4407 - acc: 0.7778 - val_loss: 0.4945 - val_acc: 0.7656\n",
      "Epoch 641/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4407 - acc: 0.7795 - val_loss: 0.4945 - val_acc: 0.7656\n",
      "Epoch 642/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4406 - acc: 0.7795 - val_loss: 0.4945 - val_acc: 0.7656\n",
      "Epoch 643/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4405 - acc: 0.7778 - val_loss: 0.4945 - val_acc: 0.7656\n",
      "Epoch 644/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4405 - acc: 0.7795 - val_loss: 0.4945 - val_acc: 0.7656\n",
      "Epoch 645/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4405 - acc: 0.7795 - val_loss: 0.4945 - val_acc: 0.7656\n",
      "Epoch 646/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4404 - acc: 0.7778 - val_loss: 0.4945 - val_acc: 0.7656\n",
      "Epoch 647/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4404 - acc: 0.7778 - val_loss: 0.4946 - val_acc: 0.7604\n",
      "Epoch 648/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4404 - acc: 0.7795 - val_loss: 0.4946 - val_acc: 0.7604\n",
      "Epoch 649/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4404 - acc: 0.7778 - val_loss: 0.4946 - val_acc: 0.7604\n",
      "Epoch 650/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4403 - acc: 0.7778 - val_loss: 0.4946 - val_acc: 0.7604\n",
      "Epoch 651/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4404 - acc: 0.7795 - val_loss: 0.4946 - val_acc: 0.7604\n",
      "Epoch 652/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4403 - acc: 0.7795 - val_loss: 0.4946 - val_acc: 0.7604\n",
      "Epoch 653/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4403 - acc: 0.7778 - val_loss: 0.4946 - val_acc: 0.7604\n",
      "Epoch 654/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4403 - acc: 0.7778 - val_loss: 0.4946 - val_acc: 0.7604\n",
      "Epoch 655/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4402 - acc: 0.7760 - val_loss: 0.4947 - val_acc: 0.7604\n",
      "Epoch 656/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4402 - acc: 0.7760 - val_loss: 0.4947 - val_acc: 0.7604\n",
      "Epoch 657/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4402 - acc: 0.7760 - val_loss: 0.4947 - val_acc: 0.7604\n",
      "Epoch 658/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4402 - acc: 0.7778 - val_loss: 0.4947 - val_acc: 0.7604\n",
      "Epoch 659/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4401 - acc: 0.7778 - val_loss: 0.4947 - val_acc: 0.7604\n",
      "Epoch 660/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4401 - acc: 0.7795 - val_loss: 0.4948 - val_acc: 0.7604\n",
      "Epoch 661/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4401 - acc: 0.7760 - val_loss: 0.4948 - val_acc: 0.7604\n",
      "Epoch 662/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4401 - acc: 0.7778 - val_loss: 0.4948 - val_acc: 0.7604\n",
      "Epoch 663/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4400 - acc: 0.7778 - val_loss: 0.4948 - val_acc: 0.7604\n",
      "Epoch 664/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4400 - acc: 0.7778 - val_loss: 0.4948 - val_acc: 0.7604\n",
      "Epoch 665/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4399 - acc: 0.7778 - val_loss: 0.4948 - val_acc: 0.7604\n",
      "Epoch 666/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4399 - acc: 0.7778 - val_loss: 0.4948 - val_acc: 0.7604\n",
      "Epoch 667/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4399 - acc: 0.7778 - val_loss: 0.4948 - val_acc: 0.7604\n",
      "Epoch 668/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4399 - acc: 0.7778 - val_loss: 0.4948 - val_acc: 0.7604\n",
      "Epoch 669/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4398 - acc: 0.7778 - val_loss: 0.4948 - val_acc: 0.7604\n",
      "Epoch 670/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4398 - acc: 0.7778 - val_loss: 0.4949 - val_acc: 0.7604\n",
      "Epoch 671/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4398 - acc: 0.7760 - val_loss: 0.4949 - val_acc: 0.7604\n",
      "Epoch 672/1500\n",
      "576/576 [==============================] - 0s 33us/sample - loss: 0.4398 - acc: 0.7778 - val_loss: 0.4949 - val_acc: 0.7604\n",
      "Epoch 673/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4397 - acc: 0.7778 - val_loss: 0.4949 - val_acc: 0.7604\n",
      "Epoch 674/1500\n",
      "576/576 [==============================] - 0s 33us/sample - loss: 0.4397 - acc: 0.7778 - val_loss: 0.4949 - val_acc: 0.7604\n",
      "Epoch 675/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4397 - acc: 0.7795 - val_loss: 0.4949 - val_acc: 0.7604\n",
      "Epoch 676/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4396 - acc: 0.7760 - val_loss: 0.4950 - val_acc: 0.7604\n",
      "Epoch 677/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4397 - acc: 0.7778 - val_loss: 0.4950 - val_acc: 0.7604\n",
      "Epoch 678/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4397 - acc: 0.7778 - val_loss: 0.4950 - val_acc: 0.7604\n",
      "Epoch 679/1500\n",
      "576/576 [==============================] - 0s 33us/sample - loss: 0.4396 - acc: 0.7778 - val_loss: 0.4950 - val_acc: 0.7604\n",
      "Epoch 680/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4396 - acc: 0.7778 - val_loss: 0.4950 - val_acc: 0.7604\n",
      "Epoch 681/1500\n",
      "576/576 [==============================] - 0s 35us/sample - loss: 0.4396 - acc: 0.7778 - val_loss: 0.4950 - val_acc: 0.7604\n",
      "Epoch 682/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4395 - acc: 0.7778 - val_loss: 0.4951 - val_acc: 0.7604\n",
      "Epoch 683/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4395 - acc: 0.7778 - val_loss: 0.4951 - val_acc: 0.7604\n",
      "Epoch 684/1500\n",
      "576/576 [==============================] - 0s 31us/sample - loss: 0.4395 - acc: 0.7778 - val_loss: 0.4951 - val_acc: 0.7604\n",
      "Epoch 685/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4394 - acc: 0.7795 - val_loss: 0.4951 - val_acc: 0.7604\n",
      "Epoch 686/1500\n",
      "576/576 [==============================] - 0s 47us/sample - loss: 0.4394 - acc: 0.7778 - val_loss: 0.4951 - val_acc: 0.7604\n",
      "Epoch 687/1500\n",
      "576/576 [==============================] - 0s 31us/sample - loss: 0.4394 - acc: 0.7778 - val_loss: 0.4952 - val_acc: 0.7604\n",
      "Epoch 688/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4394 - acc: 0.7778 - val_loss: 0.4952 - val_acc: 0.7604\n",
      "Epoch 689/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4393 - acc: 0.7795 - val_loss: 0.4952 - val_acc: 0.7656\n",
      "Epoch 690/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4393 - acc: 0.7778 - val_loss: 0.4952 - val_acc: 0.7656\n",
      "Epoch 691/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4393 - acc: 0.7778 - val_loss: 0.4953 - val_acc: 0.7656\n",
      "Epoch 692/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4392 - acc: 0.7795 - val_loss: 0.4953 - val_acc: 0.7656\n",
      "Epoch 693/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4392 - acc: 0.7795 - val_loss: 0.4953 - val_acc: 0.7656\n",
      "Epoch 694/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4392 - acc: 0.7795 - val_loss: 0.4953 - val_acc: 0.7656\n",
      "Epoch 695/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4392 - acc: 0.7778 - val_loss: 0.4954 - val_acc: 0.7656\n",
      "Epoch 696/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4391 - acc: 0.7795 - val_loss: 0.4954 - val_acc: 0.7656\n",
      "Epoch 697/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4391 - acc: 0.7795 - val_loss: 0.4954 - val_acc: 0.7656\n",
      "Epoch 698/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4392 - acc: 0.7778 - val_loss: 0.4954 - val_acc: 0.7656\n",
      "Epoch 699/1500\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.3753 - acc: 0.781 - 0s 26us/sample - loss: 0.4391 - acc: 0.7795 - val_loss: 0.4955 - val_acc: 0.7656\n",
      "Epoch 700/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4391 - acc: 0.7778 - val_loss: 0.4955 - val_acc: 0.7656\n",
      "Epoch 701/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4391 - acc: 0.7795 - val_loss: 0.4955 - val_acc: 0.7656\n",
      "Epoch 702/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4390 - acc: 0.7795 - val_loss: 0.4956 - val_acc: 0.7656\n",
      "Epoch 703/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4390 - acc: 0.7795 - val_loss: 0.4956 - val_acc: 0.7656\n",
      "Epoch 704/1500\n",
      "576/576 [==============================] - 0s 33us/sample - loss: 0.4390 - acc: 0.7795 - val_loss: 0.4956 - val_acc: 0.7656\n",
      "Epoch 705/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4389 - acc: 0.7795 - val_loss: 0.4956 - val_acc: 0.7656\n",
      "Epoch 706/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4389 - acc: 0.7795 - val_loss: 0.4957 - val_acc: 0.7656\n",
      "Epoch 707/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4389 - acc: 0.7795 - val_loss: 0.4957 - val_acc: 0.7656\n",
      "Epoch 708/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4389 - acc: 0.7795 - val_loss: 0.4957 - val_acc: 0.7656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 709/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4388 - acc: 0.7795 - val_loss: 0.4957 - val_acc: 0.7708\n",
      "Epoch 710/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4388 - acc: 0.7795 - val_loss: 0.4957 - val_acc: 0.7708\n",
      "Epoch 711/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4388 - acc: 0.7795 - val_loss: 0.4958 - val_acc: 0.7708\n",
      "Epoch 712/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4387 - acc: 0.7795 - val_loss: 0.4958 - val_acc: 0.7708\n",
      "Epoch 713/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4387 - acc: 0.7795 - val_loss: 0.4958 - val_acc: 0.7708\n",
      "Epoch 714/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4387 - acc: 0.7795 - val_loss: 0.4958 - val_acc: 0.7708\n",
      "Epoch 715/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4387 - acc: 0.7778 - val_loss: 0.4959 - val_acc: 0.7708\n",
      "Epoch 716/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4387 - acc: 0.7795 - val_loss: 0.4959 - val_acc: 0.7708\n",
      "Epoch 717/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4386 - acc: 0.7795 - val_loss: 0.4959 - val_acc: 0.7708\n",
      "Epoch 718/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4386 - acc: 0.7795 - val_loss: 0.4959 - val_acc: 0.7708\n",
      "Epoch 719/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4385 - acc: 0.7795 - val_loss: 0.4959 - val_acc: 0.7708\n",
      "Epoch 720/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4386 - acc: 0.7795 - val_loss: 0.4960 - val_acc: 0.7708\n",
      "Epoch 721/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4385 - acc: 0.7795 - val_loss: 0.4960 - val_acc: 0.7708\n",
      "Epoch 722/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4385 - acc: 0.7795 - val_loss: 0.4960 - val_acc: 0.7708\n",
      "Epoch 723/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4385 - acc: 0.7795 - val_loss: 0.4960 - val_acc: 0.7708\n",
      "Epoch 724/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4384 - acc: 0.7795 - val_loss: 0.4960 - val_acc: 0.7708\n",
      "Epoch 725/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4384 - acc: 0.7795 - val_loss: 0.4961 - val_acc: 0.7708\n",
      "Epoch 726/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4384 - acc: 0.7795 - val_loss: 0.4961 - val_acc: 0.7708\n",
      "Epoch 727/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4383 - acc: 0.7778 - val_loss: 0.4961 - val_acc: 0.7708\n",
      "Epoch 728/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4383 - acc: 0.7795 - val_loss: 0.4961 - val_acc: 0.7708\n",
      "Epoch 729/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4383 - acc: 0.7778 - val_loss: 0.4962 - val_acc: 0.7708\n",
      "Epoch 730/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4383 - acc: 0.7778 - val_loss: 0.4962 - val_acc: 0.7708\n",
      "Epoch 731/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4383 - acc: 0.7778 - val_loss: 0.4962 - val_acc: 0.7708\n",
      "Epoch 732/1500\n",
      "576/576 [==============================] - 0s 31us/sample - loss: 0.4382 - acc: 0.7778 - val_loss: 0.4963 - val_acc: 0.7708\n",
      "Epoch 733/1500\n",
      "576/576 [==============================] - 0s 31us/sample - loss: 0.4382 - acc: 0.7778 - val_loss: 0.4963 - val_acc: 0.7708\n",
      "Epoch 734/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4382 - acc: 0.7778 - val_loss: 0.4963 - val_acc: 0.7708\n",
      "Epoch 735/1500\n",
      "576/576 [==============================] - 0s 31us/sample - loss: 0.4382 - acc: 0.7778 - val_loss: 0.4964 - val_acc: 0.7708\n",
      "Epoch 736/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4382 - acc: 0.7778 - val_loss: 0.4964 - val_acc: 0.7708\n",
      "Epoch 737/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4381 - acc: 0.7812 - val_loss: 0.4964 - val_acc: 0.7708\n",
      "Epoch 738/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4381 - acc: 0.7778 - val_loss: 0.4964 - val_acc: 0.7708\n",
      "Epoch 739/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4380 - acc: 0.7795 - val_loss: 0.4965 - val_acc: 0.7708\n",
      "Epoch 740/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4380 - acc: 0.7778 - val_loss: 0.4965 - val_acc: 0.7708\n",
      "Epoch 741/1500\n",
      "576/576 [==============================] - 0s 35us/sample - loss: 0.4380 - acc: 0.7778 - val_loss: 0.4965 - val_acc: 0.7708\n",
      "Epoch 742/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4380 - acc: 0.7795 - val_loss: 0.4966 - val_acc: 0.7708\n",
      "Epoch 743/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4380 - acc: 0.7795 - val_loss: 0.4966 - val_acc: 0.7708\n",
      "Epoch 744/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4379 - acc: 0.7795 - val_loss: 0.4966 - val_acc: 0.7708\n",
      "Epoch 745/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4379 - acc: 0.7795 - val_loss: 0.4966 - val_acc: 0.7708\n",
      "Epoch 746/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4379 - acc: 0.7812 - val_loss: 0.4967 - val_acc: 0.7708\n",
      "Epoch 747/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4379 - acc: 0.7812 - val_loss: 0.4967 - val_acc: 0.7708\n",
      "Epoch 748/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4378 - acc: 0.7812 - val_loss: 0.4967 - val_acc: 0.7708\n",
      "Epoch 749/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4378 - acc: 0.7795 - val_loss: 0.4967 - val_acc: 0.7708\n",
      "Epoch 750/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4378 - acc: 0.7812 - val_loss: 0.4968 - val_acc: 0.7708\n",
      "Epoch 751/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4378 - acc: 0.7812 - val_loss: 0.4968 - val_acc: 0.7708\n",
      "Epoch 752/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4378 - acc: 0.7812 - val_loss: 0.4968 - val_acc: 0.7708\n",
      "Epoch 753/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4377 - acc: 0.7812 - val_loss: 0.4969 - val_acc: 0.7708\n",
      "Epoch 754/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4377 - acc: 0.7812 - val_loss: 0.4969 - val_acc: 0.7708\n",
      "Epoch 755/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4377 - acc: 0.7812 - val_loss: 0.4969 - val_acc: 0.7708\n",
      "Epoch 756/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4377 - acc: 0.7830 - val_loss: 0.4969 - val_acc: 0.7708\n",
      "Epoch 757/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4377 - acc: 0.7795 - val_loss: 0.4969 - val_acc: 0.7708\n",
      "Epoch 758/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4376 - acc: 0.7812 - val_loss: 0.4970 - val_acc: 0.7708\n",
      "Epoch 759/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4376 - acc: 0.7812 - val_loss: 0.4970 - val_acc: 0.7708\n",
      "Epoch 760/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4375 - acc: 0.7812 - val_loss: 0.4970 - val_acc: 0.7708\n",
      "Epoch 761/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4375 - acc: 0.7830 - val_loss: 0.4970 - val_acc: 0.7708\n",
      "Epoch 762/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4375 - acc: 0.7830 - val_loss: 0.4971 - val_acc: 0.7708\n",
      "Epoch 763/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4375 - acc: 0.7795 - val_loss: 0.4971 - val_acc: 0.7708\n",
      "Epoch 764/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4374 - acc: 0.7830 - val_loss: 0.4971 - val_acc: 0.7708\n",
      "Epoch 765/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4375 - acc: 0.7812 - val_loss: 0.4971 - val_acc: 0.7708\n",
      "Epoch 766/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4374 - acc: 0.7830 - val_loss: 0.4971 - val_acc: 0.7708\n",
      "Epoch 767/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4375 - acc: 0.7812 - val_loss: 0.4971 - val_acc: 0.7708\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 768/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4374 - acc: 0.7830 - val_loss: 0.4972 - val_acc: 0.7708\n",
      "Epoch 769/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4374 - acc: 0.7830 - val_loss: 0.4972 - val_acc: 0.7708\n",
      "Epoch 770/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4373 - acc: 0.7830 - val_loss: 0.4972 - val_acc: 0.7708\n",
      "Epoch 771/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4373 - acc: 0.7778 - val_loss: 0.4972 - val_acc: 0.7708\n",
      "Epoch 772/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4372 - acc: 0.7812 - val_loss: 0.4972 - val_acc: 0.7708\n",
      "Epoch 773/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4372 - acc: 0.7830 - val_loss: 0.4973 - val_acc: 0.7708\n",
      "Epoch 774/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4372 - acc: 0.7812 - val_loss: 0.4973 - val_acc: 0.7708\n",
      "Epoch 775/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4372 - acc: 0.7812 - val_loss: 0.4973 - val_acc: 0.7708\n",
      "Epoch 776/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4372 - acc: 0.7812 - val_loss: 0.4974 - val_acc: 0.7708\n",
      "Epoch 777/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4372 - acc: 0.7795 - val_loss: 0.4974 - val_acc: 0.7708\n",
      "Epoch 778/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4371 - acc: 0.7812 - val_loss: 0.4974 - val_acc: 0.7708\n",
      "Epoch 779/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4371 - acc: 0.7812 - val_loss: 0.4974 - val_acc: 0.7708\n",
      "Epoch 780/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4371 - acc: 0.7795 - val_loss: 0.4974 - val_acc: 0.7708\n",
      "Epoch 781/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4371 - acc: 0.7812 - val_loss: 0.4975 - val_acc: 0.7708\n",
      "Epoch 782/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4371 - acc: 0.7812 - val_loss: 0.4975 - val_acc: 0.7708\n",
      "Epoch 783/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4370 - acc: 0.7812 - val_loss: 0.4975 - val_acc: 0.7708\n",
      "Epoch 784/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4370 - acc: 0.7812 - val_loss: 0.4975 - val_acc: 0.7708\n",
      "Epoch 785/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4370 - acc: 0.7812 - val_loss: 0.4976 - val_acc: 0.7708\n",
      "Epoch 786/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4370 - acc: 0.7812 - val_loss: 0.4976 - val_acc: 0.7708\n",
      "Epoch 787/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4369 - acc: 0.7830 - val_loss: 0.4977 - val_acc: 0.7708\n",
      "Epoch 788/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4369 - acc: 0.7812 - val_loss: 0.4977 - val_acc: 0.7708\n",
      "Epoch 789/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4369 - acc: 0.7795 - val_loss: 0.4977 - val_acc: 0.7708\n",
      "Epoch 790/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4369 - acc: 0.7812 - val_loss: 0.4977 - val_acc: 0.7708\n",
      "Epoch 791/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4368 - acc: 0.7812 - val_loss: 0.4978 - val_acc: 0.7708\n",
      "Epoch 792/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4369 - acc: 0.7812 - val_loss: 0.4978 - val_acc: 0.7708\n",
      "Epoch 793/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4368 - acc: 0.7778 - val_loss: 0.4978 - val_acc: 0.7708\n",
      "Epoch 794/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4367 - acc: 0.7812 - val_loss: 0.4979 - val_acc: 0.7708\n",
      "Epoch 795/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4367 - acc: 0.7795 - val_loss: 0.4979 - val_acc: 0.7708\n",
      "Epoch 796/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4367 - acc: 0.7812 - val_loss: 0.4979 - val_acc: 0.7708\n",
      "Epoch 797/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4367 - acc: 0.7795 - val_loss: 0.4980 - val_acc: 0.7708\n",
      "Epoch 798/1500\n",
      "576/576 [==============================] - 0s 31us/sample - loss: 0.4367 - acc: 0.7795 - val_loss: 0.4980 - val_acc: 0.7708\n",
      "Epoch 799/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4366 - acc: 0.7812 - val_loss: 0.4980 - val_acc: 0.7708\n",
      "Epoch 800/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4366 - acc: 0.7778 - val_loss: 0.4981 - val_acc: 0.7708\n",
      "Epoch 801/1500\n",
      "576/576 [==============================] - 0s 31us/sample - loss: 0.4366 - acc: 0.7778 - val_loss: 0.4981 - val_acc: 0.7708\n",
      "Epoch 802/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4366 - acc: 0.7778 - val_loss: 0.4981 - val_acc: 0.7708\n",
      "Epoch 803/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4366 - acc: 0.7778 - val_loss: 0.4982 - val_acc: 0.7708\n",
      "Epoch 804/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4366 - acc: 0.7778 - val_loss: 0.4982 - val_acc: 0.7708\n",
      "Epoch 805/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4365 - acc: 0.7778 - val_loss: 0.4982 - val_acc: 0.7708\n",
      "Epoch 806/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4365 - acc: 0.7778 - val_loss: 0.4983 - val_acc: 0.7708\n",
      "Epoch 807/1500\n",
      "576/576 [==============================] - 0s 31us/sample - loss: 0.4365 - acc: 0.7778 - val_loss: 0.4983 - val_acc: 0.7708\n",
      "Epoch 808/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4364 - acc: 0.7795 - val_loss: 0.4983 - val_acc: 0.7708\n",
      "Epoch 809/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4365 - acc: 0.7778 - val_loss: 0.4983 - val_acc: 0.7708\n",
      "Epoch 810/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4364 - acc: 0.7812 - val_loss: 0.4984 - val_acc: 0.7708\n",
      "Epoch 811/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4364 - acc: 0.7778 - val_loss: 0.4984 - val_acc: 0.7656\n",
      "Epoch 812/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4363 - acc: 0.7778 - val_loss: 0.4984 - val_acc: 0.7656\n",
      "Epoch 813/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4363 - acc: 0.7778 - val_loss: 0.4985 - val_acc: 0.7656\n",
      "Epoch 814/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4363 - acc: 0.7778 - val_loss: 0.4985 - val_acc: 0.7656\n",
      "Epoch 815/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4363 - acc: 0.7778 - val_loss: 0.4985 - val_acc: 0.7656\n",
      "Epoch 816/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4362 - acc: 0.7778 - val_loss: 0.4986 - val_acc: 0.7656\n",
      "Epoch 817/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4362 - acc: 0.7778 - val_loss: 0.4986 - val_acc: 0.7656\n",
      "Epoch 818/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4362 - acc: 0.7778 - val_loss: 0.4986 - val_acc: 0.7656\n",
      "Epoch 819/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4362 - acc: 0.7778 - val_loss: 0.4987 - val_acc: 0.7656\n",
      "Epoch 820/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4361 - acc: 0.7778 - val_loss: 0.4987 - val_acc: 0.7656\n",
      "Epoch 821/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4362 - acc: 0.7778 - val_loss: 0.4987 - val_acc: 0.7656\n",
      "Epoch 822/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4361 - acc: 0.7778 - val_loss: 0.4987 - val_acc: 0.7656\n",
      "Epoch 823/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4361 - acc: 0.7778 - val_loss: 0.4987 - val_acc: 0.7656\n",
      "Epoch 824/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4361 - acc: 0.7778 - val_loss: 0.4987 - val_acc: 0.7656\n",
      "Epoch 825/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4361 - acc: 0.7778 - val_loss: 0.4987 - val_acc: 0.7656\n",
      "Epoch 826/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4361 - acc: 0.7778 - val_loss: 0.4988 - val_acc: 0.7656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 827/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4360 - acc: 0.7778 - val_loss: 0.4988 - val_acc: 0.7656\n",
      "Epoch 828/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4360 - acc: 0.7778 - val_loss: 0.4988 - val_acc: 0.7656\n",
      "Epoch 829/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4359 - acc: 0.7778 - val_loss: 0.4988 - val_acc: 0.7656\n",
      "Epoch 830/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4360 - acc: 0.7778 - val_loss: 0.4988 - val_acc: 0.7656\n",
      "Epoch 831/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4359 - acc: 0.7778 - val_loss: 0.4989 - val_acc: 0.7656\n",
      "Epoch 832/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4359 - acc: 0.7778 - val_loss: 0.4989 - val_acc: 0.7656\n",
      "Epoch 833/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4359 - acc: 0.7778 - val_loss: 0.4989 - val_acc: 0.7656\n",
      "Epoch 834/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4358 - acc: 0.7778 - val_loss: 0.4989 - val_acc: 0.7656\n",
      "Epoch 835/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4358 - acc: 0.7778 - val_loss: 0.4989 - val_acc: 0.7656\n",
      "Epoch 836/1500\n",
      "576/576 [==============================] - 0s 31us/sample - loss: 0.4358 - acc: 0.7778 - val_loss: 0.4989 - val_acc: 0.7656\n",
      "Epoch 837/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4358 - acc: 0.7778 - val_loss: 0.4990 - val_acc: 0.7656\n",
      "Epoch 838/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4357 - acc: 0.7778 - val_loss: 0.4990 - val_acc: 0.7656\n",
      "Epoch 839/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4357 - acc: 0.7778 - val_loss: 0.4990 - val_acc: 0.7656\n",
      "Epoch 840/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4357 - acc: 0.7778 - val_loss: 0.4991 - val_acc: 0.7656\n",
      "Epoch 841/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4357 - acc: 0.7778 - val_loss: 0.4991 - val_acc: 0.7656\n",
      "Epoch 842/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4356 - acc: 0.7778 - val_loss: 0.4991 - val_acc: 0.7656\n",
      "Epoch 843/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4356 - acc: 0.7778 - val_loss: 0.4991 - val_acc: 0.7656\n",
      "Epoch 844/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4356 - acc: 0.7778 - val_loss: 0.4991 - val_acc: 0.7656\n",
      "Epoch 845/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4356 - acc: 0.7778 - val_loss: 0.4991 - val_acc: 0.7656\n",
      "Epoch 846/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4355 - acc: 0.7778 - val_loss: 0.4991 - val_acc: 0.7656\n",
      "Epoch 847/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4355 - acc: 0.7778 - val_loss: 0.4991 - val_acc: 0.7656\n",
      "Epoch 848/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4355 - acc: 0.7778 - val_loss: 0.4992 - val_acc: 0.7656\n",
      "Epoch 849/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4355 - acc: 0.7778 - val_loss: 0.4992 - val_acc: 0.7656\n",
      "Epoch 850/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4354 - acc: 0.7778 - val_loss: 0.4992 - val_acc: 0.7656\n",
      "Epoch 851/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4354 - acc: 0.7795 - val_loss: 0.4992 - val_acc: 0.7656\n",
      "Epoch 852/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4354 - acc: 0.7795 - val_loss: 0.4992 - val_acc: 0.7656\n",
      "Epoch 853/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4354 - acc: 0.7778 - val_loss: 0.4992 - val_acc: 0.7656\n",
      "Epoch 854/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4354 - acc: 0.7778 - val_loss: 0.4992 - val_acc: 0.7656\n",
      "Epoch 855/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4354 - acc: 0.7795 - val_loss: 0.4992 - val_acc: 0.7656\n",
      "Epoch 856/1500\n",
      "576/576 [==============================] - 0s 35us/sample - loss: 0.4353 - acc: 0.7778 - val_loss: 0.4993 - val_acc: 0.7656\n",
      "Epoch 857/1500\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.3976 - acc: 0.875 - 0s 30us/sample - loss: 0.4353 - acc: 0.7778 - val_loss: 0.4993 - val_acc: 0.7656\n",
      "Epoch 858/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4352 - acc: 0.7778 - val_loss: 0.4993 - val_acc: 0.7656\n",
      "Epoch 859/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4353 - acc: 0.7778 - val_loss: 0.4993 - val_acc: 0.7656\n",
      "Epoch 860/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4352 - acc: 0.7778 - val_loss: 0.4993 - val_acc: 0.7656\n",
      "Epoch 861/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4352 - acc: 0.7778 - val_loss: 0.4993 - val_acc: 0.7656\n",
      "Epoch 862/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4352 - acc: 0.7778 - val_loss: 0.4994 - val_acc: 0.7656\n",
      "Epoch 863/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4352 - acc: 0.7795 - val_loss: 0.4994 - val_acc: 0.7656\n",
      "Epoch 864/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4352 - acc: 0.7778 - val_loss: 0.4994 - val_acc: 0.7656\n",
      "Epoch 865/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4351 - acc: 0.7778 - val_loss: 0.4994 - val_acc: 0.7656\n",
      "Epoch 866/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4352 - acc: 0.7778 - val_loss: 0.4994 - val_acc: 0.7656\n",
      "Epoch 867/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4351 - acc: 0.7778 - val_loss: 0.4994 - val_acc: 0.7656\n",
      "Epoch 868/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4351 - acc: 0.7778 - val_loss: 0.4994 - val_acc: 0.7656\n",
      "Epoch 869/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4350 - acc: 0.7778 - val_loss: 0.4994 - val_acc: 0.7656\n",
      "Epoch 870/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4350 - acc: 0.7795 - val_loss: 0.4995 - val_acc: 0.7656\n",
      "Epoch 871/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4350 - acc: 0.7812 - val_loss: 0.4995 - val_acc: 0.7656\n",
      "Epoch 872/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4349 - acc: 0.7812 - val_loss: 0.4995 - val_acc: 0.7656\n",
      "Epoch 873/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4350 - acc: 0.7795 - val_loss: 0.4995 - val_acc: 0.7656\n",
      "Epoch 874/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4349 - acc: 0.7812 - val_loss: 0.4995 - val_acc: 0.7656\n",
      "Epoch 875/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4349 - acc: 0.7812 - val_loss: 0.4996 - val_acc: 0.7656\n",
      "Epoch 876/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4349 - acc: 0.7795 - val_loss: 0.4996 - val_acc: 0.7656\n",
      "Epoch 877/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4348 - acc: 0.7812 - val_loss: 0.4996 - val_acc: 0.7656\n",
      "Epoch 878/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4348 - acc: 0.7795 - val_loss: 0.4996 - val_acc: 0.7656\n",
      "Epoch 879/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4347 - acc: 0.7830 - val_loss: 0.4996 - val_acc: 0.7656\n",
      "Epoch 880/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4348 - acc: 0.7830 - val_loss: 0.4996 - val_acc: 0.7656\n",
      "Epoch 881/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4347 - acc: 0.7812 - val_loss: 0.4997 - val_acc: 0.7656\n",
      "Epoch 882/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4347 - acc: 0.7812 - val_loss: 0.4997 - val_acc: 0.7656\n",
      "Epoch 883/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4348 - acc: 0.7812 - val_loss: 0.4997 - val_acc: 0.7656\n",
      "Epoch 884/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4347 - acc: 0.7812 - val_loss: 0.4997 - val_acc: 0.7656\n",
      "Epoch 885/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4346 - acc: 0.7830 - val_loss: 0.4997 - val_acc: 0.7656\n",
      "Epoch 886/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4346 - acc: 0.7830 - val_loss: 0.4998 - val_acc: 0.7656\n",
      "Epoch 887/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4346 - acc: 0.7830 - val_loss: 0.4998 - val_acc: 0.7656\n",
      "Epoch 888/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4346 - acc: 0.7812 - val_loss: 0.4998 - val_acc: 0.7656\n",
      "Epoch 889/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4345 - acc: 0.7830 - val_loss: 0.4998 - val_acc: 0.7656\n",
      "Epoch 890/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4345 - acc: 0.7830 - val_loss: 0.4998 - val_acc: 0.7656\n",
      "Epoch 891/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4344 - acc: 0.7830 - val_loss: 0.4998 - val_acc: 0.7656\n",
      "Epoch 892/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4344 - acc: 0.7830 - val_loss: 0.4999 - val_acc: 0.7656\n",
      "Epoch 893/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4344 - acc: 0.7830 - val_loss: 0.4999 - val_acc: 0.7656\n",
      "Epoch 894/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4344 - acc: 0.7830 - val_loss: 0.4999 - val_acc: 0.7656\n",
      "Epoch 895/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4344 - acc: 0.7830 - val_loss: 0.4999 - val_acc: 0.7656\n",
      "Epoch 896/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4344 - acc: 0.7830 - val_loss: 0.4999 - val_acc: 0.7656\n",
      "Epoch 897/1500\n",
      "576/576 [==============================] - 0s 33us/sample - loss: 0.4344 - acc: 0.7830 - val_loss: 0.5000 - val_acc: 0.7656\n",
      "Epoch 898/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4343 - acc: 0.7830 - val_loss: 0.5000 - val_acc: 0.7656\n",
      "Epoch 899/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4343 - acc: 0.7830 - val_loss: 0.5000 - val_acc: 0.7656\n",
      "Epoch 900/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4342 - acc: 0.7830 - val_loss: 0.5000 - val_acc: 0.7656\n",
      "Epoch 901/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4342 - acc: 0.7830 - val_loss: 0.5001 - val_acc: 0.7656\n",
      "Epoch 902/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4343 - acc: 0.7830 - val_loss: 0.5001 - val_acc: 0.7656\n",
      "Epoch 903/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4342 - acc: 0.7830 - val_loss: 0.5001 - val_acc: 0.7656\n",
      "Epoch 904/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4342 - acc: 0.7830 - val_loss: 0.5001 - val_acc: 0.7656\n",
      "Epoch 905/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4341 - acc: 0.7830 - val_loss: 0.5002 - val_acc: 0.7656\n",
      "Epoch 906/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4341 - acc: 0.7830 - val_loss: 0.5002 - val_acc: 0.7656\n",
      "Epoch 907/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4341 - acc: 0.7847 - val_loss: 0.5002 - val_acc: 0.7656\n",
      "Epoch 908/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4341 - acc: 0.7830 - val_loss: 0.5002 - val_acc: 0.7656\n",
      "Epoch 909/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4341 - acc: 0.7830 - val_loss: 0.5002 - val_acc: 0.7656\n",
      "Epoch 910/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4341 - acc: 0.7812 - val_loss: 0.5003 - val_acc: 0.7656\n",
      "Epoch 911/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4340 - acc: 0.7830 - val_loss: 0.5003 - val_acc: 0.7656\n",
      "Epoch 912/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4340 - acc: 0.7830 - val_loss: 0.5004 - val_acc: 0.7656\n",
      "Epoch 913/1500\n",
      "576/576 [==============================] - 0s 35us/sample - loss: 0.4339 - acc: 0.7812 - val_loss: 0.5004 - val_acc: 0.7656\n",
      "Epoch 914/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4339 - acc: 0.7830 - val_loss: 0.5004 - val_acc: 0.7656\n",
      "Epoch 915/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4339 - acc: 0.7847 - val_loss: 0.5004 - val_acc: 0.7656\n",
      "Epoch 916/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4339 - acc: 0.7830 - val_loss: 0.5004 - val_acc: 0.7656\n",
      "Epoch 917/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4339 - acc: 0.7812 - val_loss: 0.5005 - val_acc: 0.7656\n",
      "Epoch 918/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4339 - acc: 0.7830 - val_loss: 0.5005 - val_acc: 0.7656\n",
      "Epoch 919/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4338 - acc: 0.7812 - val_loss: 0.5005 - val_acc: 0.7656\n",
      "Epoch 920/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4338 - acc: 0.7830 - val_loss: 0.5005 - val_acc: 0.7656\n",
      "Epoch 921/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4338 - acc: 0.7847 - val_loss: 0.5006 - val_acc: 0.7656\n",
      "Epoch 922/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4337 - acc: 0.7812 - val_loss: 0.5006 - val_acc: 0.7656\n",
      "Epoch 923/1500\n",
      "576/576 [==============================] - 0s 31us/sample - loss: 0.4337 - acc: 0.7830 - val_loss: 0.5006 - val_acc: 0.7656\n",
      "Epoch 924/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4337 - acc: 0.7812 - val_loss: 0.5007 - val_acc: 0.7656\n",
      "Epoch 925/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4336 - acc: 0.7830 - val_loss: 0.5007 - val_acc: 0.7656\n",
      "Epoch 926/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4336 - acc: 0.7830 - val_loss: 0.5007 - val_acc: 0.7656\n",
      "Epoch 927/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4336 - acc: 0.7812 - val_loss: 0.5007 - val_acc: 0.7656\n",
      "Epoch 928/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4336 - acc: 0.7812 - val_loss: 0.5008 - val_acc: 0.7656\n",
      "Epoch 929/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4335 - acc: 0.7830 - val_loss: 0.5008 - val_acc: 0.7656\n",
      "Epoch 930/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4335 - acc: 0.7795 - val_loss: 0.5008 - val_acc: 0.7656\n",
      "Epoch 931/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4335 - acc: 0.7830 - val_loss: 0.5008 - val_acc: 0.7656\n",
      "Epoch 932/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4335 - acc: 0.7812 - val_loss: 0.5008 - val_acc: 0.7708\n",
      "Epoch 933/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4334 - acc: 0.7795 - val_loss: 0.5009 - val_acc: 0.7708\n",
      "Epoch 934/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4334 - acc: 0.7830 - val_loss: 0.5009 - val_acc: 0.7708\n",
      "Epoch 935/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4335 - acc: 0.7812 - val_loss: 0.5009 - val_acc: 0.7708\n",
      "Epoch 936/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4334 - acc: 0.7812 - val_loss: 0.5009 - val_acc: 0.7708\n",
      "Epoch 937/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4334 - acc: 0.7812 - val_loss: 0.5009 - val_acc: 0.7708\n",
      "Epoch 938/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4333 - acc: 0.7830 - val_loss: 0.5009 - val_acc: 0.7708\n",
      "Epoch 939/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4333 - acc: 0.7830 - val_loss: 0.5010 - val_acc: 0.7708\n",
      "Epoch 940/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4333 - acc: 0.7830 - val_loss: 0.5010 - val_acc: 0.7708\n",
      "Epoch 941/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4333 - acc: 0.7812 - val_loss: 0.5010 - val_acc: 0.7708\n",
      "Epoch 942/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4333 - acc: 0.7812 - val_loss: 0.5010 - val_acc: 0.7760\n",
      "Epoch 943/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4332 - acc: 0.7830 - val_loss: 0.5011 - val_acc: 0.7708\n",
      "Epoch 944/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4332 - acc: 0.7812 - val_loss: 0.5011 - val_acc: 0.7708\n",
      "Epoch 945/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4332 - acc: 0.7812 - val_loss: 0.5011 - val_acc: 0.7708\n",
      "Epoch 946/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4332 - acc: 0.7812 - val_loss: 0.5011 - val_acc: 0.7760\n",
      "Epoch 947/1500\n",
      "576/576 [==============================] - 0s 31us/sample - loss: 0.4332 - acc: 0.7812 - val_loss: 0.5011 - val_acc: 0.7760\n",
      "Epoch 948/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4331 - acc: 0.7830 - val_loss: 0.5012 - val_acc: 0.7760\n",
      "Epoch 949/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4331 - acc: 0.7795 - val_loss: 0.5012 - val_acc: 0.7760\n",
      "Epoch 950/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4330 - acc: 0.7812 - val_loss: 0.5012 - val_acc: 0.7760\n",
      "Epoch 951/1500\n",
      "576/576 [==============================] - 0s 33us/sample - loss: 0.4331 - acc: 0.7812 - val_loss: 0.5012 - val_acc: 0.7760\n",
      "Epoch 952/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4331 - acc: 0.7830 - val_loss: 0.5013 - val_acc: 0.7760\n",
      "Epoch 953/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4331 - acc: 0.7812 - val_loss: 0.5013 - val_acc: 0.7760\n",
      "Epoch 954/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4330 - acc: 0.7812 - val_loss: 0.5013 - val_acc: 0.7760\n",
      "Epoch 955/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4330 - acc: 0.7830 - val_loss: 0.5014 - val_acc: 0.7760\n",
      "Epoch 956/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4330 - acc: 0.7812 - val_loss: 0.5014 - val_acc: 0.7760\n",
      "Epoch 957/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4328 - acc: 0.7812 - val_loss: 0.5014 - val_acc: 0.7760\n",
      "Epoch 958/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4329 - acc: 0.7812 - val_loss: 0.5014 - val_acc: 0.7760\n",
      "Epoch 959/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4328 - acc: 0.7812 - val_loss: 0.5015 - val_acc: 0.7760\n",
      "Epoch 960/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4328 - acc: 0.7812 - val_loss: 0.5015 - val_acc: 0.7760\n",
      "Epoch 961/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4328 - acc: 0.7812 - val_loss: 0.5015 - val_acc: 0.7760\n",
      "Epoch 962/1500\n",
      "576/576 [==============================] - 0s 31us/sample - loss: 0.4328 - acc: 0.7812 - val_loss: 0.5015 - val_acc: 0.7760\n",
      "Epoch 963/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4328 - acc: 0.7812 - val_loss: 0.5015 - val_acc: 0.7760\n",
      "Epoch 964/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4327 - acc: 0.7812 - val_loss: 0.5016 - val_acc: 0.7760\n",
      "Epoch 965/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4327 - acc: 0.7812 - val_loss: 0.5016 - val_acc: 0.7760\n",
      "Epoch 966/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4327 - acc: 0.7812 - val_loss: 0.5016 - val_acc: 0.7760\n",
      "Epoch 967/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4327 - acc: 0.7830 - val_loss: 0.5016 - val_acc: 0.7760\n",
      "Epoch 968/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4327 - acc: 0.7830 - val_loss: 0.5017 - val_acc: 0.7760\n",
      "Epoch 969/1500\n",
      "576/576 [==============================] - 0s 31us/sample - loss: 0.4326 - acc: 0.7812 - val_loss: 0.5017 - val_acc: 0.7760\n",
      "Epoch 970/1500\n",
      "576/576 [==============================] - 0s 35us/sample - loss: 0.4326 - acc: 0.7812 - val_loss: 0.5017 - val_acc: 0.7760\n",
      "Epoch 971/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4326 - acc: 0.7812 - val_loss: 0.5018 - val_acc: 0.7760\n",
      "Epoch 972/1500\n",
      "576/576 [==============================] - 0s 33us/sample - loss: 0.4326 - acc: 0.7812 - val_loss: 0.5018 - val_acc: 0.7760\n",
      "Epoch 973/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4325 - acc: 0.7812 - val_loss: 0.5018 - val_acc: 0.7760\n",
      "Epoch 974/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4325 - acc: 0.7830 - val_loss: 0.5018 - val_acc: 0.7760\n",
      "Epoch 975/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4325 - acc: 0.7830 - val_loss: 0.5019 - val_acc: 0.7760\n",
      "Epoch 976/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4325 - acc: 0.7812 - val_loss: 0.5019 - val_acc: 0.7760\n",
      "Epoch 977/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4324 - acc: 0.7830 - val_loss: 0.5019 - val_acc: 0.7760\n",
      "Epoch 978/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4324 - acc: 0.7830 - val_loss: 0.5019 - val_acc: 0.7760\n",
      "Epoch 979/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4324 - acc: 0.7830 - val_loss: 0.5020 - val_acc: 0.7760\n",
      "Epoch 980/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4323 - acc: 0.7830 - val_loss: 0.5020 - val_acc: 0.7760\n",
      "Epoch 981/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4323 - acc: 0.7830 - val_loss: 0.5020 - val_acc: 0.7760\n",
      "Epoch 982/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4323 - acc: 0.7830 - val_loss: 0.5020 - val_acc: 0.7760\n",
      "Epoch 983/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4323 - acc: 0.7830 - val_loss: 0.5021 - val_acc: 0.7760\n",
      "Epoch 984/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4323 - acc: 0.7830 - val_loss: 0.5021 - val_acc: 0.7760\n",
      "Epoch 985/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4323 - acc: 0.7830 - val_loss: 0.5021 - val_acc: 0.7760\n",
      "Epoch 986/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4323 - acc: 0.7830 - val_loss: 0.5022 - val_acc: 0.7760\n",
      "Epoch 987/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4322 - acc: 0.7830 - val_loss: 0.5022 - val_acc: 0.7760\n",
      "Epoch 988/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4322 - acc: 0.7830 - val_loss: 0.5022 - val_acc: 0.7760\n",
      "Epoch 989/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4322 - acc: 0.7830 - val_loss: 0.5022 - val_acc: 0.7760\n",
      "Epoch 990/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4322 - acc: 0.7830 - val_loss: 0.5022 - val_acc: 0.7760\n",
      "Epoch 991/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4321 - acc: 0.7830 - val_loss: 0.5023 - val_acc: 0.7760\n",
      "Epoch 992/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4321 - acc: 0.7830 - val_loss: 0.5023 - val_acc: 0.7760\n",
      "Epoch 993/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4321 - acc: 0.7830 - val_loss: 0.5023 - val_acc: 0.7760\n",
      "Epoch 994/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4321 - acc: 0.7830 - val_loss: 0.5024 - val_acc: 0.7760\n",
      "Epoch 995/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4320 - acc: 0.7830 - val_loss: 0.5024 - val_acc: 0.7760\n",
      "Epoch 996/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4320 - acc: 0.7830 - val_loss: 0.5024 - val_acc: 0.7760\n",
      "Epoch 997/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4320 - acc: 0.7830 - val_loss: 0.5025 - val_acc: 0.7760\n",
      "Epoch 998/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4320 - acc: 0.7830 - val_loss: 0.5025 - val_acc: 0.7760\n",
      "Epoch 999/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4320 - acc: 0.7830 - val_loss: 0.5025 - val_acc: 0.7760\n",
      "Epoch 1000/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4319 - acc: 0.7830 - val_loss: 0.5025 - val_acc: 0.7760\n",
      "Epoch 1001/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4320 - acc: 0.7830 - val_loss: 0.5026 - val_acc: 0.7760\n",
      "Epoch 1002/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4319 - acc: 0.7830 - val_loss: 0.5026 - val_acc: 0.7760\n",
      "Epoch 1003/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4319 - acc: 0.7830 - val_loss: 0.5026 - val_acc: 0.7760\n",
      "Epoch 1004/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4319 - acc: 0.7830 - val_loss: 0.5026 - val_acc: 0.7760\n",
      "Epoch 1005/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4319 - acc: 0.7830 - val_loss: 0.5027 - val_acc: 0.7708\n",
      "Epoch 1006/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4318 - acc: 0.7830 - val_loss: 0.5027 - val_acc: 0.7708\n",
      "Epoch 1007/1500\n",
      "576/576 [==============================] - 0s 31us/sample - loss: 0.4317 - acc: 0.7830 - val_loss: 0.5027 - val_acc: 0.7708\n",
      "Epoch 1008/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4318 - acc: 0.7830 - val_loss: 0.5028 - val_acc: 0.7708\n",
      "Epoch 1009/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4318 - acc: 0.7830 - val_loss: 0.5028 - val_acc: 0.7708\n",
      "Epoch 1010/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4317 - acc: 0.7830 - val_loss: 0.5028 - val_acc: 0.7708\n",
      "Epoch 1011/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4317 - acc: 0.7830 - val_loss: 0.5028 - val_acc: 0.7708\n",
      "Epoch 1012/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4317 - acc: 0.7830 - val_loss: 0.5029 - val_acc: 0.7708\n",
      "Epoch 1013/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4316 - acc: 0.7830 - val_loss: 0.5029 - val_acc: 0.7708\n",
      "Epoch 1014/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4317 - acc: 0.7830 - val_loss: 0.5029 - val_acc: 0.7708\n",
      "Epoch 1015/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4316 - acc: 0.7830 - val_loss: 0.5029 - val_acc: 0.7708\n",
      "Epoch 1016/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4316 - acc: 0.7830 - val_loss: 0.5030 - val_acc: 0.7708\n",
      "Epoch 1017/1500\n",
      "576/576 [==============================] - 0s 31us/sample - loss: 0.4316 - acc: 0.7830 - val_loss: 0.5030 - val_acc: 0.7708\n",
      "Epoch 1018/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4315 - acc: 0.7830 - val_loss: 0.5030 - val_acc: 0.7708\n",
      "Epoch 1019/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4315 - acc: 0.7830 - val_loss: 0.5031 - val_acc: 0.7708\n",
      "Epoch 1020/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4315 - acc: 0.7830 - val_loss: 0.5031 - val_acc: 0.7708\n",
      "Epoch 1021/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4315 - acc: 0.7830 - val_loss: 0.5031 - val_acc: 0.7708\n",
      "Epoch 1022/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4314 - acc: 0.7830 - val_loss: 0.5031 - val_acc: 0.7708\n",
      "Epoch 1023/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4315 - acc: 0.7830 - val_loss: 0.5031 - val_acc: 0.7708\n",
      "Epoch 1024/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4314 - acc: 0.7830 - val_loss: 0.5031 - val_acc: 0.7708\n",
      "Epoch 1025/1500\n",
      "576/576 [==============================] - 0s 31us/sample - loss: 0.4314 - acc: 0.7830 - val_loss: 0.5032 - val_acc: 0.7708\n",
      "Epoch 1026/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4314 - acc: 0.7830 - val_loss: 0.5032 - val_acc: 0.7708\n",
      "Epoch 1027/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4314 - acc: 0.7830 - val_loss: 0.5032 - val_acc: 0.7708\n",
      "Epoch 1028/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4314 - acc: 0.7830 - val_loss: 0.5032 - val_acc: 0.7708\n",
      "Epoch 1029/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4313 - acc: 0.7830 - val_loss: 0.5032 - val_acc: 0.7708\n",
      "Epoch 1030/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4313 - acc: 0.7830 - val_loss: 0.5033 - val_acc: 0.7708\n",
      "Epoch 1031/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4314 - acc: 0.7830 - val_loss: 0.5033 - val_acc: 0.7708\n",
      "Epoch 1032/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4313 - acc: 0.7830 - val_loss: 0.5033 - val_acc: 0.7708\n",
      "Epoch 1033/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4312 - acc: 0.7830 - val_loss: 0.5033 - val_acc: 0.7708\n",
      "Epoch 1034/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4312 - acc: 0.7830 - val_loss: 0.5034 - val_acc: 0.7708\n",
      "Epoch 1035/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4312 - acc: 0.7830 - val_loss: 0.5034 - val_acc: 0.7708\n",
      "Epoch 1036/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4312 - acc: 0.7830 - val_loss: 0.5034 - val_acc: 0.7708\n",
      "Epoch 1037/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4312 - acc: 0.7830 - val_loss: 0.5034 - val_acc: 0.7708\n",
      "Epoch 1038/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4311 - acc: 0.7830 - val_loss: 0.5034 - val_acc: 0.7708\n",
      "Epoch 1039/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4312 - acc: 0.7830 - val_loss: 0.5034 - val_acc: 0.7708\n",
      "Epoch 1040/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4311 - acc: 0.7830 - val_loss: 0.5035 - val_acc: 0.7708\n",
      "Epoch 1041/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4311 - acc: 0.7830 - val_loss: 0.5035 - val_acc: 0.7708\n",
      "Epoch 1042/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4311 - acc: 0.7830 - val_loss: 0.5035 - val_acc: 0.7708\n",
      "Epoch 1043/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4311 - acc: 0.7830 - val_loss: 0.5035 - val_acc: 0.7708\n",
      "Epoch 1044/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4311 - acc: 0.7830 - val_loss: 0.5035 - val_acc: 0.7708\n",
      "Epoch 1045/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4310 - acc: 0.7830 - val_loss: 0.5035 - val_acc: 0.7708\n",
      "Epoch 1046/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4310 - acc: 0.7830 - val_loss: 0.5036 - val_acc: 0.7708\n",
      "Epoch 1047/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4310 - acc: 0.7830 - val_loss: 0.5036 - val_acc: 0.7708\n",
      "Epoch 1048/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4310 - acc: 0.7830 - val_loss: 0.5036 - val_acc: 0.7708\n",
      "Epoch 1049/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4309 - acc: 0.7830 - val_loss: 0.5036 - val_acc: 0.7708\n",
      "Epoch 1050/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4309 - acc: 0.7830 - val_loss: 0.5036 - val_acc: 0.7708\n",
      "Epoch 1051/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4309 - acc: 0.7830 - val_loss: 0.5036 - val_acc: 0.7708\n",
      "Epoch 1052/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4310 - acc: 0.7830 - val_loss: 0.5037 - val_acc: 0.7708\n",
      "Epoch 1053/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4309 - acc: 0.7830 - val_loss: 0.5037 - val_acc: 0.7760\n",
      "Epoch 1054/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4309 - acc: 0.7830 - val_loss: 0.5037 - val_acc: 0.7760\n",
      "Epoch 1055/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4308 - acc: 0.7830 - val_loss: 0.5037 - val_acc: 0.7760\n",
      "Epoch 1056/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4308 - acc: 0.7830 - val_loss: 0.5038 - val_acc: 0.7760\n",
      "Epoch 1057/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4308 - acc: 0.7830 - val_loss: 0.5038 - val_acc: 0.7760\n",
      "Epoch 1058/1500\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.5005 - acc: 0.687 - 0s 28us/sample - loss: 0.4307 - acc: 0.7830 - val_loss: 0.5038 - val_acc: 0.7760\n",
      "Epoch 1059/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4307 - acc: 0.7830 - val_loss: 0.5038 - val_acc: 0.7760\n",
      "Epoch 1060/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4308 - acc: 0.7830 - val_loss: 0.5038 - val_acc: 0.7760\n",
      "Epoch 1061/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4307 - acc: 0.7830 - val_loss: 0.5038 - val_acc: 0.7760\n",
      "Epoch 1062/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4307 - acc: 0.7830 - val_loss: 0.5038 - val_acc: 0.7760\n",
      "Epoch 1063/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4307 - acc: 0.7830 - val_loss: 0.5039 - val_acc: 0.7760\n",
      "Epoch 1064/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4307 - acc: 0.7830 - val_loss: 0.5039 - val_acc: 0.7760\n",
      "Epoch 1065/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4306 - acc: 0.7830 - val_loss: 0.5039 - val_acc: 0.7760\n",
      "Epoch 1066/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4306 - acc: 0.7830 - val_loss: 0.5039 - val_acc: 0.7760\n",
      "Epoch 1067/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4306 - acc: 0.7830 - val_loss: 0.5039 - val_acc: 0.7760\n",
      "Epoch 1068/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4306 - acc: 0.7830 - val_loss: 0.5039 - val_acc: 0.7760\n",
      "Epoch 1069/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4305 - acc: 0.7830 - val_loss: 0.5040 - val_acc: 0.7760\n",
      "Epoch 1070/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4305 - acc: 0.7830 - val_loss: 0.5040 - val_acc: 0.7760\n",
      "Epoch 1071/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4305 - acc: 0.7830 - val_loss: 0.5040 - val_acc: 0.7760\n",
      "Epoch 1072/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4305 - acc: 0.7830 - val_loss: 0.5040 - val_acc: 0.7812\n",
      "Epoch 1073/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4305 - acc: 0.7830 - val_loss: 0.5040 - val_acc: 0.7812\n",
      "Epoch 1074/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4305 - acc: 0.7847 - val_loss: 0.5040 - val_acc: 0.7812\n",
      "Epoch 1075/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4304 - acc: 0.7830 - val_loss: 0.5040 - val_acc: 0.7812\n",
      "Epoch 1076/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4304 - acc: 0.7830 - val_loss: 0.5040 - val_acc: 0.7812\n",
      "Epoch 1077/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4304 - acc: 0.7830 - val_loss: 0.5040 - val_acc: 0.7812\n",
      "Epoch 1078/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4304 - acc: 0.7830 - val_loss: 0.5040 - val_acc: 0.7812\n",
      "Epoch 1079/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4304 - acc: 0.7830 - val_loss: 0.5041 - val_acc: 0.7812\n",
      "Epoch 1080/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4304 - acc: 0.7830 - val_loss: 0.5041 - val_acc: 0.7812\n",
      "Epoch 1081/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4304 - acc: 0.7830 - val_loss: 0.5041 - val_acc: 0.7812\n",
      "Epoch 1082/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4303 - acc: 0.7830 - val_loss: 0.5041 - val_acc: 0.7812\n",
      "Epoch 1083/1500\n",
      "576/576 [==============================] - 0s 38us/sample - loss: 0.4303 - acc: 0.7830 - val_loss: 0.5041 - val_acc: 0.7812\n",
      "Epoch 1084/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4302 - acc: 0.7830 - val_loss: 0.5041 - val_acc: 0.7812\n",
      "Epoch 1085/1500\n",
      "576/576 [==============================] - 0s 31us/sample - loss: 0.4303 - acc: 0.7830 - val_loss: 0.5042 - val_acc: 0.7812\n",
      "Epoch 1086/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4303 - acc: 0.7847 - val_loss: 0.5042 - val_acc: 0.7812\n",
      "Epoch 1087/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4302 - acc: 0.7830 - val_loss: 0.5042 - val_acc: 0.7812\n",
      "Epoch 1088/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4302 - acc: 0.7830 - val_loss: 0.5042 - val_acc: 0.7812\n",
      "Epoch 1089/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4302 - acc: 0.7830 - val_loss: 0.5042 - val_acc: 0.7812\n",
      "Epoch 1090/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4302 - acc: 0.7847 - val_loss: 0.5042 - val_acc: 0.7812\n",
      "Epoch 1091/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4302 - acc: 0.7830 - val_loss: 0.5042 - val_acc: 0.7812\n",
      "Epoch 1092/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4302 - acc: 0.7830 - val_loss: 0.5042 - val_acc: 0.7812\n",
      "Epoch 1093/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4301 - acc: 0.7830 - val_loss: 0.5043 - val_acc: 0.7812\n",
      "Epoch 1094/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4301 - acc: 0.7847 - val_loss: 0.5043 - val_acc: 0.7812\n",
      "Epoch 1095/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4301 - acc: 0.7830 - val_loss: 0.5043 - val_acc: 0.7812\n",
      "Epoch 1096/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4300 - acc: 0.7847 - val_loss: 0.5043 - val_acc: 0.7812\n",
      "Epoch 1097/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4300 - acc: 0.7830 - val_loss: 0.5043 - val_acc: 0.7812\n",
      "Epoch 1098/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4300 - acc: 0.7830 - val_loss: 0.5043 - val_acc: 0.7812\n",
      "Epoch 1099/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4300 - acc: 0.7830 - val_loss: 0.5044 - val_acc: 0.7812\n",
      "Epoch 1100/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4300 - acc: 0.7847 - val_loss: 0.5044 - val_acc: 0.7812\n",
      "Epoch 1101/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4300 - acc: 0.7830 - val_loss: 0.5044 - val_acc: 0.7812\n",
      "Epoch 1102/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4299 - acc: 0.7830 - val_loss: 0.5044 - val_acc: 0.7812\n",
      "Epoch 1103/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4300 - acc: 0.7812 - val_loss: 0.5045 - val_acc: 0.7812\n",
      "Epoch 1104/1500\n",
      "576/576 [==============================] - 0s 31us/sample - loss: 0.4299 - acc: 0.7847 - val_loss: 0.5045 - val_acc: 0.7812\n",
      "Epoch 1105/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4299 - acc: 0.7830 - val_loss: 0.5045 - val_acc: 0.7812\n",
      "Epoch 1106/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4298 - acc: 0.7847 - val_loss: 0.5045 - val_acc: 0.7812\n",
      "Epoch 1107/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4299 - acc: 0.7812 - val_loss: 0.5045 - val_acc: 0.7812\n",
      "Epoch 1108/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4298 - acc: 0.7812 - val_loss: 0.5045 - val_acc: 0.7812\n",
      "Epoch 1109/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4298 - acc: 0.7830 - val_loss: 0.5045 - val_acc: 0.7812\n",
      "Epoch 1110/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4298 - acc: 0.7830 - val_loss: 0.5045 - val_acc: 0.7812\n",
      "Epoch 1111/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4297 - acc: 0.7812 - val_loss: 0.5046 - val_acc: 0.7760\n",
      "Epoch 1112/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4298 - acc: 0.7830 - val_loss: 0.5046 - val_acc: 0.7760\n",
      "Epoch 1113/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4298 - acc: 0.7830 - val_loss: 0.5046 - val_acc: 0.7760\n",
      "Epoch 1114/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4298 - acc: 0.7830 - val_loss: 0.5046 - val_acc: 0.7760\n",
      "Epoch 1115/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4297 - acc: 0.7830 - val_loss: 0.5046 - val_acc: 0.7760\n",
      "Epoch 1116/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4296 - acc: 0.7830 - val_loss: 0.5047 - val_acc: 0.7760\n",
      "Epoch 1117/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4297 - acc: 0.7812 - val_loss: 0.5047 - val_acc: 0.7760\n",
      "Epoch 1118/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4296 - acc: 0.7830 - val_loss: 0.5047 - val_acc: 0.7760\n",
      "Epoch 1119/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4296 - acc: 0.7830 - val_loss: 0.5047 - val_acc: 0.7760\n",
      "Epoch 1120/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4297 - acc: 0.7830 - val_loss: 0.5047 - val_acc: 0.7760\n",
      "Epoch 1121/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4297 - acc: 0.7830 - val_loss: 0.5047 - val_acc: 0.7760\n",
      "Epoch 1122/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4295 - acc: 0.7830 - val_loss: 0.5047 - val_acc: 0.7760\n",
      "Epoch 1123/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4295 - acc: 0.7830 - val_loss: 0.5048 - val_acc: 0.7760\n",
      "Epoch 1124/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4295 - acc: 0.7830 - val_loss: 0.5048 - val_acc: 0.7760\n",
      "Epoch 1125/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4295 - acc: 0.7830 - val_loss: 0.5048 - val_acc: 0.7760\n",
      "Epoch 1126/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4295 - acc: 0.7830 - val_loss: 0.5048 - val_acc: 0.7760\n",
      "Epoch 1127/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4295 - acc: 0.7830 - val_loss: 0.5048 - val_acc: 0.7760\n",
      "Epoch 1128/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4294 - acc: 0.7830 - val_loss: 0.5049 - val_acc: 0.7760\n",
      "Epoch 1129/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4294 - acc: 0.7830 - val_loss: 0.5049 - val_acc: 0.7760\n",
      "Epoch 1130/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4294 - acc: 0.7830 - val_loss: 0.5049 - val_acc: 0.7760\n",
      "Epoch 1131/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4294 - acc: 0.7830 - val_loss: 0.5049 - val_acc: 0.7760\n",
      "Epoch 1132/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4294 - acc: 0.7830 - val_loss: 0.5049 - val_acc: 0.7760\n",
      "Epoch 1133/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4294 - acc: 0.7830 - val_loss: 0.5049 - val_acc: 0.7760\n",
      "Epoch 1134/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4293 - acc: 0.7830 - val_loss: 0.5050 - val_acc: 0.7760\n",
      "Epoch 1135/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4293 - acc: 0.7830 - val_loss: 0.5050 - val_acc: 0.7760\n",
      "Epoch 1136/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4293 - acc: 0.7830 - val_loss: 0.5050 - val_acc: 0.7760\n",
      "Epoch 1137/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4293 - acc: 0.7830 - val_loss: 0.5050 - val_acc: 0.7760\n",
      "Epoch 1138/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4293 - acc: 0.7830 - val_loss: 0.5050 - val_acc: 0.7760\n",
      "Epoch 1139/1500\n",
      "576/576 [==============================] - 0s 38us/sample - loss: 0.4293 - acc: 0.7847 - val_loss: 0.5050 - val_acc: 0.7760\n",
      "Epoch 1140/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4292 - acc: 0.7847 - val_loss: 0.5050 - val_acc: 0.7760\n",
      "Epoch 1141/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4293 - acc: 0.7830 - val_loss: 0.5050 - val_acc: 0.7760\n",
      "Epoch 1142/1500\n",
      "576/576 [==============================] - 0s 33us/sample - loss: 0.4292 - acc: 0.7830 - val_loss: 0.5051 - val_acc: 0.7760\n",
      "Epoch 1143/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4292 - acc: 0.7830 - val_loss: 0.5051 - val_acc: 0.7760\n",
      "Epoch 1144/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4292 - acc: 0.7847 - val_loss: 0.5051 - val_acc: 0.7760\n",
      "Epoch 1145/1500\n",
      "576/576 [==============================] - 0s 31us/sample - loss: 0.4292 - acc: 0.7830 - val_loss: 0.5051 - val_acc: 0.7760\n",
      "Epoch 1146/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4292 - acc: 0.7847 - val_loss: 0.5051 - val_acc: 0.7760\n",
      "Epoch 1147/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4292 - acc: 0.7830 - val_loss: 0.5051 - val_acc: 0.7760\n",
      "Epoch 1148/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4291 - acc: 0.7830 - val_loss: 0.5051 - val_acc: 0.7760\n",
      "Epoch 1149/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4291 - acc: 0.7830 - val_loss: 0.5052 - val_acc: 0.7760\n",
      "Epoch 1150/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4290 - acc: 0.7847 - val_loss: 0.5052 - val_acc: 0.7760\n",
      "Epoch 1151/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4291 - acc: 0.7847 - val_loss: 0.5052 - val_acc: 0.7760\n",
      "Epoch 1152/1500\n",
      "576/576 [==============================] - 0s 31us/sample - loss: 0.4291 - acc: 0.7847 - val_loss: 0.5052 - val_acc: 0.7760\n",
      "Epoch 1153/1500\n",
      "576/576 [==============================] - 0s 31us/sample - loss: 0.4291 - acc: 0.7830 - val_loss: 0.5053 - val_acc: 0.7760\n",
      "Epoch 1154/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4290 - acc: 0.7847 - val_loss: 0.5053 - val_acc: 0.7760\n",
      "Epoch 1155/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4290 - acc: 0.7847 - val_loss: 0.5053 - val_acc: 0.7760\n",
      "Epoch 1156/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4290 - acc: 0.7830 - val_loss: 0.5053 - val_acc: 0.7760\n",
      "Epoch 1157/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4290 - acc: 0.7847 - val_loss: 0.5053 - val_acc: 0.7760\n",
      "Epoch 1158/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4290 - acc: 0.7830 - val_loss: 0.5053 - val_acc: 0.7760\n",
      "Epoch 1159/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4290 - acc: 0.7830 - val_loss: 0.5054 - val_acc: 0.7760\n",
      "Epoch 1160/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4289 - acc: 0.7847 - val_loss: 0.5054 - val_acc: 0.7760\n",
      "Epoch 1161/1500\n",
      "576/576 [==============================] - 0s 31us/sample - loss: 0.4289 - acc: 0.7847 - val_loss: 0.5054 - val_acc: 0.7760\n",
      "Epoch 1162/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4289 - acc: 0.7847 - val_loss: 0.5054 - val_acc: 0.7760\n",
      "Epoch 1163/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4289 - acc: 0.7847 - val_loss: 0.5054 - val_acc: 0.7760\n",
      "Epoch 1164/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4288 - acc: 0.7847 - val_loss: 0.5055 - val_acc: 0.7760\n",
      "Epoch 1165/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4288 - acc: 0.7847 - val_loss: 0.5055 - val_acc: 0.7760\n",
      "Epoch 1166/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4289 - acc: 0.7847 - val_loss: 0.5055 - val_acc: 0.7760\n",
      "Epoch 1167/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4288 - acc: 0.7847 - val_loss: 0.5055 - val_acc: 0.7760\n",
      "Epoch 1168/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4289 - acc: 0.7847 - val_loss: 0.5055 - val_acc: 0.7760\n",
      "Epoch 1169/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4288 - acc: 0.7847 - val_loss: 0.5055 - val_acc: 0.7760\n",
      "Epoch 1170/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4288 - acc: 0.7847 - val_loss: 0.5055 - val_acc: 0.7760\n",
      "Epoch 1171/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4288 - acc: 0.7847 - val_loss: 0.5055 - val_acc: 0.7760\n",
      "Epoch 1172/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4287 - acc: 0.7847 - val_loss: 0.5055 - val_acc: 0.7760\n",
      "Epoch 1173/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4287 - acc: 0.7847 - val_loss: 0.5055 - val_acc: 0.7760\n",
      "Epoch 1174/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4287 - acc: 0.7847 - val_loss: 0.5056 - val_acc: 0.7760\n",
      "Epoch 1175/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4287 - acc: 0.7847 - val_loss: 0.5056 - val_acc: 0.7760\n",
      "Epoch 1176/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4286 - acc: 0.7847 - val_loss: 0.5056 - val_acc: 0.7760\n",
      "Epoch 1177/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4286 - acc: 0.7847 - val_loss: 0.5056 - val_acc: 0.7760\n",
      "Epoch 1178/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4286 - acc: 0.7847 - val_loss: 0.5056 - val_acc: 0.7760\n",
      "Epoch 1179/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4286 - acc: 0.7847 - val_loss: 0.5057 - val_acc: 0.7760\n",
      "Epoch 1180/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4287 - acc: 0.7847 - val_loss: 0.5056 - val_acc: 0.7760\n",
      "Epoch 1181/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4287 - acc: 0.7847 - val_loss: 0.5056 - val_acc: 0.7760\n",
      "Epoch 1182/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4286 - acc: 0.7847 - val_loss: 0.5057 - val_acc: 0.7760\n",
      "Epoch 1183/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4286 - acc: 0.7847 - val_loss: 0.5057 - val_acc: 0.7760\n",
      "Epoch 1184/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4286 - acc: 0.7847 - val_loss: 0.5057 - val_acc: 0.7760\n",
      "Epoch 1185/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4285 - acc: 0.7847 - val_loss: 0.5057 - val_acc: 0.7760\n",
      "Epoch 1186/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4285 - acc: 0.7847 - val_loss: 0.5057 - val_acc: 0.7760\n",
      "Epoch 1187/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4285 - acc: 0.7847 - val_loss: 0.5057 - val_acc: 0.7760\n",
      "Epoch 1188/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4285 - acc: 0.7847 - val_loss: 0.5057 - val_acc: 0.7760\n",
      "Epoch 1189/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4285 - acc: 0.7847 - val_loss: 0.5058 - val_acc: 0.7760\n",
      "Epoch 1190/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4285 - acc: 0.7847 - val_loss: 0.5058 - val_acc: 0.7760\n",
      "Epoch 1191/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4285 - acc: 0.7847 - val_loss: 0.5057 - val_acc: 0.7760\n",
      "Epoch 1192/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4284 - acc: 0.7847 - val_loss: 0.5057 - val_acc: 0.7760\n",
      "Epoch 1193/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4284 - acc: 0.7847 - val_loss: 0.5057 - val_acc: 0.7760\n",
      "Epoch 1194/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4283 - acc: 0.7847 - val_loss: 0.5058 - val_acc: 0.7760\n",
      "Epoch 1195/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4284 - acc: 0.7847 - val_loss: 0.5058 - val_acc: 0.7760\n",
      "Epoch 1196/1500\n",
      "576/576 [==============================] - 0s 33us/sample - loss: 0.4284 - acc: 0.7847 - val_loss: 0.5058 - val_acc: 0.7760\n",
      "Epoch 1197/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4283 - acc: 0.7847 - val_loss: 0.5058 - val_acc: 0.7760\n",
      "Epoch 1198/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4283 - acc: 0.7830 - val_loss: 0.5058 - val_acc: 0.7760\n",
      "Epoch 1199/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4283 - acc: 0.7847 - val_loss: 0.5058 - val_acc: 0.7760\n",
      "Epoch 1200/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4283 - acc: 0.7847 - val_loss: 0.5058 - val_acc: 0.7760\n",
      "Epoch 1201/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4282 - acc: 0.7830 - val_loss: 0.5058 - val_acc: 0.7760\n",
      "Epoch 1202/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4283 - acc: 0.7830 - val_loss: 0.5058 - val_acc: 0.7760\n",
      "Epoch 1203/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4283 - acc: 0.7830 - val_loss: 0.5058 - val_acc: 0.7760\n",
      "Epoch 1204/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4282 - acc: 0.7830 - val_loss: 0.5058 - val_acc: 0.7760\n",
      "Epoch 1205/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4282 - acc: 0.7830 - val_loss: 0.5058 - val_acc: 0.7760\n",
      "Epoch 1206/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4281 - acc: 0.7847 - val_loss: 0.5058 - val_acc: 0.7760\n",
      "Epoch 1207/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4282 - acc: 0.7812 - val_loss: 0.5058 - val_acc: 0.7760\n",
      "Epoch 1208/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4282 - acc: 0.7830 - val_loss: 0.5058 - val_acc: 0.7760\n",
      "Epoch 1209/1500\n",
      "576/576 [==============================] - 0s 31us/sample - loss: 0.4282 - acc: 0.7830 - val_loss: 0.5058 - val_acc: 0.7760\n",
      "Epoch 1210/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4281 - acc: 0.7830 - val_loss: 0.5058 - val_acc: 0.7760\n",
      "Epoch 1211/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4281 - acc: 0.7830 - val_loss: 0.5058 - val_acc: 0.7760\n",
      "Epoch 1212/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4281 - acc: 0.7830 - val_loss: 0.5058 - val_acc: 0.7760\n",
      "Epoch 1213/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4281 - acc: 0.7830 - val_loss: 0.5058 - val_acc: 0.7760\n",
      "Epoch 1214/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4281 - acc: 0.7830 - val_loss: 0.5058 - val_acc: 0.7760\n",
      "Epoch 1215/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4281 - acc: 0.7830 - val_loss: 0.5058 - val_acc: 0.7760\n",
      "Epoch 1216/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4281 - acc: 0.7830 - val_loss: 0.5058 - val_acc: 0.7760\n",
      "Epoch 1217/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4281 - acc: 0.7830 - val_loss: 0.5058 - val_acc: 0.7760\n",
      "Epoch 1218/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4280 - acc: 0.7830 - val_loss: 0.5058 - val_acc: 0.7760\n",
      "Epoch 1219/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4280 - acc: 0.7830 - val_loss: 0.5058 - val_acc: 0.7760\n",
      "Epoch 1220/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4280 - acc: 0.7830 - val_loss: 0.5058 - val_acc: 0.7760\n",
      "Epoch 1221/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4280 - acc: 0.7830 - val_loss: 0.5058 - val_acc: 0.7760\n",
      "Epoch 1222/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4280 - acc: 0.7812 - val_loss: 0.5058 - val_acc: 0.7760\n",
      "Epoch 1223/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4279 - acc: 0.7812 - val_loss: 0.5058 - val_acc: 0.7760\n",
      "Epoch 1224/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4280 - acc: 0.7830 - val_loss: 0.5058 - val_acc: 0.7760\n",
      "Epoch 1225/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4279 - acc: 0.7812 - val_loss: 0.5058 - val_acc: 0.7760\n",
      "Epoch 1226/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4279 - acc: 0.7830 - val_loss: 0.5058 - val_acc: 0.7760\n",
      "Epoch 1227/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4279 - acc: 0.7830 - val_loss: 0.5059 - val_acc: 0.7760\n",
      "Epoch 1228/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4279 - acc: 0.7830 - val_loss: 0.5059 - val_acc: 0.7760\n",
      "Epoch 1229/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4278 - acc: 0.7830 - val_loss: 0.5059 - val_acc: 0.7760\n",
      "Epoch 1230/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4279 - acc: 0.7830 - val_loss: 0.5059 - val_acc: 0.7760\n",
      "Epoch 1231/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4278 - acc: 0.7830 - val_loss: 0.5059 - val_acc: 0.7760\n",
      "Epoch 1232/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4278 - acc: 0.7830 - val_loss: 0.5059 - val_acc: 0.7760\n",
      "Epoch 1233/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4278 - acc: 0.7830 - val_loss: 0.5059 - val_acc: 0.7760\n",
      "Epoch 1234/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4278 - acc: 0.7830 - val_loss: 0.5060 - val_acc: 0.7760\n",
      "Epoch 1235/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4277 - acc: 0.7830 - val_loss: 0.5060 - val_acc: 0.7760\n",
      "Epoch 1236/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4277 - acc: 0.7830 - val_loss: 0.5060 - val_acc: 0.7760\n",
      "Epoch 1237/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4277 - acc: 0.7830 - val_loss: 0.5060 - val_acc: 0.7760\n",
      "Epoch 1238/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4277 - acc: 0.7812 - val_loss: 0.5060 - val_acc: 0.7760\n",
      "Epoch 1239/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4277 - acc: 0.7830 - val_loss: 0.5060 - val_acc: 0.7760\n",
      "Epoch 1240/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4276 - acc: 0.7830 - val_loss: 0.5060 - val_acc: 0.7760\n",
      "Epoch 1241/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4277 - acc: 0.7812 - val_loss: 0.5060 - val_acc: 0.7760\n",
      "Epoch 1242/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4276 - acc: 0.7830 - val_loss: 0.5060 - val_acc: 0.7760\n",
      "Epoch 1243/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4276 - acc: 0.7830 - val_loss: 0.5060 - val_acc: 0.7760\n",
      "Epoch 1244/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4276 - acc: 0.7830 - val_loss: 0.5060 - val_acc: 0.7760\n",
      "Epoch 1245/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4276 - acc: 0.7847 - val_loss: 0.5060 - val_acc: 0.7760\n",
      "Epoch 1246/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4276 - acc: 0.7830 - val_loss: 0.5060 - val_acc: 0.7760\n",
      "Epoch 1247/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4275 - acc: 0.7830 - val_loss: 0.5060 - val_acc: 0.7760\n",
      "Epoch 1248/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4275 - acc: 0.7830 - val_loss: 0.5060 - val_acc: 0.7760\n",
      "Epoch 1249/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4275 - acc: 0.7830 - val_loss: 0.5060 - val_acc: 0.7760\n",
      "Epoch 1250/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4274 - acc: 0.7830 - val_loss: 0.5060 - val_acc: 0.7760\n",
      "Epoch 1251/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4275 - acc: 0.7812 - val_loss: 0.5060 - val_acc: 0.7760\n",
      "Epoch 1252/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4274 - acc: 0.7812 - val_loss: 0.5060 - val_acc: 0.7760\n",
      "Epoch 1253/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4275 - acc: 0.7812 - val_loss: 0.5060 - val_acc: 0.7760\n",
      "Epoch 1254/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4274 - acc: 0.7812 - val_loss: 0.5061 - val_acc: 0.7760\n",
      "Epoch 1255/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4274 - acc: 0.7795 - val_loss: 0.5061 - val_acc: 0.7760\n",
      "Epoch 1256/1500\n",
      "576/576 [==============================] - 0s 31us/sample - loss: 0.4273 - acc: 0.7812 - val_loss: 0.5061 - val_acc: 0.7760\n",
      "Epoch 1257/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4274 - acc: 0.7795 - val_loss: 0.5061 - val_acc: 0.7760\n",
      "Epoch 1258/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4273 - acc: 0.7795 - val_loss: 0.5061 - val_acc: 0.7760\n",
      "Epoch 1259/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4273 - acc: 0.7830 - val_loss: 0.5061 - val_acc: 0.7760\n",
      "Epoch 1260/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4273 - acc: 0.7795 - val_loss: 0.5061 - val_acc: 0.7760\n",
      "Epoch 1261/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4273 - acc: 0.7795 - val_loss: 0.5061 - val_acc: 0.7760\n",
      "Epoch 1262/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4273 - acc: 0.7795 - val_loss: 0.5062 - val_acc: 0.7760\n",
      "Epoch 1263/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4272 - acc: 0.7812 - val_loss: 0.5062 - val_acc: 0.7760\n",
      "Epoch 1264/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4272 - acc: 0.7812 - val_loss: 0.5062 - val_acc: 0.7760\n",
      "Epoch 1265/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4271 - acc: 0.7795 - val_loss: 0.5062 - val_acc: 0.7760\n",
      "Epoch 1266/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4272 - acc: 0.7812 - val_loss: 0.5062 - val_acc: 0.7760\n",
      "Epoch 1267/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4271 - acc: 0.7812 - val_loss: 0.5062 - val_acc: 0.7760\n",
      "Epoch 1268/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4271 - acc: 0.7795 - val_loss: 0.5062 - val_acc: 0.7760\n",
      "Epoch 1269/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4272 - acc: 0.7795 - val_loss: 0.5062 - val_acc: 0.7760\n",
      "Epoch 1270/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4271 - acc: 0.7795 - val_loss: 0.5062 - val_acc: 0.7760\n",
      "Epoch 1271/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4271 - acc: 0.7795 - val_loss: 0.5062 - val_acc: 0.7760\n",
      "Epoch 1272/1500\n",
      "576/576 [==============================] - 0s 31us/sample - loss: 0.4270 - acc: 0.7795 - val_loss: 0.5062 - val_acc: 0.7760\n",
      "Epoch 1273/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4270 - acc: 0.7812 - val_loss: 0.5063 - val_acc: 0.7708\n",
      "Epoch 1274/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4270 - acc: 0.7812 - val_loss: 0.5062 - val_acc: 0.7708\n",
      "Epoch 1275/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4270 - acc: 0.7812 - val_loss: 0.5063 - val_acc: 0.7708\n",
      "Epoch 1276/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4269 - acc: 0.7812 - val_loss: 0.5063 - val_acc: 0.7708\n",
      "Epoch 1277/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4269 - acc: 0.7812 - val_loss: 0.5063 - val_acc: 0.7708\n",
      "Epoch 1278/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4270 - acc: 0.7795 - val_loss: 0.5063 - val_acc: 0.7708\n",
      "Epoch 1279/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4269 - acc: 0.7812 - val_loss: 0.5063 - val_acc: 0.7708\n",
      "Epoch 1280/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4269 - acc: 0.7830 - val_loss: 0.5064 - val_acc: 0.7708\n",
      "Epoch 1281/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4269 - acc: 0.7812 - val_loss: 0.5063 - val_acc: 0.7708\n",
      "Epoch 1282/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4269 - acc: 0.7812 - val_loss: 0.5064 - val_acc: 0.7708\n",
      "Epoch 1283/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4268 - acc: 0.7812 - val_loss: 0.5064 - val_acc: 0.7708\n",
      "Epoch 1284/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4268 - acc: 0.7812 - val_loss: 0.5064 - val_acc: 0.7708\n",
      "Epoch 1285/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4268 - acc: 0.7830 - val_loss: 0.5064 - val_acc: 0.7708\n",
      "Epoch 1286/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4268 - acc: 0.7830 - val_loss: 0.5064 - val_acc: 0.7708\n",
      "Epoch 1287/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4268 - acc: 0.7812 - val_loss: 0.5064 - val_acc: 0.7708\n",
      "Epoch 1288/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4268 - acc: 0.7795 - val_loss: 0.5064 - val_acc: 0.7708\n",
      "Epoch 1289/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4268 - acc: 0.7812 - val_loss: 0.5064 - val_acc: 0.7708\n",
      "Epoch 1290/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4267 - acc: 0.7812 - val_loss: 0.5064 - val_acc: 0.7708\n",
      "Epoch 1291/1500\n",
      "576/576 [==============================] - 0s 31us/sample - loss: 0.4266 - acc: 0.7812 - val_loss: 0.5065 - val_acc: 0.7708\n",
      "Epoch 1292/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4266 - acc: 0.7812 - val_loss: 0.5065 - val_acc: 0.7708\n",
      "Epoch 1293/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4266 - acc: 0.7812 - val_loss: 0.5065 - val_acc: 0.7708\n",
      "Epoch 1294/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4266 - acc: 0.7795 - val_loss: 0.5065 - val_acc: 0.7708\n",
      "Epoch 1295/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4266 - acc: 0.7812 - val_loss: 0.5065 - val_acc: 0.7708\n",
      "Epoch 1296/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4265 - acc: 0.7812 - val_loss: 0.5065 - val_acc: 0.7708\n",
      "Epoch 1297/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4266 - acc: 0.7830 - val_loss: 0.5066 - val_acc: 0.7708\n",
      "Epoch 1298/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4265 - acc: 0.7812 - val_loss: 0.5065 - val_acc: 0.7708\n",
      "Epoch 1299/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4265 - acc: 0.7795 - val_loss: 0.5066 - val_acc: 0.7708\n",
      "Epoch 1300/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4264 - acc: 0.7795 - val_loss: 0.5066 - val_acc: 0.7708\n",
      "Epoch 1301/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4264 - acc: 0.7795 - val_loss: 0.5066 - val_acc: 0.7708\n",
      "Epoch 1302/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4265 - acc: 0.7795 - val_loss: 0.5066 - val_acc: 0.7708\n",
      "Epoch 1303/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4264 - acc: 0.7812 - val_loss: 0.5066 - val_acc: 0.7708\n",
      "Epoch 1304/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4264 - acc: 0.7795 - val_loss: 0.5066 - val_acc: 0.7708\n",
      "Epoch 1305/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4264 - acc: 0.7795 - val_loss: 0.5066 - val_acc: 0.7708\n",
      "Epoch 1306/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4263 - acc: 0.7830 - val_loss: 0.5066 - val_acc: 0.7708\n",
      "Epoch 1307/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4264 - acc: 0.7795 - val_loss: 0.5066 - val_acc: 0.7708\n",
      "Epoch 1308/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4263 - acc: 0.7795 - val_loss: 0.5066 - val_acc: 0.7708\n",
      "Epoch 1309/1500\n",
      "576/576 [==============================] - 0s 33us/sample - loss: 0.4263 - acc: 0.7778 - val_loss: 0.5066 - val_acc: 0.7708\n",
      "Epoch 1310/1500\n",
      "576/576 [==============================] - 0s 35us/sample - loss: 0.4263 - acc: 0.7795 - val_loss: 0.5066 - val_acc: 0.7708\n",
      "Epoch 1311/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4262 - acc: 0.7812 - val_loss: 0.5067 - val_acc: 0.7708\n",
      "Epoch 1312/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4262 - acc: 0.7795 - val_loss: 0.5067 - val_acc: 0.7708\n",
      "Epoch 1313/1500\n",
      "576/576 [==============================] - 0s 31us/sample - loss: 0.4262 - acc: 0.7830 - val_loss: 0.5067 - val_acc: 0.7708\n",
      "Epoch 1314/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4262 - acc: 0.7847 - val_loss: 0.5067 - val_acc: 0.7708\n",
      "Epoch 1315/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4262 - acc: 0.7795 - val_loss: 0.5067 - val_acc: 0.7708\n",
      "Epoch 1316/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4261 - acc: 0.7795 - val_loss: 0.5067 - val_acc: 0.7708\n",
      "Epoch 1317/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4261 - acc: 0.7778 - val_loss: 0.5067 - val_acc: 0.7708\n",
      "Epoch 1318/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4262 - acc: 0.7830 - val_loss: 0.5067 - val_acc: 0.7708\n",
      "Epoch 1319/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4262 - acc: 0.7847 - val_loss: 0.5068 - val_acc: 0.7708\n",
      "Epoch 1320/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4261 - acc: 0.7830 - val_loss: 0.5068 - val_acc: 0.7708\n",
      "Epoch 1321/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4261 - acc: 0.7865 - val_loss: 0.5068 - val_acc: 0.7708\n",
      "Epoch 1322/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4260 - acc: 0.7830 - val_loss: 0.5068 - val_acc: 0.7708\n",
      "Epoch 1323/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4260 - acc: 0.7830 - val_loss: 0.5068 - val_acc: 0.7708\n",
      "Epoch 1324/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4260 - acc: 0.7865 - val_loss: 0.5068 - val_acc: 0.7708\n",
      "Epoch 1325/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4260 - acc: 0.7847 - val_loss: 0.5069 - val_acc: 0.7708\n",
      "Epoch 1326/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4260 - acc: 0.7847 - val_loss: 0.5069 - val_acc: 0.7708\n",
      "Epoch 1327/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4259 - acc: 0.7847 - val_loss: 0.5069 - val_acc: 0.7708\n",
      "Epoch 1328/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4259 - acc: 0.7812 - val_loss: 0.5069 - val_acc: 0.7708\n",
      "Epoch 1329/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4260 - acc: 0.7847 - val_loss: 0.5069 - val_acc: 0.7708\n",
      "Epoch 1330/1500\n",
      "576/576 [==============================] - 0s 31us/sample - loss: 0.4259 - acc: 0.7830 - val_loss: 0.5069 - val_acc: 0.7708\n",
      "Epoch 1331/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4258 - acc: 0.7830 - val_loss: 0.5069 - val_acc: 0.7708\n",
      "Epoch 1332/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4258 - acc: 0.7812 - val_loss: 0.5070 - val_acc: 0.7708\n",
      "Epoch 1333/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4258 - acc: 0.7830 - val_loss: 0.5069 - val_acc: 0.7708\n",
      "Epoch 1334/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4259 - acc: 0.7865 - val_loss: 0.5069 - val_acc: 0.7708\n",
      "Epoch 1335/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4258 - acc: 0.7847 - val_loss: 0.5070 - val_acc: 0.7708\n",
      "Epoch 1336/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4258 - acc: 0.7830 - val_loss: 0.5070 - val_acc: 0.7708\n",
      "Epoch 1337/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4257 - acc: 0.7812 - val_loss: 0.5070 - val_acc: 0.7708\n",
      "Epoch 1338/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4257 - acc: 0.7812 - val_loss: 0.5070 - val_acc: 0.7708\n",
      "Epoch 1339/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4257 - acc: 0.7847 - val_loss: 0.5070 - val_acc: 0.7708\n",
      "Epoch 1340/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4257 - acc: 0.7847 - val_loss: 0.5070 - val_acc: 0.7708\n",
      "Epoch 1341/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4257 - acc: 0.7830 - val_loss: 0.5071 - val_acc: 0.7708\n",
      "Epoch 1342/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4256 - acc: 0.7795 - val_loss: 0.5071 - val_acc: 0.7708\n",
      "Epoch 1343/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4256 - acc: 0.7795 - val_loss: 0.5071 - val_acc: 0.7708\n",
      "Epoch 1344/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4256 - acc: 0.7812 - val_loss: 0.5072 - val_acc: 0.7708\n",
      "Epoch 1345/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4256 - acc: 0.7795 - val_loss: 0.5072 - val_acc: 0.7708\n",
      "Epoch 1346/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4256 - acc: 0.7830 - val_loss: 0.5072 - val_acc: 0.7708\n",
      "Epoch 1347/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4255 - acc: 0.7812 - val_loss: 0.5072 - val_acc: 0.7708\n",
      "Epoch 1348/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4255 - acc: 0.7812 - val_loss: 0.5073 - val_acc: 0.7708\n",
      "Epoch 1349/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4255 - acc: 0.7847 - val_loss: 0.5073 - val_acc: 0.7708\n",
      "Epoch 1350/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4254 - acc: 0.7795 - val_loss: 0.5073 - val_acc: 0.7708\n",
      "Epoch 1351/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4254 - acc: 0.7795 - val_loss: 0.5073 - val_acc: 0.7708\n",
      "Epoch 1352/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4254 - acc: 0.7830 - val_loss: 0.5074 - val_acc: 0.7708\n",
      "Epoch 1353/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4254 - acc: 0.7830 - val_loss: 0.5074 - val_acc: 0.7708\n",
      "Epoch 1354/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4254 - acc: 0.7830 - val_loss: 0.5074 - val_acc: 0.7708\n",
      "Epoch 1355/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4254 - acc: 0.7812 - val_loss: 0.5074 - val_acc: 0.7708\n",
      "Epoch 1356/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4253 - acc: 0.7795 - val_loss: 0.5075 - val_acc: 0.7708\n",
      "Epoch 1357/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4253 - acc: 0.7830 - val_loss: 0.5075 - val_acc: 0.7708\n",
      "Epoch 1358/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4252 - acc: 0.7830 - val_loss: 0.5075 - val_acc: 0.7708\n",
      "Epoch 1359/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4252 - acc: 0.7830 - val_loss: 0.5075 - val_acc: 0.7708\n",
      "Epoch 1360/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4253 - acc: 0.7830 - val_loss: 0.5076 - val_acc: 0.7656\n",
      "Epoch 1361/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4253 - acc: 0.7812 - val_loss: 0.5076 - val_acc: 0.7656\n",
      "Epoch 1362/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4251 - acc: 0.7847 - val_loss: 0.5076 - val_acc: 0.7656\n",
      "Epoch 1363/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4251 - acc: 0.7865 - val_loss: 0.5076 - val_acc: 0.7656\n",
      "Epoch 1364/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4251 - acc: 0.7847 - val_loss: 0.5077 - val_acc: 0.7656\n",
      "Epoch 1365/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4251 - acc: 0.7847 - val_loss: 0.5077 - val_acc: 0.7656\n",
      "Epoch 1366/1500\n",
      "576/576 [==============================] - 0s 36us/sample - loss: 0.4251 - acc: 0.7865 - val_loss: 0.5077 - val_acc: 0.7656\n",
      "Epoch 1367/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4250 - acc: 0.7847 - val_loss: 0.5077 - val_acc: 0.7656\n",
      "Epoch 1368/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4251 - acc: 0.7847 - val_loss: 0.5077 - val_acc: 0.7708\n",
      "Epoch 1369/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4251 - acc: 0.7847 - val_loss: 0.5077 - val_acc: 0.7708\n",
      "Epoch 1370/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4250 - acc: 0.7847 - val_loss: 0.5078 - val_acc: 0.7656\n",
      "Epoch 1371/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4250 - acc: 0.7847 - val_loss: 0.5078 - val_acc: 0.7656\n",
      "Epoch 1372/1500\n",
      "576/576 [==============================] - 0s 31us/sample - loss: 0.4249 - acc: 0.7830 - val_loss: 0.5078 - val_acc: 0.7656\n",
      "Epoch 1373/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4249 - acc: 0.7865 - val_loss: 0.5078 - val_acc: 0.7656\n",
      "Epoch 1374/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4249 - acc: 0.7847 - val_loss: 0.5078 - val_acc: 0.7656\n",
      "Epoch 1375/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4249 - acc: 0.7865 - val_loss: 0.5078 - val_acc: 0.7656\n",
      "Epoch 1376/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4248 - acc: 0.7847 - val_loss: 0.5079 - val_acc: 0.7656\n",
      "Epoch 1377/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4248 - acc: 0.7812 - val_loss: 0.5079 - val_acc: 0.7656\n",
      "Epoch 1378/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4249 - acc: 0.7830 - val_loss: 0.5079 - val_acc: 0.7656\n",
      "Epoch 1379/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4248 - acc: 0.7865 - val_loss: 0.5079 - val_acc: 0.7656\n",
      "Epoch 1380/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4248 - acc: 0.7847 - val_loss: 0.5079 - val_acc: 0.7656\n",
      "Epoch 1381/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4248 - acc: 0.7812 - val_loss: 0.5079 - val_acc: 0.7656\n",
      "Epoch 1382/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4248 - acc: 0.7847 - val_loss: 0.5080 - val_acc: 0.7656\n",
      "Epoch 1383/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4248 - acc: 0.7830 - val_loss: 0.5080 - val_acc: 0.7656\n",
      "Epoch 1384/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4247 - acc: 0.7830 - val_loss: 0.5080 - val_acc: 0.7656\n",
      "Epoch 1385/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4247 - acc: 0.7830 - val_loss: 0.5080 - val_acc: 0.7656\n",
      "Epoch 1386/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4247 - acc: 0.7830 - val_loss: 0.5080 - val_acc: 0.7656\n",
      "Epoch 1387/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4246 - acc: 0.7847 - val_loss: 0.5080 - val_acc: 0.7656\n",
      "Epoch 1388/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4246 - acc: 0.7830 - val_loss: 0.5080 - val_acc: 0.7656\n",
      "Epoch 1389/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4247 - acc: 0.7847 - val_loss: 0.5080 - val_acc: 0.7656\n",
      "Epoch 1390/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4246 - acc: 0.7865 - val_loss: 0.5080 - val_acc: 0.7656\n",
      "Epoch 1391/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4246 - acc: 0.7830 - val_loss: 0.5080 - val_acc: 0.7656\n",
      "Epoch 1392/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4246 - acc: 0.7847 - val_loss: 0.5080 - val_acc: 0.7656\n",
      "Epoch 1393/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4245 - acc: 0.7847 - val_loss: 0.5080 - val_acc: 0.7656\n",
      "Epoch 1394/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4245 - acc: 0.7830 - val_loss: 0.5080 - val_acc: 0.7656\n",
      "Epoch 1395/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4246 - acc: 0.7812 - val_loss: 0.5080 - val_acc: 0.7656\n",
      "Epoch 1396/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4245 - acc: 0.7830 - val_loss: 0.5080 - val_acc: 0.7656\n",
      "Epoch 1397/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4245 - acc: 0.7830 - val_loss: 0.5081 - val_acc: 0.7656\n",
      "Epoch 1398/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4245 - acc: 0.7830 - val_loss: 0.5081 - val_acc: 0.7656\n",
      "Epoch 1399/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4245 - acc: 0.7830 - val_loss: 0.5081 - val_acc: 0.7656\n",
      "Epoch 1400/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4244 - acc: 0.7865 - val_loss: 0.5081 - val_acc: 0.7656\n",
      "Epoch 1401/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4244 - acc: 0.7847 - val_loss: 0.5081 - val_acc: 0.7656\n",
      "Epoch 1402/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4243 - acc: 0.7847 - val_loss: 0.5081 - val_acc: 0.7656\n",
      "Epoch 1403/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4243 - acc: 0.7847 - val_loss: 0.5081 - val_acc: 0.7656\n",
      "Epoch 1404/1500\n",
      "576/576 [==============================] - 0s 31us/sample - loss: 0.4243 - acc: 0.7830 - val_loss: 0.5081 - val_acc: 0.7656\n",
      "Epoch 1405/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4243 - acc: 0.7847 - val_loss: 0.5081 - val_acc: 0.7656\n",
      "Epoch 1406/1500\n",
      "576/576 [==============================] - 0s 33us/sample - loss: 0.4243 - acc: 0.7830 - val_loss: 0.5081 - val_acc: 0.7656\n",
      "Epoch 1407/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4243 - acc: 0.7865 - val_loss: 0.5081 - val_acc: 0.7656\n",
      "Epoch 1408/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4243 - acc: 0.7847 - val_loss: 0.5081 - val_acc: 0.7656\n",
      "Epoch 1409/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 31us/sample - loss: 0.4242 - acc: 0.7882 - val_loss: 0.5081 - val_acc: 0.7656\n",
      "Epoch 1410/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4243 - acc: 0.7865 - val_loss: 0.5081 - val_acc: 0.7656\n",
      "Epoch 1411/1500\n",
      "576/576 [==============================] - 0s 35us/sample - loss: 0.4242 - acc: 0.7882 - val_loss: 0.5081 - val_acc: 0.7656\n",
      "Epoch 1412/1500\n",
      "576/576 [==============================] - 0s 31us/sample - loss: 0.4242 - acc: 0.7865 - val_loss: 0.5081 - val_acc: 0.7656\n",
      "Epoch 1413/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4242 - acc: 0.7899 - val_loss: 0.5081 - val_acc: 0.7656\n",
      "Epoch 1414/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4241 - acc: 0.7899 - val_loss: 0.5081 - val_acc: 0.7656\n",
      "Epoch 1415/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4242 - acc: 0.7865 - val_loss: 0.5081 - val_acc: 0.7656\n",
      "Epoch 1416/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4241 - acc: 0.7882 - val_loss: 0.5082 - val_acc: 0.7656\n",
      "Epoch 1417/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4242 - acc: 0.7882 - val_loss: 0.5082 - val_acc: 0.7656\n",
      "Epoch 1418/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4240 - acc: 0.7899 - val_loss: 0.5082 - val_acc: 0.7656\n",
      "Epoch 1419/1500\n",
      "576/576 [==============================] - 0s 31us/sample - loss: 0.4241 - acc: 0.7882 - val_loss: 0.5082 - val_acc: 0.7656\n",
      "Epoch 1420/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4240 - acc: 0.7899 - val_loss: 0.5082 - val_acc: 0.7656\n",
      "Epoch 1421/1500\n",
      "576/576 [==============================] - 0s 35us/sample - loss: 0.4240 - acc: 0.7865 - val_loss: 0.5082 - val_acc: 0.7656\n",
      "Epoch 1422/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4240 - acc: 0.7899 - val_loss: 0.5082 - val_acc: 0.7656\n",
      "Epoch 1423/1500\n",
      "576/576 [==============================] - 0s 33us/sample - loss: 0.4240 - acc: 0.7917 - val_loss: 0.5082 - val_acc: 0.7656\n",
      "Epoch 1424/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4239 - acc: 0.7899 - val_loss: 0.5082 - val_acc: 0.7656\n",
      "Epoch 1425/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4240 - acc: 0.7865 - val_loss: 0.5082 - val_acc: 0.7656\n",
      "Epoch 1426/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4239 - acc: 0.7882 - val_loss: 0.5083 - val_acc: 0.7656\n",
      "Epoch 1427/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4239 - acc: 0.7882 - val_loss: 0.5083 - val_acc: 0.7656\n",
      "Epoch 1428/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4238 - acc: 0.7882 - val_loss: 0.5083 - val_acc: 0.7656\n",
      "Epoch 1429/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4239 - acc: 0.7917 - val_loss: 0.5083 - val_acc: 0.7656\n",
      "Epoch 1430/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4239 - acc: 0.7899 - val_loss: 0.5083 - val_acc: 0.7656\n",
      "Epoch 1431/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4239 - acc: 0.7882 - val_loss: 0.5083 - val_acc: 0.7656\n",
      "Epoch 1432/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4238 - acc: 0.7882 - val_loss: 0.5083 - val_acc: 0.7656\n",
      "Epoch 1433/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4237 - acc: 0.7917 - val_loss: 0.5083 - val_acc: 0.7656\n",
      "Epoch 1434/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4238 - acc: 0.7917 - val_loss: 0.5084 - val_acc: 0.7656\n",
      "Epoch 1435/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4237 - acc: 0.7934 - val_loss: 0.5084 - val_acc: 0.7656\n",
      "Epoch 1436/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4237 - acc: 0.7899 - val_loss: 0.5084 - val_acc: 0.7656\n",
      "Epoch 1437/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4237 - acc: 0.7934 - val_loss: 0.5084 - val_acc: 0.7656\n",
      "Epoch 1438/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4237 - acc: 0.7917 - val_loss: 0.5084 - val_acc: 0.7656\n",
      "Epoch 1439/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4238 - acc: 0.7899 - val_loss: 0.5084 - val_acc: 0.7656\n",
      "Epoch 1440/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4237 - acc: 0.7917 - val_loss: 0.5084 - val_acc: 0.7656\n",
      "Epoch 1441/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4236 - acc: 0.7934 - val_loss: 0.5084 - val_acc: 0.7656\n",
      "Epoch 1442/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4237 - acc: 0.7899 - val_loss: 0.5085 - val_acc: 0.7656\n",
      "Epoch 1443/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4236 - acc: 0.7934 - val_loss: 0.5085 - val_acc: 0.7656\n",
      "Epoch 1444/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4236 - acc: 0.7899 - val_loss: 0.5085 - val_acc: 0.7656\n",
      "Epoch 1445/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4236 - acc: 0.7917 - val_loss: 0.5085 - val_acc: 0.7656\n",
      "Epoch 1446/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4235 - acc: 0.7934 - val_loss: 0.5085 - val_acc: 0.7656\n",
      "Epoch 1447/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4236 - acc: 0.7934 - val_loss: 0.5085 - val_acc: 0.7656\n",
      "Epoch 1448/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4235 - acc: 0.7934 - val_loss: 0.5085 - val_acc: 0.7656\n",
      "Epoch 1449/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4234 - acc: 0.7934 - val_loss: 0.5085 - val_acc: 0.7656\n",
      "Epoch 1450/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4235 - acc: 0.7934 - val_loss: 0.5086 - val_acc: 0.7656\n",
      "Epoch 1451/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4236 - acc: 0.7882 - val_loss: 0.5086 - val_acc: 0.7656\n",
      "Epoch 1452/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4236 - acc: 0.7951 - val_loss: 0.5086 - val_acc: 0.7656\n",
      "Epoch 1453/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4235 - acc: 0.7917 - val_loss: 0.5086 - val_acc: 0.7656\n",
      "Epoch 1454/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4236 - acc: 0.7917 - val_loss: 0.5086 - val_acc: 0.7656\n",
      "Epoch 1455/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4235 - acc: 0.7899 - val_loss: 0.5086 - val_acc: 0.7656\n",
      "Epoch 1456/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4234 - acc: 0.7934 - val_loss: 0.5086 - val_acc: 0.7656\n",
      "Epoch 1457/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4234 - acc: 0.7917 - val_loss: 0.5087 - val_acc: 0.7656\n",
      "Epoch 1458/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4234 - acc: 0.7917 - val_loss: 0.5087 - val_acc: 0.7656\n",
      "Epoch 1459/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4233 - acc: 0.7934 - val_loss: 0.5087 - val_acc: 0.7604\n",
      "Epoch 1460/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4233 - acc: 0.7934 - val_loss: 0.5088 - val_acc: 0.7604\n",
      "Epoch 1461/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4233 - acc: 0.7934 - val_loss: 0.5088 - val_acc: 0.7604\n",
      "Epoch 1462/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4233 - acc: 0.7934 - val_loss: 0.5088 - val_acc: 0.7604\n",
      "Epoch 1463/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4233 - acc: 0.7934 - val_loss: 0.5089 - val_acc: 0.7604\n",
      "Epoch 1464/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4232 - acc: 0.7917 - val_loss: 0.5089 - val_acc: 0.7604\n",
      "Epoch 1465/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4232 - acc: 0.7917 - val_loss: 0.5089 - val_acc: 0.7604\n",
      "Epoch 1466/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4232 - acc: 0.7917 - val_loss: 0.5089 - val_acc: 0.7604\n",
      "Epoch 1467/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4232 - acc: 0.7917 - val_loss: 0.5090 - val_acc: 0.7604\n",
      "Epoch 1468/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4232 - acc: 0.7917 - val_loss: 0.5090 - val_acc: 0.7604\n",
      "Epoch 1469/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4232 - acc: 0.7917 - val_loss: 0.5090 - val_acc: 0.7604\n",
      "Epoch 1470/1500\n",
      "576/576 [==============================] - 0s 33us/sample - loss: 0.4232 - acc: 0.7917 - val_loss: 0.5091 - val_acc: 0.7604\n",
      "Epoch 1471/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4232 - acc: 0.7934 - val_loss: 0.5091 - val_acc: 0.7604\n",
      "Epoch 1472/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4231 - acc: 0.7917 - val_loss: 0.5091 - val_acc: 0.7604\n",
      "Epoch 1473/1500\n",
      "576/576 [==============================] - 0s 31us/sample - loss: 0.4231 - acc: 0.7917 - val_loss: 0.5091 - val_acc: 0.7604\n",
      "Epoch 1474/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4231 - acc: 0.7934 - val_loss: 0.5091 - val_acc: 0.7604\n",
      "Epoch 1475/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4231 - acc: 0.7917 - val_loss: 0.5091 - val_acc: 0.7604\n",
      "Epoch 1476/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4231 - acc: 0.7917 - val_loss: 0.5091 - val_acc: 0.7604\n",
      "Epoch 1477/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4230 - acc: 0.7917 - val_loss: 0.5092 - val_acc: 0.7604\n",
      "Epoch 1478/1500\n",
      "576/576 [==============================] - 0s 38us/sample - loss: 0.4230 - acc: 0.7917 - val_loss: 0.5092 - val_acc: 0.7604\n",
      "Epoch 1479/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4231 - acc: 0.7917 - val_loss: 0.5092 - val_acc: 0.7604\n",
      "Epoch 1480/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4230 - acc: 0.7917 - val_loss: 0.5092 - val_acc: 0.7604\n",
      "Epoch 1481/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4230 - acc: 0.7934 - val_loss: 0.5092 - val_acc: 0.7604\n",
      "Epoch 1482/1500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4229 - acc: 0.7934 - val_loss: 0.5092 - val_acc: 0.7604\n",
      "Epoch 1483/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4230 - acc: 0.7934 - val_loss: 0.5092 - val_acc: 0.7604\n",
      "Epoch 1484/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4229 - acc: 0.7934 - val_loss: 0.5092 - val_acc: 0.7604\n",
      "Epoch 1485/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4230 - acc: 0.7917 - val_loss: 0.5093 - val_acc: 0.7604\n",
      "Epoch 1486/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4229 - acc: 0.7917 - val_loss: 0.5093 - val_acc: 0.7604\n",
      "Epoch 1487/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4229 - acc: 0.7917 - val_loss: 0.5093 - val_acc: 0.7604\n",
      "Epoch 1488/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4229 - acc: 0.7934 - val_loss: 0.5093 - val_acc: 0.7604\n",
      "Epoch 1489/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4229 - acc: 0.7934 - val_loss: 0.5093 - val_acc: 0.7604\n",
      "Epoch 1490/1500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4228 - acc: 0.7917 - val_loss: 0.5093 - val_acc: 0.7604\n",
      "Epoch 1491/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4229 - acc: 0.7934 - val_loss: 0.5093 - val_acc: 0.7604\n",
      "Epoch 1492/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4228 - acc: 0.7934 - val_loss: 0.5093 - val_acc: 0.7604\n",
      "Epoch 1493/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4228 - acc: 0.7917 - val_loss: 0.5094 - val_acc: 0.7604\n",
      "Epoch 1494/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4227 - acc: 0.7951 - val_loss: 0.5094 - val_acc: 0.7604\n",
      "Epoch 1495/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4227 - acc: 0.7934 - val_loss: 0.5094 - val_acc: 0.7604\n",
      "Epoch 1496/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4227 - acc: 0.7951 - val_loss: 0.5094 - val_acc: 0.7604\n",
      "Epoch 1497/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4228 - acc: 0.7934 - val_loss: 0.5094 - val_acc: 0.7604\n",
      "Epoch 1498/1500\n",
      "576/576 [==============================] - 0s 26us/sample - loss: 0.4227 - acc: 0.7951 - val_loss: 0.5094 - val_acc: 0.7604\n",
      "Epoch 1499/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4227 - acc: 0.7934 - val_loss: 0.5094 - val_acc: 0.7604\n",
      "Epoch 1500/1500\n",
      "576/576 [==============================] - 0s 24us/sample - loss: 0.4228 - acc: 0.7917 - val_loss: 0.5094 - val_acc: 0.7604\n"
     ]
    }
   ],
   "source": [
    "model_2.compile(SGD(lr=.003), \"binary_crossentropy\", \n",
    "                 metrics=[\"accuracy\"])\n",
    "run_hist_2=model_2.fit(X_train_norm, y_train, \n",
    "                       validation_data=(X_test_norm, y_test),\n",
    "                      epochs=1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'acc', 'val_loss', 'val_acc'])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_hist_2.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Accuracy over iterations')"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = len(run_hist_2.history[\"loss\"])\n",
    "\n",
    "fig = plt.figure(figsize=(12, 6))\n",
    "ax = fig.add_subplot(1, 2, 1)\n",
    "ax.plot(range(n), (run_hist_2.history[\"loss\"]),'r.', label=\"Train Loss\")\n",
    "ax.plot(range(n), (run_hist_2.history[\"val_loss\"]),'b.', label=\"Validation Loss\")\n",
    "ax.legend()\n",
    "ax.set_title('Loss over iterations')\n",
    "\n",
    "ax = fig.add_subplot(1, 2, 2)\n",
    "ax.plot(range(n), (run_hist_2.history[\"acc\"]),'r.', label=\"Train Acc\")\n",
    "ax.plot(range(n), (run_hist_2.history[\"val_acc\"]),'b.', label=\"Validation Acc\")\n",
    "ax.legend(loc='lower right')\n",
    "ax.set_title('Accuracy over iterations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "accuracy is 0.760\n",
      "roc-auc is 0.819\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred_class_nn_2 = model_2.predict_classes(X_test_norm)\n",
    "y_pred_prob_nn_2 = model_2.predict(X_test_norm)\n",
    "print('')\n",
    "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_nn_2)))\n",
    "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_nn_2)))\n",
    "\n",
    "plot_roc(y_test, y_pred_prob_nn_2, 'NN-2')\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
