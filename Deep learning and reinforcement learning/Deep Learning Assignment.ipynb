{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IBM Machine Learning\n",
    "## Course 5: Deep Learning\n",
    "## Topic: CIFAR-10 Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Introduction\n",
    "We will work ont he famouse CIFAR-10 dataset, which consists of 60000 32x32 color images. The dataset can be split into 50k training image and 10k validation images.  \n",
    "The objective is to classify the images to 10 different classes.\n",
    "The 10 classes are:\n",
    "\n",
    "<ol start=\"0\">\n",
    "<li> airplane\n",
    "<li>  automobile\n",
    "<li> bird\n",
    "<li>  cat\n",
    "<li> deer\n",
    "<li> dog\n",
    "<li>  frog\n",
    "<li>  horse\n",
    "<li>  ship\n",
    "<li>  truck\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Explorative Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 CIFAR data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load the data \n",
    "from keras.datasets import cifar10\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class list\n",
    "class_list=['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
    "           'dog', 'frog', 'horse', 'ship', 'truck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test)=cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "## the size of training and test set\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The image selected is:  8486\n"
     ]
    }
   ],
   "source": [
    "## randomly select one image from training set\n",
    "selected=np.random.randint(50000)\n",
    "\n",
    "print(\"The image selected is: \", selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(y_train[selected])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "automobile\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(-0.5, 31.5, 31.5, -0.5)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Let's look at one of the images\n",
    "\n",
    "print(class_list[int(y_train[selected])])\n",
    "plt.imshow(x_train[selected])\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Data preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's make everything float and scale\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 1000,\n",
       " 1: 1000,\n",
       " 2: 1000,\n",
       " 3: 1000,\n",
       " 4: 1000,\n",
       " 5: 1000,\n",
       " 6: 1000,\n",
       " 7: 1000,\n",
       " 8: 1000,\n",
       " 9: 1000}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The distribution of class in test set\n",
    "unique, counts = np.unique(y_test, return_counts=True)\n",
    "dict(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Build Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Get a baseline performance using Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "## flatten our data\n",
    "x_train_flat=x_train.reshape(len(x_train), -1)\n",
    "x_test_flat=x_test.reshape(len(x_test), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train_flat shape: (50000, 3072)\n"
     ]
    }
   ],
   "source": [
    "## the size of training \n",
    "print('x_train_flat shape:', x_train_flat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_test_flat shape: (10000, 3072)\n"
     ]
    }
   ],
   "source": [
    "## the size of testing\n",
    "print('x_test_flat shape:', x_test_flat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "#used to help some of the timing functions\n",
    "now = datetime.datetime.now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 0:06:34.270555\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, precision_recall_curve, roc_auc_score, roc_curve, accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "## Train the RF Model\n",
    "t = now()\n",
    "rf_model = RandomForestClassifier(n_estimators=200)\n",
    "rf_model.fit(x_train_flat, y_train)\n",
    "print('Training time: %s' % (now() - t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.485\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test set - both \"hard\" predictions, and the scores (percent of trees voting yes)\n",
    "y_pred_class_rf = rf_model.predict(x_test_flat)\n",
    "y_pred_prob_rf = rf_model.predict_proba(x_test_flat)\n",
    "\n",
    "\n",
    "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_rf)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[570,  38,  52,  21,  36,  18,  26,  22, 160,  57],\n",
       "       [ 29, 546,  16,  33,  15,  28,  43,  28,  62, 200],\n",
       "       [ 90,  45, 349,  72, 142,  67, 124,  50,  33,  28],\n",
       "       [ 50,  43,  68, 289,  71, 183, 144,  57,  22,  73],\n",
       "       [ 58,  15, 143,  58, 400,  47, 155,  80,  21,  23],\n",
       "       [ 26,  26,  83, 141,  83, 414,  86,  82,  28,  31],\n",
       "       [ 11,  38,  70,  73,  92,  54, 597,  21,   5,  39],\n",
       "       [ 43,  36,  43,  59, 102,  73,  46, 479,  23,  96],\n",
       "       [ 87,  87,  17,  28,  19,  33,   9,  22, 628,  70],\n",
       "       [ 39, 153,  20,  33,  18,  24,  24,  36,  78, 575]], dtype=int64)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test,y_pred_class_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see above, the training time is long and the accuracy is quite low(less than 50%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Build a full connected neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1=Sequential()\n",
    "model_1.add(Dense(100,input_shape=(3072,), activation='sigmoid'))\n",
    "model_1.add(Dense(10,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_8 (Dense)              (None, 100)               307300    \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 308,310\n",
      "Trainable params: 308,310\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1563/1563 [==============================] - 7s 5ms/step - loss: 1.7753 - accuracy: 0.3732 - val_loss: 1.8364 - val_accuracy: 0.3599\n",
      "Epoch 2/200\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 1.7714 - accuracy: 0.3757 - val_loss: 1.8374 - val_accuracy: 0.3595\n",
      "Epoch 3/200\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 1.7708 - accuracy: 0.3762 - val_loss: 1.8450 - val_accuracy: 0.3596\n",
      "Epoch 4/200\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 1.7662 - accuracy: 0.3793 - val_loss: 1.8249 - val_accuracy: 0.3642\n",
      "Epoch 5/200\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 1.7632 - accuracy: 0.3775 - val_loss: 1.8341 - val_accuracy: 0.3648\n",
      "Epoch 6/200\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 1.7604 - accuracy: 0.3805 - val_loss: 1.8345 - val_accuracy: 0.3594\n",
      "Epoch 7/200\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 1.7570 - accuracy: 0.3825 - val_loss: 1.8225 - val_accuracy: 0.3676\n",
      "Epoch 8/200\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 1.7573 - accuracy: 0.3823 - val_loss: 1.8215 - val_accuracy: 0.3632\n",
      "Epoch 9/200\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 1.7509 - accuracy: 0.3845 - val_loss: 1.8144 - val_accuracy: 0.3664\n",
      "Epoch 10/200\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 1.7487 - accuracy: 0.3873 - val_loss: 1.8236 - val_accuracy: 0.3596\n",
      "Epoch 11/200\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 1.7448 - accuracy: 0.3875 - val_loss: 1.8130 - val_accuracy: 0.3689\n",
      "Epoch 12/200\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 1.7406 - accuracy: 0.3887 - val_loss: 1.8193 - val_accuracy: 0.3625\n",
      "Epoch 13/200\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 1.7396 - accuracy: 0.3897 - val_loss: 1.8114 - val_accuracy: 0.3708\n",
      "Epoch 14/200\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 1.7369 - accuracy: 0.3902 - val_loss: 1.8179 - val_accuracy: 0.3690\n",
      "Epoch 15/200\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 1.7315 - accuracy: 0.3928 - val_loss: 1.8024 - val_accuracy: 0.3760\n",
      "Epoch 16/200\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 1.7293 - accuracy: 0.3943 - val_loss: 1.8054 - val_accuracy: 0.3730\n",
      "Epoch 17/200\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 1.7259 - accuracy: 0.3965 - val_loss: 1.8081 - val_accuracy: 0.3699\n",
      "Epoch 18/200\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 1.7230 - accuracy: 0.3946 - val_loss: 1.7994 - val_accuracy: 0.3782\n",
      "Epoch 19/200\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 1.7208 - accuracy: 0.3990 - val_loss: 1.8170 - val_accuracy: 0.3729\n",
      "Epoch 20/200\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 1.7182 - accuracy: 0.3979 - val_loss: 1.7920 - val_accuracy: 0.3760\n",
      "Epoch 21/200\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 1.7152 - accuracy: 0.4010 - val_loss: 1.8056 - val_accuracy: 0.3778\n",
      "Epoch 22/200\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 1.7113 - accuracy: 0.4038 - val_loss: 1.7907 - val_accuracy: 0.3775\n",
      "Epoch 23/200\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 1.7079 - accuracy: 0.4007 - val_loss: 1.7980 - val_accuracy: 0.3812\n",
      "Epoch 24/200\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 1.7059 - accuracy: 0.4023 - val_loss: 1.7958 - val_accuracy: 0.3803\n",
      "Epoch 25/200\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 1.7042 - accuracy: 0.4051 - val_loss: 1.7860 - val_accuracy: 0.3843\n",
      "Epoch 26/200\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 1.6995 - accuracy: 0.4069 - val_loss: 1.7881 - val_accuracy: 0.3825\n",
      "Epoch 27/200\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 1.6978 - accuracy: 0.4072 - val_loss: 1.7851 - val_accuracy: 0.3793\n",
      "Epoch 28/200\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 1.6955 - accuracy: 0.4089 - val_loss: 1.7839 - val_accuracy: 0.3811\n",
      "Epoch 29/200\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 1.6946 - accuracy: 0.4090 - val_loss: 1.7917 - val_accuracy: 0.3860\n",
      "Epoch 30/200\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 1.6905 - accuracy: 0.4104 - val_loss: 1.7916 - val_accuracy: 0.3749\n",
      "Epoch 31/200\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 1.6873 - accuracy: 0.4111 - val_loss: 1.7907 - val_accuracy: 0.3866\n",
      "Epoch 32/200\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 1.6811 - accuracy: 0.4156 - val_loss: 1.8059 - val_accuracy: 0.3841\n",
      "Epoch 33/200\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 1.6765 - accuracy: 0.4174 - val_loss: 1.7768 - val_accuracy: 0.3865\n",
      "Epoch 34/200\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 1.6713 - accuracy: 0.4185 - val_loss: 1.7791 - val_accuracy: 0.3921\n",
      "Epoch 35/200\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 1.6693 - accuracy: 0.4215 - val_loss: 1.7829 - val_accuracy: 0.3840\n",
      "Epoch 36/200\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 1.6683 - accuracy: 0.4213 - val_loss: 1.7811 - val_accuracy: 0.3933\n",
      "Epoch 37/200\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 1.6627 - accuracy: 0.4234 - val_loss: 1.7589 - val_accuracy: 0.4036\n",
      "Epoch 38/200\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 1.6614 - accuracy: 0.4227 - val_loss: 1.7588 - val_accuracy: 0.3979\n",
      "Epoch 39/200\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 1.6592 - accuracy: 0.4263 - val_loss: 1.7726 - val_accuracy: 0.3939\n",
      "Epoch 40/200\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 1.6545 - accuracy: 0.4277 - val_loss: 1.7608 - val_accuracy: 0.3974\n",
      "Epoch 41/200\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 1.6552 - accuracy: 0.4263 - val_loss: 1.7616 - val_accuracy: 0.3961\n",
      "Epoch 42/200\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 1.6516 - accuracy: 0.4284 - val_loss: 1.7589 - val_accuracy: 0.3976\n",
      "Epoch 43/200\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 1.6497 - accuracy: 0.4285 - val_loss: 1.7775 - val_accuracy: 0.3979\n",
      "Epoch 44/200\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 1.6455 - accuracy: 0.4294 - val_loss: 1.7616 - val_accuracy: 0.4044\n",
      "Epoch 45/200\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 1.6449 - accuracy: 0.4309 - val_loss: 1.7745 - val_accuracy: 0.3997\n",
      "Epoch 46/200\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 1.6446 - accuracy: 0.4332 - val_loss: 1.7648 - val_accuracy: 0.3958\n",
      "Epoch 47/200\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 1.6416 - accuracy: 0.4331 - val_loss: 1.7610 - val_accuracy: 0.3998\n",
      "Epoch 48/200\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 1.6391 - accuracy: 0.4324 - val_loss: 1.7831 - val_accuracy: 0.3945\n",
      "Epoch 49/200\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 1.6382 - accuracy: 0.4335 - val_loss: 1.7722 - val_accuracy: 0.3981\n",
      "Epoch 50/200\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 1.6359 - accuracy: 0.4347 - val_loss: 1.7544 - val_accuracy: 0.4027\n",
      "Epoch 51/200\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 1.6332 - accuracy: 0.4353 - val_loss: 1.7558 - val_accuracy: 0.4016\n",
      "Epoch 52/200\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 1.6353 - accuracy: 0.4340 - val_loss: 1.7559 - val_accuracy: 0.4004\n",
      "Epoch 53/200\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 1.6309 - accuracy: 0.4382 - val_loss: 1.7531 - val_accuracy: 0.3997\n",
      "Epoch 54/200\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 1.6302 - accuracy: 0.4368 - val_loss: 1.7627 - val_accuracy: 0.3930\n",
      "Epoch 55/200\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 1.6294 - accuracy: 0.4374 - val_loss: 1.7664 - val_accuracy: 0.3967\n",
      "Epoch 56/200\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 1.6270 - accuracy: 0.4383 - val_loss: 1.7551 - val_accuracy: 0.4027\n",
      "Epoch 57/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 6s 4ms/step - loss: 1.6239 - accuracy: 0.4379 - val_loss: 1.7495 - val_accuracy: 0.4101\n",
      "Epoch 58/200\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 1.6228 - accuracy: 0.4383 - val_loss: 1.7484 - val_accuracy: 0.4051\n",
      "Epoch 59/200\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 1.6220 - accuracy: 0.4389 - val_loss: 1.7505 - val_accuracy: 0.4049\n",
      "Epoch 60/200\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 1.6183 - accuracy: 0.4392 - val_loss: 1.7400 - val_accuracy: 0.4093\n",
      "Epoch 61/200\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 1.6174 - accuracy: 0.4405 - val_loss: 1.7462 - val_accuracy: 0.4098\n",
      "Epoch 62/200\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 1.6149 - accuracy: 0.4415 - val_loss: 1.7469 - val_accuracy: 0.4059\n",
      "Epoch 63/200\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 1.6140 - accuracy: 0.4415 - val_loss: 1.7463 - val_accuracy: 0.4061\n",
      "Epoch 64/200\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 1.6119 - accuracy: 0.4436 - val_loss: 1.7801 - val_accuracy: 0.4023\n",
      "Epoch 65/200\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 1.6119 - accuracy: 0.4418 - val_loss: 1.7809 - val_accuracy: 0.3961\n",
      "Epoch 66/200\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 1.6086 - accuracy: 0.4448 - val_loss: 1.7486 - val_accuracy: 0.4150\n",
      "Epoch 67/200\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 1.6061 - accuracy: 0.4421 - val_loss: 1.7624 - val_accuracy: 0.3997\n",
      "Epoch 68/200\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 1.6052 - accuracy: 0.4443 - val_loss: 1.7455 - val_accuracy: 0.4101\n",
      "Epoch 69/200\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 1.6050 - accuracy: 0.4448 - val_loss: 1.7549 - val_accuracy: 0.4049\n",
      "Epoch 70/200\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 1.6037 - accuracy: 0.4448 - val_loss: 1.7660 - val_accuracy: 0.4008\n",
      "Epoch 71/200\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 1.6027 - accuracy: 0.4461 - val_loss: 1.7568 - val_accuracy: 0.4108\n",
      "Epoch 72/200\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 1.6000 - accuracy: 0.4478 - val_loss: 1.7776 - val_accuracy: 0.4033\n",
      "Epoch 73/200\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 1.6013 - accuracy: 0.4456 - val_loss: 1.7602 - val_accuracy: 0.4126\n",
      "Epoch 74/200\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 1.5971 - accuracy: 0.4488 - val_loss: 1.7679 - val_accuracy: 0.3958\n",
      "Epoch 75/200\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 1.5967 - accuracy: 0.4472 - val_loss: 1.7799 - val_accuracy: 0.4002\n",
      "Epoch 76/200\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 1.5952 - accuracy: 0.4466 - val_loss: 1.7412 - val_accuracy: 0.4064\n",
      "Epoch 77/200\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 1.5952 - accuracy: 0.4495 - val_loss: 1.7412 - val_accuracy: 0.4044\n",
      "Epoch 78/200\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 1.5934 - accuracy: 0.4489 - val_loss: 1.7488 - val_accuracy: 0.4083\n",
      "Epoch 79/200\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 1.5916 - accuracy: 0.4484 - val_loss: 1.7437 - val_accuracy: 0.4100\n",
      "Epoch 80/200\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 1.5911 - accuracy: 0.4486 - val_loss: 1.7642 - val_accuracy: 0.4001\n",
      "Epoch 81/200\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 1.5905 - accuracy: 0.4489 - val_loss: 1.7744 - val_accuracy: 0.4113\n",
      "Epoch 82/200\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 1.5890 - accuracy: 0.4511 - val_loss: 1.7724 - val_accuracy: 0.3965\n",
      "Epoch 83/200\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 1.5866 - accuracy: 0.4519 - val_loss: 1.7813 - val_accuracy: 0.4068\n",
      "Epoch 84/200\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 1.5872 - accuracy: 0.4492 - val_loss: 1.7353 - val_accuracy: 0.4130\n",
      "Epoch 85/200\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 1.5852 - accuracy: 0.4497 - val_loss: 1.7641 - val_accuracy: 0.4103\n",
      "Epoch 86/200\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 1.5850 - accuracy: 0.4511 - val_loss: 1.7369 - val_accuracy: 0.4110\n",
      "Epoch 87/200\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 1.5831 - accuracy: 0.4514 - val_loss: 1.7397 - val_accuracy: 0.4083\n",
      "Epoch 88/200\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 1.5820 - accuracy: 0.4519 - val_loss: 1.7731 - val_accuracy: 0.4015\n",
      "Epoch 89/200\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 1.5810 - accuracy: 0.4492 - val_loss: 1.7550 - val_accuracy: 0.4117\n",
      "Epoch 90/200\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 1.5798 - accuracy: 0.4502 - val_loss: 1.7639 - val_accuracy: 0.4077\n",
      "Epoch 91/200\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 1.5785 - accuracy: 0.4535 - val_loss: 1.7557 - val_accuracy: 0.4008\n",
      "Epoch 92/200\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 1.5783 - accuracy: 0.4513 - val_loss: 1.7611 - val_accuracy: 0.4135\n",
      "Epoch 93/200\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 1.5753 - accuracy: 0.4526 - val_loss: 1.7657 - val_accuracy: 0.4085\n",
      "Epoch 94/200\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 1.5748 - accuracy: 0.4533 - val_loss: 1.7625 - val_accuracy: 0.3946\n",
      "Epoch 95/200\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 1.5737 - accuracy: 0.4533 - val_loss: 1.7971 - val_accuracy: 0.4034\n",
      "Epoch 96/200\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 1.5734 - accuracy: 0.4524 - val_loss: 1.7784 - val_accuracy: 0.4091\n",
      "Epoch 97/200\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 1.5719 - accuracy: 0.4537 - val_loss: 1.7541 - val_accuracy: 0.3980\n",
      "Epoch 98/200\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 1.5726 - accuracy: 0.4526 - val_loss: 1.7499 - val_accuracy: 0.4050\n",
      "Epoch 99/200\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 1.5698 - accuracy: 0.4552 - val_loss: 1.7507 - val_accuracy: 0.4035\n",
      "Epoch 100/200\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 1.5707 - accuracy: 0.4545 - val_loss: 1.7452 - val_accuracy: 0.4119\n",
      "Epoch 101/200\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 1.5691 - accuracy: 0.4550 - val_loss: 1.7272 - val_accuracy: 0.4162\n",
      "Epoch 102/200\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 1.5679 - accuracy: 0.4536 - val_loss: 1.7612 - val_accuracy: 0.3999\n",
      "Epoch 103/200\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 1.5663 - accuracy: 0.4566 - val_loss: 1.7401 - val_accuracy: 0.4124\n",
      "Epoch 104/200\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 1.5667 - accuracy: 0.4555 - val_loss: 1.7727 - val_accuracy: 0.4004\n",
      "Epoch 105/200\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 1.5661 - accuracy: 0.4543 - val_loss: 1.7521 - val_accuracy: 0.4147\n",
      "Epoch 106/200\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 1.5644 - accuracy: 0.4574 - val_loss: 1.7428 - val_accuracy: 0.4125\n",
      "Epoch 107/200\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 1.5639 - accuracy: 0.4553 - val_loss: 1.7601 - val_accuracy: 0.4103\n",
      "Epoch 108/200\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 1.5634 - accuracy: 0.4542 - val_loss: 1.7645 - val_accuracy: 0.4035\n",
      "Epoch 109/200\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 1.5618 - accuracy: 0.4565 - val_loss: 1.7523 - val_accuracy: 0.4164\n",
      "Epoch 110/200\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 1.5605 - accuracy: 0.4583 - val_loss: 1.7436 - val_accuracy: 0.4111\n",
      "Epoch 111/200\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 1.5608 - accuracy: 0.4570 - val_loss: 1.7548 - val_accuracy: 0.4166\n",
      "Epoch 112/200\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 1.5599 - accuracy: 0.4561 - val_loss: 1.7500 - val_accuracy: 0.4136\n",
      "Epoch 113/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 6s 4ms/step - loss: 1.5590 - accuracy: 0.4569 - val_loss: 1.7451 - val_accuracy: 0.4081\n",
      "Epoch 114/200\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 1.5584 - accuracy: 0.4579 - val_loss: 1.7352 - val_accuracy: 0.4071\n",
      "Epoch 115/200\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 1.5570 - accuracy: 0.4587 - val_loss: 1.7414 - val_accuracy: 0.4120\n",
      "Epoch 116/200\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 1.5571 - accuracy: 0.4567 - val_loss: 1.7536 - val_accuracy: 0.4079\n",
      "Epoch 117/200\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 1.5564 - accuracy: 0.4566 - val_loss: 1.7513 - val_accuracy: 0.4054\n",
      "Epoch 118/200\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 1.5529 - accuracy: 0.4589 - val_loss: 1.7357 - val_accuracy: 0.4167\n",
      "Epoch 119/200\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 1.5546 - accuracy: 0.4567 - val_loss: 1.7779 - val_accuracy: 0.4043\n",
      "Epoch 120/200\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 1.5543 - accuracy: 0.4572 - val_loss: 1.7536 - val_accuracy: 0.4056\n",
      "Epoch 121/200\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 1.5528 - accuracy: 0.4589 - val_loss: 1.7670 - val_accuracy: 0.4045\n",
      "Epoch 122/200\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 1.5525 - accuracy: 0.4600 - val_loss: 1.7611 - val_accuracy: 0.4069\n",
      "Epoch 123/200\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 1.5513 - accuracy: 0.4602 - val_loss: 1.7469 - val_accuracy: 0.4145\n",
      "Epoch 124/200\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 1.5505 - accuracy: 0.4582 - val_loss: 1.7449 - val_accuracy: 0.4114\n",
      "Epoch 125/200\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 1.5501 - accuracy: 0.4601 - val_loss: 1.7653 - val_accuracy: 0.4150\n",
      "Epoch 126/200\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 1.5485 - accuracy: 0.4602 - val_loss: 1.7530 - val_accuracy: 0.4100\n",
      "Epoch 127/200\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 1.5482 - accuracy: 0.4598 - val_loss: 1.8053 - val_accuracy: 0.3922\n",
      "Epoch 128/200\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 1.5485 - accuracy: 0.4617 - val_loss: 1.7721 - val_accuracy: 0.4122\n",
      "Epoch 129/200\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 1.5491 - accuracy: 0.4601 - val_loss: 1.7802 - val_accuracy: 0.4111\n",
      "Epoch 130/200\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 1.5492 - accuracy: 0.4606 - val_loss: 1.7479 - val_accuracy: 0.4158\n",
      "Epoch 131/200\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 1.5464 - accuracy: 0.4613 - val_loss: 1.7580 - val_accuracy: 0.4018\n",
      "Epoch 132/200\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 1.5484 - accuracy: 0.4618 - val_loss: 1.7523 - val_accuracy: 0.4126\n",
      "Epoch 133/200\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 1.5449 - accuracy: 0.4629 - val_loss: 1.8178 - val_accuracy: 0.4029\n",
      "Epoch 134/200\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 1.5447 - accuracy: 0.4630 - val_loss: 1.7783 - val_accuracy: 0.4064\n",
      "Epoch 135/200\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 1.5463 - accuracy: 0.4606 - val_loss: 1.7805 - val_accuracy: 0.4046\n",
      "Epoch 136/200\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 1.5435 - accuracy: 0.4616 - val_loss: 1.7468 - val_accuracy: 0.4184\n",
      "Epoch 137/200\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 1.5439 - accuracy: 0.4626 - val_loss: 1.7811 - val_accuracy: 0.4074\n",
      "Epoch 138/200\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 1.5426 - accuracy: 0.4617 - val_loss: 1.7743 - val_accuracy: 0.4043\n",
      "Epoch 139/200\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 1.5402 - accuracy: 0.4638 - val_loss: 1.7582 - val_accuracy: 0.4158\n",
      "Epoch 140/200\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 1.5393 - accuracy: 0.4627 - val_loss: 1.7738 - val_accuracy: 0.4108\n",
      "Epoch 141/200\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 1.5391 - accuracy: 0.4637 - val_loss: 1.7505 - val_accuracy: 0.4111\n",
      "Epoch 142/200\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 1.5369 - accuracy: 0.4641 - val_loss: 1.7794 - val_accuracy: 0.4039\n",
      "Epoch 143/200\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 1.5365 - accuracy: 0.4635 - val_loss: 1.7590 - val_accuracy: 0.4081\n",
      "Epoch 144/200\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 1.5363 - accuracy: 0.4625 - val_loss: 1.7358 - val_accuracy: 0.4120\n",
      "Epoch 145/200\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 1.5349 - accuracy: 0.4639 - val_loss: 1.7730 - val_accuracy: 0.4104\n",
      "Epoch 146/200\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 1.5335 - accuracy: 0.4635 - val_loss: 1.7428 - val_accuracy: 0.4092\n",
      "Epoch 147/200\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 1.5334 - accuracy: 0.4640 - val_loss: 1.7604 - val_accuracy: 0.4065\n",
      "Epoch 148/200\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 1.5322 - accuracy: 0.4658 - val_loss: 1.7377 - val_accuracy: 0.4199\n",
      "Epoch 149/200\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 1.5317 - accuracy: 0.4652 - val_loss: 1.7632 - val_accuracy: 0.4036\n",
      "Epoch 150/200\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 1.5300 - accuracy: 0.4665 - val_loss: 1.7730 - val_accuracy: 0.4073\n",
      "Epoch 151/200\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 1.5309 - accuracy: 0.4648 - val_loss: 1.7722 - val_accuracy: 0.4085\n",
      "Epoch 152/200\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 1.5291 - accuracy: 0.4659 - val_loss: 1.7554 - val_accuracy: 0.4206\n",
      "Epoch 153/200\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 1.5297 - accuracy: 0.4647 - val_loss: 1.7698 - val_accuracy: 0.4030\n",
      "Epoch 154/200\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 1.5288 - accuracy: 0.4666 - val_loss: 1.7402 - val_accuracy: 0.4175\n",
      "Epoch 155/200\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 1.5269 - accuracy: 0.4672 - val_loss: 1.7677 - val_accuracy: 0.4088\n",
      "Epoch 156/200\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 1.5266 - accuracy: 0.4685 - val_loss: 1.7678 - val_accuracy: 0.4080\n",
      "Epoch 157/200\n",
      "1563/1563 [==============================] - 7s 5ms/step - loss: 1.5242 - accuracy: 0.4665 - val_loss: 1.7380 - val_accuracy: 0.4167\n",
      "Epoch 158/200\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 1.5248 - accuracy: 0.4676 - val_loss: 1.7763 - val_accuracy: 0.4044\n",
      "Epoch 159/200\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 1.5261 - accuracy: 0.4672 - val_loss: 1.7667 - val_accuracy: 0.4007\n",
      "Epoch 160/200\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 1.5246 - accuracy: 0.4678 - val_loss: 1.7637 - val_accuracy: 0.4041\n",
      "Epoch 161/200\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 1.5238 - accuracy: 0.4672 - val_loss: 1.8007 - val_accuracy: 0.3998\n",
      "Epoch 162/200\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 1.5223 - accuracy: 0.4684 - val_loss: 1.7691 - val_accuracy: 0.4040\n",
      "Epoch 163/200\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 1.5210 - accuracy: 0.4694 - val_loss: 1.7559 - val_accuracy: 0.4189\n",
      "Epoch 164/200\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 1.5215 - accuracy: 0.4687 - val_loss: 1.7640 - val_accuracy: 0.4120\n",
      "Epoch 165/200\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 1.5196 - accuracy: 0.4692 - val_loss: 1.7571 - val_accuracy: 0.4075\n",
      "Epoch 166/200\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 1.5192 - accuracy: 0.4688 - val_loss: 1.8014 - val_accuracy: 0.3929\n",
      "Epoch 167/200\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 1.5191 - accuracy: 0.4700 - val_loss: 1.7407 - val_accuracy: 0.4191\n",
      "Epoch 168/200\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 1.5183 - accuracy: 0.4698 - val_loss: 1.7611 - val_accuracy: 0.4081\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 169/200\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 1.5181 - accuracy: 0.4694 - val_loss: 1.7541 - val_accuracy: 0.4132\n",
      "Epoch 170/200\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 1.5175 - accuracy: 0.4683 - val_loss: 1.7457 - val_accuracy: 0.4151\n",
      "Epoch 171/200\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 1.5174 - accuracy: 0.4699 - val_loss: 1.7496 - val_accuracy: 0.4116\n",
      "Epoch 172/200\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 1.5172 - accuracy: 0.4703 - val_loss: 1.7905 - val_accuracy: 0.4140\n",
      "Epoch 173/200\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 1.5141 - accuracy: 0.4706 - val_loss: 1.7446 - val_accuracy: 0.4165\n",
      "Epoch 174/200\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 1.5139 - accuracy: 0.4713 - val_loss: 1.7878 - val_accuracy: 0.4068\n",
      "Epoch 175/200\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 1.5136 - accuracy: 0.4712 - val_loss: 1.7577 - val_accuracy: 0.4127\n",
      "Epoch 176/200\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 1.5128 - accuracy: 0.4707 - val_loss: 1.7484 - val_accuracy: 0.4103\n",
      "Epoch 177/200\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 1.5130 - accuracy: 0.4714 - val_loss: 1.8095 - val_accuracy: 0.4026\n",
      "Epoch 178/200\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 1.5106 - accuracy: 0.4711 - val_loss: 1.7465 - val_accuracy: 0.4184\n",
      "Epoch 179/200\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 1.5103 - accuracy: 0.4728 - val_loss: 1.7731 - val_accuracy: 0.4156\n",
      "Epoch 180/200\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 1.5105 - accuracy: 0.4714 - val_loss: 1.7469 - val_accuracy: 0.4165\n",
      "Epoch 181/200\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 1.5086 - accuracy: 0.4721 - val_loss: 1.8107 - val_accuracy: 0.4093\n",
      "Epoch 182/200\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 1.5095 - accuracy: 0.4738 - val_loss: 1.7758 - val_accuracy: 0.4114\n",
      "Epoch 183/200\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 1.5067 - accuracy: 0.4735 - val_loss: 1.7903 - val_accuracy: 0.4042\n",
      "Epoch 184/200\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 1.5065 - accuracy: 0.4736 - val_loss: 1.7793 - val_accuracy: 0.4065\n",
      "Epoch 185/200\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 1.5060 - accuracy: 0.4751 - val_loss: 1.7929 - val_accuracy: 0.4118\n",
      "Epoch 186/200\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 1.5063 - accuracy: 0.4729 - val_loss: 1.7792 - val_accuracy: 0.3999\n",
      "Epoch 187/200\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 1.5021 - accuracy: 0.4756 - val_loss: 1.7628 - val_accuracy: 0.4096\n",
      "Epoch 188/200\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 1.5027 - accuracy: 0.4746 - val_loss: 1.7772 - val_accuracy: 0.4132\n",
      "Epoch 189/200\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 1.5016 - accuracy: 0.4773 - val_loss: 1.8193 - val_accuracy: 0.3956\n",
      "Epoch 190/200\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 1.5003 - accuracy: 0.4761 - val_loss: 1.7568 - val_accuracy: 0.4180\n",
      "Epoch 191/200\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 1.5012 - accuracy: 0.4735 - val_loss: 1.8485 - val_accuracy: 0.3959\n",
      "Epoch 192/200\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 1.4985 - accuracy: 0.4759 - val_loss: 1.7831 - val_accuracy: 0.4067\n",
      "Epoch 193/200\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 1.4995 - accuracy: 0.4756 - val_loss: 1.7515 - val_accuracy: 0.4168\n",
      "Epoch 194/200\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 1.4974 - accuracy: 0.4747 - val_loss: 1.7682 - val_accuracy: 0.4162\n",
      "Epoch 195/200\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 1.4986 - accuracy: 0.4759 - val_loss: 1.7614 - val_accuracy: 0.4206\n",
      "Epoch 196/200\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 1.4972 - accuracy: 0.4775 - val_loss: 1.8539 - val_accuracy: 0.3975\n",
      "Epoch 197/200\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 1.4954 - accuracy: 0.4782 - val_loss: 1.8442 - val_accuracy: 0.3868\n",
      "Epoch 198/200\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 1.4975 - accuracy: 0.4768 - val_loss: 1.7631 - val_accuracy: 0.4150\n",
      "Epoch 199/200\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 1.4941 - accuracy: 0.4764 - val_loss: 1.7668 - val_accuracy: 0.4108\n",
      "Epoch 200/200\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 1.4930 - accuracy: 0.4783 - val_loss: 1.7833 - val_accuracy: 0.4139\n",
      "Training time: 0:18:58.958390\n"
     ]
    }
   ],
   "source": [
    "t = now()\n",
    "\n",
    "# Compile the model with Optimizer, Loss Function and Metrics\n",
    "opt_1 = keras.optimizers.RMSprop(lr=0.0005)\n",
    "\n",
    "model_1.compile(optimizer=opt_1, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "run_hist_1 = model_1.fit(x_train_flat, y_train, validation_data=(x_test_flat, y_test), epochs=200)\n",
    "\n",
    "print('Training time: %s' % (now() - t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 1.783251166343689\n",
      "Test accuracy: 0.4138999879360199\n"
     ]
    }
   ],
   "source": [
    "score = model_1.evaluate(x_test_flat, y_test, verbose=0)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The full connection neural network perform slightly better than random forest. The accuray is similar to random forest. We can increase the hidden layers and number of epochs, however the time will increase too."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3 Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = Sequential()\n",
    "\n",
    "model_2.add(Conv2D(32, (3, 3), padding='same',\n",
    "                 input_shape=x_train.shape[1:]))\n",
    "model_2.add(Activation('relu'))\n",
    "model_2.add(Conv2D(32, (3, 3)))\n",
    "model_2.add(Activation('relu'))\n",
    "model_2.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_2.add(Dropout(0.25))\n",
    "\n",
    "model_2.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model_2.add(Activation('relu'))\n",
    "model_2.add(Conv2D(64, (3, 3)))\n",
    "model_2.add(Activation('relu'))\n",
    "model_2.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_2.add(Dropout(0.25))\n",
    "\n",
    "model_2.add(Flatten())\n",
    "model_2.add(Dense(512))\n",
    "model_2.add(Activation('relu'))\n",
    "model_2.add(Dropout(0.5))\n",
    "model_2.add(Dense(num_classes))\n",
    "model_2.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 30, 30, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 15, 15, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 15, 15, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 13, 13, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 512)               1180160   \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,250,858\n",
      "Trainable params: 1,250,858\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "# initiate RMSprop optimizer\n",
    "opt_2 = keras.optimizers.RMSprop(lr=0.0005)\n",
    "\n",
    "# Let's train the model using RMSprop\n",
    "model_2.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt_2,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1563/1563 [==============================] - 121s 77ms/step - loss: 1.5786 - accuracy: 0.4241 - val_loss: 1.2191 - val_accuracy: 0.5587\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 121s 77ms/step - loss: 1.1826 - accuracy: 0.5803 - val_loss: 1.1232 - val_accuracy: 0.6035\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 122s 78ms/step - loss: 1.0084 - accuracy: 0.6490 - val_loss: 0.8676 - val_accuracy: 0.6975\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 121s 78ms/step - loss: 0.9088 - accuracy: 0.6838 - val_loss: 0.8868 - val_accuracy: 0.7032\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 121s 78ms/step - loss: 0.8552 - accuracy: 0.7069 - val_loss: 0.8810 - val_accuracy: 0.6986\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - 121s 78ms/step - loss: 0.8237 - accuracy: 0.7176 - val_loss: 0.8932 - val_accuracy: 0.7008\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - 122s 78ms/step - loss: 0.8139 - accuracy: 0.7250 - val_loss: 0.8127 - val_accuracy: 0.7383\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 123s 79ms/step - loss: 0.8150 - accuracy: 0.7280 - val_loss: 0.8685 - val_accuracy: 0.7352\n",
      "Epoch 9/10\n",
      "1563/1563 [==============================] - 123s 79ms/step - loss: 0.8285 - accuracy: 0.7278 - val_loss: 0.8039 - val_accuracy: 0.7467\n",
      "Epoch 10/10\n",
      "1563/1563 [==============================] - 122s 78ms/step - loss: 0.8387 - accuracy: 0.7237 - val_loss: 0.9243 - val_accuracy: 0.7309\n",
      "Training time: 0:20:19.926330\n"
     ]
    }
   ],
   "source": [
    "t = now()\n",
    "model_2.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=10,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True)\n",
    "print('Training time: %s' % (now() - t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 0.9243311285972595\n",
      "Test accuracy: 0.73089998960495\n"
     ]
    }
   ],
   "source": [
    "score = model_2.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this course, we learn different deep learning architecture. They are suitable for different task. Convolutional Neural network is very good in image classfication tasks. Each pixel can be treated as one feature. The relative location and value of each pixel is very important for image.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
