{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Foundation\n",
    "\n",
    "## Transfer Learning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "now=datetime.datetime.now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set some parameters\n",
    "batch_size=128\n",
    "num_classes=5\n",
    "epochs=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set some more parameters\n",
    "img_rows, img_cols = 28, 28\n",
    "filters = 32\n",
    "pool_size = 2\n",
    "kernel_size = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This just handles some variability in how the input data is loaded\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    input_shape = (img_rows, img_cols, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# the data, shuffled and split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28, 1)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.reshape((x_train.shape[0],) + input_shape).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create two datasets: one with digits below 5 and one with 5 and above\n",
    "x_train_lt5 = x_train[y_train < 5]\n",
    "y_train_lt5 = y_train[y_train < 5]\n",
    "x_test_lt5 = x_test[y_test < 5]\n",
    "y_test_lt5 = y_test[y_test < 5]\n",
    "\n",
    "x_train_gte5 = x_train[y_train >= 5]\n",
    "y_train_gte5 = y_train[y_train >= 5] - 5\n",
    "x_test_gte5 = x_test[y_test >= 5]\n",
    "y_test_gte5 = y_test[y_test >= 5] - 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the \"feature\" layers.  These are the early layers that we expect will \"transfer\"\n",
    "# to a new problem.  We will freeze these layers during the fine-tuning process\n",
    "\n",
    "feature_layers = [\n",
    "    Conv2D(filters, kernel_size,\n",
    "           padding='valid',\n",
    "           input_shape=input_shape),\n",
    "    Activation('relu'),\n",
    "    Conv2D(filters, kernel_size),\n",
    "    Activation('relu'),\n",
    "    MaxPooling2D(pool_size=pool_size),\n",
    "    Dropout(0.25),\n",
    "    Flatten(),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x00000000068EBF98>, <tensorflow.python.keras.layers.core.Activation object at 0x0000000006BAF2B0>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x0000000006BAF400>, <tensorflow.python.keras.layers.core.Activation object at 0x0000000006BAF668>, <tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x0000000006BAF7B8>, <tensorflow.python.keras.layers.core.Dropout object at 0x0000000006BAF908>, <tensorflow.python.keras.layers.core.Flatten object at 0x0000000006BAFA58>]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the \"classification\" layers.  These are the later layers that predict the specific classes from the features\n",
    "# learned by the feature layers.  This is the part of the model that needs to be re-trained for a new problem\n",
    "\n",
    "classification_layers = [\n",
    "    Dense(128),\n",
    "    Activation('relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(num_classes),\n",
    "    Activation('softmax')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create our model by combining the two sets of layers as follows\n",
    "model = Sequential(feature_layers + classification_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 26, 26, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 24, 24, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               589952    \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 645       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 600,165\n",
      "Trainable params: 600,165\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Let's take a look\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "## To simplify things, write a function to include all the training steps\n",
    "## As input, function takes a model, training set, test set, and the number of classes\n",
    "## Inside the model object will be the state about which layers we are freezing and which we are training\n",
    "\n",
    "def train_model(model, train, test, num_classes):\n",
    "    x_train = train[0].reshape((train[0].shape[0],) + input_shape)\n",
    "    x_test = test[0].reshape((test[0].shape[0],) + input_shape)\n",
    "    x_train = x_train.astype('float32')\n",
    "    x_test = x_test.astype('float32')\n",
    "    x_train /= 255\n",
    "    x_test /= 255\n",
    "    print('x_train shape:', x_train.shape)\n",
    "    print(x_train.shape[0], 'train samples')\n",
    "    print(x_test.shape[0], 'test samples')\n",
    "\n",
    "    # convert class vectors to binary class matrices\n",
    "    y_train = keras.utils.to_categorical(train[1], num_classes)\n",
    "    y_test = keras.utils.to_categorical(test[1], num_classes)\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adadelta',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    t = now()\n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              verbose=1,\n",
    "              validation_data=(x_test, y_test))\n",
    "    print('Training time: %s' % (now() - t))\n",
    "\n",
    "    score = model.evaluate(x_test, y_test, verbose=0)\n",
    "    print('Test score:', score[0])\n",
    "    print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (29404, 28, 28, 1)\n",
      "29404 train samples\n",
      "4861 test samples\n",
      "Epoch 1/10\n",
      "230/230 [==============================] - 22s 97ms/step - loss: 1.4557 - accuracy: 0.5084 - val_loss: 1.4127 - val_accuracy: 0.6704\n",
      "Epoch 2/10\n",
      "230/230 [==============================] - 21s 93ms/step - loss: 1.4193 - accuracy: 0.5457 - val_loss: 1.3685 - val_accuracy: 0.6939\n",
      "Epoch 3/10\n",
      "230/230 [==============================] - 22s 95ms/step - loss: 1.3754 - accuracy: 0.5848 - val_loss: 1.3181 - val_accuracy: 0.7132\n",
      "Epoch 4/10\n",
      "230/230 [==============================] - 22s 94ms/step - loss: 1.3287 - accuracy: 0.6150 - val_loss: 1.2613 - val_accuracy: 0.7357\n",
      "Epoch 5/10\n",
      "230/230 [==============================] - 22s 94ms/step - loss: 1.2746 - accuracy: 0.6452 - val_loss: 1.1981 - val_accuracy: 0.7593\n",
      "Epoch 6/10\n",
      "230/230 [==============================] - 24s 106ms/step - loss: 1.2167 - accuracy: 0.6642 - val_loss: 1.1299 - val_accuracy: 0.7807\n",
      "Epoch 7/10\n",
      "230/230 [==============================] - 22s 95ms/step - loss: 1.1568 - accuracy: 0.6909 - val_loss: 1.0595 - val_accuracy: 0.8013\n",
      "Epoch 8/10\n",
      "230/230 [==============================] - 22s 94ms/step - loss: 1.0943 - accuracy: 0.7121 - val_loss: 0.9888 - val_accuracy: 0.8208\n",
      "Epoch 9/10\n",
      "230/230 [==============================] - 22s 94ms/step - loss: 1.0288 - accuracy: 0.7257 - val_loss: 0.9192 - val_accuracy: 0.8391\n",
      "Epoch 10/10\n",
      "230/230 [==============================] - 22s 94ms/step - loss: 0.9725 - accuracy: 0.7391 - val_loss: 0.8530 - val_accuracy: 0.8504\n",
      "Training time: 0:03:41.798822\n",
      "Test score: 0.8529799580574036\n",
      "Test accuracy: 0.8504422903060913\n"
     ]
    }
   ],
   "source": [
    "# Now, let's train our model on the digits 5,6,7,8,9\n",
    "\n",
    "train_model(model,\n",
    "            (x_train_gte5, y_train_gte5),\n",
    "            (x_test_gte5, y_test_gte5), num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze only the feature layers\n",
    "for l in feature_layers:\n",
    "    l.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 26, 26, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 24, 24, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               589952    \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 645       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 600,165\n",
      "Trainable params: 590,597\n",
      "Non-trainable params: 9,568\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (30596, 28, 28, 1)\n",
      "30596 train samples\n",
      "5139 test samples\n",
      "Epoch 1/10\n",
      "240/240 [==============================] - 7s 28ms/step - loss: 1.5205 - accuracy: 0.3819 - val_loss: 1.4048 - val_accuracy: 0.4594\n",
      "Epoch 2/10\n",
      "240/240 [==============================] - 6s 27ms/step - loss: 1.4110 - accuracy: 0.4338 - val_loss: 1.2982 - val_accuracy: 0.5089\n",
      "Epoch 3/10\n",
      "240/240 [==============================] - 6s 27ms/step - loss: 1.3185 - accuracy: 0.4852 - val_loss: 1.2078 - val_accuracy: 0.5820\n",
      "Epoch 4/10\n",
      "240/240 [==============================] - 6s 27ms/step - loss: 1.2369 - accuracy: 0.5362 - val_loss: 1.1234 - val_accuracy: 0.6618\n",
      "Epoch 5/10\n",
      "240/240 [==============================] - 6s 27ms/step - loss: 1.1579 - accuracy: 0.5909 - val_loss: 1.0448 - val_accuracy: 0.7317\n",
      "Epoch 6/10\n",
      "240/240 [==============================] - 6s 27ms/step - loss: 1.0886 - accuracy: 0.6474 - val_loss: 0.9727 - val_accuracy: 0.7793\n",
      "Epoch 7/10\n",
      "240/240 [==============================] - 7s 27ms/step - loss: 1.0223 - accuracy: 0.6968 - val_loss: 0.9055 - val_accuracy: 0.8122\n",
      "Epoch 8/10\n",
      "240/240 [==============================] - 7s 29ms/step - loss: 0.9606 - accuracy: 0.7345 - val_loss: 0.8434 - val_accuracy: 0.8391\n",
      "Epoch 9/10\n",
      "240/240 [==============================] - 6s 27ms/step - loss: 0.9041 - accuracy: 0.7624 - val_loss: 0.7863 - val_accuracy: 0.8576\n",
      "Epoch 10/10\n",
      "240/240 [==============================] - 6s 27ms/step - loss: 0.8529 - accuracy: 0.7880 - val_loss: 0.7341 - val_accuracy: 0.8698\n",
      "Training time: 0:01:06.169161\n",
      "Test score: 0.734108030796051\n",
      "Test accuracy: 0.8698190450668335\n"
     ]
    }
   ],
   "source": [
    "train_model(model,\n",
    "            (x_train_lt5, y_train_lt5),\n",
    "            (x_test_lt5, y_test_lt5), num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "We will train on the digits 0-4, finetune the last layer on the digits 5-9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 26, 26, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 24, 24, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               589952    \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 5)                 645       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 600,165\n",
      "Trainable params: 600,165\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create layers and define the model as above\n",
    "feature_layers2 = [\n",
    "    Conv2D(filters, kernel_size,\n",
    "           padding='valid',\n",
    "           input_shape=input_shape),\n",
    "    Activation('relu'),\n",
    "    Conv2D(filters, kernel_size),\n",
    "    Activation('relu'),\n",
    "    MaxPooling2D(pool_size=pool_size),\n",
    "    Dropout(0.25),\n",
    "    Flatten(),\n",
    "]\n",
    "\n",
    "classification_layers2 = [\n",
    "    Dense(128),\n",
    "    Activation('relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(num_classes),\n",
    "    Activation('softmax')\n",
    "]\n",
    "model2 = Sequential(feature_layers2 + classification_layers2)\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (30596, 28, 28, 1)\n",
      "30596 train samples\n",
      "5139 test samples\n",
      "Epoch 1/10\n",
      "240/240 [==============================] - 24s 98ms/step - loss: 1.5996 - accuracy: 0.2452 - val_loss: 1.5828 - val_accuracy: 0.4112\n",
      "Epoch 2/10\n",
      "240/240 [==============================] - 23s 97ms/step - loss: 1.5763 - accuracy: 0.3242 - val_loss: 1.5567 - val_accuracy: 0.5071\n",
      "Epoch 3/10\n",
      "240/240 [==============================] - 23s 95ms/step - loss: 1.5506 - accuracy: 0.4000 - val_loss: 1.5272 - val_accuracy: 0.6159\n",
      "Epoch 4/10\n",
      "240/240 [==============================] - 23s 96ms/step - loss: 1.5218 - accuracy: 0.4695 - val_loss: 1.4926 - val_accuracy: 0.7262\n",
      "Epoch 5/10\n",
      "240/240 [==============================] - 23s 98ms/step - loss: 1.4859 - accuracy: 0.5475 - val_loss: 1.4504 - val_accuracy: 0.8074\n",
      "Epoch 6/10\n",
      "240/240 [==============================] - 23s 97ms/step - loss: 1.4439 - accuracy: 0.6116 - val_loss: 1.3981 - val_accuracy: 0.8607\n",
      "Epoch 7/10\n",
      "240/240 [==============================] - 25s 104ms/step - loss: 1.3909 - accuracy: 0.6681 - val_loss: 1.3346 - val_accuracy: 0.8885\n",
      "Epoch 8/10\n",
      "240/240 [==============================] - 26s 106ms/step - loss: 1.3293 - accuracy: 0.7178 - val_loss: 1.2579 - val_accuracy: 0.9072\n",
      "Epoch 9/10\n",
      "240/240 [==============================] - 26s 107ms/step - loss: 1.2542 - accuracy: 0.7555 - val_loss: 1.1659 - val_accuracy: 0.9233\n",
      "Epoch 10/10\n",
      "240/240 [==============================] - 25s 105ms/step - loss: 1.1659 - accuracy: 0.7847 - val_loss: 1.0604 - val_accuracy: 0.9290\n",
      "Training time: 0:04:02.222862\n",
      "Test score: 1.060368299484253\n",
      "Test accuracy: 0.9289745092391968\n"
     ]
    }
   ],
   "source": [
    "# Now, let's train our model on the digits 0,1,2,3,4\n",
    "train_model(model2,\n",
    "            (x_train_lt5, y_train_lt5),\n",
    "            (x_test_lt5, y_test_lt5), num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Freeze layers\n",
    "for l in feature_layers2:\n",
    "    l.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 26, 26, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 24, 24, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               589952    \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 5)                 645       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 600,165\n",
      "Trainable params: 590,597\n",
      "Non-trainable params: 9,568\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (29404, 28, 28, 1)\n",
      "29404 train samples\n",
      "4861 test samples\n",
      "Epoch 1/10\n",
      "230/230 [==============================] - 7s 31ms/step - loss: 1.5370 - accuracy: 0.3431 - val_loss: 1.4769 - val_accuracy: 0.4452\n",
      "Epoch 2/10\n",
      "230/230 [==============================] - 7s 29ms/step - loss: 1.4923 - accuracy: 0.3775 - val_loss: 1.4273 - val_accuracy: 0.4976\n",
      "Epoch 3/10\n",
      "230/230 [==============================] - 7s 29ms/step - loss: 1.4444 - accuracy: 0.4247 - val_loss: 1.3803 - val_accuracy: 0.5573\n",
      "Epoch 4/10\n",
      "230/230 [==============================] - 7s 29ms/step - loss: 1.3997 - accuracy: 0.4709 - val_loss: 1.3349 - val_accuracy: 0.6120\n",
      "Epoch 5/10\n",
      "230/230 [==============================] - 7s 29ms/step - loss: 1.3566 - accuracy: 0.5166 - val_loss: 1.2908 - val_accuracy: 0.6630\n",
      "Epoch 6/10\n",
      "230/230 [==============================] - 7s 29ms/step - loss: 1.3140 - accuracy: 0.5598 - val_loss: 1.2484 - val_accuracy: 0.7017\n",
      "Epoch 7/10\n",
      "230/230 [==============================] - 7s 29ms/step - loss: 1.2801 - accuracy: 0.5908 - val_loss: 1.2075 - val_accuracy: 0.7276\n",
      "Epoch 8/10\n",
      "230/230 [==============================] - 7s 29ms/step - loss: 1.2406 - accuracy: 0.6247 - val_loss: 1.1679 - val_accuracy: 0.7513\n",
      "Epoch 9/10\n",
      "230/230 [==============================] - 7s 30ms/step - loss: 1.2036 - accuracy: 0.6523 - val_loss: 1.1301 - val_accuracy: 0.7717\n",
      "Epoch 10/10\n",
      "230/230 [==============================] - 7s 29ms/step - loss: 1.1676 - accuracy: 0.6743 - val_loss: 1.0937 - val_accuracy: 0.7852\n",
      "Training time: 0:01:07.929147\n",
      "Test score: 1.0937341451644897\n",
      "Test accuracy: 0.7852293848991394\n"
     ]
    }
   ],
   "source": [
    "train_model(model2,\n",
    "            (x_train_gte5, y_train_gte5),\n",
    "            (x_test_gte5, y_test_gte5), num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
