{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Foundation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras Intro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Keras to build and train neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attributes: (all numeric-valued)\n",
    "   1. Number of times pregnant\n",
    "   2. Plasma glucose concentration a 2 hours in an oral glucose tolerance test\n",
    "   3. Diastolic blood pressure (mm Hg)\n",
    "   4. Triceps skin fold thickness (mm)\n",
    "   5. 2-Hour serum insulin (mu U/ml)\n",
    "   6. Body mass index (weight in kg/(height in m)^2)\n",
    "   7. Diabetes pedigree function\n",
    "   8. Age (years)\n",
    "   9. Class variable (0 or 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_curve,roc_auc_score, roc_curve, accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import Keras objects for Deep Learning\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Dense, Flatten, Dropout, BatchNormalization\n",
    "from keras.optimizers import Adam,SGD,RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>times_pregnant</th>\n",
       "      <th>glucose_tolerance_test</th>\n",
       "      <th>blood_pressure</th>\n",
       "      <th>skin_thickness</th>\n",
       "      <th>insulin</th>\n",
       "      <th>bmi</th>\n",
       "      <th>pedigree_function</th>\n",
       "      <th>age</th>\n",
       "      <th>has_diabetes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   times_pregnant  glucose_tolerance_test  blood_pressure  skin_thickness  \\\n",
       "0               6                     148              72              35   \n",
       "1               1                      85              66              29   \n",
       "2               8                     183              64               0   \n",
       "3               1                      89              66              23   \n",
       "4               0                     137              40              35   \n",
       "\n",
       "   insulin   bmi  pedigree_function  age  has_diabetes  \n",
       "0        0  33.6              0.627   50             1  \n",
       "1        0  26.6              0.351   31             0  \n",
       "2        0  23.3              0.672   32             1  \n",
       "3       94  28.1              0.167   21             0  \n",
       "4      168  43.1              2.288   33             1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Load in th data set\n",
    "names = [\"times_pregnant\", \"glucose_tolerance_test\", \"blood_pressure\", \"skin_thickness\", \"insulin\", \n",
    "         \"bmi\", \"pedigree_function\", \"age\", \"has_diabetes\"]\n",
    "\n",
    "diabetes_df=pd.read_csv('data/diabetes.csv', names=names,header=0)\n",
    "diabetes_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768, 9)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=diabetes_df.iloc[:,:-1].values\n",
    "y=diabetes_df['has_diabetes'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train and test(75% and 25%)\n",
    "X_train, X_test, y_train, y_test=train_test_split(X, y, \n",
    "                                                  test_size=0.25,\n",
    "                                                 random_state=11111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3489583333333333"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is about 35% of the patients in this dataset have diabetes, while 65% do not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get baseline performance using Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=200)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Train rf model\n",
    "rf_model =RandomForestClassifier(n_estimators=200)\n",
    "rf_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.776\n",
      "roc-auc is 0.824\n"
     ]
    }
   ],
   "source": [
    "## Make prediction on the test set\n",
    "## both \"hard\" prediction and the scores\n",
    "## (percent of trees voting yes)\n",
    "y_pred_class_rf=rf_model.predict(X_test)\n",
    "y_pred_prob_rf=rf_model.predict_proba(X_test)\n",
    "\n",
    "print(\"accuracy is {:.3f}\".format(accuracy_score(y_test, y_pred_class_rf)))\n",
    "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_rf[:,1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_roc(y_test, y_pred, model_name):\n",
    "    fpr, tpr, thr=roc_curve(y_test, y_pred)\n",
    "    fig, ax=plt.subplots(figsize=(8,8))\n",
    "    ax.plot(fpr, tpr, 'k-')\n",
    "    ax.plot([0,1], [0,1], 'k--', linewidth=.5)\n",
    "    ax.grid(True)\n",
    "    ax.set(title='ROC curve for {} on PIMA diabetes problem'.format(model_name),\n",
    "          xlim=[-0.01, 1.01], ylim=[-0.01, 1.01])\n",
    "\n",
    "plot_roc(y_test, y_pred_prob_rf[:,1], 'RF')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a single hidden layer neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the Sequential model to quickly build a neural network.  Our first network will be a single layer network.  We have 8 variables, so we set the input shape to 8.  Let's start by having a single hidden layer with 12 nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "## we normalize the data first\n",
    "## it will aid the numerical stability\n",
    "\n",
    "normalizer=StandardScaler()\n",
    "X_train_norm=normalizer.fit_transform(X_train)\n",
    "X_test_norm=normalizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "## define model\n",
    "## input size is 8dimensional\n",
    "## 1 hidden layer , 12 hidden nodes sigmoid activation\n",
    "## final layer has one node with a sigmoid activation\n",
    "\n",
    "model_1=Sequential()\n",
    "model_1.add(Dense(12, input_shape=(8,), activation='sigmoid'))\n",
    "model_1.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 12)                108       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 121\n",
      "Trainable params: 121\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.7109 - accuracy: 0.6545 - val_loss: 0.7213 - val_accuracy: 0.6406\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.7065 - accuracy: 0.6545 - val_loss: 0.7166 - val_accuracy: 0.6406\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.7025 - accuracy: 0.6545 - val_loss: 0.7123 - val_accuracy: 0.6406\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6988 - accuracy: 0.6545 - val_loss: 0.7082 - val_accuracy: 0.6406\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6952 - accuracy: 0.6545 - val_loss: 0.7043 - val_accuracy: 0.6406\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6919 - accuracy: 0.6545 - val_loss: 0.7008 - val_accuracy: 0.6406\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6889 - accuracy: 0.6545 - val_loss: 0.6974 - val_accuracy: 0.6406\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6860 - accuracy: 0.6545 - val_loss: 0.6943 - val_accuracy: 0.6406\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6834 - accuracy: 0.6545 - val_loss: 0.6913 - val_accuracy: 0.6406\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6809 - accuracy: 0.6545 - val_loss: 0.6886 - val_accuracy: 0.6406\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6786 - accuracy: 0.6545 - val_loss: 0.6860 - val_accuracy: 0.6406\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6764 - accuracy: 0.6545 - val_loss: 0.6836 - val_accuracy: 0.6406\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6744 - accuracy: 0.6545 - val_loss: 0.6813 - val_accuracy: 0.6406\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6725 - accuracy: 0.6545 - val_loss: 0.6792 - val_accuracy: 0.6406\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6707 - accuracy: 0.6545 - val_loss: 0.6772 - val_accuracy: 0.6406\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6690 - accuracy: 0.6545 - val_loss: 0.6753 - val_accuracy: 0.6406\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6674 - accuracy: 0.6545 - val_loss: 0.6735 - val_accuracy: 0.6406\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6660 - accuracy: 0.6545 - val_loss: 0.6718 - val_accuracy: 0.6406\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6645 - accuracy: 0.6545 - val_loss: 0.6702 - val_accuracy: 0.6406\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6631 - accuracy: 0.6545 - val_loss: 0.6687 - val_accuracy: 0.6406\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6619 - accuracy: 0.6545 - val_loss: 0.6672 - val_accuracy: 0.6406\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6607 - accuracy: 0.6545 - val_loss: 0.6659 - val_accuracy: 0.6406\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6595 - accuracy: 0.6545 - val_loss: 0.6646 - val_accuracy: 0.6406\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6584 - accuracy: 0.6545 - val_loss: 0.6633 - val_accuracy: 0.6406\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6574 - accuracy: 0.6545 - val_loss: 0.6621 - val_accuracy: 0.6406\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6564 - accuracy: 0.6545 - val_loss: 0.6610 - val_accuracy: 0.6406\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6554 - accuracy: 0.6545 - val_loss: 0.6599 - val_accuracy: 0.6406\n",
      "Epoch 28/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6545 - accuracy: 0.6545 - val_loss: 0.6588 - val_accuracy: 0.6406\n",
      "Epoch 29/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6536 - accuracy: 0.6545 - val_loss: 0.6578 - val_accuracy: 0.6406\n",
      "Epoch 30/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6528 - accuracy: 0.6545 - val_loss: 0.6569 - val_accuracy: 0.6406\n",
      "Epoch 31/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6519 - accuracy: 0.6545 - val_loss: 0.6559 - val_accuracy: 0.6406\n",
      "Epoch 32/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6511 - accuracy: 0.6545 - val_loss: 0.6550 - val_accuracy: 0.6406\n",
      "Epoch 33/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6503 - accuracy: 0.6545 - val_loss: 0.6541 - val_accuracy: 0.6406\n",
      "Epoch 34/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6496 - accuracy: 0.6545 - val_loss: 0.6533 - val_accuracy: 0.6406\n",
      "Epoch 35/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6488 - accuracy: 0.6545 - val_loss: 0.6525 - val_accuracy: 0.6406\n",
      "Epoch 36/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6481 - accuracy: 0.6545 - val_loss: 0.6517 - val_accuracy: 0.6406\n",
      "Epoch 37/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6474 - accuracy: 0.6545 - val_loss: 0.6509 - val_accuracy: 0.6406\n",
      "Epoch 38/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6467 - accuracy: 0.6545 - val_loss: 0.6501 - val_accuracy: 0.6406\n",
      "Epoch 39/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6461 - accuracy: 0.6545 - val_loss: 0.6494 - val_accuracy: 0.6406\n",
      "Epoch 40/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6454 - accuracy: 0.6545 - val_loss: 0.6487 - val_accuracy: 0.6406\n",
      "Epoch 41/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6447 - accuracy: 0.6545 - val_loss: 0.6479 - val_accuracy: 0.6406\n",
      "Epoch 42/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6441 - accuracy: 0.6545 - val_loss: 0.6472 - val_accuracy: 0.6406\n",
      "Epoch 43/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6435 - accuracy: 0.6545 - val_loss: 0.6466 - val_accuracy: 0.6406\n",
      "Epoch 44/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6428 - accuracy: 0.6545 - val_loss: 0.6459 - val_accuracy: 0.6406\n",
      "Epoch 45/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6422 - accuracy: 0.6545 - val_loss: 0.6452 - val_accuracy: 0.6406\n",
      "Epoch 46/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6416 - accuracy: 0.6545 - val_loss: 0.6446 - val_accuracy: 0.6406\n",
      "Epoch 47/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6410 - accuracy: 0.6545 - val_loss: 0.6439 - val_accuracy: 0.6406\n",
      "Epoch 48/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6404 - accuracy: 0.6545 - val_loss: 0.6433 - val_accuracy: 0.6406\n",
      "Epoch 49/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6399 - accuracy: 0.6545 - val_loss: 0.6427 - val_accuracy: 0.6406\n",
      "Epoch 50/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6393 - accuracy: 0.6545 - val_loss: 0.6421 - val_accuracy: 0.6406\n",
      "Epoch 51/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6387 - accuracy: 0.6528 - val_loss: 0.6415 - val_accuracy: 0.6406\n",
      "Epoch 52/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6381 - accuracy: 0.6528 - val_loss: 0.6409 - val_accuracy: 0.6406\n",
      "Epoch 53/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6375 - accuracy: 0.6528 - val_loss: 0.6403 - val_accuracy: 0.6406\n",
      "Epoch 54/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6370 - accuracy: 0.6528 - val_loss: 0.6397 - val_accuracy: 0.6406\n",
      "Epoch 55/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6364 - accuracy: 0.6528 - val_loss: 0.6391 - val_accuracy: 0.6406\n",
      "Epoch 56/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6359 - accuracy: 0.6528 - val_loss: 0.6386 - val_accuracy: 0.6406\n",
      "Epoch 57/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6353 - accuracy: 0.6528 - val_loss: 0.6380 - val_accuracy: 0.6406\n",
      "Epoch 58/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6348 - accuracy: 0.6528 - val_loss: 0.6374 - val_accuracy: 0.6406\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6342 - accuracy: 0.6528 - val_loss: 0.6369 - val_accuracy: 0.6406\n",
      "Epoch 60/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6337 - accuracy: 0.6528 - val_loss: 0.6363 - val_accuracy: 0.6406\n",
      "Epoch 61/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6332 - accuracy: 0.6528 - val_loss: 0.6358 - val_accuracy: 0.6406\n",
      "Epoch 62/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6326 - accuracy: 0.6528 - val_loss: 0.6352 - val_accuracy: 0.6406\n",
      "Epoch 63/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6320 - accuracy: 0.6528 - val_loss: 0.6347 - val_accuracy: 0.6406\n",
      "Epoch 64/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6316 - accuracy: 0.6528 - val_loss: 0.6341 - val_accuracy: 0.6406\n",
      "Epoch 65/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6310 - accuracy: 0.6528 - val_loss: 0.6336 - val_accuracy: 0.6406\n",
      "Epoch 66/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6305 - accuracy: 0.6528 - val_loss: 0.6331 - val_accuracy: 0.6406\n",
      "Epoch 67/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6300 - accuracy: 0.6528 - val_loss: 0.6325 - val_accuracy: 0.6406\n",
      "Epoch 68/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6294 - accuracy: 0.6510 - val_loss: 0.6320 - val_accuracy: 0.6406\n",
      "Epoch 69/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6289 - accuracy: 0.6510 - val_loss: 0.6315 - val_accuracy: 0.6406\n",
      "Epoch 70/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6284 - accuracy: 0.6510 - val_loss: 0.6310 - val_accuracy: 0.6406\n",
      "Epoch 71/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6279 - accuracy: 0.6510 - val_loss: 0.6305 - val_accuracy: 0.6458\n",
      "Epoch 72/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6274 - accuracy: 0.6510 - val_loss: 0.6299 - val_accuracy: 0.6458\n",
      "Epoch 73/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6268 - accuracy: 0.6510 - val_loss: 0.6294 - val_accuracy: 0.6458\n",
      "Epoch 74/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6263 - accuracy: 0.6510 - val_loss: 0.6289 - val_accuracy: 0.6458\n",
      "Epoch 75/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6258 - accuracy: 0.6510 - val_loss: 0.6284 - val_accuracy: 0.6458\n",
      "Epoch 76/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6253 - accuracy: 0.6510 - val_loss: 0.6279 - val_accuracy: 0.6458\n",
      "Epoch 77/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6248 - accuracy: 0.6510 - val_loss: 0.6274 - val_accuracy: 0.6458\n",
      "Epoch 78/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6243 - accuracy: 0.6510 - val_loss: 0.6269 - val_accuracy: 0.6458\n",
      "Epoch 79/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6238 - accuracy: 0.6510 - val_loss: 0.6264 - val_accuracy: 0.6458\n",
      "Epoch 80/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6233 - accuracy: 0.6510 - val_loss: 0.6259 - val_accuracy: 0.6458\n",
      "Epoch 81/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6228 - accuracy: 0.6510 - val_loss: 0.6254 - val_accuracy: 0.6458\n",
      "Epoch 82/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6223 - accuracy: 0.6510 - val_loss: 0.6249 - val_accuracy: 0.6458\n",
      "Epoch 83/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6218 - accuracy: 0.6510 - val_loss: 0.6244 - val_accuracy: 0.6458\n",
      "Epoch 84/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6213 - accuracy: 0.6510 - val_loss: 0.6239 - val_accuracy: 0.6458\n",
      "Epoch 85/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6208 - accuracy: 0.6510 - val_loss: 0.6234 - val_accuracy: 0.6458\n",
      "Epoch 86/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6203 - accuracy: 0.6510 - val_loss: 0.6230 - val_accuracy: 0.6458\n",
      "Epoch 87/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6198 - accuracy: 0.6528 - val_loss: 0.6225 - val_accuracy: 0.6458\n",
      "Epoch 88/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6193 - accuracy: 0.6510 - val_loss: 0.6220 - val_accuracy: 0.6458\n",
      "Epoch 89/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6188 - accuracy: 0.6528 - val_loss: 0.6215 - val_accuracy: 0.6458\n",
      "Epoch 90/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6183 - accuracy: 0.6528 - val_loss: 0.6210 - val_accuracy: 0.6458\n",
      "Epoch 91/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6178 - accuracy: 0.6528 - val_loss: 0.6205 - val_accuracy: 0.6458\n",
      "Epoch 92/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6173 - accuracy: 0.6528 - val_loss: 0.6201 - val_accuracy: 0.6458\n",
      "Epoch 93/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6168 - accuracy: 0.6545 - val_loss: 0.6196 - val_accuracy: 0.6458\n",
      "Epoch 94/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6163 - accuracy: 0.6528 - val_loss: 0.6191 - val_accuracy: 0.6458\n",
      "Epoch 95/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6159 - accuracy: 0.6545 - val_loss: 0.6186 - val_accuracy: 0.6458\n",
      "Epoch 96/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6154 - accuracy: 0.6528 - val_loss: 0.6182 - val_accuracy: 0.6458\n",
      "Epoch 97/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6149 - accuracy: 0.6528 - val_loss: 0.6177 - val_accuracy: 0.6458\n",
      "Epoch 98/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6144 - accuracy: 0.6562 - val_loss: 0.6172 - val_accuracy: 0.6458\n",
      "Epoch 99/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6139 - accuracy: 0.6562 - val_loss: 0.6167 - val_accuracy: 0.6458\n",
      "Epoch 100/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6134 - accuracy: 0.6562 - val_loss: 0.6163 - val_accuracy: 0.6458\n",
      "Epoch 101/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6129 - accuracy: 0.6562 - val_loss: 0.6158 - val_accuracy: 0.6458\n",
      "Epoch 102/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6125 - accuracy: 0.6562 - val_loss: 0.6153 - val_accuracy: 0.6458\n",
      "Epoch 103/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6120 - accuracy: 0.6562 - val_loss: 0.6149 - val_accuracy: 0.6458\n",
      "Epoch 104/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6115 - accuracy: 0.6562 - val_loss: 0.6144 - val_accuracy: 0.6458\n",
      "Epoch 105/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6110 - accuracy: 0.6562 - val_loss: 0.6139 - val_accuracy: 0.6458\n",
      "Epoch 106/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6106 - accuracy: 0.6580 - val_loss: 0.6135 - val_accuracy: 0.6458\n",
      "Epoch 107/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6101 - accuracy: 0.6580 - val_loss: 0.6130 - val_accuracy: 0.6458\n",
      "Epoch 108/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6096 - accuracy: 0.6580 - val_loss: 0.6126 - val_accuracy: 0.6458\n",
      "Epoch 109/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6091 - accuracy: 0.6580 - val_loss: 0.6121 - val_accuracy: 0.6458\n",
      "Epoch 110/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6086 - accuracy: 0.6580 - val_loss: 0.6116 - val_accuracy: 0.6458\n",
      "Epoch 111/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6082 - accuracy: 0.6580 - val_loss: 0.6112 - val_accuracy: 0.6458\n",
      "Epoch 112/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6077 - accuracy: 0.6580 - val_loss: 0.6107 - val_accuracy: 0.6458\n",
      "Epoch 113/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6072 - accuracy: 0.6580 - val_loss: 0.6103 - val_accuracy: 0.6458\n",
      "Epoch 114/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6068 - accuracy: 0.6580 - val_loss: 0.6098 - val_accuracy: 0.6458\n",
      "Epoch 115/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6063 - accuracy: 0.6580 - val_loss: 0.6094 - val_accuracy: 0.6458\n",
      "Epoch 116/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6058 - accuracy: 0.6580 - val_loss: 0.6089 - val_accuracy: 0.6458\n",
      "Epoch 117/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6054 - accuracy: 0.6580 - val_loss: 0.6085 - val_accuracy: 0.6458\n",
      "Epoch 118/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6049 - accuracy: 0.6562 - val_loss: 0.6080 - val_accuracy: 0.6458\n",
      "Epoch 119/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6044 - accuracy: 0.6580 - val_loss: 0.6076 - val_accuracy: 0.6406\n",
      "Epoch 120/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6039 - accuracy: 0.6597 - val_loss: 0.6071 - val_accuracy: 0.6406\n",
      "Epoch 121/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6035 - accuracy: 0.6597 - val_loss: 0.6067 - val_accuracy: 0.6406\n",
      "Epoch 122/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6030 - accuracy: 0.6597 - val_loss: 0.6062 - val_accuracy: 0.6406\n",
      "Epoch 123/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6026 - accuracy: 0.6597 - val_loss: 0.6058 - val_accuracy: 0.6406\n",
      "Epoch 124/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6021 - accuracy: 0.6597 - val_loss: 0.6053 - val_accuracy: 0.6406\n",
      "Epoch 125/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6016 - accuracy: 0.6615 - val_loss: 0.6049 - val_accuracy: 0.6458\n",
      "Epoch 126/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6012 - accuracy: 0.6615 - val_loss: 0.6044 - val_accuracy: 0.6458\n",
      "Epoch 127/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6008 - accuracy: 0.6615 - val_loss: 0.6040 - val_accuracy: 0.6458\n",
      "Epoch 128/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6003 - accuracy: 0.6615 - val_loss: 0.6036 - val_accuracy: 0.6458\n",
      "Epoch 129/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5998 - accuracy: 0.6615 - val_loss: 0.6031 - val_accuracy: 0.6458\n",
      "Epoch 130/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5994 - accuracy: 0.6615 - val_loss: 0.6027 - val_accuracy: 0.6458\n",
      "Epoch 131/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5989 - accuracy: 0.6615 - val_loss: 0.6022 - val_accuracy: 0.6510\n",
      "Epoch 132/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5984 - accuracy: 0.6615 - val_loss: 0.6018 - val_accuracy: 0.6510\n",
      "Epoch 133/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5980 - accuracy: 0.6615 - val_loss: 0.6014 - val_accuracy: 0.6510\n",
      "Epoch 134/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5975 - accuracy: 0.6632 - val_loss: 0.6009 - val_accuracy: 0.6510\n",
      "Epoch 135/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5971 - accuracy: 0.6632 - val_loss: 0.6005 - val_accuracy: 0.6510\n",
      "Epoch 136/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5966 - accuracy: 0.6632 - val_loss: 0.6001 - val_accuracy: 0.6510\n",
      "Epoch 137/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5962 - accuracy: 0.6632 - val_loss: 0.5996 - val_accuracy: 0.6510\n",
      "Epoch 138/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5958 - accuracy: 0.6632 - val_loss: 0.5992 - val_accuracy: 0.6562\n",
      "Epoch 139/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5953 - accuracy: 0.6632 - val_loss: 0.5988 - val_accuracy: 0.6562\n",
      "Epoch 140/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5948 - accuracy: 0.6632 - val_loss: 0.5983 - val_accuracy: 0.6562\n",
      "Epoch 141/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5944 - accuracy: 0.6649 - val_loss: 0.5979 - val_accuracy: 0.6562\n",
      "Epoch 142/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5940 - accuracy: 0.6649 - val_loss: 0.5975 - val_accuracy: 0.6615\n",
      "Epoch 143/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5935 - accuracy: 0.6667 - val_loss: 0.5970 - val_accuracy: 0.6615\n",
      "Epoch 144/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5931 - accuracy: 0.6667 - val_loss: 0.5966 - val_accuracy: 0.6615\n",
      "Epoch 145/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5926 - accuracy: 0.6684 - val_loss: 0.5962 - val_accuracy: 0.6615\n",
      "Epoch 146/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5922 - accuracy: 0.6684 - val_loss: 0.5958 - val_accuracy: 0.6615\n",
      "Epoch 147/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5918 - accuracy: 0.6684 - val_loss: 0.5953 - val_accuracy: 0.6615\n",
      "Epoch 148/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5913 - accuracy: 0.6684 - val_loss: 0.5949 - val_accuracy: 0.6667\n",
      "Epoch 149/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5909 - accuracy: 0.6684 - val_loss: 0.5945 - val_accuracy: 0.6667\n",
      "Epoch 150/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5904 - accuracy: 0.6684 - val_loss: 0.5941 - val_accuracy: 0.6667\n",
      "Epoch 151/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5900 - accuracy: 0.6701 - val_loss: 0.5936 - val_accuracy: 0.6667\n",
      "Epoch 152/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5895 - accuracy: 0.6701 - val_loss: 0.5932 - val_accuracy: 0.6719\n",
      "Epoch 153/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5891 - accuracy: 0.6719 - val_loss: 0.5928 - val_accuracy: 0.6719\n",
      "Epoch 154/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5887 - accuracy: 0.6736 - val_loss: 0.5924 - val_accuracy: 0.6719\n",
      "Epoch 155/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5883 - accuracy: 0.6736 - val_loss: 0.5920 - val_accuracy: 0.6719\n",
      "Epoch 156/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5878 - accuracy: 0.6753 - val_loss: 0.5915 - val_accuracy: 0.6719\n",
      "Epoch 157/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5874 - accuracy: 0.6753 - val_loss: 0.5911 - val_accuracy: 0.6719\n",
      "Epoch 158/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5870 - accuracy: 0.6753 - val_loss: 0.5907 - val_accuracy: 0.6719\n",
      "Epoch 159/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5865 - accuracy: 0.6771 - val_loss: 0.5903 - val_accuracy: 0.6719\n",
      "Epoch 160/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5861 - accuracy: 0.6771 - val_loss: 0.5899 - val_accuracy: 0.6719\n",
      "Epoch 161/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5856 - accuracy: 0.6771 - val_loss: 0.5895 - val_accuracy: 0.6719\n",
      "Epoch 162/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5852 - accuracy: 0.6771 - val_loss: 0.5891 - val_accuracy: 0.6771\n",
      "Epoch 163/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5848 - accuracy: 0.6771 - val_loss: 0.5886 - val_accuracy: 0.6771\n",
      "Epoch 164/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5844 - accuracy: 0.6771 - val_loss: 0.5882 - val_accuracy: 0.6823\n",
      "Epoch 165/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5839 - accuracy: 0.6771 - val_loss: 0.5878 - val_accuracy: 0.6875\n",
      "Epoch 166/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5835 - accuracy: 0.6771 - val_loss: 0.5874 - val_accuracy: 0.6875\n",
      "Epoch 167/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5831 - accuracy: 0.6788 - val_loss: 0.5870 - val_accuracy: 0.6875\n",
      "Epoch 168/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5827 - accuracy: 0.6806 - val_loss: 0.5866 - val_accuracy: 0.6875\n",
      "Epoch 169/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5822 - accuracy: 0.6806 - val_loss: 0.5862 - val_accuracy: 0.6875\n",
      "Epoch 170/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5818 - accuracy: 0.6823 - val_loss: 0.5858 - val_accuracy: 0.6875\n",
      "Epoch 171/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5814 - accuracy: 0.6823 - val_loss: 0.5854 - val_accuracy: 0.6875\n",
      "Epoch 172/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5810 - accuracy: 0.6823 - val_loss: 0.5850 - val_accuracy: 0.6875\n",
      "Epoch 173/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5805 - accuracy: 0.6806 - val_loss: 0.5846 - val_accuracy: 0.6875\n",
      "Epoch 174/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5801 - accuracy: 0.6823 - val_loss: 0.5842 - val_accuracy: 0.6875\n",
      "Epoch 175/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5797 - accuracy: 0.6806 - val_loss: 0.5838 - val_accuracy: 0.6927\n",
      "Epoch 176/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5793 - accuracy: 0.6788 - val_loss: 0.5834 - val_accuracy: 0.6927\n",
      "Epoch 177/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5789 - accuracy: 0.6823 - val_loss: 0.5830 - val_accuracy: 0.6927\n",
      "Epoch 178/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5785 - accuracy: 0.6823 - val_loss: 0.5826 - val_accuracy: 0.6927\n",
      "Epoch 179/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5780 - accuracy: 0.6823 - val_loss: 0.5822 - val_accuracy: 0.6927\n",
      "Epoch 180/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5776 - accuracy: 0.6823 - val_loss: 0.5818 - val_accuracy: 0.6927\n",
      "Epoch 181/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5772 - accuracy: 0.6823 - val_loss: 0.5814 - val_accuracy: 0.6927\n",
      "Epoch 182/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5768 - accuracy: 0.6823 - val_loss: 0.5810 - val_accuracy: 0.6979\n",
      "Epoch 183/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5764 - accuracy: 0.6840 - val_loss: 0.5806 - val_accuracy: 0.6979\n",
      "Epoch 184/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5760 - accuracy: 0.6840 - val_loss: 0.5802 - val_accuracy: 0.6979\n",
      "Epoch 185/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5756 - accuracy: 0.6858 - val_loss: 0.5798 - val_accuracy: 0.6979\n",
      "Epoch 186/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5752 - accuracy: 0.6840 - val_loss: 0.5794 - val_accuracy: 0.6979\n",
      "Epoch 187/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5747 - accuracy: 0.6858 - val_loss: 0.5790 - val_accuracy: 0.6979\n",
      "Epoch 188/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5743 - accuracy: 0.6858 - val_loss: 0.5786 - val_accuracy: 0.7031\n",
      "Epoch 189/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5740 - accuracy: 0.6858 - val_loss: 0.5783 - val_accuracy: 0.7031\n",
      "Epoch 190/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5735 - accuracy: 0.6840 - val_loss: 0.5779 - val_accuracy: 0.7031\n",
      "Epoch 191/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5731 - accuracy: 0.6840 - val_loss: 0.5775 - val_accuracy: 0.7031\n",
      "Epoch 192/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5727 - accuracy: 0.6858 - val_loss: 0.5771 - val_accuracy: 0.7083\n",
      "Epoch 193/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5723 - accuracy: 0.6875 - val_loss: 0.5767 - val_accuracy: 0.7083\n",
      "Epoch 194/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5719 - accuracy: 0.6875 - val_loss: 0.5763 - val_accuracy: 0.7083\n",
      "Epoch 195/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5715 - accuracy: 0.6875 - val_loss: 0.5760 - val_accuracy: 0.7083\n",
      "Epoch 196/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5711 - accuracy: 0.6892 - val_loss: 0.5756 - val_accuracy: 0.7083\n",
      "Epoch 197/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5707 - accuracy: 0.6892 - val_loss: 0.5752 - val_accuracy: 0.7083\n",
      "Epoch 198/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5703 - accuracy: 0.6892 - val_loss: 0.5748 - val_accuracy: 0.7083\n",
      "Epoch 199/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5699 - accuracy: 0.6910 - val_loss: 0.5744 - val_accuracy: 0.7135\n",
      "Epoch 200/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5695 - accuracy: 0.6910 - val_loss: 0.5741 - val_accuracy: 0.7135\n"
     ]
    }
   ],
   "source": [
    "## Fit the model\n",
    "model_1.compile(SGD(lr=.003), \"binary_crossentropy\", \n",
    "                 metrics=[\"accuracy\"])\n",
    "run_hist_1=model_1.fit(X_train_norm, y_train, \n",
    "                       validation_data=(X_test_norm, y_test),\n",
    "                      epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-32-0ad2bd438a74>:5: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n"
     ]
    }
   ],
   "source": [
    "## Like we did for the Random Forest, we generate two kinds of prediction\n",
    "## One is hard prediction\n",
    "## the other is a probabilstic score\n",
    "\n",
    "y_pred_class_nn_1=model_1.predict_classes(X_test_norm)\n",
    "y_pred_prob_nn_1=model_1.predict(X_test_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0]], dtype=int32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_class_nn_1[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.37275234],\n",
       "       [0.5064256 ],\n",
       "       [0.340949  ],\n",
       "       [0.3692815 ],\n",
       "       [0.27821034],\n",
       "       [0.4220354 ],\n",
       "       [0.23324189],\n",
       "       [0.38173282],\n",
       "       [0.4826442 ],\n",
       "       [0.3890062 ]], dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_prob_nn_1[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.714\n",
      "roc-auc is 0.792\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print model performance and plot the roc curve\n",
    "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_nn_1)))\n",
    "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_nn_1)))\n",
    "\n",
    "plot_roc(y_test, y_pred_prob_nn_1, 'NN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_hist_1.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fa1eca471c0>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(run_hist_1.history[\"loss\"],'r', marker='.', label=\"Train Loss\")\n",
    "ax.plot(run_hist_1.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5692 - accuracy: 0.6910 - val_loss: 0.5737 - val_accuracy: 0.7135\n",
      "Epoch 2/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5687 - accuracy: 0.6910 - val_loss: 0.5733 - val_accuracy: 0.7135\n",
      "Epoch 3/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5684 - accuracy: 0.6927 - val_loss: 0.5729 - val_accuracy: 0.7135\n",
      "Epoch 4/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5680 - accuracy: 0.6927 - val_loss: 0.5726 - val_accuracy: 0.7188\n",
      "Epoch 5/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5676 - accuracy: 0.6927 - val_loss: 0.5722 - val_accuracy: 0.7188\n",
      "Epoch 6/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5672 - accuracy: 0.6927 - val_loss: 0.5718 - val_accuracy: 0.7240\n",
      "Epoch 7/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5668 - accuracy: 0.6927 - val_loss: 0.5714 - val_accuracy: 0.7240\n",
      "Epoch 8/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5664 - accuracy: 0.6927 - val_loss: 0.5711 - val_accuracy: 0.7240\n",
      "Epoch 9/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5660 - accuracy: 0.6927 - val_loss: 0.5707 - val_accuracy: 0.7240\n",
      "Epoch 10/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5656 - accuracy: 0.6910 - val_loss: 0.5703 - val_accuracy: 0.7240\n",
      "Epoch 11/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5652 - accuracy: 0.6927 - val_loss: 0.5700 - val_accuracy: 0.7240\n",
      "Epoch 12/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5649 - accuracy: 0.6927 - val_loss: 0.5696 - val_accuracy: 0.7240\n",
      "Epoch 13/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5645 - accuracy: 0.6927 - val_loss: 0.5692 - val_accuracy: 0.7240\n",
      "Epoch 14/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5641 - accuracy: 0.6927 - val_loss: 0.5689 - val_accuracy: 0.7240\n",
      "Epoch 15/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5637 - accuracy: 0.6944 - val_loss: 0.5685 - val_accuracy: 0.7292\n",
      "Epoch 16/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5633 - accuracy: 0.6944 - val_loss: 0.5681 - val_accuracy: 0.7292\n",
      "Epoch 17/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5629 - accuracy: 0.6944 - val_loss: 0.5678 - val_accuracy: 0.7344\n",
      "Epoch 18/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5625 - accuracy: 0.6944 - val_loss: 0.5674 - val_accuracy: 0.7344\n",
      "Epoch 19/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5622 - accuracy: 0.6927 - val_loss: 0.5671 - val_accuracy: 0.7344\n",
      "Epoch 20/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5618 - accuracy: 0.6979 - val_loss: 0.5667 - val_accuracy: 0.7344\n",
      "Epoch 21/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5614 - accuracy: 0.6962 - val_loss: 0.5663 - val_accuracy: 0.7344\n",
      "Epoch 22/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5611 - accuracy: 0.6979 - val_loss: 0.5660 - val_accuracy: 0.7344\n",
      "Epoch 23/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5607 - accuracy: 0.6979 - val_loss: 0.5656 - val_accuracy: 0.7344\n",
      "Epoch 24/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5603 - accuracy: 0.6962 - val_loss: 0.5653 - val_accuracy: 0.7344\n",
      "Epoch 25/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5599 - accuracy: 0.6979 - val_loss: 0.5649 - val_accuracy: 0.7344\n",
      "Epoch 26/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5596 - accuracy: 0.6979 - val_loss: 0.5646 - val_accuracy: 0.7292\n",
      "Epoch 27/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5592 - accuracy: 0.6979 - val_loss: 0.5642 - val_accuracy: 0.7292\n",
      "Epoch 28/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5588 - accuracy: 0.6997 - val_loss: 0.5639 - val_accuracy: 0.7292\n",
      "Epoch 29/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5585 - accuracy: 0.6997 - val_loss: 0.5635 - val_accuracy: 0.7344\n",
      "Epoch 30/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5581 - accuracy: 0.6997 - val_loss: 0.5632 - val_accuracy: 0.7344\n",
      "Epoch 31/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5577 - accuracy: 0.6997 - val_loss: 0.5628 - val_accuracy: 0.7344\n",
      "Epoch 32/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5573 - accuracy: 0.7014 - val_loss: 0.5625 - val_accuracy: 0.7344\n",
      "Epoch 33/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5570 - accuracy: 0.7014 - val_loss: 0.5621 - val_accuracy: 0.7344\n",
      "Epoch 34/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5566 - accuracy: 0.7014 - val_loss: 0.5618 - val_accuracy: 0.7344\n",
      "Epoch 35/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5563 - accuracy: 0.7014 - val_loss: 0.5614 - val_accuracy: 0.7344\n",
      "Epoch 36/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5559 - accuracy: 0.7049 - val_loss: 0.5611 - val_accuracy: 0.7344\n",
      "Epoch 37/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5555 - accuracy: 0.7049 - val_loss: 0.5608 - val_accuracy: 0.7344\n",
      "Epoch 38/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5552 - accuracy: 0.7049 - val_loss: 0.5604 - val_accuracy: 0.7344\n",
      "Epoch 39/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5548 - accuracy: 0.7049 - val_loss: 0.5601 - val_accuracy: 0.7344\n",
      "Epoch 40/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5545 - accuracy: 0.7066 - val_loss: 0.5597 - val_accuracy: 0.7344\n",
      "Epoch 41/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5541 - accuracy: 0.7066 - val_loss: 0.5594 - val_accuracy: 0.7396\n",
      "Epoch 42/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5537 - accuracy: 0.7066 - val_loss: 0.5591 - val_accuracy: 0.7344\n",
      "Epoch 43/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5534 - accuracy: 0.7066 - val_loss: 0.5587 - val_accuracy: 0.7344\n",
      "Epoch 44/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5530 - accuracy: 0.7049 - val_loss: 0.5584 - val_accuracy: 0.7344\n",
      "Epoch 45/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5527 - accuracy: 0.7066 - val_loss: 0.5581 - val_accuracy: 0.7344\n",
      "Epoch 46/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5523 - accuracy: 0.7066 - val_loss: 0.5577 - val_accuracy: 0.7344\n",
      "Epoch 47/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5520 - accuracy: 0.7066 - val_loss: 0.5574 - val_accuracy: 0.7344\n",
      "Epoch 48/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5516 - accuracy: 0.7066 - val_loss: 0.5571 - val_accuracy: 0.7344\n",
      "Epoch 49/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5513 - accuracy: 0.7066 - val_loss: 0.5567 - val_accuracy: 0.7344\n",
      "Epoch 50/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5509 - accuracy: 0.7066 - val_loss: 0.5564 - val_accuracy: 0.7344\n",
      "Epoch 51/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5506 - accuracy: 0.7083 - val_loss: 0.5561 - val_accuracy: 0.7344\n",
      "Epoch 52/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5502 - accuracy: 0.7083 - val_loss: 0.5558 - val_accuracy: 0.7344\n",
      "Epoch 53/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5499 - accuracy: 0.7083 - val_loss: 0.5554 - val_accuracy: 0.7344\n",
      "Epoch 54/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5495 - accuracy: 0.7135 - val_loss: 0.5551 - val_accuracy: 0.7344\n",
      "Epoch 55/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5492 - accuracy: 0.7153 - val_loss: 0.5548 - val_accuracy: 0.7344\n",
      "Epoch 56/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5489 - accuracy: 0.7135 - val_loss: 0.5545 - val_accuracy: 0.7344\n",
      "Epoch 57/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5485 - accuracy: 0.7153 - val_loss: 0.5542 - val_accuracy: 0.7344\n",
      "Epoch 58/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5482 - accuracy: 0.7153 - val_loss: 0.5538 - val_accuracy: 0.7344\n",
      "Epoch 59/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5478 - accuracy: 0.7188 - val_loss: 0.5535 - val_accuracy: 0.7396\n",
      "Epoch 60/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5475 - accuracy: 0.7188 - val_loss: 0.5532 - val_accuracy: 0.7396\n",
      "Epoch 61/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5472 - accuracy: 0.7188 - val_loss: 0.5529 - val_accuracy: 0.7448\n",
      "Epoch 62/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5468 - accuracy: 0.7188 - val_loss: 0.5526 - val_accuracy: 0.7448\n",
      "Epoch 63/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5465 - accuracy: 0.7205 - val_loss: 0.5523 - val_accuracy: 0.7448\n",
      "Epoch 64/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5462 - accuracy: 0.7205 - val_loss: 0.5519 - val_accuracy: 0.7448\n",
      "Epoch 65/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5458 - accuracy: 0.7205 - val_loss: 0.5516 - val_accuracy: 0.7448\n",
      "Epoch 66/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5455 - accuracy: 0.7205 - val_loss: 0.5513 - val_accuracy: 0.7448\n",
      "Epoch 67/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5452 - accuracy: 0.7222 - val_loss: 0.5510 - val_accuracy: 0.7448\n",
      "Epoch 68/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5448 - accuracy: 0.7222 - val_loss: 0.5507 - val_accuracy: 0.7448\n",
      "Epoch 69/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5445 - accuracy: 0.7222 - val_loss: 0.5504 - val_accuracy: 0.7448\n",
      "Epoch 70/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5442 - accuracy: 0.7222 - val_loss: 0.5501 - val_accuracy: 0.7448\n",
      "Epoch 71/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5439 - accuracy: 0.7240 - val_loss: 0.5498 - val_accuracy: 0.7448\n",
      "Epoch 72/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5435 - accuracy: 0.7240 - val_loss: 0.5495 - val_accuracy: 0.7448\n",
      "Epoch 73/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5432 - accuracy: 0.7257 - val_loss: 0.5492 - val_accuracy: 0.7448\n",
      "Epoch 74/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5429 - accuracy: 0.7257 - val_loss: 0.5489 - val_accuracy: 0.7448\n",
      "Epoch 75/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5426 - accuracy: 0.7257 - val_loss: 0.5486 - val_accuracy: 0.7448\n",
      "Epoch 76/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5422 - accuracy: 0.7257 - val_loss: 0.5483 - val_accuracy: 0.7448\n",
      "Epoch 77/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5419 - accuracy: 0.7257 - val_loss: 0.5480 - val_accuracy: 0.7448\n",
      "Epoch 78/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5416 - accuracy: 0.7257 - val_loss: 0.5477 - val_accuracy: 0.7500\n",
      "Epoch 79/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5413 - accuracy: 0.7257 - val_loss: 0.5474 - val_accuracy: 0.7500\n",
      "Epoch 80/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5409 - accuracy: 0.7257 - val_loss: 0.5471 - val_accuracy: 0.7448\n",
      "Epoch 81/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5407 - accuracy: 0.7257 - val_loss: 0.5468 - val_accuracy: 0.7448\n",
      "Epoch 82/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5403 - accuracy: 0.7274 - val_loss: 0.5465 - val_accuracy: 0.7448\n",
      "Epoch 83/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5400 - accuracy: 0.7274 - val_loss: 0.5462 - val_accuracy: 0.7448\n",
      "Epoch 84/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5397 - accuracy: 0.7274 - val_loss: 0.5459 - val_accuracy: 0.7448\n",
      "Epoch 85/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5394 - accuracy: 0.7326 - val_loss: 0.5456 - val_accuracy: 0.7448\n",
      "Epoch 86/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5391 - accuracy: 0.7274 - val_loss: 0.5453 - val_accuracy: 0.7448\n",
      "Epoch 87/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5388 - accuracy: 0.7326 - val_loss: 0.5450 - val_accuracy: 0.7448\n",
      "Epoch 88/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5384 - accuracy: 0.7344 - val_loss: 0.5447 - val_accuracy: 0.7448\n",
      "Epoch 89/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5381 - accuracy: 0.7344 - val_loss: 0.5444 - val_accuracy: 0.7448\n",
      "Epoch 90/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5378 - accuracy: 0.7344 - val_loss: 0.5442 - val_accuracy: 0.7448\n",
      "Epoch 91/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5375 - accuracy: 0.7344 - val_loss: 0.5439 - val_accuracy: 0.7448\n",
      "Epoch 92/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5372 - accuracy: 0.7344 - val_loss: 0.5436 - val_accuracy: 0.7448\n",
      "Epoch 93/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5369 - accuracy: 0.7361 - val_loss: 0.5433 - val_accuracy: 0.7500\n",
      "Epoch 94/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5366 - accuracy: 0.7344 - val_loss: 0.5430 - val_accuracy: 0.7500\n",
      "Epoch 95/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5363 - accuracy: 0.7361 - val_loss: 0.5427 - val_accuracy: 0.7500\n",
      "Epoch 96/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5360 - accuracy: 0.7344 - val_loss: 0.5425 - val_accuracy: 0.7500\n",
      "Epoch 97/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5357 - accuracy: 0.7344 - val_loss: 0.5422 - val_accuracy: 0.7500\n",
      "Epoch 98/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5354 - accuracy: 0.7378 - val_loss: 0.5419 - val_accuracy: 0.7500\n",
      "Epoch 99/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5351 - accuracy: 0.7396 - val_loss: 0.5416 - val_accuracy: 0.7500\n",
      "Epoch 100/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5348 - accuracy: 0.7396 - val_loss: 0.5414 - val_accuracy: 0.7500\n",
      "Epoch 101/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5345 - accuracy: 0.7396 - val_loss: 0.5411 - val_accuracy: 0.7500\n",
      "Epoch 102/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5342 - accuracy: 0.7396 - val_loss: 0.5408 - val_accuracy: 0.7500\n",
      "Epoch 103/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5339 - accuracy: 0.7378 - val_loss: 0.5405 - val_accuracy: 0.7500\n",
      "Epoch 104/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5336 - accuracy: 0.7396 - val_loss: 0.5403 - val_accuracy: 0.7500\n",
      "Epoch 105/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5333 - accuracy: 0.7413 - val_loss: 0.5400 - val_accuracy: 0.7500\n",
      "Epoch 106/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5330 - accuracy: 0.7413 - val_loss: 0.5397 - val_accuracy: 0.7500\n",
      "Epoch 107/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5328 - accuracy: 0.7396 - val_loss: 0.5395 - val_accuracy: 0.7500\n",
      "Epoch 108/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5325 - accuracy: 0.7378 - val_loss: 0.5392 - val_accuracy: 0.7500\n",
      "Epoch 109/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5322 - accuracy: 0.7378 - val_loss: 0.5389 - val_accuracy: 0.7500\n",
      "Epoch 110/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5319 - accuracy: 0.7378 - val_loss: 0.5387 - val_accuracy: 0.7500\n",
      "Epoch 111/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5316 - accuracy: 0.7361 - val_loss: 0.5384 - val_accuracy: 0.7500\n",
      "Epoch 112/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5313 - accuracy: 0.7378 - val_loss: 0.5381 - val_accuracy: 0.7500\n",
      "Epoch 113/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5310 - accuracy: 0.7378 - val_loss: 0.5379 - val_accuracy: 0.7500\n",
      "Epoch 114/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5307 - accuracy: 0.7361 - val_loss: 0.5376 - val_accuracy: 0.7500\n",
      "Epoch 115/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5305 - accuracy: 0.7361 - val_loss: 0.5374 - val_accuracy: 0.7500\n",
      "Epoch 116/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5302 - accuracy: 0.7361 - val_loss: 0.5371 - val_accuracy: 0.7500\n",
      "Epoch 117/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5299 - accuracy: 0.7361 - val_loss: 0.5368 - val_accuracy: 0.7500\n",
      "Epoch 118/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5296 - accuracy: 0.7361 - val_loss: 0.5366 - val_accuracy: 0.7552\n",
      "Epoch 119/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5293 - accuracy: 0.7326 - val_loss: 0.5363 - val_accuracy: 0.7552\n",
      "Epoch 120/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5291 - accuracy: 0.7326 - val_loss: 0.5361 - val_accuracy: 0.7552\n",
      "Epoch 121/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5288 - accuracy: 0.7326 - val_loss: 0.5358 - val_accuracy: 0.7552\n",
      "Epoch 122/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5285 - accuracy: 0.7344 - val_loss: 0.5356 - val_accuracy: 0.7604\n",
      "Epoch 123/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5283 - accuracy: 0.7326 - val_loss: 0.5353 - val_accuracy: 0.7604\n",
      "Epoch 124/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5280 - accuracy: 0.7361 - val_loss: 0.5351 - val_accuracy: 0.7604\n",
      "Epoch 125/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5277 - accuracy: 0.7361 - val_loss: 0.5348 - val_accuracy: 0.7604\n",
      "Epoch 126/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5274 - accuracy: 0.7344 - val_loss: 0.5346 - val_accuracy: 0.7604\n",
      "Epoch 127/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5272 - accuracy: 0.7361 - val_loss: 0.5343 - val_accuracy: 0.7604\n",
      "Epoch 128/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5269 - accuracy: 0.7344 - val_loss: 0.5341 - val_accuracy: 0.7604\n",
      "Epoch 129/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5266 - accuracy: 0.7361 - val_loss: 0.5338 - val_accuracy: 0.7604\n",
      "Epoch 130/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5264 - accuracy: 0.7378 - val_loss: 0.5336 - val_accuracy: 0.7604\n",
      "Epoch 131/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5261 - accuracy: 0.7378 - val_loss: 0.5333 - val_accuracy: 0.7604\n",
      "Epoch 132/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5258 - accuracy: 0.7378 - val_loss: 0.5331 - val_accuracy: 0.7604\n",
      "Epoch 133/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5256 - accuracy: 0.7378 - val_loss: 0.5329 - val_accuracy: 0.7604\n",
      "Epoch 134/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5253 - accuracy: 0.7396 - val_loss: 0.5326 - val_accuracy: 0.7604\n",
      "Epoch 135/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5250 - accuracy: 0.7448 - val_loss: 0.5324 - val_accuracy: 0.7604\n",
      "Epoch 136/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5248 - accuracy: 0.7448 - val_loss: 0.5321 - val_accuracy: 0.7604\n",
      "Epoch 137/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5245 - accuracy: 0.7431 - val_loss: 0.5319 - val_accuracy: 0.7604\n",
      "Epoch 138/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5243 - accuracy: 0.7448 - val_loss: 0.5317 - val_accuracy: 0.7604\n",
      "Epoch 139/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5240 - accuracy: 0.7413 - val_loss: 0.5314 - val_accuracy: 0.7604\n",
      "Epoch 140/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5237 - accuracy: 0.7431 - val_loss: 0.5312 - val_accuracy: 0.7604\n",
      "Epoch 141/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5235 - accuracy: 0.7465 - val_loss: 0.5310 - val_accuracy: 0.7604\n",
      "Epoch 142/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5232 - accuracy: 0.7465 - val_loss: 0.5307 - val_accuracy: 0.7604\n",
      "Epoch 143/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5230 - accuracy: 0.7448 - val_loss: 0.5305 - val_accuracy: 0.7604\n",
      "Epoch 144/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5227 - accuracy: 0.7448 - val_loss: 0.5303 - val_accuracy: 0.7604\n",
      "Epoch 145/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5225 - accuracy: 0.7448 - val_loss: 0.5300 - val_accuracy: 0.7604\n",
      "Epoch 146/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5222 - accuracy: 0.7465 - val_loss: 0.5298 - val_accuracy: 0.7552\n",
      "Epoch 147/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5219 - accuracy: 0.7448 - val_loss: 0.5296 - val_accuracy: 0.7604\n",
      "Epoch 148/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5217 - accuracy: 0.7448 - val_loss: 0.5294 - val_accuracy: 0.7604\n",
      "Epoch 149/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5215 - accuracy: 0.7465 - val_loss: 0.5291 - val_accuracy: 0.7604\n",
      "Epoch 150/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5212 - accuracy: 0.7465 - val_loss: 0.5289 - val_accuracy: 0.7604\n",
      "Epoch 151/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5209 - accuracy: 0.7448 - val_loss: 0.5287 - val_accuracy: 0.7604\n",
      "Epoch 152/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5207 - accuracy: 0.7431 - val_loss: 0.5285 - val_accuracy: 0.7604\n",
      "Epoch 153/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5205 - accuracy: 0.7431 - val_loss: 0.5282 - val_accuracy: 0.7656\n",
      "Epoch 154/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5202 - accuracy: 0.7448 - val_loss: 0.5280 - val_accuracy: 0.7656\n",
      "Epoch 155/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5200 - accuracy: 0.7448 - val_loss: 0.5278 - val_accuracy: 0.7656\n",
      "Epoch 156/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5197 - accuracy: 0.7448 - val_loss: 0.5276 - val_accuracy: 0.7656\n",
      "Epoch 157/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5195 - accuracy: 0.7465 - val_loss: 0.5274 - val_accuracy: 0.7656\n",
      "Epoch 158/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5192 - accuracy: 0.7483 - val_loss: 0.5271 - val_accuracy: 0.7656\n",
      "Epoch 159/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5190 - accuracy: 0.7483 - val_loss: 0.5269 - val_accuracy: 0.7656\n",
      "Epoch 160/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5188 - accuracy: 0.7483 - val_loss: 0.5267 - val_accuracy: 0.7656\n",
      "Epoch 161/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5185 - accuracy: 0.7483 - val_loss: 0.5265 - val_accuracy: 0.7604\n",
      "Epoch 162/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5183 - accuracy: 0.7483 - val_loss: 0.5263 - val_accuracy: 0.7604\n",
      "Epoch 163/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5180 - accuracy: 0.7483 - val_loss: 0.5261 - val_accuracy: 0.7656\n",
      "Epoch 164/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5178 - accuracy: 0.7483 - val_loss: 0.5259 - val_accuracy: 0.7656\n",
      "Epoch 165/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5176 - accuracy: 0.7483 - val_loss: 0.5256 - val_accuracy: 0.7656\n",
      "Epoch 166/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5174 - accuracy: 0.7483 - val_loss: 0.5254 - val_accuracy: 0.7656\n",
      "Epoch 167/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5171 - accuracy: 0.7483 - val_loss: 0.5252 - val_accuracy: 0.7656\n",
      "Epoch 168/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5169 - accuracy: 0.7483 - val_loss: 0.5250 - val_accuracy: 0.7656\n",
      "Epoch 169/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5167 - accuracy: 0.7483 - val_loss: 0.5248 - val_accuracy: 0.7656\n",
      "Epoch 170/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5164 - accuracy: 0.7483 - val_loss: 0.5246 - val_accuracy: 0.7656\n",
      "Epoch 171/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5162 - accuracy: 0.7483 - val_loss: 0.5244 - val_accuracy: 0.7656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5160 - accuracy: 0.7483 - val_loss: 0.5242 - val_accuracy: 0.7656\n",
      "Epoch 173/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5157 - accuracy: 0.7483 - val_loss: 0.5240 - val_accuracy: 0.7656\n",
      "Epoch 174/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5155 - accuracy: 0.7500 - val_loss: 0.5238 - val_accuracy: 0.7656\n",
      "Epoch 175/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5153 - accuracy: 0.7500 - val_loss: 0.5236 - val_accuracy: 0.7656\n",
      "Epoch 176/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5151 - accuracy: 0.7500 - val_loss: 0.5234 - val_accuracy: 0.7656\n",
      "Epoch 177/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5149 - accuracy: 0.7517 - val_loss: 0.5232 - val_accuracy: 0.7656\n",
      "Epoch 178/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5146 - accuracy: 0.7517 - val_loss: 0.5230 - val_accuracy: 0.7708\n",
      "Epoch 179/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5144 - accuracy: 0.7517 - val_loss: 0.5228 - val_accuracy: 0.7708\n",
      "Epoch 180/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5142 - accuracy: 0.7517 - val_loss: 0.5226 - val_accuracy: 0.7760\n",
      "Epoch 181/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5139 - accuracy: 0.7517 - val_loss: 0.5224 - val_accuracy: 0.7760\n",
      "Epoch 182/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5137 - accuracy: 0.7535 - val_loss: 0.5222 - val_accuracy: 0.7760\n",
      "Epoch 183/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5135 - accuracy: 0.7552 - val_loss: 0.5220 - val_accuracy: 0.7760\n",
      "Epoch 184/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5133 - accuracy: 0.7552 - val_loss: 0.5218 - val_accuracy: 0.7760\n",
      "Epoch 185/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5131 - accuracy: 0.7552 - val_loss: 0.5216 - val_accuracy: 0.7760\n",
      "Epoch 186/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5129 - accuracy: 0.7552 - val_loss: 0.5214 - val_accuracy: 0.7708\n",
      "Epoch 187/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5126 - accuracy: 0.7552 - val_loss: 0.5212 - val_accuracy: 0.7708\n",
      "Epoch 188/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5124 - accuracy: 0.7552 - val_loss: 0.5211 - val_accuracy: 0.7760\n",
      "Epoch 189/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5122 - accuracy: 0.7552 - val_loss: 0.5209 - val_accuracy: 0.7760\n",
      "Epoch 190/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5120 - accuracy: 0.7569 - val_loss: 0.5207 - val_accuracy: 0.7812\n",
      "Epoch 191/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5118 - accuracy: 0.7587 - val_loss: 0.5205 - val_accuracy: 0.7812\n",
      "Epoch 192/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5116 - accuracy: 0.7569 - val_loss: 0.5203 - val_accuracy: 0.7812\n",
      "Epoch 193/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5114 - accuracy: 0.7552 - val_loss: 0.5201 - val_accuracy: 0.7812\n",
      "Epoch 194/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5111 - accuracy: 0.7552 - val_loss: 0.5199 - val_accuracy: 0.7812\n",
      "Epoch 195/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5109 - accuracy: 0.7552 - val_loss: 0.5197 - val_accuracy: 0.7812\n",
      "Epoch 196/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5107 - accuracy: 0.7587 - val_loss: 0.5196 - val_accuracy: 0.7812\n",
      "Epoch 197/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5105 - accuracy: 0.7552 - val_loss: 0.5194 - val_accuracy: 0.7812\n",
      "Epoch 198/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5103 - accuracy: 0.7587 - val_loss: 0.5192 - val_accuracy: 0.7812\n",
      "Epoch 199/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5101 - accuracy: 0.7587 - val_loss: 0.5190 - val_accuracy: 0.7812\n",
      "Epoch 200/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5099 - accuracy: 0.7587 - val_loss: 0.5188 - val_accuracy: 0.7812\n",
      "Epoch 201/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5097 - accuracy: 0.7569 - val_loss: 0.5187 - val_accuracy: 0.7812\n",
      "Epoch 202/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5095 - accuracy: 0.7587 - val_loss: 0.5185 - val_accuracy: 0.7812\n",
      "Epoch 203/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5093 - accuracy: 0.7587 - val_loss: 0.5183 - val_accuracy: 0.7812\n",
      "Epoch 204/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5091 - accuracy: 0.7587 - val_loss: 0.5181 - val_accuracy: 0.7812\n",
      "Epoch 205/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5089 - accuracy: 0.7587 - val_loss: 0.5180 - val_accuracy: 0.7812\n",
      "Epoch 206/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5087 - accuracy: 0.7587 - val_loss: 0.5178 - val_accuracy: 0.7812\n",
      "Epoch 207/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5085 - accuracy: 0.7587 - val_loss: 0.5176 - val_accuracy: 0.7812\n",
      "Epoch 208/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5083 - accuracy: 0.7587 - val_loss: 0.5174 - val_accuracy: 0.7812\n",
      "Epoch 209/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5081 - accuracy: 0.7587 - val_loss: 0.5173 - val_accuracy: 0.7812\n",
      "Epoch 210/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5079 - accuracy: 0.7587 - val_loss: 0.5171 - val_accuracy: 0.7812\n",
      "Epoch 211/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5077 - accuracy: 0.7587 - val_loss: 0.5169 - val_accuracy: 0.7812\n",
      "Epoch 212/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5075 - accuracy: 0.7587 - val_loss: 0.5168 - val_accuracy: 0.7812\n",
      "Epoch 213/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5073 - accuracy: 0.7587 - val_loss: 0.5166 - val_accuracy: 0.7812\n",
      "Epoch 214/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5071 - accuracy: 0.7587 - val_loss: 0.5164 - val_accuracy: 0.7812\n",
      "Epoch 215/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5069 - accuracy: 0.7587 - val_loss: 0.5163 - val_accuracy: 0.7812\n",
      "Epoch 216/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5068 - accuracy: 0.7587 - val_loss: 0.5161 - val_accuracy: 0.7812\n",
      "Epoch 217/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5066 - accuracy: 0.7587 - val_loss: 0.5159 - val_accuracy: 0.7812\n",
      "Epoch 218/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5064 - accuracy: 0.7587 - val_loss: 0.5158 - val_accuracy: 0.7812\n",
      "Epoch 219/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5062 - accuracy: 0.7587 - val_loss: 0.5156 - val_accuracy: 0.7812\n",
      "Epoch 220/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5060 - accuracy: 0.7587 - val_loss: 0.5154 - val_accuracy: 0.7760\n",
      "Epoch 221/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5058 - accuracy: 0.7587 - val_loss: 0.5153 - val_accuracy: 0.7760\n",
      "Epoch 222/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5056 - accuracy: 0.7604 - val_loss: 0.5151 - val_accuracy: 0.7760\n",
      "Epoch 223/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.7604 - val_loss: 0.5149 - val_accuracy: 0.7760\n",
      "Epoch 224/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5052 - accuracy: 0.7604 - val_loss: 0.5148 - val_accuracy: 0.7760\n",
      "Epoch 225/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5051 - accuracy: 0.7604 - val_loss: 0.5146 - val_accuracy: 0.7760\n",
      "Epoch 226/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5049 - accuracy: 0.7604 - val_loss: 0.5145 - val_accuracy: 0.7760\n",
      "Epoch 227/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5047 - accuracy: 0.7604 - val_loss: 0.5143 - val_accuracy: 0.7760\n",
      "Epoch 228/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5045 - accuracy: 0.7604 - val_loss: 0.5141 - val_accuracy: 0.7760\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 229/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5043 - accuracy: 0.7604 - val_loss: 0.5140 - val_accuracy: 0.7760\n",
      "Epoch 230/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5041 - accuracy: 0.7604 - val_loss: 0.5138 - val_accuracy: 0.7760\n",
      "Epoch 231/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5040 - accuracy: 0.7604 - val_loss: 0.5137 - val_accuracy: 0.7708\n",
      "Epoch 232/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5038 - accuracy: 0.7604 - val_loss: 0.5135 - val_accuracy: 0.7708\n",
      "Epoch 233/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5036 - accuracy: 0.7639 - val_loss: 0.5134 - val_accuracy: 0.7708\n",
      "Epoch 234/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5034 - accuracy: 0.7622 - val_loss: 0.5132 - val_accuracy: 0.7708\n",
      "Epoch 235/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5033 - accuracy: 0.7622 - val_loss: 0.5131 - val_accuracy: 0.7708\n",
      "Epoch 236/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5031 - accuracy: 0.7622 - val_loss: 0.5129 - val_accuracy: 0.7708\n",
      "Epoch 237/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5029 - accuracy: 0.7639 - val_loss: 0.5128 - val_accuracy: 0.7708\n",
      "Epoch 238/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5027 - accuracy: 0.7639 - val_loss: 0.5126 - val_accuracy: 0.7708\n",
      "Epoch 239/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5025 - accuracy: 0.7639 - val_loss: 0.5125 - val_accuracy: 0.7708\n",
      "Epoch 240/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5024 - accuracy: 0.7622 - val_loss: 0.5123 - val_accuracy: 0.7708\n",
      "Epoch 241/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5022 - accuracy: 0.7622 - val_loss: 0.5122 - val_accuracy: 0.7708\n",
      "Epoch 242/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5020 - accuracy: 0.7639 - val_loss: 0.5120 - val_accuracy: 0.7708\n",
      "Epoch 243/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5018 - accuracy: 0.7639 - val_loss: 0.5119 - val_accuracy: 0.7708\n",
      "Epoch 244/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5017 - accuracy: 0.7639 - val_loss: 0.5117 - val_accuracy: 0.7708\n",
      "Epoch 245/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5015 - accuracy: 0.7639 - val_loss: 0.5116 - val_accuracy: 0.7708\n",
      "Epoch 246/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5014 - accuracy: 0.7622 - val_loss: 0.5114 - val_accuracy: 0.7708\n",
      "Epoch 247/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5012 - accuracy: 0.7639 - val_loss: 0.5113 - val_accuracy: 0.7708\n",
      "Epoch 248/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5010 - accuracy: 0.7639 - val_loss: 0.5112 - val_accuracy: 0.7708\n",
      "Epoch 249/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5008 - accuracy: 0.7639 - val_loss: 0.5110 - val_accuracy: 0.7708\n",
      "Epoch 250/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5007 - accuracy: 0.7622 - val_loss: 0.5109 - val_accuracy: 0.7708\n",
      "Epoch 251/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5005 - accuracy: 0.7639 - val_loss: 0.5107 - val_accuracy: 0.7708\n",
      "Epoch 252/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5003 - accuracy: 0.7622 - val_loss: 0.5106 - val_accuracy: 0.7708\n",
      "Epoch 253/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5002 - accuracy: 0.7622 - val_loss: 0.5105 - val_accuracy: 0.7656\n",
      "Epoch 254/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5000 - accuracy: 0.7604 - val_loss: 0.5103 - val_accuracy: 0.7656\n",
      "Epoch 255/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4999 - accuracy: 0.7622 - val_loss: 0.5102 - val_accuracy: 0.7656\n",
      "Epoch 256/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4997 - accuracy: 0.7604 - val_loss: 0.5100 - val_accuracy: 0.7708\n",
      "Epoch 257/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4995 - accuracy: 0.7622 - val_loss: 0.5099 - val_accuracy: 0.7708\n",
      "Epoch 258/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4993 - accuracy: 0.7604 - val_loss: 0.5098 - val_accuracy: 0.7708\n",
      "Epoch 259/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4992 - accuracy: 0.7604 - val_loss: 0.5096 - val_accuracy: 0.7708\n",
      "Epoch 260/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4990 - accuracy: 0.7604 - val_loss: 0.5095 - val_accuracy: 0.7708\n",
      "Epoch 261/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4989 - accuracy: 0.7604 - val_loss: 0.5094 - val_accuracy: 0.7708\n",
      "Epoch 262/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4987 - accuracy: 0.7604 - val_loss: 0.5092 - val_accuracy: 0.7656\n",
      "Epoch 263/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4985 - accuracy: 0.7604 - val_loss: 0.5091 - val_accuracy: 0.7656\n",
      "Epoch 264/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4984 - accuracy: 0.7604 - val_loss: 0.5090 - val_accuracy: 0.7656\n",
      "Epoch 265/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4982 - accuracy: 0.7604 - val_loss: 0.5088 - val_accuracy: 0.7656\n",
      "Epoch 266/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4981 - accuracy: 0.7622 - val_loss: 0.5087 - val_accuracy: 0.7656\n",
      "Epoch 267/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4979 - accuracy: 0.7622 - val_loss: 0.5086 - val_accuracy: 0.7656\n",
      "Epoch 268/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4978 - accuracy: 0.7622 - val_loss: 0.5085 - val_accuracy: 0.7656\n",
      "Epoch 269/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4976 - accuracy: 0.7622 - val_loss: 0.5083 - val_accuracy: 0.7656\n",
      "Epoch 270/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4975 - accuracy: 0.7639 - val_loss: 0.5082 - val_accuracy: 0.7656\n",
      "Epoch 271/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4973 - accuracy: 0.7639 - val_loss: 0.5081 - val_accuracy: 0.7656\n",
      "Epoch 272/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4972 - accuracy: 0.7639 - val_loss: 0.5079 - val_accuracy: 0.7656\n",
      "Epoch 273/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4970 - accuracy: 0.7639 - val_loss: 0.5078 - val_accuracy: 0.7656\n",
      "Epoch 274/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4969 - accuracy: 0.7639 - val_loss: 0.5077 - val_accuracy: 0.7656\n",
      "Epoch 275/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4967 - accuracy: 0.7639 - val_loss: 0.5076 - val_accuracy: 0.7656\n",
      "Epoch 276/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4966 - accuracy: 0.7639 - val_loss: 0.5074 - val_accuracy: 0.7656\n",
      "Epoch 277/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4964 - accuracy: 0.7656 - val_loss: 0.5073 - val_accuracy: 0.7656\n",
      "Epoch 278/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4963 - accuracy: 0.7656 - val_loss: 0.5072 - val_accuracy: 0.7656\n",
      "Epoch 279/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4961 - accuracy: 0.7656 - val_loss: 0.5071 - val_accuracy: 0.7656\n",
      "Epoch 280/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4960 - accuracy: 0.7656 - val_loss: 0.5069 - val_accuracy: 0.7656\n",
      "Epoch 281/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4958 - accuracy: 0.7656 - val_loss: 0.5068 - val_accuracy: 0.7656\n",
      "Epoch 282/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4957 - accuracy: 0.7656 - val_loss: 0.5067 - val_accuracy: 0.7656\n",
      "Epoch 283/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4955 - accuracy: 0.7656 - val_loss: 0.5066 - val_accuracy: 0.7656\n",
      "Epoch 284/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4954 - accuracy: 0.7656 - val_loss: 0.5065 - val_accuracy: 0.7656\n",
      "Epoch 285/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4952 - accuracy: 0.7674 - val_loss: 0.5063 - val_accuracy: 0.7656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 286/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4951 - accuracy: 0.7656 - val_loss: 0.5062 - val_accuracy: 0.7656\n",
      "Epoch 287/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4949 - accuracy: 0.7674 - val_loss: 0.5061 - val_accuracy: 0.7708\n",
      "Epoch 288/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4948 - accuracy: 0.7674 - val_loss: 0.5060 - val_accuracy: 0.7708\n",
      "Epoch 289/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4947 - accuracy: 0.7674 - val_loss: 0.5059 - val_accuracy: 0.7708\n",
      "Epoch 290/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4945 - accuracy: 0.7674 - val_loss: 0.5058 - val_accuracy: 0.7708\n",
      "Epoch 291/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4944 - accuracy: 0.7674 - val_loss: 0.5056 - val_accuracy: 0.7708\n",
      "Epoch 292/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4942 - accuracy: 0.7674 - val_loss: 0.5055 - val_accuracy: 0.7708\n",
      "Epoch 293/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4941 - accuracy: 0.7691 - val_loss: 0.5054 - val_accuracy: 0.7708\n",
      "Epoch 294/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4940 - accuracy: 0.7691 - val_loss: 0.5053 - val_accuracy: 0.7708\n",
      "Epoch 295/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4938 - accuracy: 0.7691 - val_loss: 0.5052 - val_accuracy: 0.7708\n",
      "Epoch 296/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4937 - accuracy: 0.7691 - val_loss: 0.5051 - val_accuracy: 0.7708\n",
      "Epoch 297/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4935 - accuracy: 0.7674 - val_loss: 0.5050 - val_accuracy: 0.7708\n",
      "Epoch 298/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4934 - accuracy: 0.7674 - val_loss: 0.5049 - val_accuracy: 0.7708\n",
      "Epoch 299/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4933 - accuracy: 0.7674 - val_loss: 0.5047 - val_accuracy: 0.7708\n",
      "Epoch 300/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4931 - accuracy: 0.7674 - val_loss: 0.5046 - val_accuracy: 0.7708\n",
      "Epoch 301/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4930 - accuracy: 0.7674 - val_loss: 0.5045 - val_accuracy: 0.7708\n",
      "Epoch 302/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4929 - accuracy: 0.7674 - val_loss: 0.5044 - val_accuracy: 0.7708\n",
      "Epoch 303/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4927 - accuracy: 0.7691 - val_loss: 0.5043 - val_accuracy: 0.7708\n",
      "Epoch 304/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4926 - accuracy: 0.7691 - val_loss: 0.5042 - val_accuracy: 0.7708\n",
      "Epoch 305/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4925 - accuracy: 0.7691 - val_loss: 0.5041 - val_accuracy: 0.7708\n",
      "Epoch 306/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4923 - accuracy: 0.7691 - val_loss: 0.5040 - val_accuracy: 0.7708\n",
      "Epoch 307/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4922 - accuracy: 0.7691 - val_loss: 0.5039 - val_accuracy: 0.7708\n",
      "Epoch 308/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4921 - accuracy: 0.7691 - val_loss: 0.5038 - val_accuracy: 0.7708\n",
      "Epoch 309/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4919 - accuracy: 0.7691 - val_loss: 0.5037 - val_accuracy: 0.7708\n",
      "Epoch 310/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4918 - accuracy: 0.7691 - val_loss: 0.5036 - val_accuracy: 0.7708\n",
      "Epoch 311/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4917 - accuracy: 0.7691 - val_loss: 0.5035 - val_accuracy: 0.7708\n",
      "Epoch 312/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4915 - accuracy: 0.7691 - val_loss: 0.5034 - val_accuracy: 0.7708\n",
      "Epoch 313/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4914 - accuracy: 0.7691 - val_loss: 0.5033 - val_accuracy: 0.7708\n",
      "Epoch 314/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4913 - accuracy: 0.7691 - val_loss: 0.5032 - val_accuracy: 0.7708\n",
      "Epoch 315/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4911 - accuracy: 0.7674 - val_loss: 0.5031 - val_accuracy: 0.7708\n",
      "Epoch 316/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4910 - accuracy: 0.7674 - val_loss: 0.5030 - val_accuracy: 0.7656\n",
      "Epoch 317/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4909 - accuracy: 0.7674 - val_loss: 0.5028 - val_accuracy: 0.7656\n",
      "Epoch 318/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4908 - accuracy: 0.7674 - val_loss: 0.5028 - val_accuracy: 0.7656\n",
      "Epoch 319/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4906 - accuracy: 0.7674 - val_loss: 0.5027 - val_accuracy: 0.7656\n",
      "Epoch 320/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4905 - accuracy: 0.7674 - val_loss: 0.5026 - val_accuracy: 0.7656\n",
      "Epoch 321/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4904 - accuracy: 0.7674 - val_loss: 0.5025 - val_accuracy: 0.7656\n",
      "Epoch 322/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4903 - accuracy: 0.7674 - val_loss: 0.5024 - val_accuracy: 0.7656\n",
      "Epoch 323/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4901 - accuracy: 0.7674 - val_loss: 0.5023 - val_accuracy: 0.7656\n",
      "Epoch 324/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4900 - accuracy: 0.7674 - val_loss: 0.5022 - val_accuracy: 0.7656\n",
      "Epoch 325/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4899 - accuracy: 0.7674 - val_loss: 0.5021 - val_accuracy: 0.7656\n",
      "Epoch 326/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4898 - accuracy: 0.7674 - val_loss: 0.5020 - val_accuracy: 0.7656\n",
      "Epoch 327/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4897 - accuracy: 0.7674 - val_loss: 0.5019 - val_accuracy: 0.7656\n",
      "Epoch 328/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4895 - accuracy: 0.7674 - val_loss: 0.5018 - val_accuracy: 0.7656\n",
      "Epoch 329/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4894 - accuracy: 0.7674 - val_loss: 0.5017 - val_accuracy: 0.7656\n",
      "Epoch 330/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4893 - accuracy: 0.7674 - val_loss: 0.5016 - val_accuracy: 0.7656\n",
      "Epoch 331/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4892 - accuracy: 0.7674 - val_loss: 0.5015 - val_accuracy: 0.7656\n",
      "Epoch 332/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4891 - accuracy: 0.7674 - val_loss: 0.5014 - val_accuracy: 0.7656\n",
      "Epoch 333/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4889 - accuracy: 0.7674 - val_loss: 0.5013 - val_accuracy: 0.7656\n",
      "Epoch 334/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4888 - accuracy: 0.7674 - val_loss: 0.5012 - val_accuracy: 0.7656\n",
      "Epoch 335/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4887 - accuracy: 0.7674 - val_loss: 0.5011 - val_accuracy: 0.7656\n",
      "Epoch 336/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4886 - accuracy: 0.7674 - val_loss: 0.5010 - val_accuracy: 0.7656\n",
      "Epoch 337/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4885 - accuracy: 0.7674 - val_loss: 0.5009 - val_accuracy: 0.7656\n",
      "Epoch 338/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4884 - accuracy: 0.7674 - val_loss: 0.5008 - val_accuracy: 0.7656\n",
      "Epoch 339/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4882 - accuracy: 0.7674 - val_loss: 0.5008 - val_accuracy: 0.7656\n",
      "Epoch 340/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4881 - accuracy: 0.7674 - val_loss: 0.5007 - val_accuracy: 0.7656\n",
      "Epoch 341/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4880 - accuracy: 0.7674 - val_loss: 0.5006 - val_accuracy: 0.7656\n",
      "Epoch 342/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4879 - accuracy: 0.7674 - val_loss: 0.5005 - val_accuracy: 0.7656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 343/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4878 - accuracy: 0.7674 - val_loss: 0.5004 - val_accuracy: 0.7656\n",
      "Epoch 344/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4877 - accuracy: 0.7674 - val_loss: 0.5003 - val_accuracy: 0.7656\n",
      "Epoch 345/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4876 - accuracy: 0.7691 - val_loss: 0.5002 - val_accuracy: 0.7656\n",
      "Epoch 346/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4874 - accuracy: 0.7691 - val_loss: 0.5001 - val_accuracy: 0.7604\n",
      "Epoch 347/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4873 - accuracy: 0.7691 - val_loss: 0.5001 - val_accuracy: 0.7604\n",
      "Epoch 348/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4872 - accuracy: 0.7691 - val_loss: 0.5000 - val_accuracy: 0.7604\n",
      "Epoch 349/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4871 - accuracy: 0.7691 - val_loss: 0.4999 - val_accuracy: 0.7604\n",
      "Epoch 350/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4870 - accuracy: 0.7691 - val_loss: 0.4998 - val_accuracy: 0.7604\n",
      "Epoch 351/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4869 - accuracy: 0.7691 - val_loss: 0.4997 - val_accuracy: 0.7604\n",
      "Epoch 352/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4868 - accuracy: 0.7691 - val_loss: 0.4996 - val_accuracy: 0.7604\n",
      "Epoch 353/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4867 - accuracy: 0.7691 - val_loss: 0.4995 - val_accuracy: 0.7604\n",
      "Epoch 354/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4865 - accuracy: 0.7691 - val_loss: 0.4995 - val_accuracy: 0.7604\n",
      "Epoch 355/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4864 - accuracy: 0.7691 - val_loss: 0.4994 - val_accuracy: 0.7604\n",
      "Epoch 356/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4863 - accuracy: 0.7691 - val_loss: 0.4993 - val_accuracy: 0.7604\n",
      "Epoch 357/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4863 - accuracy: 0.7691 - val_loss: 0.4992 - val_accuracy: 0.7656\n",
      "Epoch 358/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4861 - accuracy: 0.7691 - val_loss: 0.4991 - val_accuracy: 0.7656\n",
      "Epoch 359/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4860 - accuracy: 0.7691 - val_loss: 0.4991 - val_accuracy: 0.7656\n",
      "Epoch 360/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4859 - accuracy: 0.7691 - val_loss: 0.4990 - val_accuracy: 0.7604\n",
      "Epoch 361/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4858 - accuracy: 0.7691 - val_loss: 0.4989 - val_accuracy: 0.7604\n",
      "Epoch 362/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4857 - accuracy: 0.7691 - val_loss: 0.4988 - val_accuracy: 0.7604\n",
      "Epoch 363/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4856 - accuracy: 0.7691 - val_loss: 0.4987 - val_accuracy: 0.7604\n",
      "Epoch 364/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4855 - accuracy: 0.7691 - val_loss: 0.4987 - val_accuracy: 0.7604\n",
      "Epoch 365/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4854 - accuracy: 0.7691 - val_loss: 0.4986 - val_accuracy: 0.7604\n",
      "Epoch 366/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4853 - accuracy: 0.7691 - val_loss: 0.4985 - val_accuracy: 0.7604\n",
      "Epoch 367/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4852 - accuracy: 0.7691 - val_loss: 0.4984 - val_accuracy: 0.7604\n",
      "Epoch 368/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4851 - accuracy: 0.7691 - val_loss: 0.4983 - val_accuracy: 0.7604\n",
      "Epoch 369/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4850 - accuracy: 0.7674 - val_loss: 0.4983 - val_accuracy: 0.7604\n",
      "Epoch 370/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4849 - accuracy: 0.7674 - val_loss: 0.4982 - val_accuracy: 0.7604\n",
      "Epoch 371/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4848 - accuracy: 0.7674 - val_loss: 0.4981 - val_accuracy: 0.7604\n",
      "Epoch 372/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4847 - accuracy: 0.7674 - val_loss: 0.4980 - val_accuracy: 0.7604\n",
      "Epoch 373/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4846 - accuracy: 0.7674 - val_loss: 0.4980 - val_accuracy: 0.7604\n",
      "Epoch 374/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4845 - accuracy: 0.7656 - val_loss: 0.4979 - val_accuracy: 0.7604\n",
      "Epoch 375/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4844 - accuracy: 0.7656 - val_loss: 0.4978 - val_accuracy: 0.7604\n",
      "Epoch 376/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4843 - accuracy: 0.7674 - val_loss: 0.4977 - val_accuracy: 0.7604\n",
      "Epoch 377/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4842 - accuracy: 0.7656 - val_loss: 0.4977 - val_accuracy: 0.7604\n",
      "Epoch 378/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4841 - accuracy: 0.7656 - val_loss: 0.4976 - val_accuracy: 0.7604\n",
      "Epoch 379/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4840 - accuracy: 0.7656 - val_loss: 0.4975 - val_accuracy: 0.7604\n",
      "Epoch 380/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4839 - accuracy: 0.7656 - val_loss: 0.4974 - val_accuracy: 0.7604\n",
      "Epoch 381/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4838 - accuracy: 0.7656 - val_loss: 0.4974 - val_accuracy: 0.7604\n",
      "Epoch 382/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4837 - accuracy: 0.7656 - val_loss: 0.4973 - val_accuracy: 0.7604\n",
      "Epoch 383/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4836 - accuracy: 0.7656 - val_loss: 0.4972 - val_accuracy: 0.7604\n",
      "Epoch 384/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4835 - accuracy: 0.7656 - val_loss: 0.4971 - val_accuracy: 0.7604\n",
      "Epoch 385/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4834 - accuracy: 0.7656 - val_loss: 0.4971 - val_accuracy: 0.7604\n",
      "Epoch 386/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4833 - accuracy: 0.7656 - val_loss: 0.4970 - val_accuracy: 0.7604\n",
      "Epoch 387/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4832 - accuracy: 0.7656 - val_loss: 0.4969 - val_accuracy: 0.7604\n",
      "Epoch 388/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4831 - accuracy: 0.7674 - val_loss: 0.4969 - val_accuracy: 0.7604\n",
      "Epoch 389/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4830 - accuracy: 0.7674 - val_loss: 0.4968 - val_accuracy: 0.7604\n",
      "Epoch 390/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4829 - accuracy: 0.7656 - val_loss: 0.4967 - val_accuracy: 0.7604\n",
      "Epoch 391/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4828 - accuracy: 0.7656 - val_loss: 0.4967 - val_accuracy: 0.7656\n",
      "Epoch 392/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4827 - accuracy: 0.7674 - val_loss: 0.4966 - val_accuracy: 0.7656\n",
      "Epoch 393/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4826 - accuracy: 0.7674 - val_loss: 0.4965 - val_accuracy: 0.7656\n",
      "Epoch 394/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4825 - accuracy: 0.7674 - val_loss: 0.4965 - val_accuracy: 0.7656\n",
      "Epoch 395/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4824 - accuracy: 0.7674 - val_loss: 0.4964 - val_accuracy: 0.7656\n",
      "Epoch 396/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4823 - accuracy: 0.7674 - val_loss: 0.4963 - val_accuracy: 0.7656\n",
      "Epoch 397/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4823 - accuracy: 0.7674 - val_loss: 0.4963 - val_accuracy: 0.7656\n",
      "Epoch 398/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4822 - accuracy: 0.7674 - val_loss: 0.4962 - val_accuracy: 0.7656\n",
      "Epoch 399/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4821 - accuracy: 0.7674 - val_loss: 0.4961 - val_accuracy: 0.7656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4820 - accuracy: 0.7674 - val_loss: 0.4961 - val_accuracy: 0.7656\n",
      "Epoch 401/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4819 - accuracy: 0.7674 - val_loss: 0.4960 - val_accuracy: 0.7656\n",
      "Epoch 402/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4818 - accuracy: 0.7674 - val_loss: 0.4959 - val_accuracy: 0.7656\n",
      "Epoch 403/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4817 - accuracy: 0.7674 - val_loss: 0.4959 - val_accuracy: 0.7656\n",
      "Epoch 404/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4816 - accuracy: 0.7674 - val_loss: 0.4958 - val_accuracy: 0.7656\n",
      "Epoch 405/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4815 - accuracy: 0.7674 - val_loss: 0.4957 - val_accuracy: 0.7656\n",
      "Epoch 406/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4814 - accuracy: 0.7674 - val_loss: 0.4957 - val_accuracy: 0.7656\n",
      "Epoch 407/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4813 - accuracy: 0.7674 - val_loss: 0.4956 - val_accuracy: 0.7656\n",
      "Epoch 408/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4813 - accuracy: 0.7674 - val_loss: 0.4955 - val_accuracy: 0.7656\n",
      "Epoch 409/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4812 - accuracy: 0.7674 - val_loss: 0.4955 - val_accuracy: 0.7656\n",
      "Epoch 410/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4811 - accuracy: 0.7674 - val_loss: 0.4954 - val_accuracy: 0.7656\n",
      "Epoch 411/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4810 - accuracy: 0.7674 - val_loss: 0.4954 - val_accuracy: 0.7656\n",
      "Epoch 412/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4809 - accuracy: 0.7674 - val_loss: 0.4953 - val_accuracy: 0.7656\n",
      "Epoch 413/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4808 - accuracy: 0.7674 - val_loss: 0.4952 - val_accuracy: 0.7656\n",
      "Epoch 414/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4807 - accuracy: 0.7674 - val_loss: 0.4952 - val_accuracy: 0.7656\n",
      "Epoch 415/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4807 - accuracy: 0.7656 - val_loss: 0.4951 - val_accuracy: 0.7656\n",
      "Epoch 416/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4806 - accuracy: 0.7674 - val_loss: 0.4951 - val_accuracy: 0.7656\n",
      "Epoch 417/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4805 - accuracy: 0.7674 - val_loss: 0.4950 - val_accuracy: 0.7656\n",
      "Epoch 418/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4804 - accuracy: 0.7674 - val_loss: 0.4949 - val_accuracy: 0.7656\n",
      "Epoch 419/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4803 - accuracy: 0.7674 - val_loss: 0.4949 - val_accuracy: 0.7656\n",
      "Epoch 420/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4802 - accuracy: 0.7691 - val_loss: 0.4948 - val_accuracy: 0.7656\n",
      "Epoch 421/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4802 - accuracy: 0.7691 - val_loss: 0.4948 - val_accuracy: 0.7656\n",
      "Epoch 422/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4801 - accuracy: 0.7691 - val_loss: 0.4947 - val_accuracy: 0.7656\n",
      "Epoch 423/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4800 - accuracy: 0.7674 - val_loss: 0.4946 - val_accuracy: 0.7656\n",
      "Epoch 424/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4799 - accuracy: 0.7691 - val_loss: 0.4946 - val_accuracy: 0.7656\n",
      "Epoch 425/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4798 - accuracy: 0.7691 - val_loss: 0.4945 - val_accuracy: 0.7656\n",
      "Epoch 426/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4797 - accuracy: 0.7691 - val_loss: 0.4945 - val_accuracy: 0.7656\n",
      "Epoch 427/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4797 - accuracy: 0.7691 - val_loss: 0.4944 - val_accuracy: 0.7656\n",
      "Epoch 428/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4796 - accuracy: 0.7691 - val_loss: 0.4944 - val_accuracy: 0.7656\n",
      "Epoch 429/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4795 - accuracy: 0.7708 - val_loss: 0.4943 - val_accuracy: 0.7656\n",
      "Epoch 430/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4794 - accuracy: 0.7708 - val_loss: 0.4942 - val_accuracy: 0.7656\n",
      "Epoch 431/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4794 - accuracy: 0.7708 - val_loss: 0.4942 - val_accuracy: 0.7656\n",
      "Epoch 432/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4793 - accuracy: 0.7708 - val_loss: 0.4941 - val_accuracy: 0.7656\n",
      "Epoch 433/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4792 - accuracy: 0.7708 - val_loss: 0.4941 - val_accuracy: 0.7656\n",
      "Epoch 434/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4791 - accuracy: 0.7708 - val_loss: 0.4940 - val_accuracy: 0.7656\n",
      "Epoch 435/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4790 - accuracy: 0.7708 - val_loss: 0.4940 - val_accuracy: 0.7656\n",
      "Epoch 436/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4790 - accuracy: 0.7708 - val_loss: 0.4939 - val_accuracy: 0.7656\n",
      "Epoch 437/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4789 - accuracy: 0.7708 - val_loss: 0.4939 - val_accuracy: 0.7656\n",
      "Epoch 438/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4788 - accuracy: 0.7708 - val_loss: 0.4938 - val_accuracy: 0.7656\n",
      "Epoch 439/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4787 - accuracy: 0.7708 - val_loss: 0.4938 - val_accuracy: 0.7656\n",
      "Epoch 440/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4786 - accuracy: 0.7708 - val_loss: 0.4937 - val_accuracy: 0.7656\n",
      "Epoch 441/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4786 - accuracy: 0.7708 - val_loss: 0.4936 - val_accuracy: 0.7656\n",
      "Epoch 442/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4785 - accuracy: 0.7708 - val_loss: 0.4936 - val_accuracy: 0.7656\n",
      "Epoch 443/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4784 - accuracy: 0.7708 - val_loss: 0.4935 - val_accuracy: 0.7656\n",
      "Epoch 444/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4783 - accuracy: 0.7726 - val_loss: 0.4935 - val_accuracy: 0.7656\n",
      "Epoch 445/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4783 - accuracy: 0.7708 - val_loss: 0.4934 - val_accuracy: 0.7656\n",
      "Epoch 446/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4782 - accuracy: 0.7708 - val_loss: 0.4934 - val_accuracy: 0.7656\n",
      "Epoch 447/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4781 - accuracy: 0.7708 - val_loss: 0.4933 - val_accuracy: 0.7656\n",
      "Epoch 448/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4780 - accuracy: 0.7708 - val_loss: 0.4933 - val_accuracy: 0.7656\n",
      "Epoch 449/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4779 - accuracy: 0.7708 - val_loss: 0.4932 - val_accuracy: 0.7656\n",
      "Epoch 450/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4779 - accuracy: 0.7708 - val_loss: 0.4932 - val_accuracy: 0.7656\n",
      "Epoch 451/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4778 - accuracy: 0.7708 - val_loss: 0.4931 - val_accuracy: 0.7656\n",
      "Epoch 452/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4777 - accuracy: 0.7708 - val_loss: 0.4931 - val_accuracy: 0.7656\n",
      "Epoch 453/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4776 - accuracy: 0.7708 - val_loss: 0.4930 - val_accuracy: 0.7656\n",
      "Epoch 454/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4776 - accuracy: 0.7708 - val_loss: 0.4930 - val_accuracy: 0.7656\n",
      "Epoch 455/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4775 - accuracy: 0.7691 - val_loss: 0.4929 - val_accuracy: 0.7656\n",
      "Epoch 456/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4774 - accuracy: 0.7708 - val_loss: 0.4929 - val_accuracy: 0.7656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 457/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4774 - accuracy: 0.7691 - val_loss: 0.4928 - val_accuracy: 0.7656\n",
      "Epoch 458/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4773 - accuracy: 0.7708 - val_loss: 0.4928 - val_accuracy: 0.7656\n",
      "Epoch 459/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4772 - accuracy: 0.7708 - val_loss: 0.4927 - val_accuracy: 0.7656\n",
      "Epoch 460/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4771 - accuracy: 0.7708 - val_loss: 0.4927 - val_accuracy: 0.7656\n",
      "Epoch 461/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4771 - accuracy: 0.7708 - val_loss: 0.4927 - val_accuracy: 0.7656\n",
      "Epoch 462/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4770 - accuracy: 0.7691 - val_loss: 0.4926 - val_accuracy: 0.7656\n",
      "Epoch 463/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4769 - accuracy: 0.7708 - val_loss: 0.4926 - val_accuracy: 0.7656\n",
      "Epoch 464/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4768 - accuracy: 0.7691 - val_loss: 0.4925 - val_accuracy: 0.7656\n",
      "Epoch 465/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4768 - accuracy: 0.7708 - val_loss: 0.4925 - val_accuracy: 0.7656\n",
      "Epoch 466/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4767 - accuracy: 0.7674 - val_loss: 0.4924 - val_accuracy: 0.7656\n",
      "Epoch 467/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4767 - accuracy: 0.7691 - val_loss: 0.4924 - val_accuracy: 0.7656\n",
      "Epoch 468/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4766 - accuracy: 0.7674 - val_loss: 0.4923 - val_accuracy: 0.7656\n",
      "Epoch 469/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4765 - accuracy: 0.7691 - val_loss: 0.4923 - val_accuracy: 0.7656\n",
      "Epoch 470/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4764 - accuracy: 0.7691 - val_loss: 0.4922 - val_accuracy: 0.7604\n",
      "Epoch 471/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4764 - accuracy: 0.7674 - val_loss: 0.4922 - val_accuracy: 0.7604\n",
      "Epoch 472/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4763 - accuracy: 0.7691 - val_loss: 0.4921 - val_accuracy: 0.7604\n",
      "Epoch 473/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4762 - accuracy: 0.7691 - val_loss: 0.4921 - val_accuracy: 0.7604\n",
      "Epoch 474/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4762 - accuracy: 0.7691 - val_loss: 0.4921 - val_accuracy: 0.7604\n",
      "Epoch 475/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4761 - accuracy: 0.7691 - val_loss: 0.4920 - val_accuracy: 0.7604\n",
      "Epoch 476/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4760 - accuracy: 0.7674 - val_loss: 0.4920 - val_accuracy: 0.7604\n",
      "Epoch 477/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4760 - accuracy: 0.7674 - val_loss: 0.4919 - val_accuracy: 0.7604\n",
      "Epoch 478/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4759 - accuracy: 0.7674 - val_loss: 0.4919 - val_accuracy: 0.7604\n",
      "Epoch 479/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4758 - accuracy: 0.7674 - val_loss: 0.4918 - val_accuracy: 0.7604\n",
      "Epoch 480/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4758 - accuracy: 0.7674 - val_loss: 0.4918 - val_accuracy: 0.7604\n",
      "Epoch 481/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4757 - accuracy: 0.7674 - val_loss: 0.4918 - val_accuracy: 0.7604\n",
      "Epoch 482/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4756 - accuracy: 0.7674 - val_loss: 0.4917 - val_accuracy: 0.7604\n",
      "Epoch 483/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4756 - accuracy: 0.7691 - val_loss: 0.4917 - val_accuracy: 0.7604\n",
      "Epoch 484/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4755 - accuracy: 0.7691 - val_loss: 0.4916 - val_accuracy: 0.7604\n",
      "Epoch 485/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4754 - accuracy: 0.7708 - val_loss: 0.4916 - val_accuracy: 0.7604\n",
      "Epoch 486/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4754 - accuracy: 0.7691 - val_loss: 0.4916 - val_accuracy: 0.7604\n",
      "Epoch 487/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4753 - accuracy: 0.7691 - val_loss: 0.4915 - val_accuracy: 0.7604\n",
      "Epoch 488/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4752 - accuracy: 0.7691 - val_loss: 0.4915 - val_accuracy: 0.7604\n",
      "Epoch 489/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4752 - accuracy: 0.7691 - val_loss: 0.4914 - val_accuracy: 0.7604\n",
      "Epoch 490/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4751 - accuracy: 0.7691 - val_loss: 0.4914 - val_accuracy: 0.7604\n",
      "Epoch 491/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4750 - accuracy: 0.7691 - val_loss: 0.4913 - val_accuracy: 0.7604\n",
      "Epoch 492/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4750 - accuracy: 0.7691 - val_loss: 0.4913 - val_accuracy: 0.7604\n",
      "Epoch 493/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4749 - accuracy: 0.7708 - val_loss: 0.4913 - val_accuracy: 0.7604\n",
      "Epoch 494/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4748 - accuracy: 0.7691 - val_loss: 0.4912 - val_accuracy: 0.7604\n",
      "Epoch 495/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4748 - accuracy: 0.7691 - val_loss: 0.4912 - val_accuracy: 0.7604\n",
      "Epoch 496/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4747 - accuracy: 0.7691 - val_loss: 0.4911 - val_accuracy: 0.7604\n",
      "Epoch 497/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4747 - accuracy: 0.7691 - val_loss: 0.4911 - val_accuracy: 0.7656\n",
      "Epoch 498/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4746 - accuracy: 0.7691 - val_loss: 0.4911 - val_accuracy: 0.7656\n",
      "Epoch 499/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4746 - accuracy: 0.7691 - val_loss: 0.4910 - val_accuracy: 0.7656\n",
      "Epoch 500/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4745 - accuracy: 0.7691 - val_loss: 0.4910 - val_accuracy: 0.7656\n",
      "Epoch 501/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4744 - accuracy: 0.7691 - val_loss: 0.4910 - val_accuracy: 0.7656\n",
      "Epoch 502/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4744 - accuracy: 0.7691 - val_loss: 0.4909 - val_accuracy: 0.7656\n",
      "Epoch 503/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4743 - accuracy: 0.7691 - val_loss: 0.4909 - val_accuracy: 0.7656\n",
      "Epoch 504/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4742 - accuracy: 0.7691 - val_loss: 0.4908 - val_accuracy: 0.7656\n",
      "Epoch 505/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4742 - accuracy: 0.7691 - val_loss: 0.4908 - val_accuracy: 0.7656\n",
      "Epoch 506/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4741 - accuracy: 0.7691 - val_loss: 0.4908 - val_accuracy: 0.7656\n",
      "Epoch 507/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4741 - accuracy: 0.7691 - val_loss: 0.4907 - val_accuracy: 0.7656\n",
      "Epoch 508/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4740 - accuracy: 0.7691 - val_loss: 0.4907 - val_accuracy: 0.7656\n",
      "Epoch 509/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4739 - accuracy: 0.7691 - val_loss: 0.4907 - val_accuracy: 0.7656\n",
      "Epoch 510/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4739 - accuracy: 0.7691 - val_loss: 0.4906 - val_accuracy: 0.7656\n",
      "Epoch 511/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4738 - accuracy: 0.7691 - val_loss: 0.4906 - val_accuracy: 0.7656\n",
      "Epoch 512/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4738 - accuracy: 0.7691 - val_loss: 0.4906 - val_accuracy: 0.7656\n",
      "Epoch 513/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4737 - accuracy: 0.7691 - val_loss: 0.4905 - val_accuracy: 0.7656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 514/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4737 - accuracy: 0.7691 - val_loss: 0.4905 - val_accuracy: 0.7656\n",
      "Epoch 515/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4736 - accuracy: 0.7691 - val_loss: 0.4904 - val_accuracy: 0.7656\n",
      "Epoch 516/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4735 - accuracy: 0.7691 - val_loss: 0.4904 - val_accuracy: 0.7656\n",
      "Epoch 517/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4735 - accuracy: 0.7691 - val_loss: 0.4904 - val_accuracy: 0.7656\n",
      "Epoch 518/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4734 - accuracy: 0.7691 - val_loss: 0.4903 - val_accuracy: 0.7656\n",
      "Epoch 519/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4734 - accuracy: 0.7691 - val_loss: 0.4903 - val_accuracy: 0.7656\n",
      "Epoch 520/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4733 - accuracy: 0.7691 - val_loss: 0.4903 - val_accuracy: 0.7656\n",
      "Epoch 521/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4733 - accuracy: 0.7691 - val_loss: 0.4902 - val_accuracy: 0.7656\n",
      "Epoch 522/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4732 - accuracy: 0.7691 - val_loss: 0.4902 - val_accuracy: 0.7656\n",
      "Epoch 523/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4731 - accuracy: 0.7691 - val_loss: 0.4902 - val_accuracy: 0.7656\n",
      "Epoch 524/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4731 - accuracy: 0.7691 - val_loss: 0.4901 - val_accuracy: 0.7656\n",
      "Epoch 525/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4730 - accuracy: 0.7691 - val_loss: 0.4901 - val_accuracy: 0.7656\n",
      "Epoch 526/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4730 - accuracy: 0.7691 - val_loss: 0.4901 - val_accuracy: 0.7656\n",
      "Epoch 527/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4729 - accuracy: 0.7674 - val_loss: 0.4900 - val_accuracy: 0.7656\n",
      "Epoch 528/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4728 - accuracy: 0.7691 - val_loss: 0.4900 - val_accuracy: 0.7656\n",
      "Epoch 529/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4728 - accuracy: 0.7691 - val_loss: 0.4900 - val_accuracy: 0.7656\n",
      "Epoch 530/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4727 - accuracy: 0.7691 - val_loss: 0.4899 - val_accuracy: 0.7656\n",
      "Epoch 531/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4727 - accuracy: 0.7691 - val_loss: 0.4899 - val_accuracy: 0.7656\n",
      "Epoch 532/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4726 - accuracy: 0.7691 - val_loss: 0.4899 - val_accuracy: 0.7656\n",
      "Epoch 533/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4726 - accuracy: 0.7691 - val_loss: 0.4898 - val_accuracy: 0.7656\n",
      "Epoch 534/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4725 - accuracy: 0.7708 - val_loss: 0.4898 - val_accuracy: 0.7656\n",
      "Epoch 535/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4725 - accuracy: 0.7691 - val_loss: 0.4898 - val_accuracy: 0.7656\n",
      "Epoch 536/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4724 - accuracy: 0.7691 - val_loss: 0.4897 - val_accuracy: 0.7656\n",
      "Epoch 537/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4724 - accuracy: 0.7708 - val_loss: 0.4897 - val_accuracy: 0.7656\n",
      "Epoch 538/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4723 - accuracy: 0.7691 - val_loss: 0.4897 - val_accuracy: 0.7656\n",
      "Epoch 539/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4722 - accuracy: 0.7708 - val_loss: 0.4897 - val_accuracy: 0.7656\n",
      "Epoch 540/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4722 - accuracy: 0.7708 - val_loss: 0.4896 - val_accuracy: 0.7656\n",
      "Epoch 541/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4721 - accuracy: 0.7708 - val_loss: 0.4896 - val_accuracy: 0.7656\n",
      "Epoch 542/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4721 - accuracy: 0.7708 - val_loss: 0.4896 - val_accuracy: 0.7656\n",
      "Epoch 543/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4721 - accuracy: 0.7674 - val_loss: 0.4895 - val_accuracy: 0.7656\n",
      "Epoch 544/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4720 - accuracy: 0.7674 - val_loss: 0.4895 - val_accuracy: 0.7656\n",
      "Epoch 545/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4719 - accuracy: 0.7674 - val_loss: 0.4895 - val_accuracy: 0.7656\n",
      "Epoch 546/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4719 - accuracy: 0.7674 - val_loss: 0.4894 - val_accuracy: 0.7656\n",
      "Epoch 547/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4718 - accuracy: 0.7674 - val_loss: 0.4894 - val_accuracy: 0.7656\n",
      "Epoch 548/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4718 - accuracy: 0.7674 - val_loss: 0.4894 - val_accuracy: 0.7656\n",
      "Epoch 549/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4717 - accuracy: 0.7674 - val_loss: 0.4894 - val_accuracy: 0.7656\n",
      "Epoch 550/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4717 - accuracy: 0.7674 - val_loss: 0.4893 - val_accuracy: 0.7656\n",
      "Epoch 551/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4716 - accuracy: 0.7674 - val_loss: 0.4893 - val_accuracy: 0.7656\n",
      "Epoch 552/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4716 - accuracy: 0.7674 - val_loss: 0.4893 - val_accuracy: 0.7656\n",
      "Epoch 553/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4715 - accuracy: 0.7674 - val_loss: 0.4892 - val_accuracy: 0.7656\n",
      "Epoch 554/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4715 - accuracy: 0.7656 - val_loss: 0.4892 - val_accuracy: 0.7656\n",
      "Epoch 555/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4714 - accuracy: 0.7656 - val_loss: 0.4892 - val_accuracy: 0.7656\n",
      "Epoch 556/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4714 - accuracy: 0.7656 - val_loss: 0.4892 - val_accuracy: 0.7656\n",
      "Epoch 557/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4713 - accuracy: 0.7656 - val_loss: 0.4891 - val_accuracy: 0.7656\n",
      "Epoch 558/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4713 - accuracy: 0.7656 - val_loss: 0.4891 - val_accuracy: 0.7656\n",
      "Epoch 559/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4712 - accuracy: 0.7656 - val_loss: 0.4891 - val_accuracy: 0.7656\n",
      "Epoch 560/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4712 - accuracy: 0.7656 - val_loss: 0.4890 - val_accuracy: 0.7656\n",
      "Epoch 561/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4711 - accuracy: 0.7674 - val_loss: 0.4890 - val_accuracy: 0.7656\n",
      "Epoch 562/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4711 - accuracy: 0.7656 - val_loss: 0.4890 - val_accuracy: 0.7656\n",
      "Epoch 563/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4710 - accuracy: 0.7656 - val_loss: 0.4890 - val_accuracy: 0.7656\n",
      "Epoch 564/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4710 - accuracy: 0.7656 - val_loss: 0.4889 - val_accuracy: 0.7656\n",
      "Epoch 565/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4709 - accuracy: 0.7656 - val_loss: 0.4889 - val_accuracy: 0.7656\n",
      "Epoch 566/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4709 - accuracy: 0.7656 - val_loss: 0.4889 - val_accuracy: 0.7656\n",
      "Epoch 567/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4708 - accuracy: 0.7656 - val_loss: 0.4889 - val_accuracy: 0.7656\n",
      "Epoch 568/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4708 - accuracy: 0.7656 - val_loss: 0.4888 - val_accuracy: 0.7656\n",
      "Epoch 569/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4707 - accuracy: 0.7656 - val_loss: 0.4888 - val_accuracy: 0.7656\n",
      "Epoch 570/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4707 - accuracy: 0.7656 - val_loss: 0.4888 - val_accuracy: 0.7656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 571/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4706 - accuracy: 0.7656 - val_loss: 0.4888 - val_accuracy: 0.7656\n",
      "Epoch 572/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4706 - accuracy: 0.7656 - val_loss: 0.4887 - val_accuracy: 0.7656\n",
      "Epoch 573/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4706 - accuracy: 0.7656 - val_loss: 0.4887 - val_accuracy: 0.7656\n",
      "Epoch 574/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4705 - accuracy: 0.7656 - val_loss: 0.4887 - val_accuracy: 0.7656\n",
      "Epoch 575/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4705 - accuracy: 0.7656 - val_loss: 0.4887 - val_accuracy: 0.7656\n",
      "Epoch 576/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4704 - accuracy: 0.7656 - val_loss: 0.4886 - val_accuracy: 0.7656\n",
      "Epoch 577/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4704 - accuracy: 0.7656 - val_loss: 0.4886 - val_accuracy: 0.7656\n",
      "Epoch 578/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4703 - accuracy: 0.7656 - val_loss: 0.4886 - val_accuracy: 0.7656\n",
      "Epoch 579/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4703 - accuracy: 0.7656 - val_loss: 0.4886 - val_accuracy: 0.7656\n",
      "Epoch 580/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4702 - accuracy: 0.7656 - val_loss: 0.4885 - val_accuracy: 0.7656\n",
      "Epoch 581/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4702 - accuracy: 0.7656 - val_loss: 0.4885 - val_accuracy: 0.7656\n",
      "Epoch 582/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4701 - accuracy: 0.7656 - val_loss: 0.4885 - val_accuracy: 0.7656\n",
      "Epoch 583/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4701 - accuracy: 0.7656 - val_loss: 0.4885 - val_accuracy: 0.7656\n",
      "Epoch 584/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4701 - accuracy: 0.7674 - val_loss: 0.4884 - val_accuracy: 0.7656\n",
      "Epoch 585/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4700 - accuracy: 0.7674 - val_loss: 0.4884 - val_accuracy: 0.7656\n",
      "Epoch 586/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4700 - accuracy: 0.7674 - val_loss: 0.4884 - val_accuracy: 0.7656\n",
      "Epoch 587/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4699 - accuracy: 0.7674 - val_loss: 0.4884 - val_accuracy: 0.7656\n",
      "Epoch 588/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4699 - accuracy: 0.7674 - val_loss: 0.4883 - val_accuracy: 0.7656\n",
      "Epoch 589/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4698 - accuracy: 0.7674 - val_loss: 0.4883 - val_accuracy: 0.7656\n",
      "Epoch 590/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4698 - accuracy: 0.7674 - val_loss: 0.4883 - val_accuracy: 0.7656\n",
      "Epoch 591/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4697 - accuracy: 0.7674 - val_loss: 0.4883 - val_accuracy: 0.7656\n",
      "Epoch 592/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4697 - accuracy: 0.7656 - val_loss: 0.4883 - val_accuracy: 0.7656\n",
      "Epoch 593/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4696 - accuracy: 0.7656 - val_loss: 0.4882 - val_accuracy: 0.7656\n",
      "Epoch 594/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4696 - accuracy: 0.7674 - val_loss: 0.4882 - val_accuracy: 0.7656\n",
      "Epoch 595/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4696 - accuracy: 0.7656 - val_loss: 0.4882 - val_accuracy: 0.7656\n",
      "Epoch 596/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4695 - accuracy: 0.7674 - val_loss: 0.4882 - val_accuracy: 0.7656\n",
      "Epoch 597/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4695 - accuracy: 0.7656 - val_loss: 0.4881 - val_accuracy: 0.7656\n",
      "Epoch 598/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4694 - accuracy: 0.7674 - val_loss: 0.4881 - val_accuracy: 0.7656\n",
      "Epoch 599/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4694 - accuracy: 0.7674 - val_loss: 0.4881 - val_accuracy: 0.7656\n",
      "Epoch 600/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4693 - accuracy: 0.7674 - val_loss: 0.4881 - val_accuracy: 0.7656\n",
      "Epoch 601/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4693 - accuracy: 0.7674 - val_loss: 0.4881 - val_accuracy: 0.7656\n",
      "Epoch 602/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4693 - accuracy: 0.7674 - val_loss: 0.4880 - val_accuracy: 0.7656\n",
      "Epoch 603/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4692 - accuracy: 0.7674 - val_loss: 0.4880 - val_accuracy: 0.7656\n",
      "Epoch 604/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4692 - accuracy: 0.7674 - val_loss: 0.4880 - val_accuracy: 0.7656\n",
      "Epoch 605/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4691 - accuracy: 0.7674 - val_loss: 0.4880 - val_accuracy: 0.7656\n",
      "Epoch 606/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4691 - accuracy: 0.7674 - val_loss: 0.4880 - val_accuracy: 0.7656\n",
      "Epoch 607/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4691 - accuracy: 0.7674 - val_loss: 0.4879 - val_accuracy: 0.7656\n",
      "Epoch 608/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4690 - accuracy: 0.7674 - val_loss: 0.4879 - val_accuracy: 0.7656\n",
      "Epoch 609/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4690 - accuracy: 0.7674 - val_loss: 0.4879 - val_accuracy: 0.7656\n",
      "Epoch 610/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4689 - accuracy: 0.7674 - val_loss: 0.4879 - val_accuracy: 0.7656\n",
      "Epoch 611/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4689 - accuracy: 0.7674 - val_loss: 0.4879 - val_accuracy: 0.7656\n",
      "Epoch 612/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4689 - accuracy: 0.7674 - val_loss: 0.4878 - val_accuracy: 0.7656\n",
      "Epoch 613/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4688 - accuracy: 0.7674 - val_loss: 0.4878 - val_accuracy: 0.7708\n",
      "Epoch 614/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4688 - accuracy: 0.7674 - val_loss: 0.4878 - val_accuracy: 0.7708\n",
      "Epoch 615/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4687 - accuracy: 0.7674 - val_loss: 0.4878 - val_accuracy: 0.7708\n",
      "Epoch 616/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4687 - accuracy: 0.7674 - val_loss: 0.4878 - val_accuracy: 0.7708\n",
      "Epoch 617/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4686 - accuracy: 0.7674 - val_loss: 0.4877 - val_accuracy: 0.7708\n",
      "Epoch 618/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4686 - accuracy: 0.7674 - val_loss: 0.4877 - val_accuracy: 0.7708\n",
      "Epoch 619/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4686 - accuracy: 0.7674 - val_loss: 0.4877 - val_accuracy: 0.7708\n",
      "Epoch 620/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4685 - accuracy: 0.7674 - val_loss: 0.4877 - val_accuracy: 0.7708\n",
      "Epoch 621/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4685 - accuracy: 0.7674 - val_loss: 0.4877 - val_accuracy: 0.7708\n",
      "Epoch 622/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4684 - accuracy: 0.7674 - val_loss: 0.4876 - val_accuracy: 0.7708\n",
      "Epoch 623/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4684 - accuracy: 0.7674 - val_loss: 0.4876 - val_accuracy: 0.7708\n",
      "Epoch 624/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4684 - accuracy: 0.7674 - val_loss: 0.4876 - val_accuracy: 0.7708\n",
      "Epoch 625/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4683 - accuracy: 0.7674 - val_loss: 0.4876 - val_accuracy: 0.7708\n",
      "Epoch 626/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4683 - accuracy: 0.7674 - val_loss: 0.4876 - val_accuracy: 0.7708\n",
      "Epoch 627/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4682 - accuracy: 0.7674 - val_loss: 0.4875 - val_accuracy: 0.7708\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 628/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4682 - accuracy: 0.7674 - val_loss: 0.4875 - val_accuracy: 0.7708\n",
      "Epoch 629/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4682 - accuracy: 0.7691 - val_loss: 0.4875 - val_accuracy: 0.7708\n",
      "Epoch 630/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4681 - accuracy: 0.7691 - val_loss: 0.4875 - val_accuracy: 0.7708\n",
      "Epoch 631/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4681 - accuracy: 0.7691 - val_loss: 0.4875 - val_accuracy: 0.7708\n",
      "Epoch 632/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4681 - accuracy: 0.7691 - val_loss: 0.4875 - val_accuracy: 0.7708\n",
      "Epoch 633/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4681 - accuracy: 0.7691 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 634/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4680 - accuracy: 0.7691 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 635/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4679 - accuracy: 0.7691 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 636/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4679 - accuracy: 0.7691 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 637/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4679 - accuracy: 0.7691 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 638/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4678 - accuracy: 0.7691 - val_loss: 0.4873 - val_accuracy: 0.7708\n",
      "Epoch 639/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4678 - accuracy: 0.7691 - val_loss: 0.4873 - val_accuracy: 0.7708\n",
      "Epoch 640/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4678 - accuracy: 0.7691 - val_loss: 0.4873 - val_accuracy: 0.7708\n",
      "Epoch 641/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4677 - accuracy: 0.7691 - val_loss: 0.4873 - val_accuracy: 0.7708\n",
      "Epoch 642/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4677 - accuracy: 0.7691 - val_loss: 0.4873 - val_accuracy: 0.7708\n",
      "Epoch 643/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4677 - accuracy: 0.7691 - val_loss: 0.4873 - val_accuracy: 0.7708\n",
      "Epoch 644/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4676 - accuracy: 0.7691 - val_loss: 0.4872 - val_accuracy: 0.7708\n",
      "Epoch 645/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4676 - accuracy: 0.7691 - val_loss: 0.4872 - val_accuracy: 0.7708\n",
      "Epoch 646/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4675 - accuracy: 0.7691 - val_loss: 0.4872 - val_accuracy: 0.7708\n",
      "Epoch 647/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4675 - accuracy: 0.7691 - val_loss: 0.4872 - val_accuracy: 0.7708\n",
      "Epoch 648/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4675 - accuracy: 0.7691 - val_loss: 0.4872 - val_accuracy: 0.7708\n",
      "Epoch 649/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4674 - accuracy: 0.7691 - val_loss: 0.4872 - val_accuracy: 0.7708\n",
      "Epoch 650/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4674 - accuracy: 0.7691 - val_loss: 0.4871 - val_accuracy: 0.7708\n",
      "Epoch 651/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4674 - accuracy: 0.7691 - val_loss: 0.4871 - val_accuracy: 0.7708\n",
      "Epoch 652/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4673 - accuracy: 0.7691 - val_loss: 0.4871 - val_accuracy: 0.7708\n",
      "Epoch 653/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4673 - accuracy: 0.7691 - val_loss: 0.4871 - val_accuracy: 0.7708\n",
      "Epoch 654/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4672 - accuracy: 0.7691 - val_loss: 0.4871 - val_accuracy: 0.7708\n",
      "Epoch 655/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4672 - accuracy: 0.7691 - val_loss: 0.4871 - val_accuracy: 0.7708\n",
      "Epoch 656/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4672 - accuracy: 0.7691 - val_loss: 0.4871 - val_accuracy: 0.7708\n",
      "Epoch 657/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4672 - accuracy: 0.7691 - val_loss: 0.4870 - val_accuracy: 0.7708\n",
      "Epoch 658/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4671 - accuracy: 0.7691 - val_loss: 0.4870 - val_accuracy: 0.7708\n",
      "Epoch 659/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4671 - accuracy: 0.7691 - val_loss: 0.4870 - val_accuracy: 0.7708\n",
      "Epoch 660/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4670 - accuracy: 0.7691 - val_loss: 0.4870 - val_accuracy: 0.7708\n",
      "Epoch 661/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4670 - accuracy: 0.7691 - val_loss: 0.4870 - val_accuracy: 0.7708\n",
      "Epoch 662/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4670 - accuracy: 0.7691 - val_loss: 0.4870 - val_accuracy: 0.7708\n",
      "Epoch 663/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4669 - accuracy: 0.7691 - val_loss: 0.4870 - val_accuracy: 0.7708\n",
      "Epoch 664/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4669 - accuracy: 0.7691 - val_loss: 0.4869 - val_accuracy: 0.7708\n",
      "Epoch 665/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4669 - accuracy: 0.7691 - val_loss: 0.4869 - val_accuracy: 0.7708\n",
      "Epoch 666/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4669 - accuracy: 0.7691 - val_loss: 0.4869 - val_accuracy: 0.7708\n",
      "Epoch 667/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4668 - accuracy: 0.7691 - val_loss: 0.4869 - val_accuracy: 0.7708\n",
      "Epoch 668/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4668 - accuracy: 0.7691 - val_loss: 0.4869 - val_accuracy: 0.7708\n",
      "Epoch 669/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4667 - accuracy: 0.7691 - val_loss: 0.4869 - val_accuracy: 0.7708\n",
      "Epoch 670/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4667 - accuracy: 0.7691 - val_loss: 0.4869 - val_accuracy: 0.7708\n",
      "Epoch 671/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4667 - accuracy: 0.7691 - val_loss: 0.4868 - val_accuracy: 0.7708\n",
      "Epoch 672/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4667 - accuracy: 0.7691 - val_loss: 0.4868 - val_accuracy: 0.7708\n",
      "Epoch 673/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4666 - accuracy: 0.7691 - val_loss: 0.4868 - val_accuracy: 0.7708\n",
      "Epoch 674/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4666 - accuracy: 0.7691 - val_loss: 0.4868 - val_accuracy: 0.7708\n",
      "Epoch 675/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4666 - accuracy: 0.7691 - val_loss: 0.4868 - val_accuracy: 0.7708\n",
      "Epoch 676/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4665 - accuracy: 0.7691 - val_loss: 0.4868 - val_accuracy: 0.7708\n",
      "Epoch 677/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4665 - accuracy: 0.7691 - val_loss: 0.4868 - val_accuracy: 0.7708\n",
      "Epoch 678/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4665 - accuracy: 0.7691 - val_loss: 0.4867 - val_accuracy: 0.7708\n",
      "Epoch 679/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4664 - accuracy: 0.7691 - val_loss: 0.4867 - val_accuracy: 0.7708\n",
      "Epoch 680/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4664 - accuracy: 0.7691 - val_loss: 0.4867 - val_accuracy: 0.7708\n",
      "Epoch 681/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4664 - accuracy: 0.7691 - val_loss: 0.4867 - val_accuracy: 0.7708\n",
      "Epoch 682/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4663 - accuracy: 0.7691 - val_loss: 0.4867 - val_accuracy: 0.7708\n",
      "Epoch 683/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4663 - accuracy: 0.7691 - val_loss: 0.4867 - val_accuracy: 0.7708\n",
      "Epoch 684/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4663 - accuracy: 0.7691 - val_loss: 0.4867 - val_accuracy: 0.7708\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 685/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4662 - accuracy: 0.7691 - val_loss: 0.4866 - val_accuracy: 0.7708\n",
      "Epoch 686/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4662 - accuracy: 0.7708 - val_loss: 0.4866 - val_accuracy: 0.7708\n",
      "Epoch 687/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4662 - accuracy: 0.7708 - val_loss: 0.4866 - val_accuracy: 0.7708\n",
      "Epoch 688/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4661 - accuracy: 0.7708 - val_loss: 0.4866 - val_accuracy: 0.7708\n",
      "Epoch 689/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4661 - accuracy: 0.7708 - val_loss: 0.4866 - val_accuracy: 0.7708\n",
      "Epoch 690/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4661 - accuracy: 0.7708 - val_loss: 0.4866 - val_accuracy: 0.7708\n",
      "Epoch 691/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4660 - accuracy: 0.7708 - val_loss: 0.4866 - val_accuracy: 0.7708\n",
      "Epoch 692/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4660 - accuracy: 0.7708 - val_loss: 0.4866 - val_accuracy: 0.7708\n",
      "Epoch 693/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4660 - accuracy: 0.7708 - val_loss: 0.4865 - val_accuracy: 0.7708\n",
      "Epoch 694/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4659 - accuracy: 0.7708 - val_loss: 0.4865 - val_accuracy: 0.7708\n",
      "Epoch 695/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4659 - accuracy: 0.7708 - val_loss: 0.4865 - val_accuracy: 0.7708\n",
      "Epoch 696/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4659 - accuracy: 0.7708 - val_loss: 0.4865 - val_accuracy: 0.7708\n",
      "Epoch 697/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4659 - accuracy: 0.7708 - val_loss: 0.4865 - val_accuracy: 0.7708\n",
      "Epoch 698/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4658 - accuracy: 0.7708 - val_loss: 0.4865 - val_accuracy: 0.7708\n",
      "Epoch 699/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4658 - accuracy: 0.7708 - val_loss: 0.4865 - val_accuracy: 0.7708\n",
      "Epoch 700/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4658 - accuracy: 0.7708 - val_loss: 0.4865 - val_accuracy: 0.7656\n",
      "Epoch 701/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4657 - accuracy: 0.7708 - val_loss: 0.4865 - val_accuracy: 0.7656\n",
      "Epoch 702/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4657 - accuracy: 0.7708 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 703/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4657 - accuracy: 0.7708 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 704/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4656 - accuracy: 0.7708 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 705/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4656 - accuracy: 0.7708 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 706/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4656 - accuracy: 0.7708 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 707/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4656 - accuracy: 0.7708 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 708/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4655 - accuracy: 0.7726 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 709/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4655 - accuracy: 0.7708 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 710/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4655 - accuracy: 0.7708 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 711/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4654 - accuracy: 0.7708 - val_loss: 0.4863 - val_accuracy: 0.7656\n",
      "Epoch 712/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4654 - accuracy: 0.7726 - val_loss: 0.4863 - val_accuracy: 0.7656\n",
      "Epoch 713/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4654 - accuracy: 0.7708 - val_loss: 0.4863 - val_accuracy: 0.7656\n",
      "Epoch 714/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4654 - accuracy: 0.7726 - val_loss: 0.4863 - val_accuracy: 0.7656\n",
      "Epoch 715/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4653 - accuracy: 0.7726 - val_loss: 0.4863 - val_accuracy: 0.7656\n",
      "Epoch 716/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4653 - accuracy: 0.7726 - val_loss: 0.4863 - val_accuracy: 0.7656\n",
      "Epoch 717/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4653 - accuracy: 0.7726 - val_loss: 0.4863 - val_accuracy: 0.7656\n",
      "Epoch 718/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4652 - accuracy: 0.7726 - val_loss: 0.4863 - val_accuracy: 0.7656\n",
      "Epoch 719/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4652 - accuracy: 0.7726 - val_loss: 0.4863 - val_accuracy: 0.7656\n",
      "Epoch 720/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4652 - accuracy: 0.7726 - val_loss: 0.4863 - val_accuracy: 0.7656\n",
      "Epoch 721/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4651 - accuracy: 0.7726 - val_loss: 0.4862 - val_accuracy: 0.7656\n",
      "Epoch 722/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4651 - accuracy: 0.7726 - val_loss: 0.4862 - val_accuracy: 0.7656\n",
      "Epoch 723/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4651 - accuracy: 0.7726 - val_loss: 0.4862 - val_accuracy: 0.7656\n",
      "Epoch 724/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4651 - accuracy: 0.7726 - val_loss: 0.4862 - val_accuracy: 0.7656\n",
      "Epoch 725/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4650 - accuracy: 0.7726 - val_loss: 0.4862 - val_accuracy: 0.7656\n",
      "Epoch 726/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4650 - accuracy: 0.7726 - val_loss: 0.4862 - val_accuracy: 0.7656\n",
      "Epoch 727/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4650 - accuracy: 0.7726 - val_loss: 0.4862 - val_accuracy: 0.7656\n",
      "Epoch 728/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4650 - accuracy: 0.7726 - val_loss: 0.4862 - val_accuracy: 0.7656\n",
      "Epoch 729/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4649 - accuracy: 0.7708 - val_loss: 0.4862 - val_accuracy: 0.7656\n",
      "Epoch 730/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4649 - accuracy: 0.7726 - val_loss: 0.4862 - val_accuracy: 0.7656\n",
      "Epoch 731/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4649 - accuracy: 0.7708 - val_loss: 0.4862 - val_accuracy: 0.7656\n",
      "Epoch 732/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4649 - accuracy: 0.7708 - val_loss: 0.4861 - val_accuracy: 0.7656\n",
      "Epoch 733/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4648 - accuracy: 0.7726 - val_loss: 0.4861 - val_accuracy: 0.7656\n",
      "Epoch 734/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4648 - accuracy: 0.7708 - val_loss: 0.4861 - val_accuracy: 0.7656\n",
      "Epoch 735/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4648 - accuracy: 0.7708 - val_loss: 0.4861 - val_accuracy: 0.7656\n",
      "Epoch 736/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4647 - accuracy: 0.7708 - val_loss: 0.4861 - val_accuracy: 0.7656\n",
      "Epoch 737/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4647 - accuracy: 0.7708 - val_loss: 0.4861 - val_accuracy: 0.7656\n",
      "Epoch 738/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4647 - accuracy: 0.7708 - val_loss: 0.4861 - val_accuracy: 0.7656\n",
      "Epoch 739/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4647 - accuracy: 0.7708 - val_loss: 0.4861 - val_accuracy: 0.7656\n",
      "Epoch 740/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4646 - accuracy: 0.7708 - val_loss: 0.4861 - val_accuracy: 0.7656\n",
      "Epoch 741/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4646 - accuracy: 0.7708 - val_loss: 0.4861 - val_accuracy: 0.7656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 742/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4646 - accuracy: 0.7708 - val_loss: 0.4861 - val_accuracy: 0.7656\n",
      "Epoch 743/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4646 - accuracy: 0.7708 - val_loss: 0.4860 - val_accuracy: 0.7656\n",
      "Epoch 744/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4646 - accuracy: 0.7708 - val_loss: 0.4860 - val_accuracy: 0.7656\n",
      "Epoch 745/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4645 - accuracy: 0.7708 - val_loss: 0.4860 - val_accuracy: 0.7656\n",
      "Epoch 746/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4645 - accuracy: 0.7708 - val_loss: 0.4860 - val_accuracy: 0.7656\n",
      "Epoch 747/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4644 - accuracy: 0.7708 - val_loss: 0.4860 - val_accuracy: 0.7656\n",
      "Epoch 748/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4644 - accuracy: 0.7708 - val_loss: 0.4860 - val_accuracy: 0.7656\n",
      "Epoch 749/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4644 - accuracy: 0.7708 - val_loss: 0.4860 - val_accuracy: 0.7656\n",
      "Epoch 750/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4644 - accuracy: 0.7708 - val_loss: 0.4860 - val_accuracy: 0.7656\n",
      "Epoch 751/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4644 - accuracy: 0.7708 - val_loss: 0.4860 - val_accuracy: 0.7656\n",
      "Epoch 752/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4643 - accuracy: 0.7708 - val_loss: 0.4860 - val_accuracy: 0.7656\n",
      "Epoch 753/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4643 - accuracy: 0.7708 - val_loss: 0.4860 - val_accuracy: 0.7656\n",
      "Epoch 754/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4643 - accuracy: 0.7708 - val_loss: 0.4860 - val_accuracy: 0.7604\n",
      "Epoch 755/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4642 - accuracy: 0.7708 - val_loss: 0.4859 - val_accuracy: 0.7604\n",
      "Epoch 756/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4642 - accuracy: 0.7708 - val_loss: 0.4859 - val_accuracy: 0.7604\n",
      "Epoch 757/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4642 - accuracy: 0.7708 - val_loss: 0.4859 - val_accuracy: 0.7604\n",
      "Epoch 758/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4642 - accuracy: 0.7708 - val_loss: 0.4859 - val_accuracy: 0.7604\n",
      "Epoch 759/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4642 - accuracy: 0.7708 - val_loss: 0.4859 - val_accuracy: 0.7604\n",
      "Epoch 760/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4641 - accuracy: 0.7708 - val_loss: 0.4859 - val_accuracy: 0.7604\n",
      "Epoch 761/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4641 - accuracy: 0.7708 - val_loss: 0.4859 - val_accuracy: 0.7604\n",
      "Epoch 762/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4641 - accuracy: 0.7708 - val_loss: 0.4859 - val_accuracy: 0.7604\n",
      "Epoch 763/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4641 - accuracy: 0.7708 - val_loss: 0.4859 - val_accuracy: 0.7604\n",
      "Epoch 764/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4640 - accuracy: 0.7726 - val_loss: 0.4859 - val_accuracy: 0.7604\n",
      "Epoch 765/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4640 - accuracy: 0.7726 - val_loss: 0.4859 - val_accuracy: 0.7604\n",
      "Epoch 766/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4640 - accuracy: 0.7726 - val_loss: 0.4859 - val_accuracy: 0.7604\n",
      "Epoch 767/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4640 - accuracy: 0.7726 - val_loss: 0.4859 - val_accuracy: 0.7604\n",
      "Epoch 768/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4639 - accuracy: 0.7726 - val_loss: 0.4859 - val_accuracy: 0.7604\n",
      "Epoch 769/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4639 - accuracy: 0.7726 - val_loss: 0.4858 - val_accuracy: 0.7604\n",
      "Epoch 770/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4639 - accuracy: 0.7726 - val_loss: 0.4858 - val_accuracy: 0.7604\n",
      "Epoch 771/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4639 - accuracy: 0.7726 - val_loss: 0.4858 - val_accuracy: 0.7604\n",
      "Epoch 772/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4638 - accuracy: 0.7726 - val_loss: 0.4858 - val_accuracy: 0.7604\n",
      "Epoch 773/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4638 - accuracy: 0.7726 - val_loss: 0.4858 - val_accuracy: 0.7604\n",
      "Epoch 774/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4638 - accuracy: 0.7726 - val_loss: 0.4858 - val_accuracy: 0.7604\n",
      "Epoch 775/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4638 - accuracy: 0.7726 - val_loss: 0.4858 - val_accuracy: 0.7604\n",
      "Epoch 776/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4637 - accuracy: 0.7726 - val_loss: 0.4858 - val_accuracy: 0.7604\n",
      "Epoch 777/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4637 - accuracy: 0.7726 - val_loss: 0.4858 - val_accuracy: 0.7604\n",
      "Epoch 778/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4637 - accuracy: 0.7726 - val_loss: 0.4858 - val_accuracy: 0.7604\n",
      "Epoch 779/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4637 - accuracy: 0.7726 - val_loss: 0.4858 - val_accuracy: 0.7604\n",
      "Epoch 780/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4636 - accuracy: 0.7726 - val_loss: 0.4858 - val_accuracy: 0.7604\n",
      "Epoch 781/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4636 - accuracy: 0.7726 - val_loss: 0.4858 - val_accuracy: 0.7604\n",
      "Epoch 782/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4636 - accuracy: 0.7726 - val_loss: 0.4858 - val_accuracy: 0.7604\n",
      "Epoch 783/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4636 - accuracy: 0.7726 - val_loss: 0.4858 - val_accuracy: 0.7604\n",
      "Epoch 784/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4635 - accuracy: 0.7726 - val_loss: 0.4857 - val_accuracy: 0.7604\n",
      "Epoch 785/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4635 - accuracy: 0.7726 - val_loss: 0.4857 - val_accuracy: 0.7604\n",
      "Epoch 786/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4635 - accuracy: 0.7726 - val_loss: 0.4857 - val_accuracy: 0.7604\n",
      "Epoch 787/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4635 - accuracy: 0.7726 - val_loss: 0.4857 - val_accuracy: 0.7604\n",
      "Epoch 788/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4635 - accuracy: 0.7726 - val_loss: 0.4857 - val_accuracy: 0.7604\n",
      "Epoch 789/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4634 - accuracy: 0.7726 - val_loss: 0.4857 - val_accuracy: 0.7604\n",
      "Epoch 790/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4634 - accuracy: 0.7726 - val_loss: 0.4857 - val_accuracy: 0.7604\n",
      "Epoch 791/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4634 - accuracy: 0.7726 - val_loss: 0.4857 - val_accuracy: 0.7604\n",
      "Epoch 792/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4634 - accuracy: 0.7726 - val_loss: 0.4857 - val_accuracy: 0.7604\n",
      "Epoch 793/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4633 - accuracy: 0.7743 - val_loss: 0.4857 - val_accuracy: 0.7604\n",
      "Epoch 794/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4633 - accuracy: 0.7743 - val_loss: 0.4857 - val_accuracy: 0.7604\n",
      "Epoch 795/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4633 - accuracy: 0.7743 - val_loss: 0.4857 - val_accuracy: 0.7604\n",
      "Epoch 796/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4633 - accuracy: 0.7726 - val_loss: 0.4857 - val_accuracy: 0.7604\n",
      "Epoch 797/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4633 - accuracy: 0.7743 - val_loss: 0.4857 - val_accuracy: 0.7604\n",
      "Epoch 798/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4632 - accuracy: 0.7743 - val_loss: 0.4857 - val_accuracy: 0.7604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 799/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4632 - accuracy: 0.7743 - val_loss: 0.4857 - val_accuracy: 0.7604\n",
      "Epoch 800/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4632 - accuracy: 0.7743 - val_loss: 0.4857 - val_accuracy: 0.7604\n",
      "Epoch 801/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4632 - accuracy: 0.7743 - val_loss: 0.4857 - val_accuracy: 0.7604\n",
      "Epoch 802/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4632 - accuracy: 0.7743 - val_loss: 0.4856 - val_accuracy: 0.7604\n",
      "Epoch 803/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4631 - accuracy: 0.7743 - val_loss: 0.4856 - val_accuracy: 0.7604\n",
      "Epoch 804/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4631 - accuracy: 0.7743 - val_loss: 0.4856 - val_accuracy: 0.7604\n",
      "Epoch 805/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4631 - accuracy: 0.7743 - val_loss: 0.4856 - val_accuracy: 0.7604\n",
      "Epoch 806/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4631 - accuracy: 0.7743 - val_loss: 0.4856 - val_accuracy: 0.7604\n",
      "Epoch 807/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4631 - accuracy: 0.7743 - val_loss: 0.4856 - val_accuracy: 0.7604\n",
      "Epoch 808/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4630 - accuracy: 0.7743 - val_loss: 0.4856 - val_accuracy: 0.7604\n",
      "Epoch 809/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4630 - accuracy: 0.7743 - val_loss: 0.4856 - val_accuracy: 0.7604\n",
      "Epoch 810/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4630 - accuracy: 0.7743 - val_loss: 0.4856 - val_accuracy: 0.7604\n",
      "Epoch 811/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4630 - accuracy: 0.7743 - val_loss: 0.4856 - val_accuracy: 0.7604\n",
      "Epoch 812/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4629 - accuracy: 0.7743 - val_loss: 0.4856 - val_accuracy: 0.7604\n",
      "Epoch 813/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4629 - accuracy: 0.7743 - val_loss: 0.4856 - val_accuracy: 0.7604\n",
      "Epoch 814/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4629 - accuracy: 0.7743 - val_loss: 0.4856 - val_accuracy: 0.7604\n",
      "Epoch 815/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4629 - accuracy: 0.7743 - val_loss: 0.4856 - val_accuracy: 0.7604\n",
      "Epoch 816/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4628 - accuracy: 0.7743 - val_loss: 0.4856 - val_accuracy: 0.7604\n",
      "Epoch 817/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4628 - accuracy: 0.7743 - val_loss: 0.4856 - val_accuracy: 0.7604\n",
      "Epoch 818/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4628 - accuracy: 0.7743 - val_loss: 0.4856 - val_accuracy: 0.7604\n",
      "Epoch 819/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4628 - accuracy: 0.7743 - val_loss: 0.4856 - val_accuracy: 0.7604\n",
      "Epoch 820/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4628 - accuracy: 0.7760 - val_loss: 0.4856 - val_accuracy: 0.7604\n",
      "Epoch 821/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4628 - accuracy: 0.7760 - val_loss: 0.4856 - val_accuracy: 0.7604\n",
      "Epoch 822/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4627 - accuracy: 0.7743 - val_loss: 0.4856 - val_accuracy: 0.7604\n",
      "Epoch 823/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4627 - accuracy: 0.7760 - val_loss: 0.4855 - val_accuracy: 0.7604\n",
      "Epoch 824/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4627 - accuracy: 0.7760 - val_loss: 0.4855 - val_accuracy: 0.7604\n",
      "Epoch 825/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4627 - accuracy: 0.7743 - val_loss: 0.4855 - val_accuracy: 0.7604\n",
      "Epoch 826/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4627 - accuracy: 0.7743 - val_loss: 0.4855 - val_accuracy: 0.7604\n",
      "Epoch 827/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4626 - accuracy: 0.7760 - val_loss: 0.4855 - val_accuracy: 0.7604\n",
      "Epoch 828/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4626 - accuracy: 0.7760 - val_loss: 0.4855 - val_accuracy: 0.7604\n",
      "Epoch 829/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4626 - accuracy: 0.7743 - val_loss: 0.4855 - val_accuracy: 0.7604\n",
      "Epoch 830/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4626 - accuracy: 0.7743 - val_loss: 0.4855 - val_accuracy: 0.7604\n",
      "Epoch 831/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4625 - accuracy: 0.7760 - val_loss: 0.4855 - val_accuracy: 0.7604\n",
      "Epoch 832/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4625 - accuracy: 0.7760 - val_loss: 0.4855 - val_accuracy: 0.7604\n",
      "Epoch 833/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4625 - accuracy: 0.7760 - val_loss: 0.4855 - val_accuracy: 0.7604\n",
      "Epoch 834/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4625 - accuracy: 0.7743 - val_loss: 0.4855 - val_accuracy: 0.7604\n",
      "Epoch 835/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4625 - accuracy: 0.7743 - val_loss: 0.4855 - val_accuracy: 0.7604\n",
      "Epoch 836/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4625 - accuracy: 0.7760 - val_loss: 0.4855 - val_accuracy: 0.7604\n",
      "Epoch 837/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4624 - accuracy: 0.7743 - val_loss: 0.4855 - val_accuracy: 0.7604\n",
      "Epoch 838/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4624 - accuracy: 0.7760 - val_loss: 0.4855 - val_accuracy: 0.7604\n",
      "Epoch 839/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4624 - accuracy: 0.7760 - val_loss: 0.4855 - val_accuracy: 0.7604\n",
      "Epoch 840/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4624 - accuracy: 0.7760 - val_loss: 0.4855 - val_accuracy: 0.7552\n",
      "Epoch 841/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4624 - accuracy: 0.7760 - val_loss: 0.4855 - val_accuracy: 0.7552\n",
      "Epoch 842/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4624 - accuracy: 0.7760 - val_loss: 0.4855 - val_accuracy: 0.7552\n",
      "Epoch 843/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4623 - accuracy: 0.7760 - val_loss: 0.4855 - val_accuracy: 0.7552\n",
      "Epoch 844/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4623 - accuracy: 0.7760 - val_loss: 0.4855 - val_accuracy: 0.7552\n",
      "Epoch 845/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4623 - accuracy: 0.7760 - val_loss: 0.4855 - val_accuracy: 0.7552\n",
      "Epoch 846/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4623 - accuracy: 0.7760 - val_loss: 0.4855 - val_accuracy: 0.7552\n",
      "Epoch 847/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4622 - accuracy: 0.7760 - val_loss: 0.4855 - val_accuracy: 0.7552\n",
      "Epoch 848/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4622 - accuracy: 0.7760 - val_loss: 0.4855 - val_accuracy: 0.7552\n",
      "Epoch 849/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4622 - accuracy: 0.7760 - val_loss: 0.4855 - val_accuracy: 0.7552\n",
      "Epoch 850/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4622 - accuracy: 0.7760 - val_loss: 0.4854 - val_accuracy: 0.7552\n",
      "Epoch 851/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4622 - accuracy: 0.7760 - val_loss: 0.4854 - val_accuracy: 0.7552\n",
      "Epoch 852/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4622 - accuracy: 0.7760 - val_loss: 0.4854 - val_accuracy: 0.7552\n",
      "Epoch 853/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4622 - accuracy: 0.7760 - val_loss: 0.4854 - val_accuracy: 0.7552\n",
      "Epoch 854/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4621 - accuracy: 0.7760 - val_loss: 0.4854 - val_accuracy: 0.7552\n",
      "Epoch 855/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4621 - accuracy: 0.7760 - val_loss: 0.4854 - val_accuracy: 0.7552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 856/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4621 - accuracy: 0.7760 - val_loss: 0.4854 - val_accuracy: 0.7552\n",
      "Epoch 857/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4621 - accuracy: 0.7760 - val_loss: 0.4854 - val_accuracy: 0.7552\n",
      "Epoch 858/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4620 - accuracy: 0.7760 - val_loss: 0.4854 - val_accuracy: 0.7552\n",
      "Epoch 859/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4620 - accuracy: 0.7760 - val_loss: 0.4854 - val_accuracy: 0.7552\n",
      "Epoch 860/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4620 - accuracy: 0.7760 - val_loss: 0.4854 - val_accuracy: 0.7552\n",
      "Epoch 861/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4620 - accuracy: 0.7760 - val_loss: 0.4854 - val_accuracy: 0.7552\n",
      "Epoch 862/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4620 - accuracy: 0.7760 - val_loss: 0.4854 - val_accuracy: 0.7552\n",
      "Epoch 863/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4620 - accuracy: 0.7760 - val_loss: 0.4854 - val_accuracy: 0.7552\n",
      "Epoch 864/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4620 - accuracy: 0.7760 - val_loss: 0.4854 - val_accuracy: 0.7552\n",
      "Epoch 865/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4619 - accuracy: 0.7760 - val_loss: 0.4854 - val_accuracy: 0.7552\n",
      "Epoch 866/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4619 - accuracy: 0.7760 - val_loss: 0.4854 - val_accuracy: 0.7552\n",
      "Epoch 867/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4619 - accuracy: 0.7760 - val_loss: 0.4854 - val_accuracy: 0.7552\n",
      "Epoch 868/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4619 - accuracy: 0.7760 - val_loss: 0.4854 - val_accuracy: 0.7552\n",
      "Epoch 869/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4618 - accuracy: 0.7760 - val_loss: 0.4854 - val_accuracy: 0.7552\n",
      "Epoch 870/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4618 - accuracy: 0.7760 - val_loss: 0.4854 - val_accuracy: 0.7552\n",
      "Epoch 871/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4618 - accuracy: 0.7760 - val_loss: 0.4854 - val_accuracy: 0.7552\n",
      "Epoch 872/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4618 - accuracy: 0.7760 - val_loss: 0.4854 - val_accuracy: 0.7552\n",
      "Epoch 873/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4618 - accuracy: 0.7760 - val_loss: 0.4854 - val_accuracy: 0.7552\n",
      "Epoch 874/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4618 - accuracy: 0.7760 - val_loss: 0.4854 - val_accuracy: 0.7552\n",
      "Epoch 875/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4617 - accuracy: 0.7760 - val_loss: 0.4854 - val_accuracy: 0.7552\n",
      "Epoch 876/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4617 - accuracy: 0.7760 - val_loss: 0.4854 - val_accuracy: 0.7552\n",
      "Epoch 877/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4617 - accuracy: 0.7760 - val_loss: 0.4854 - val_accuracy: 0.7552\n",
      "Epoch 878/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4617 - accuracy: 0.7760 - val_loss: 0.4854 - val_accuracy: 0.7552\n",
      "Epoch 879/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4617 - accuracy: 0.7760 - val_loss: 0.4854 - val_accuracy: 0.7552\n",
      "Epoch 880/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4617 - accuracy: 0.7760 - val_loss: 0.4854 - val_accuracy: 0.7552\n",
      "Epoch 881/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4616 - accuracy: 0.7760 - val_loss: 0.4854 - val_accuracy: 0.7552\n",
      "Epoch 882/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4616 - accuracy: 0.7760 - val_loss: 0.4854 - val_accuracy: 0.7552\n",
      "Epoch 883/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4616 - accuracy: 0.7760 - val_loss: 0.4854 - val_accuracy: 0.7552\n",
      "Epoch 884/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4616 - accuracy: 0.7760 - val_loss: 0.4854 - val_accuracy: 0.7552\n",
      "Epoch 885/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4616 - accuracy: 0.7760 - val_loss: 0.4854 - val_accuracy: 0.7552\n",
      "Epoch 886/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4616 - accuracy: 0.7760 - val_loss: 0.4854 - val_accuracy: 0.7552\n",
      "Epoch 887/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4615 - accuracy: 0.7760 - val_loss: 0.4853 - val_accuracy: 0.7552\n",
      "Epoch 888/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4615 - accuracy: 0.7760 - val_loss: 0.4853 - val_accuracy: 0.7552\n",
      "Epoch 889/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4615 - accuracy: 0.7760 - val_loss: 0.4853 - val_accuracy: 0.7552\n",
      "Epoch 890/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4615 - accuracy: 0.7760 - val_loss: 0.4853 - val_accuracy: 0.7552\n",
      "Epoch 891/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4615 - accuracy: 0.7760 - val_loss: 0.4853 - val_accuracy: 0.7552\n",
      "Epoch 892/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4615 - accuracy: 0.7760 - val_loss: 0.4853 - val_accuracy: 0.7552\n",
      "Epoch 893/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4614 - accuracy: 0.7760 - val_loss: 0.4853 - val_accuracy: 0.7552\n",
      "Epoch 894/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4614 - accuracy: 0.7760 - val_loss: 0.4853 - val_accuracy: 0.7552\n",
      "Epoch 895/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4614 - accuracy: 0.7760 - val_loss: 0.4853 - val_accuracy: 0.7604\n",
      "Epoch 896/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4614 - accuracy: 0.7760 - val_loss: 0.4853 - val_accuracy: 0.7604\n",
      "Epoch 897/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4614 - accuracy: 0.7760 - val_loss: 0.4853 - val_accuracy: 0.7604\n",
      "Epoch 898/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4613 - accuracy: 0.7760 - val_loss: 0.4853 - val_accuracy: 0.7604\n",
      "Epoch 899/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4613 - accuracy: 0.7760 - val_loss: 0.4853 - val_accuracy: 0.7604\n",
      "Epoch 900/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4613 - accuracy: 0.7760 - val_loss: 0.4853 - val_accuracy: 0.7604\n",
      "Epoch 901/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4613 - accuracy: 0.7760 - val_loss: 0.4853 - val_accuracy: 0.7604\n",
      "Epoch 902/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4613 - accuracy: 0.7760 - val_loss: 0.4853 - val_accuracy: 0.7604\n",
      "Epoch 903/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4613 - accuracy: 0.7760 - val_loss: 0.4853 - val_accuracy: 0.7604\n",
      "Epoch 904/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4613 - accuracy: 0.7760 - val_loss: 0.4853 - val_accuracy: 0.7604\n",
      "Epoch 905/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4612 - accuracy: 0.7760 - val_loss: 0.4853 - val_accuracy: 0.7604\n",
      "Epoch 906/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4612 - accuracy: 0.7760 - val_loss: 0.4853 - val_accuracy: 0.7604\n",
      "Epoch 907/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4612 - accuracy: 0.7760 - val_loss: 0.4853 - val_accuracy: 0.7604\n",
      "Epoch 908/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4612 - accuracy: 0.7760 - val_loss: 0.4853 - val_accuracy: 0.7604\n",
      "Epoch 909/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4612 - accuracy: 0.7760 - val_loss: 0.4853 - val_accuracy: 0.7604\n",
      "Epoch 910/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4612 - accuracy: 0.7760 - val_loss: 0.4853 - val_accuracy: 0.7604\n",
      "Epoch 911/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4611 - accuracy: 0.7760 - val_loss: 0.4853 - val_accuracy: 0.7604\n",
      "Epoch 912/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4611 - accuracy: 0.7760 - val_loss: 0.4853 - val_accuracy: 0.7604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 913/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4611 - accuracy: 0.7760 - val_loss: 0.4853 - val_accuracy: 0.7604\n",
      "Epoch 914/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4611 - accuracy: 0.7760 - val_loss: 0.4853 - val_accuracy: 0.7604\n",
      "Epoch 915/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4611 - accuracy: 0.7760 - val_loss: 0.4853 - val_accuracy: 0.7604\n",
      "Epoch 916/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4611 - accuracy: 0.7760 - val_loss: 0.4853 - val_accuracy: 0.7604\n",
      "Epoch 917/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4611 - accuracy: 0.7760 - val_loss: 0.4853 - val_accuracy: 0.7604\n",
      "Epoch 918/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4610 - accuracy: 0.7760 - val_loss: 0.4853 - val_accuracy: 0.7604\n",
      "Epoch 919/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4610 - accuracy: 0.7760 - val_loss: 0.4853 - val_accuracy: 0.7604\n",
      "Epoch 920/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4610 - accuracy: 0.7760 - val_loss: 0.4853 - val_accuracy: 0.7604\n",
      "Epoch 921/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4610 - accuracy: 0.7760 - val_loss: 0.4853 - val_accuracy: 0.7604\n",
      "Epoch 922/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4610 - accuracy: 0.7778 - val_loss: 0.4853 - val_accuracy: 0.7604\n",
      "Epoch 923/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4610 - accuracy: 0.7778 - val_loss: 0.4853 - val_accuracy: 0.7604\n",
      "Epoch 924/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4610 - accuracy: 0.7760 - val_loss: 0.4853 - val_accuracy: 0.7604\n",
      "Epoch 925/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4609 - accuracy: 0.7760 - val_loss: 0.4853 - val_accuracy: 0.7552\n",
      "Epoch 926/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4609 - accuracy: 0.7760 - val_loss: 0.4853 - val_accuracy: 0.7552\n",
      "Epoch 927/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4609 - accuracy: 0.7760 - val_loss: 0.4853 - val_accuracy: 0.7552\n",
      "Epoch 928/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4609 - accuracy: 0.7760 - val_loss: 0.4853 - val_accuracy: 0.7552\n",
      "Epoch 929/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4609 - accuracy: 0.7760 - val_loss: 0.4853 - val_accuracy: 0.7552\n",
      "Epoch 930/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4609 - accuracy: 0.7778 - val_loss: 0.4853 - val_accuracy: 0.7552\n",
      "Epoch 931/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4608 - accuracy: 0.7760 - val_loss: 0.4853 - val_accuracy: 0.7552\n",
      "Epoch 932/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4608 - accuracy: 0.7760 - val_loss: 0.4853 - val_accuracy: 0.7552\n",
      "Epoch 933/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4608 - accuracy: 0.7778 - val_loss: 0.4853 - val_accuracy: 0.7552\n",
      "Epoch 934/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4608 - accuracy: 0.7760 - val_loss: 0.4853 - val_accuracy: 0.7552\n",
      "Epoch 935/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4608 - accuracy: 0.7760 - val_loss: 0.4853 - val_accuracy: 0.7552\n",
      "Epoch 936/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4608 - accuracy: 0.7778 - val_loss: 0.4853 - val_accuracy: 0.7552\n",
      "Epoch 937/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4607 - accuracy: 0.7760 - val_loss: 0.4853 - val_accuracy: 0.7552\n",
      "Epoch 938/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4607 - accuracy: 0.7760 - val_loss: 0.4853 - val_accuracy: 0.7552\n",
      "Epoch 939/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4607 - accuracy: 0.7778 - val_loss: 0.4853 - val_accuracy: 0.7552\n",
      "Epoch 940/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4607 - accuracy: 0.7778 - val_loss: 0.4853 - val_accuracy: 0.7552\n",
      "Epoch 941/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4607 - accuracy: 0.7760 - val_loss: 0.4853 - val_accuracy: 0.7552\n",
      "Epoch 942/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4607 - accuracy: 0.7760 - val_loss: 0.4853 - val_accuracy: 0.7552\n",
      "Epoch 943/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4607 - accuracy: 0.7778 - val_loss: 0.4853 - val_accuracy: 0.7552\n",
      "Epoch 944/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4607 - accuracy: 0.7778 - val_loss: 0.4853 - val_accuracy: 0.7552\n",
      "Epoch 945/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4606 - accuracy: 0.7760 - val_loss: 0.4853 - val_accuracy: 0.7552\n",
      "Epoch 946/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4606 - accuracy: 0.7778 - val_loss: 0.4853 - val_accuracy: 0.7552\n",
      "Epoch 947/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4606 - accuracy: 0.7778 - val_loss: 0.4853 - val_accuracy: 0.7552\n",
      "Epoch 948/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4606 - accuracy: 0.7778 - val_loss: 0.4853 - val_accuracy: 0.7552\n",
      "Epoch 949/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4606 - accuracy: 0.7778 - val_loss: 0.4853 - val_accuracy: 0.7552\n",
      "Epoch 950/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4606 - accuracy: 0.7760 - val_loss: 0.4853 - val_accuracy: 0.7552\n",
      "Epoch 951/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4606 - accuracy: 0.7778 - val_loss: 0.4853 - val_accuracy: 0.7552\n",
      "Epoch 952/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4606 - accuracy: 0.7760 - val_loss: 0.4853 - val_accuracy: 0.7552\n",
      "Epoch 953/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4605 - accuracy: 0.7778 - val_loss: 0.4853 - val_accuracy: 0.7552\n",
      "Epoch 954/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4605 - accuracy: 0.7778 - val_loss: 0.4853 - val_accuracy: 0.7552\n",
      "Epoch 955/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4605 - accuracy: 0.7778 - val_loss: 0.4853 - val_accuracy: 0.7500\n",
      "Epoch 956/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4605 - accuracy: 0.7778 - val_loss: 0.4853 - val_accuracy: 0.7500\n",
      "Epoch 957/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4605 - accuracy: 0.7778 - val_loss: 0.4853 - val_accuracy: 0.7500\n",
      "Epoch 958/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4605 - accuracy: 0.7778 - val_loss: 0.4853 - val_accuracy: 0.7500\n",
      "Epoch 959/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4605 - accuracy: 0.7760 - val_loss: 0.4853 - val_accuracy: 0.7500\n",
      "Epoch 960/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4604 - accuracy: 0.7778 - val_loss: 0.4853 - val_accuracy: 0.7500\n",
      "Epoch 961/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4604 - accuracy: 0.7778 - val_loss: 0.4853 - val_accuracy: 0.7500\n",
      "Epoch 962/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4604 - accuracy: 0.7778 - val_loss: 0.4853 - val_accuracy: 0.7500\n",
      "Epoch 963/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4604 - accuracy: 0.7778 - val_loss: 0.4853 - val_accuracy: 0.7500\n",
      "Epoch 964/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4604 - accuracy: 0.7778 - val_loss: 0.4853 - val_accuracy: 0.7500\n",
      "Epoch 965/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4604 - accuracy: 0.7778 - val_loss: 0.4853 - val_accuracy: 0.7500\n",
      "Epoch 966/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4604 - accuracy: 0.7778 - val_loss: 0.4853 - val_accuracy: 0.7500\n",
      "Epoch 967/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4603 - accuracy: 0.7778 - val_loss: 0.4853 - val_accuracy: 0.7500\n",
      "Epoch 968/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4603 - accuracy: 0.7778 - val_loss: 0.4853 - val_accuracy: 0.7500\n",
      "Epoch 969/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4603 - accuracy: 0.7778 - val_loss: 0.4853 - val_accuracy: 0.7500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 970/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4603 - accuracy: 0.7778 - val_loss: 0.4853 - val_accuracy: 0.7552\n",
      "Epoch 971/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4603 - accuracy: 0.7778 - val_loss: 0.4853 - val_accuracy: 0.7552\n",
      "Epoch 972/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4603 - accuracy: 0.7778 - val_loss: 0.4853 - val_accuracy: 0.7552\n",
      "Epoch 973/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4603 - accuracy: 0.7778 - val_loss: 0.4853 - val_accuracy: 0.7552\n",
      "Epoch 974/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4603 - accuracy: 0.7778 - val_loss: 0.4853 - val_accuracy: 0.7552\n",
      "Epoch 975/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4603 - accuracy: 0.7778 - val_loss: 0.4853 - val_accuracy: 0.7552\n",
      "Epoch 976/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4602 - accuracy: 0.7778 - val_loss: 0.4853 - val_accuracy: 0.7552\n",
      "Epoch 977/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4602 - accuracy: 0.7778 - val_loss: 0.4853 - val_accuracy: 0.7552\n",
      "Epoch 978/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4602 - accuracy: 0.7778 - val_loss: 0.4853 - val_accuracy: 0.7552\n",
      "Epoch 979/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4602 - accuracy: 0.7778 - val_loss: 0.4853 - val_accuracy: 0.7552\n",
      "Epoch 980/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4602 - accuracy: 0.7778 - val_loss: 0.4853 - val_accuracy: 0.7552\n",
      "Epoch 981/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4602 - accuracy: 0.7778 - val_loss: 0.4853 - val_accuracy: 0.7552\n",
      "Epoch 982/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4601 - accuracy: 0.7760 - val_loss: 0.4853 - val_accuracy: 0.7552\n",
      "Epoch 983/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4602 - accuracy: 0.7778 - val_loss: 0.4853 - val_accuracy: 0.7552\n",
      "Epoch 984/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4601 - accuracy: 0.7778 - val_loss: 0.4853 - val_accuracy: 0.7552\n",
      "Epoch 985/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4601 - accuracy: 0.7760 - val_loss: 0.4853 - val_accuracy: 0.7552\n",
      "Epoch 986/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4601 - accuracy: 0.7760 - val_loss: 0.4853 - val_accuracy: 0.7552\n",
      "Epoch 987/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4601 - accuracy: 0.7778 - val_loss: 0.4853 - val_accuracy: 0.7552\n",
      "Epoch 988/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4601 - accuracy: 0.7778 - val_loss: 0.4853 - val_accuracy: 0.7552\n",
      "Epoch 989/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4601 - accuracy: 0.7778 - val_loss: 0.4853 - val_accuracy: 0.7552\n",
      "Epoch 990/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4600 - accuracy: 0.7778 - val_loss: 0.4853 - val_accuracy: 0.7552\n",
      "Epoch 991/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4600 - accuracy: 0.7760 - val_loss: 0.4853 - val_accuracy: 0.7552\n",
      "Epoch 992/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4600 - accuracy: 0.7760 - val_loss: 0.4853 - val_accuracy: 0.7552\n",
      "Epoch 993/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4600 - accuracy: 0.7778 - val_loss: 0.4853 - val_accuracy: 0.7552\n",
      "Epoch 994/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4600 - accuracy: 0.7778 - val_loss: 0.4853 - val_accuracy: 0.7552\n",
      "Epoch 995/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4600 - accuracy: 0.7760 - val_loss: 0.4853 - val_accuracy: 0.7552\n",
      "Epoch 996/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4600 - accuracy: 0.7760 - val_loss: 0.4853 - val_accuracy: 0.7552\n",
      "Epoch 997/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4600 - accuracy: 0.7760 - val_loss: 0.4853 - val_accuracy: 0.7552\n",
      "Epoch 998/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4600 - accuracy: 0.7760 - val_loss: 0.4853 - val_accuracy: 0.7552\n",
      "Epoch 999/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4599 - accuracy: 0.7760 - val_loss: 0.4853 - val_accuracy: 0.7552\n",
      "Epoch 1000/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4599 - accuracy: 0.7778 - val_loss: 0.4853 - val_accuracy: 0.7552\n"
     ]
    }
   ],
   "source": [
    "## we call \"fit\" again\n",
    "run_hist_1b = model_1.fit(X_train_norm, y_train, \n",
    "                          validation_data=(X_test_norm, y_test), \n",
    "                          epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fa1ecf447c0>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = len(run_hist_1.history[\"loss\"])\n",
    "m = len(run_hist_1b.history['loss'])\n",
    "fig, ax = plt.subplots(figsize=(16, 8))\n",
    "\n",
    "ax.plot(range(n), run_hist_1.history[\"loss\"],'r', marker='.', label=\"Train Loss - Run 1\")\n",
    "ax.plot(range(n, n+m), run_hist_1b.history[\"loss\"], 'hotpink', marker='.', label=\"Train Loss - Run 2\")\n",
    "\n",
    "ax.plot(range(n), run_hist_1.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss - Run 1\")\n",
    "ax.plot(range(n, n+m), run_hist_1b.history[\"val_loss\"], 'LightSkyBlue', marker='.',  label=\"Validation Loss - Run 2\")\n",
    "\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Build a model with two hidden layers, each with 6 nodes\n",
    "- Use the \"relu\" activation function for the hidden layers, and \"sigmoid\" for the final layer\n",
    "- Use a learning rate of .003 and train for 1500 epochs\n",
    "- Graph the trajectory of the loss functions, accuracy on both train and test set\n",
    "- Plot the roc curve for the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_5 (Dense)              (None, 6)                 54        \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 6)                 42        \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 7         \n",
      "=================================================================\n",
      "Total params: 103\n",
      "Trainable params: 103\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_2=Sequential()\n",
    "model_2.add(Dense(6, input_shape=(8,), activation='relu'))\n",
    "model_2.add(Dense(6, input_shape=(6,), activation='relu'))\n",
    "model_2.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.8834 - accuracy: 0.3403 - val_loss: 0.8353 - val_accuracy: 0.3177\n",
      "Epoch 2/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.8586 - accuracy: 0.3472 - val_loss: 0.8138 - val_accuracy: 0.3281\n",
      "Epoch 3/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.8368 - accuracy: 0.3542 - val_loss: 0.7949 - val_accuracy: 0.3490\n",
      "Epoch 4/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.8175 - accuracy: 0.3681 - val_loss: 0.7782 - val_accuracy: 0.3594\n",
      "Epoch 5/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.8002 - accuracy: 0.3698 - val_loss: 0.7635 - val_accuracy: 0.3698\n",
      "Epoch 6/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.7849 - accuracy: 0.3837 - val_loss: 0.7504 - val_accuracy: 0.3906\n",
      "Epoch 7/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.7710 - accuracy: 0.3941 - val_loss: 0.7387 - val_accuracy: 0.4167\n",
      "Epoch 8/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.7584 - accuracy: 0.3993 - val_loss: 0.7283 - val_accuracy: 0.4479\n",
      "Epoch 9/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.7471 - accuracy: 0.4062 - val_loss: 0.7190 - val_accuracy: 0.4688\n",
      "Epoch 10/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.7368 - accuracy: 0.4236 - val_loss: 0.7104 - val_accuracy: 0.5052\n",
      "Epoch 11/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.7273 - accuracy: 0.4410 - val_loss: 0.7027 - val_accuracy: 0.5260\n",
      "Epoch 12/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.7186 - accuracy: 0.4774 - val_loss: 0.6958 - val_accuracy: 0.5573\n",
      "Epoch 13/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.7106 - accuracy: 0.4861 - val_loss: 0.6897 - val_accuracy: 0.5729\n",
      "Epoch 14/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.7034 - accuracy: 0.5052 - val_loss: 0.6841 - val_accuracy: 0.5833\n",
      "Epoch 15/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6968 - accuracy: 0.5330 - val_loss: 0.6791 - val_accuracy: 0.6198\n",
      "Epoch 16/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6906 - accuracy: 0.5382 - val_loss: 0.6745 - val_accuracy: 0.6302\n",
      "Epoch 17/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6850 - accuracy: 0.5590 - val_loss: 0.6703 - val_accuracy: 0.6146\n",
      "Epoch 18/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6797 - accuracy: 0.5677 - val_loss: 0.6664 - val_accuracy: 0.6458\n",
      "Epoch 19/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6749 - accuracy: 0.5955 - val_loss: 0.6629 - val_accuracy: 0.6458\n",
      "Epoch 20/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6704 - accuracy: 0.6024 - val_loss: 0.6597 - val_accuracy: 0.6510\n",
      "Epoch 21/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6662 - accuracy: 0.6128 - val_loss: 0.6568 - val_accuracy: 0.6615\n",
      "Epoch 22/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6624 - accuracy: 0.6163 - val_loss: 0.6541 - val_accuracy: 0.6615\n",
      "Epoch 23/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6589 - accuracy: 0.6181 - val_loss: 0.6517 - val_accuracy: 0.6667\n",
      "Epoch 24/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6556 - accuracy: 0.6233 - val_loss: 0.6494 - val_accuracy: 0.6719\n",
      "Epoch 25/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6525 - accuracy: 0.6354 - val_loss: 0.6474 - val_accuracy: 0.6823\n",
      "Epoch 26/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6495 - accuracy: 0.6424 - val_loss: 0.6454 - val_accuracy: 0.6823\n",
      "Epoch 27/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6469 - accuracy: 0.6476 - val_loss: 0.6436 - val_accuracy: 0.6823\n",
      "Epoch 28/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6443 - accuracy: 0.6476 - val_loss: 0.6420 - val_accuracy: 0.6771\n",
      "Epoch 29/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6419 - accuracy: 0.6493 - val_loss: 0.6404 - val_accuracy: 0.6719\n",
      "Epoch 30/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6397 - accuracy: 0.6476 - val_loss: 0.6390 - val_accuracy: 0.6719\n",
      "Epoch 31/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6375 - accuracy: 0.6493 - val_loss: 0.6377 - val_accuracy: 0.6667\n",
      "Epoch 32/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6355 - accuracy: 0.6528 - val_loss: 0.6364 - val_accuracy: 0.6562\n",
      "Epoch 33/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6336 - accuracy: 0.6580 - val_loss: 0.6352 - val_accuracy: 0.6562\n",
      "Epoch 34/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6318 - accuracy: 0.6597 - val_loss: 0.6341 - val_accuracy: 0.6562\n",
      "Epoch 35/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6300 - accuracy: 0.6597 - val_loss: 0.6331 - val_accuracy: 0.6562\n",
      "Epoch 36/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6283 - accuracy: 0.6615 - val_loss: 0.6320 - val_accuracy: 0.6562\n",
      "Epoch 37/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6267 - accuracy: 0.6597 - val_loss: 0.6311 - val_accuracy: 0.6562\n",
      "Epoch 38/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6251 - accuracy: 0.6545 - val_loss: 0.6301 - val_accuracy: 0.6510\n",
      "Epoch 39/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6236 - accuracy: 0.6597 - val_loss: 0.6292 - val_accuracy: 0.6510\n",
      "Epoch 40/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6221 - accuracy: 0.6632 - val_loss: 0.6284 - val_accuracy: 0.6510\n",
      "Epoch 41/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6207 - accuracy: 0.6632 - val_loss: 0.6275 - val_accuracy: 0.6562\n",
      "Epoch 42/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6194 - accuracy: 0.6615 - val_loss: 0.6267 - val_accuracy: 0.6562\n",
      "Epoch 43/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6180 - accuracy: 0.6615 - val_loss: 0.6259 - val_accuracy: 0.6510\n",
      "Epoch 44/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6167 - accuracy: 0.6597 - val_loss: 0.6252 - val_accuracy: 0.6510\n",
      "Epoch 45/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6155 - accuracy: 0.6597 - val_loss: 0.6245 - val_accuracy: 0.6510\n",
      "Epoch 46/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6143 - accuracy: 0.6580 - val_loss: 0.6238 - val_accuracy: 0.6510\n",
      "Epoch 47/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6131 - accuracy: 0.6580 - val_loss: 0.6231 - val_accuracy: 0.6562\n",
      "Epoch 48/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6119 - accuracy: 0.6597 - val_loss: 0.6224 - val_accuracy: 0.6562\n",
      "Epoch 49/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6108 - accuracy: 0.6597 - val_loss: 0.6217 - val_accuracy: 0.6562\n",
      "Epoch 50/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6097 - accuracy: 0.6580 - val_loss: 0.6211 - val_accuracy: 0.6562\n",
      "Epoch 51/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6086 - accuracy: 0.6580 - val_loss: 0.6205 - val_accuracy: 0.6562\n",
      "Epoch 52/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6076 - accuracy: 0.6580 - val_loss: 0.6199 - val_accuracy: 0.6562\n",
      "Epoch 53/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6065 - accuracy: 0.6597 - val_loss: 0.6192 - val_accuracy: 0.6562\n",
      "Epoch 54/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6055 - accuracy: 0.6597 - val_loss: 0.6186 - val_accuracy: 0.6562\n",
      "Epoch 55/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6045 - accuracy: 0.6580 - val_loss: 0.6180 - val_accuracy: 0.6562\n",
      "Epoch 56/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6035 - accuracy: 0.6580 - val_loss: 0.6174 - val_accuracy: 0.6562\n",
      "Epoch 57/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6025 - accuracy: 0.6580 - val_loss: 0.6169 - val_accuracy: 0.6562\n",
      "Epoch 58/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6015 - accuracy: 0.6580 - val_loss: 0.6163 - val_accuracy: 0.6562\n",
      "Epoch 59/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6006 - accuracy: 0.6580 - val_loss: 0.6158 - val_accuracy: 0.6562\n",
      "Epoch 60/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5997 - accuracy: 0.6597 - val_loss: 0.6152 - val_accuracy: 0.6562\n",
      "Epoch 61/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5987 - accuracy: 0.6597 - val_loss: 0.6147 - val_accuracy: 0.6562\n",
      "Epoch 62/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5978 - accuracy: 0.6597 - val_loss: 0.6142 - val_accuracy: 0.6562\n",
      "Epoch 63/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5969 - accuracy: 0.6615 - val_loss: 0.6136 - val_accuracy: 0.6562\n",
      "Epoch 64/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5960 - accuracy: 0.6615 - val_loss: 0.6131 - val_accuracy: 0.6562\n",
      "Epoch 65/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5951 - accuracy: 0.6615 - val_loss: 0.6126 - val_accuracy: 0.6562\n",
      "Epoch 66/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5942 - accuracy: 0.6597 - val_loss: 0.6120 - val_accuracy: 0.6562\n",
      "Epoch 67/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5933 - accuracy: 0.6597 - val_loss: 0.6115 - val_accuracy: 0.6562\n",
      "Epoch 68/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5924 - accuracy: 0.6580 - val_loss: 0.6110 - val_accuracy: 0.6562\n",
      "Epoch 69/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5915 - accuracy: 0.6580 - val_loss: 0.6104 - val_accuracy: 0.6562\n",
      "Epoch 70/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5907 - accuracy: 0.6545 - val_loss: 0.6099 - val_accuracy: 0.6562\n",
      "Epoch 71/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5898 - accuracy: 0.6545 - val_loss: 0.6094 - val_accuracy: 0.6562\n",
      "Epoch 72/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5890 - accuracy: 0.6545 - val_loss: 0.6089 - val_accuracy: 0.6562\n",
      "Epoch 73/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5881 - accuracy: 0.6545 - val_loss: 0.6084 - val_accuracy: 0.6562\n",
      "Epoch 74/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5873 - accuracy: 0.6562 - val_loss: 0.6079 - val_accuracy: 0.6562\n",
      "Epoch 75/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5865 - accuracy: 0.6580 - val_loss: 0.6074 - val_accuracy: 0.6562\n",
      "Epoch 76/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5857 - accuracy: 0.6580 - val_loss: 0.6069 - val_accuracy: 0.6562\n",
      "Epoch 77/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5849 - accuracy: 0.6597 - val_loss: 0.6064 - val_accuracy: 0.6615\n",
      "Epoch 78/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5841 - accuracy: 0.6545 - val_loss: 0.6060 - val_accuracy: 0.6615\n",
      "Epoch 79/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5833 - accuracy: 0.6545 - val_loss: 0.6055 - val_accuracy: 0.6615\n",
      "Epoch 80/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5825 - accuracy: 0.6545 - val_loss: 0.6050 - val_accuracy: 0.6615\n",
      "Epoch 81/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5817 - accuracy: 0.6545 - val_loss: 0.6045 - val_accuracy: 0.6615\n",
      "Epoch 82/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5809 - accuracy: 0.6545 - val_loss: 0.6040 - val_accuracy: 0.6667\n",
      "Epoch 83/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5801 - accuracy: 0.6545 - val_loss: 0.6035 - val_accuracy: 0.6667\n",
      "Epoch 84/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5793 - accuracy: 0.6545 - val_loss: 0.6031 - val_accuracy: 0.6667\n",
      "Epoch 85/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5786 - accuracy: 0.6562 - val_loss: 0.6026 - val_accuracy: 0.6719\n",
      "Epoch 86/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5778 - accuracy: 0.6562 - val_loss: 0.6022 - val_accuracy: 0.6719\n",
      "Epoch 87/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5771 - accuracy: 0.6562 - val_loss: 0.6017 - val_accuracy: 0.6719\n",
      "Epoch 88/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5763 - accuracy: 0.6562 - val_loss: 0.6013 - val_accuracy: 0.6719\n",
      "Epoch 89/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5756 - accuracy: 0.6580 - val_loss: 0.6009 - val_accuracy: 0.6719\n",
      "Epoch 90/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5749 - accuracy: 0.6580 - val_loss: 0.6004 - val_accuracy: 0.6719\n",
      "Epoch 91/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5742 - accuracy: 0.6562 - val_loss: 0.6000 - val_accuracy: 0.6719\n",
      "Epoch 92/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5735 - accuracy: 0.6580 - val_loss: 0.5996 - val_accuracy: 0.6719\n",
      "Epoch 93/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5728 - accuracy: 0.6580 - val_loss: 0.5992 - val_accuracy: 0.6719\n",
      "Epoch 94/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5721 - accuracy: 0.6562 - val_loss: 0.5988 - val_accuracy: 0.6719\n",
      "Epoch 95/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5714 - accuracy: 0.6545 - val_loss: 0.5984 - val_accuracy: 0.6719\n",
      "Epoch 96/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5708 - accuracy: 0.6580 - val_loss: 0.5979 - val_accuracy: 0.6719\n",
      "Epoch 97/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5701 - accuracy: 0.6562 - val_loss: 0.5975 - val_accuracy: 0.6719\n",
      "Epoch 98/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5694 - accuracy: 0.6597 - val_loss: 0.5971 - val_accuracy: 0.6719\n",
      "Epoch 99/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5687 - accuracy: 0.6597 - val_loss: 0.5967 - val_accuracy: 0.6667\n",
      "Epoch 100/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5681 - accuracy: 0.6597 - val_loss: 0.5963 - val_accuracy: 0.6667\n",
      "Epoch 101/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5674 - accuracy: 0.6615 - val_loss: 0.5959 - val_accuracy: 0.6667\n",
      "Epoch 102/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5667 - accuracy: 0.6632 - val_loss: 0.5955 - val_accuracy: 0.6719\n",
      "Epoch 103/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5661 - accuracy: 0.6649 - val_loss: 0.5951 - val_accuracy: 0.6719\n",
      "Epoch 104/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5654 - accuracy: 0.6649 - val_loss: 0.5947 - val_accuracy: 0.6719\n",
      "Epoch 105/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5648 - accuracy: 0.6667 - val_loss: 0.5943 - val_accuracy: 0.6719\n",
      "Epoch 106/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5641 - accuracy: 0.6667 - val_loss: 0.5939 - val_accuracy: 0.6719\n",
      "Epoch 107/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5635 - accuracy: 0.6667 - val_loss: 0.5935 - val_accuracy: 0.6719\n",
      "Epoch 108/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5628 - accuracy: 0.6667 - val_loss: 0.5931 - val_accuracy: 0.6719\n",
      "Epoch 109/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5621 - accuracy: 0.6667 - val_loss: 0.5927 - val_accuracy: 0.6719\n",
      "Epoch 110/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5615 - accuracy: 0.6701 - val_loss: 0.5923 - val_accuracy: 0.6719\n",
      "Epoch 111/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5608 - accuracy: 0.6684 - val_loss: 0.5919 - val_accuracy: 0.6719\n",
      "Epoch 112/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5602 - accuracy: 0.6684 - val_loss: 0.5915 - val_accuracy: 0.6719\n",
      "Epoch 113/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5596 - accuracy: 0.6684 - val_loss: 0.5911 - val_accuracy: 0.6719\n",
      "Epoch 114/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5589 - accuracy: 0.6684 - val_loss: 0.5907 - val_accuracy: 0.6719\n",
      "Epoch 115/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5584 - accuracy: 0.6684 - val_loss: 0.5904 - val_accuracy: 0.6771\n",
      "Epoch 116/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5578 - accuracy: 0.6667 - val_loss: 0.5900 - val_accuracy: 0.6771\n",
      "Epoch 117/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5572 - accuracy: 0.6684 - val_loss: 0.5897 - val_accuracy: 0.6771\n",
      "Epoch 118/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5567 - accuracy: 0.6719 - val_loss: 0.5893 - val_accuracy: 0.6771\n",
      "Epoch 119/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5561 - accuracy: 0.6719 - val_loss: 0.5890 - val_accuracy: 0.6719\n",
      "Epoch 120/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5556 - accuracy: 0.6719 - val_loss: 0.5886 - val_accuracy: 0.6719\n",
      "Epoch 121/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5551 - accuracy: 0.6736 - val_loss: 0.5883 - val_accuracy: 0.6719\n",
      "Epoch 122/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5545 - accuracy: 0.6736 - val_loss: 0.5879 - val_accuracy: 0.6719\n",
      "Epoch 123/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5540 - accuracy: 0.6753 - val_loss: 0.5876 - val_accuracy: 0.6719\n",
      "Epoch 124/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5534 - accuracy: 0.6771 - val_loss: 0.5873 - val_accuracy: 0.6771\n",
      "Epoch 125/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5529 - accuracy: 0.6771 - val_loss: 0.5869 - val_accuracy: 0.6771\n",
      "Epoch 126/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5524 - accuracy: 0.6788 - val_loss: 0.5866 - val_accuracy: 0.6771\n",
      "Epoch 127/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5518 - accuracy: 0.6823 - val_loss: 0.5863 - val_accuracy: 0.6771\n",
      "Epoch 128/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5513 - accuracy: 0.6823 - val_loss: 0.5860 - val_accuracy: 0.6823\n",
      "Epoch 129/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5509 - accuracy: 0.6840 - val_loss: 0.5857 - val_accuracy: 0.6823\n",
      "Epoch 130/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5503 - accuracy: 0.6840 - val_loss: 0.5854 - val_accuracy: 0.6823\n",
      "Epoch 131/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5498 - accuracy: 0.6840 - val_loss: 0.5851 - val_accuracy: 0.6823\n",
      "Epoch 132/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5494 - accuracy: 0.6823 - val_loss: 0.5848 - val_accuracy: 0.6927\n",
      "Epoch 133/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5488 - accuracy: 0.6840 - val_loss: 0.5845 - val_accuracy: 0.6927\n",
      "Epoch 134/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5483 - accuracy: 0.6823 - val_loss: 0.5842 - val_accuracy: 0.6927\n",
      "Epoch 135/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5478 - accuracy: 0.6823 - val_loss: 0.5838 - val_accuracy: 0.6927\n",
      "Epoch 136/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5473 - accuracy: 0.6823 - val_loss: 0.5835 - val_accuracy: 0.6979\n",
      "Epoch 137/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5468 - accuracy: 0.6823 - val_loss: 0.5832 - val_accuracy: 0.6979\n",
      "Epoch 138/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5463 - accuracy: 0.6840 - val_loss: 0.5829 - val_accuracy: 0.6979\n",
      "Epoch 139/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5458 - accuracy: 0.6823 - val_loss: 0.5826 - val_accuracy: 0.6979\n",
      "Epoch 140/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5453 - accuracy: 0.6823 - val_loss: 0.5823 - val_accuracy: 0.7031\n",
      "Epoch 141/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5448 - accuracy: 0.6840 - val_loss: 0.5821 - val_accuracy: 0.7031\n",
      "Epoch 142/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5443 - accuracy: 0.6858 - val_loss: 0.5818 - val_accuracy: 0.7031\n",
      "Epoch 143/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5438 - accuracy: 0.6858 - val_loss: 0.5815 - val_accuracy: 0.7083\n",
      "Epoch 144/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5433 - accuracy: 0.6875 - val_loss: 0.5812 - val_accuracy: 0.7083\n",
      "Epoch 145/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5428 - accuracy: 0.6910 - val_loss: 0.5810 - val_accuracy: 0.7083\n",
      "Epoch 146/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5424 - accuracy: 0.6910 - val_loss: 0.5807 - val_accuracy: 0.7083\n",
      "Epoch 147/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5419 - accuracy: 0.6910 - val_loss: 0.5805 - val_accuracy: 0.7083\n",
      "Epoch 148/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5414 - accuracy: 0.6927 - val_loss: 0.5802 - val_accuracy: 0.7083\n",
      "Epoch 149/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5409 - accuracy: 0.6927 - val_loss: 0.5800 - val_accuracy: 0.7031\n",
      "Epoch 150/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5405 - accuracy: 0.6944 - val_loss: 0.5797 - val_accuracy: 0.7031\n",
      "Epoch 151/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5400 - accuracy: 0.6944 - val_loss: 0.5795 - val_accuracy: 0.7031\n",
      "Epoch 152/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5396 - accuracy: 0.6944 - val_loss: 0.5792 - val_accuracy: 0.7031\n",
      "Epoch 153/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5391 - accuracy: 0.6944 - val_loss: 0.5789 - val_accuracy: 0.7083\n",
      "Epoch 154/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5387 - accuracy: 0.6944 - val_loss: 0.5787 - val_accuracy: 0.7083\n",
      "Epoch 155/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5382 - accuracy: 0.6962 - val_loss: 0.5784 - val_accuracy: 0.7031\n",
      "Epoch 156/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5377 - accuracy: 0.6927 - val_loss: 0.5782 - val_accuracy: 0.7083\n",
      "Epoch 157/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5372 - accuracy: 0.6927 - val_loss: 0.5779 - val_accuracy: 0.7083\n",
      "Epoch 158/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5368 - accuracy: 0.6944 - val_loss: 0.5777 - val_accuracy: 0.7031\n",
      "Epoch 159/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5363 - accuracy: 0.6927 - val_loss: 0.5774 - val_accuracy: 0.6979\n",
      "Epoch 160/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5359 - accuracy: 0.6927 - val_loss: 0.5772 - val_accuracy: 0.6979\n",
      "Epoch 161/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5354 - accuracy: 0.6944 - val_loss: 0.5769 - val_accuracy: 0.6979\n",
      "Epoch 162/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5350 - accuracy: 0.6944 - val_loss: 0.5767 - val_accuracy: 0.6979\n",
      "Epoch 163/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5345 - accuracy: 0.6927 - val_loss: 0.5764 - val_accuracy: 0.6979\n",
      "Epoch 164/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5340 - accuracy: 0.6927 - val_loss: 0.5762 - val_accuracy: 0.6927\n",
      "Epoch 165/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5336 - accuracy: 0.6927 - val_loss: 0.5759 - val_accuracy: 0.6927\n",
      "Epoch 166/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5331 - accuracy: 0.6927 - val_loss: 0.5757 - val_accuracy: 0.6927\n",
      "Epoch 167/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5327 - accuracy: 0.6927 - val_loss: 0.5755 - val_accuracy: 0.6927\n",
      "Epoch 168/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5322 - accuracy: 0.6944 - val_loss: 0.5753 - val_accuracy: 0.6927\n",
      "Epoch 169/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5318 - accuracy: 0.6944 - val_loss: 0.5750 - val_accuracy: 0.6875\n",
      "Epoch 170/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5313 - accuracy: 0.6979 - val_loss: 0.5748 - val_accuracy: 0.6875\n",
      "Epoch 171/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5309 - accuracy: 0.6979 - val_loss: 0.5746 - val_accuracy: 0.6927\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5304 - accuracy: 0.6979 - val_loss: 0.5744 - val_accuracy: 0.6927\n",
      "Epoch 173/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5300 - accuracy: 0.6979 - val_loss: 0.5742 - val_accuracy: 0.6927\n",
      "Epoch 174/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5296 - accuracy: 0.6979 - val_loss: 0.5740 - val_accuracy: 0.6927\n",
      "Epoch 175/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5292 - accuracy: 0.6962 - val_loss: 0.5738 - val_accuracy: 0.6927\n",
      "Epoch 176/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5287 - accuracy: 0.6944 - val_loss: 0.5736 - val_accuracy: 0.6927\n",
      "Epoch 177/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5283 - accuracy: 0.6944 - val_loss: 0.5734 - val_accuracy: 0.6979\n",
      "Epoch 178/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5279 - accuracy: 0.6962 - val_loss: 0.5732 - val_accuracy: 0.7031\n",
      "Epoch 179/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5276 - accuracy: 0.6962 - val_loss: 0.5730 - val_accuracy: 0.7031\n",
      "Epoch 180/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5272 - accuracy: 0.6962 - val_loss: 0.5728 - val_accuracy: 0.7031\n",
      "Epoch 181/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5268 - accuracy: 0.6962 - val_loss: 0.5725 - val_accuracy: 0.7031\n",
      "Epoch 182/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5263 - accuracy: 0.6927 - val_loss: 0.5723 - val_accuracy: 0.7031\n",
      "Epoch 183/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5259 - accuracy: 0.6927 - val_loss: 0.5721 - val_accuracy: 0.7031\n",
      "Epoch 184/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5255 - accuracy: 0.6944 - val_loss: 0.5719 - val_accuracy: 0.7031\n",
      "Epoch 185/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5251 - accuracy: 0.6962 - val_loss: 0.5717 - val_accuracy: 0.7031\n",
      "Epoch 186/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5248 - accuracy: 0.6962 - val_loss: 0.5715 - val_accuracy: 0.7031\n",
      "Epoch 187/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5243 - accuracy: 0.6962 - val_loss: 0.5713 - val_accuracy: 0.7031\n",
      "Epoch 188/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5240 - accuracy: 0.6962 - val_loss: 0.5711 - val_accuracy: 0.7031\n",
      "Epoch 189/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5236 - accuracy: 0.6997 - val_loss: 0.5710 - val_accuracy: 0.7031\n",
      "Epoch 190/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5232 - accuracy: 0.6979 - val_loss: 0.5708 - val_accuracy: 0.7031\n",
      "Epoch 191/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5229 - accuracy: 0.6979 - val_loss: 0.5706 - val_accuracy: 0.7031\n",
      "Epoch 192/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5225 - accuracy: 0.6979 - val_loss: 0.5704 - val_accuracy: 0.7031\n",
      "Epoch 193/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5221 - accuracy: 0.6997 - val_loss: 0.5703 - val_accuracy: 0.7031\n",
      "Epoch 194/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5218 - accuracy: 0.7014 - val_loss: 0.5701 - val_accuracy: 0.7031\n",
      "Epoch 195/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5214 - accuracy: 0.6997 - val_loss: 0.5699 - val_accuracy: 0.7031\n",
      "Epoch 196/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5211 - accuracy: 0.7014 - val_loss: 0.5698 - val_accuracy: 0.7031\n",
      "Epoch 197/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5207 - accuracy: 0.7014 - val_loss: 0.5696 - val_accuracy: 0.7031\n",
      "Epoch 198/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5203 - accuracy: 0.7014 - val_loss: 0.5694 - val_accuracy: 0.7031\n",
      "Epoch 199/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5200 - accuracy: 0.7014 - val_loss: 0.5693 - val_accuracy: 0.7031\n",
      "Epoch 200/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5197 - accuracy: 0.7014 - val_loss: 0.5691 - val_accuracy: 0.7031\n",
      "Epoch 201/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5193 - accuracy: 0.7014 - val_loss: 0.5689 - val_accuracy: 0.7031\n",
      "Epoch 202/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5190 - accuracy: 0.7014 - val_loss: 0.5688 - val_accuracy: 0.7031\n",
      "Epoch 203/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5187 - accuracy: 0.7031 - val_loss: 0.5686 - val_accuracy: 0.7031\n",
      "Epoch 204/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5183 - accuracy: 0.7014 - val_loss: 0.5684 - val_accuracy: 0.7083\n",
      "Epoch 205/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5180 - accuracy: 0.7014 - val_loss: 0.5682 - val_accuracy: 0.7031\n",
      "Epoch 206/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5176 - accuracy: 0.7031 - val_loss: 0.5681 - val_accuracy: 0.7031\n",
      "Epoch 207/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5173 - accuracy: 0.7031 - val_loss: 0.5679 - val_accuracy: 0.6979\n",
      "Epoch 208/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5170 - accuracy: 0.7031 - val_loss: 0.5677 - val_accuracy: 0.6979\n",
      "Epoch 209/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5167 - accuracy: 0.7031 - val_loss: 0.5675 - val_accuracy: 0.7031\n",
      "Epoch 210/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5163 - accuracy: 0.7049 - val_loss: 0.5673 - val_accuracy: 0.6979\n",
      "Epoch 211/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5160 - accuracy: 0.7049 - val_loss: 0.5672 - val_accuracy: 0.6979\n",
      "Epoch 212/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5157 - accuracy: 0.7083 - val_loss: 0.5670 - val_accuracy: 0.7031\n",
      "Epoch 213/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5155 - accuracy: 0.7083 - val_loss: 0.5668 - val_accuracy: 0.7031\n",
      "Epoch 214/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5151 - accuracy: 0.7083 - val_loss: 0.5666 - val_accuracy: 0.7083\n",
      "Epoch 215/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5148 - accuracy: 0.7066 - val_loss: 0.5665 - val_accuracy: 0.7083\n",
      "Epoch 216/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5145 - accuracy: 0.7066 - val_loss: 0.5663 - val_accuracy: 0.7031\n",
      "Epoch 217/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5142 - accuracy: 0.7101 - val_loss: 0.5661 - val_accuracy: 0.6979\n",
      "Epoch 218/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5139 - accuracy: 0.7101 - val_loss: 0.5660 - val_accuracy: 0.6979\n",
      "Epoch 219/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5137 - accuracy: 0.7101 - val_loss: 0.5658 - val_accuracy: 0.6979\n",
      "Epoch 220/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5134 - accuracy: 0.7153 - val_loss: 0.5656 - val_accuracy: 0.6979\n",
      "Epoch 221/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5131 - accuracy: 0.7153 - val_loss: 0.5655 - val_accuracy: 0.6979\n",
      "Epoch 222/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5128 - accuracy: 0.7153 - val_loss: 0.5653 - val_accuracy: 0.6979\n",
      "Epoch 223/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5125 - accuracy: 0.7153 - val_loss: 0.5651 - val_accuracy: 0.6979\n",
      "Epoch 224/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5122 - accuracy: 0.7153 - val_loss: 0.5650 - val_accuracy: 0.6979\n",
      "Epoch 225/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5119 - accuracy: 0.7153 - val_loss: 0.5648 - val_accuracy: 0.7031\n",
      "Epoch 226/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5117 - accuracy: 0.7153 - val_loss: 0.5646 - val_accuracy: 0.7031\n",
      "Epoch 227/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5114 - accuracy: 0.7170 - val_loss: 0.5645 - val_accuracy: 0.7031\n",
      "Epoch 228/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5111 - accuracy: 0.7170 - val_loss: 0.5643 - val_accuracy: 0.7031\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 229/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5108 - accuracy: 0.7170 - val_loss: 0.5641 - val_accuracy: 0.7031\n",
      "Epoch 230/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5106 - accuracy: 0.7188 - val_loss: 0.5640 - val_accuracy: 0.7031\n",
      "Epoch 231/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5103 - accuracy: 0.7153 - val_loss: 0.5638 - val_accuracy: 0.7031\n",
      "Epoch 232/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5100 - accuracy: 0.7170 - val_loss: 0.5636 - val_accuracy: 0.7031\n",
      "Epoch 233/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5098 - accuracy: 0.7170 - val_loss: 0.5634 - val_accuracy: 0.7031\n",
      "Epoch 234/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5095 - accuracy: 0.7153 - val_loss: 0.5633 - val_accuracy: 0.7031\n",
      "Epoch 235/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5092 - accuracy: 0.7170 - val_loss: 0.5631 - val_accuracy: 0.7031\n",
      "Epoch 236/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5089 - accuracy: 0.7170 - val_loss: 0.5630 - val_accuracy: 0.6979\n",
      "Epoch 237/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5087 - accuracy: 0.7170 - val_loss: 0.5628 - val_accuracy: 0.6927\n",
      "Epoch 238/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5084 - accuracy: 0.7257 - val_loss: 0.5626 - val_accuracy: 0.6927\n",
      "Epoch 239/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5082 - accuracy: 0.7257 - val_loss: 0.5625 - val_accuracy: 0.7031\n",
      "Epoch 240/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5079 - accuracy: 0.7257 - val_loss: 0.5623 - val_accuracy: 0.7083\n",
      "Epoch 241/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5077 - accuracy: 0.7274 - val_loss: 0.5622 - val_accuracy: 0.7083\n",
      "Epoch 242/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5074 - accuracy: 0.7274 - val_loss: 0.5620 - val_accuracy: 0.7083\n",
      "Epoch 243/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5072 - accuracy: 0.7274 - val_loss: 0.5619 - val_accuracy: 0.7083\n",
      "Epoch 244/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5069 - accuracy: 0.7257 - val_loss: 0.5617 - val_accuracy: 0.7083\n",
      "Epoch 245/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5067 - accuracy: 0.7257 - val_loss: 0.5616 - val_accuracy: 0.7083\n",
      "Epoch 246/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5064 - accuracy: 0.7257 - val_loss: 0.5614 - val_accuracy: 0.7083\n",
      "Epoch 247/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5061 - accuracy: 0.7257 - val_loss: 0.5613 - val_accuracy: 0.7083\n",
      "Epoch 248/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5059 - accuracy: 0.7240 - val_loss: 0.5611 - val_accuracy: 0.7135\n",
      "Epoch 249/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5056 - accuracy: 0.7205 - val_loss: 0.5610 - val_accuracy: 0.7135\n",
      "Epoch 250/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5054 - accuracy: 0.7188 - val_loss: 0.5608 - val_accuracy: 0.7135\n",
      "Epoch 251/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5051 - accuracy: 0.7205 - val_loss: 0.5607 - val_accuracy: 0.7135\n",
      "Epoch 252/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5049 - accuracy: 0.7188 - val_loss: 0.5605 - val_accuracy: 0.7135\n",
      "Epoch 253/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5046 - accuracy: 0.7170 - val_loss: 0.5604 - val_accuracy: 0.7083\n",
      "Epoch 254/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5044 - accuracy: 0.7153 - val_loss: 0.5603 - val_accuracy: 0.7083\n",
      "Epoch 255/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5041 - accuracy: 0.7153 - val_loss: 0.5601 - val_accuracy: 0.7083\n",
      "Epoch 256/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5039 - accuracy: 0.7188 - val_loss: 0.5600 - val_accuracy: 0.7083\n",
      "Epoch 257/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5036 - accuracy: 0.7188 - val_loss: 0.5599 - val_accuracy: 0.7083\n",
      "Epoch 258/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5034 - accuracy: 0.7188 - val_loss: 0.5597 - val_accuracy: 0.7083\n",
      "Epoch 259/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5031 - accuracy: 0.7188 - val_loss: 0.5596 - val_accuracy: 0.7083\n",
      "Epoch 260/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5029 - accuracy: 0.7188 - val_loss: 0.5595 - val_accuracy: 0.7083\n",
      "Epoch 261/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5027 - accuracy: 0.7205 - val_loss: 0.5594 - val_accuracy: 0.7083\n",
      "Epoch 262/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5024 - accuracy: 0.7205 - val_loss: 0.5593 - val_accuracy: 0.7083\n",
      "Epoch 263/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5022 - accuracy: 0.7222 - val_loss: 0.5591 - val_accuracy: 0.7083\n",
      "Epoch 264/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5020 - accuracy: 0.7257 - val_loss: 0.5590 - val_accuracy: 0.7083\n",
      "Epoch 265/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5017 - accuracy: 0.7240 - val_loss: 0.5589 - val_accuracy: 0.7083\n",
      "Epoch 266/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5015 - accuracy: 0.7257 - val_loss: 0.5588 - val_accuracy: 0.7083\n",
      "Epoch 267/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5013 - accuracy: 0.7257 - val_loss: 0.5586 - val_accuracy: 0.7083\n",
      "Epoch 268/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5010 - accuracy: 0.7274 - val_loss: 0.5585 - val_accuracy: 0.7083\n",
      "Epoch 269/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5008 - accuracy: 0.7309 - val_loss: 0.5584 - val_accuracy: 0.7083\n",
      "Epoch 270/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5005 - accuracy: 0.7309 - val_loss: 0.5583 - val_accuracy: 0.7083\n",
      "Epoch 271/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5003 - accuracy: 0.7344 - val_loss: 0.5582 - val_accuracy: 0.7083\n",
      "Epoch 272/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5001 - accuracy: 0.7344 - val_loss: 0.5581 - val_accuracy: 0.7083\n",
      "Epoch 273/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4998 - accuracy: 0.7326 - val_loss: 0.5580 - val_accuracy: 0.7083\n",
      "Epoch 274/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4996 - accuracy: 0.7378 - val_loss: 0.5579 - val_accuracy: 0.7083\n",
      "Epoch 275/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4993 - accuracy: 0.7378 - val_loss: 0.5578 - val_accuracy: 0.7083\n",
      "Epoch 276/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4991 - accuracy: 0.7396 - val_loss: 0.5577 - val_accuracy: 0.7135\n",
      "Epoch 277/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4989 - accuracy: 0.7378 - val_loss: 0.5576 - val_accuracy: 0.7135\n",
      "Epoch 278/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4987 - accuracy: 0.7413 - val_loss: 0.5575 - val_accuracy: 0.7135\n",
      "Epoch 279/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4984 - accuracy: 0.7396 - val_loss: 0.5574 - val_accuracy: 0.7135\n",
      "Epoch 280/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4982 - accuracy: 0.7413 - val_loss: 0.5573 - val_accuracy: 0.7135\n",
      "Epoch 281/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4980 - accuracy: 0.7413 - val_loss: 0.5572 - val_accuracy: 0.7135\n",
      "Epoch 282/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4978 - accuracy: 0.7431 - val_loss: 0.5570 - val_accuracy: 0.7240\n",
      "Epoch 283/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4976 - accuracy: 0.7465 - val_loss: 0.5569 - val_accuracy: 0.7240\n",
      "Epoch 284/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4973 - accuracy: 0.7465 - val_loss: 0.5568 - val_accuracy: 0.7240\n",
      "Epoch 285/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4971 - accuracy: 0.7465 - val_loss: 0.5567 - val_accuracy: 0.7240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 286/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4969 - accuracy: 0.7465 - val_loss: 0.5566 - val_accuracy: 0.7240\n",
      "Epoch 287/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4967 - accuracy: 0.7465 - val_loss: 0.5565 - val_accuracy: 0.7240\n",
      "Epoch 288/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4965 - accuracy: 0.7465 - val_loss: 0.5564 - val_accuracy: 0.7240\n",
      "Epoch 289/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4962 - accuracy: 0.7465 - val_loss: 0.5563 - val_accuracy: 0.7240\n",
      "Epoch 290/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4960 - accuracy: 0.7465 - val_loss: 0.5561 - val_accuracy: 0.7240\n",
      "Epoch 291/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4958 - accuracy: 0.7465 - val_loss: 0.5560 - val_accuracy: 0.7240\n",
      "Epoch 292/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4956 - accuracy: 0.7465 - val_loss: 0.5559 - val_accuracy: 0.7240\n",
      "Epoch 293/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4954 - accuracy: 0.7448 - val_loss: 0.5558 - val_accuracy: 0.7292\n",
      "Epoch 294/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4952 - accuracy: 0.7448 - val_loss: 0.5557 - val_accuracy: 0.7240\n",
      "Epoch 295/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4949 - accuracy: 0.7465 - val_loss: 0.5556 - val_accuracy: 0.7240\n",
      "Epoch 296/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4947 - accuracy: 0.7465 - val_loss: 0.5555 - val_accuracy: 0.7240\n",
      "Epoch 297/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4945 - accuracy: 0.7465 - val_loss: 0.5554 - val_accuracy: 0.7240\n",
      "Epoch 298/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4943 - accuracy: 0.7465 - val_loss: 0.5552 - val_accuracy: 0.7240\n",
      "Epoch 299/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4941 - accuracy: 0.7465 - val_loss: 0.5551 - val_accuracy: 0.7240\n",
      "Epoch 300/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4939 - accuracy: 0.7483 - val_loss: 0.5550 - val_accuracy: 0.7240\n",
      "Epoch 301/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4937 - accuracy: 0.7483 - val_loss: 0.5549 - val_accuracy: 0.7240\n",
      "Epoch 302/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4935 - accuracy: 0.7483 - val_loss: 0.5548 - val_accuracy: 0.7240\n",
      "Epoch 303/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4933 - accuracy: 0.7483 - val_loss: 0.5547 - val_accuracy: 0.7240\n",
      "Epoch 304/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4930 - accuracy: 0.7500 - val_loss: 0.5546 - val_accuracy: 0.7240\n",
      "Epoch 305/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4928 - accuracy: 0.7500 - val_loss: 0.5544 - val_accuracy: 0.7240\n",
      "Epoch 306/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4926 - accuracy: 0.7500 - val_loss: 0.5543 - val_accuracy: 0.7240\n",
      "Epoch 307/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4924 - accuracy: 0.7500 - val_loss: 0.5542 - val_accuracy: 0.7188\n",
      "Epoch 308/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4922 - accuracy: 0.7517 - val_loss: 0.5541 - val_accuracy: 0.7188\n",
      "Epoch 309/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4920 - accuracy: 0.7517 - val_loss: 0.5540 - val_accuracy: 0.7188\n",
      "Epoch 310/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4918 - accuracy: 0.7517 - val_loss: 0.5538 - val_accuracy: 0.7188\n",
      "Epoch 311/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4916 - accuracy: 0.7517 - val_loss: 0.5537 - val_accuracy: 0.7188\n",
      "Epoch 312/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4914 - accuracy: 0.7517 - val_loss: 0.5536 - val_accuracy: 0.7188\n",
      "Epoch 313/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4912 - accuracy: 0.7517 - val_loss: 0.5535 - val_accuracy: 0.7188\n",
      "Epoch 314/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4911 - accuracy: 0.7517 - val_loss: 0.5533 - val_accuracy: 0.7188\n",
      "Epoch 315/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4908 - accuracy: 0.7535 - val_loss: 0.5532 - val_accuracy: 0.7135\n",
      "Epoch 316/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4906 - accuracy: 0.7500 - val_loss: 0.5531 - val_accuracy: 0.7135\n",
      "Epoch 317/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4904 - accuracy: 0.7517 - val_loss: 0.5530 - val_accuracy: 0.7135\n",
      "Epoch 318/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4902 - accuracy: 0.7517 - val_loss: 0.5528 - val_accuracy: 0.7135\n",
      "Epoch 319/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4901 - accuracy: 0.7535 - val_loss: 0.5527 - val_accuracy: 0.7135\n",
      "Epoch 320/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4898 - accuracy: 0.7535 - val_loss: 0.5526 - val_accuracy: 0.7135\n",
      "Epoch 321/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4896 - accuracy: 0.7552 - val_loss: 0.5525 - val_accuracy: 0.7135\n",
      "Epoch 322/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4894 - accuracy: 0.7569 - val_loss: 0.5524 - val_accuracy: 0.7135\n",
      "Epoch 323/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4893 - accuracy: 0.7569 - val_loss: 0.5522 - val_accuracy: 0.7135\n",
      "Epoch 324/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4890 - accuracy: 0.7569 - val_loss: 0.5521 - val_accuracy: 0.7135\n",
      "Epoch 325/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4889 - accuracy: 0.7569 - val_loss: 0.5520 - val_accuracy: 0.7188\n",
      "Epoch 326/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4887 - accuracy: 0.7569 - val_loss: 0.5519 - val_accuracy: 0.7135\n",
      "Epoch 327/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4884 - accuracy: 0.7569 - val_loss: 0.5518 - val_accuracy: 0.7135\n",
      "Epoch 328/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4882 - accuracy: 0.7587 - val_loss: 0.5516 - val_accuracy: 0.7135\n",
      "Epoch 329/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4880 - accuracy: 0.7587 - val_loss: 0.5515 - val_accuracy: 0.7135\n",
      "Epoch 330/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4878 - accuracy: 0.7587 - val_loss: 0.5514 - val_accuracy: 0.7135\n",
      "Epoch 331/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4877 - accuracy: 0.7587 - val_loss: 0.5513 - val_accuracy: 0.7135\n",
      "Epoch 332/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4874 - accuracy: 0.7587 - val_loss: 0.5512 - val_accuracy: 0.7135\n",
      "Epoch 333/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4873 - accuracy: 0.7587 - val_loss: 0.5511 - val_accuracy: 0.7135\n",
      "Epoch 334/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4871 - accuracy: 0.7587 - val_loss: 0.5510 - val_accuracy: 0.7135\n",
      "Epoch 335/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4869 - accuracy: 0.7587 - val_loss: 0.5509 - val_accuracy: 0.7135\n",
      "Epoch 336/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4867 - accuracy: 0.7587 - val_loss: 0.5507 - val_accuracy: 0.7135\n",
      "Epoch 337/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4865 - accuracy: 0.7587 - val_loss: 0.5506 - val_accuracy: 0.7135\n",
      "Epoch 338/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4864 - accuracy: 0.7604 - val_loss: 0.5505 - val_accuracy: 0.7188\n",
      "Epoch 339/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4861 - accuracy: 0.7604 - val_loss: 0.5504 - val_accuracy: 0.7188\n",
      "Epoch 340/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4860 - accuracy: 0.7604 - val_loss: 0.5503 - val_accuracy: 0.7188\n",
      "Epoch 341/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4858 - accuracy: 0.7604 - val_loss: 0.5502 - val_accuracy: 0.7188\n",
      "Epoch 342/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4856 - accuracy: 0.7604 - val_loss: 0.5501 - val_accuracy: 0.7188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 343/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4854 - accuracy: 0.7604 - val_loss: 0.5500 - val_accuracy: 0.7188\n",
      "Epoch 344/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4853 - accuracy: 0.7604 - val_loss: 0.5499 - val_accuracy: 0.7188\n",
      "Epoch 345/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4851 - accuracy: 0.7622 - val_loss: 0.5499 - val_accuracy: 0.7188\n",
      "Epoch 346/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4849 - accuracy: 0.7587 - val_loss: 0.5498 - val_accuracy: 0.7188\n",
      "Epoch 347/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4848 - accuracy: 0.7604 - val_loss: 0.5497 - val_accuracy: 0.7188\n",
      "Epoch 348/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4846 - accuracy: 0.7587 - val_loss: 0.5496 - val_accuracy: 0.7188\n",
      "Epoch 349/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4844 - accuracy: 0.7604 - val_loss: 0.5496 - val_accuracy: 0.7188\n",
      "Epoch 350/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4842 - accuracy: 0.7587 - val_loss: 0.5495 - val_accuracy: 0.7188\n",
      "Epoch 351/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4841 - accuracy: 0.7604 - val_loss: 0.5494 - val_accuracy: 0.7240\n",
      "Epoch 352/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4839 - accuracy: 0.7604 - val_loss: 0.5494 - val_accuracy: 0.7240\n",
      "Epoch 353/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4837 - accuracy: 0.7622 - val_loss: 0.5493 - val_accuracy: 0.7240\n",
      "Epoch 354/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4835 - accuracy: 0.7604 - val_loss: 0.5492 - val_accuracy: 0.7240\n",
      "Epoch 355/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4834 - accuracy: 0.7639 - val_loss: 0.5491 - val_accuracy: 0.7240\n",
      "Epoch 356/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4832 - accuracy: 0.7639 - val_loss: 0.5491 - val_accuracy: 0.7240\n",
      "Epoch 357/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4831 - accuracy: 0.7622 - val_loss: 0.5490 - val_accuracy: 0.7240\n",
      "Epoch 358/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4828 - accuracy: 0.7639 - val_loss: 0.5489 - val_accuracy: 0.7292\n",
      "Epoch 359/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4827 - accuracy: 0.7639 - val_loss: 0.5488 - val_accuracy: 0.7292\n",
      "Epoch 360/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4825 - accuracy: 0.7639 - val_loss: 0.5488 - val_accuracy: 0.7292\n",
      "Epoch 361/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4823 - accuracy: 0.7639 - val_loss: 0.5487 - val_accuracy: 0.7292\n",
      "Epoch 362/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4821 - accuracy: 0.7656 - val_loss: 0.5486 - val_accuracy: 0.7292\n",
      "Epoch 363/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4819 - accuracy: 0.7674 - val_loss: 0.5485 - val_accuracy: 0.7240\n",
      "Epoch 364/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4818 - accuracy: 0.7674 - val_loss: 0.5484 - val_accuracy: 0.7292\n",
      "Epoch 365/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4816 - accuracy: 0.7674 - val_loss: 0.5483 - val_accuracy: 0.7292\n",
      "Epoch 366/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4814 - accuracy: 0.7674 - val_loss: 0.5483 - val_accuracy: 0.7292\n",
      "Epoch 367/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4813 - accuracy: 0.7691 - val_loss: 0.5482 - val_accuracy: 0.7292\n",
      "Epoch 368/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4811 - accuracy: 0.7691 - val_loss: 0.5481 - val_accuracy: 0.7292\n",
      "Epoch 369/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4809 - accuracy: 0.7691 - val_loss: 0.5480 - val_accuracy: 0.7292\n",
      "Epoch 370/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4807 - accuracy: 0.7691 - val_loss: 0.5479 - val_accuracy: 0.7292\n",
      "Epoch 371/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4805 - accuracy: 0.7691 - val_loss: 0.5478 - val_accuracy: 0.7292\n",
      "Epoch 372/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4804 - accuracy: 0.7691 - val_loss: 0.5477 - val_accuracy: 0.7292\n",
      "Epoch 373/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4802 - accuracy: 0.7691 - val_loss: 0.5476 - val_accuracy: 0.7292\n",
      "Epoch 374/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4801 - accuracy: 0.7691 - val_loss: 0.5475 - val_accuracy: 0.7292\n",
      "Epoch 375/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4799 - accuracy: 0.7691 - val_loss: 0.5474 - val_accuracy: 0.7292\n",
      "Epoch 376/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4797 - accuracy: 0.7691 - val_loss: 0.5473 - val_accuracy: 0.7292\n",
      "Epoch 377/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4795 - accuracy: 0.7674 - val_loss: 0.5472 - val_accuracy: 0.7292\n",
      "Epoch 378/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4794 - accuracy: 0.7674 - val_loss: 0.5471 - val_accuracy: 0.7292\n",
      "Epoch 379/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4792 - accuracy: 0.7674 - val_loss: 0.5470 - val_accuracy: 0.7292\n",
      "Epoch 380/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4791 - accuracy: 0.7674 - val_loss: 0.5469 - val_accuracy: 0.7292\n",
      "Epoch 381/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4789 - accuracy: 0.7674 - val_loss: 0.5468 - val_accuracy: 0.7292\n",
      "Epoch 382/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4787 - accuracy: 0.7674 - val_loss: 0.5467 - val_accuracy: 0.7292\n",
      "Epoch 383/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4785 - accuracy: 0.7674 - val_loss: 0.5466 - val_accuracy: 0.7292\n",
      "Epoch 384/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4784 - accuracy: 0.7674 - val_loss: 0.5465 - val_accuracy: 0.7292\n",
      "Epoch 385/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4782 - accuracy: 0.7674 - val_loss: 0.5464 - val_accuracy: 0.7292\n",
      "Epoch 386/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4781 - accuracy: 0.7674 - val_loss: 0.5464 - val_accuracy: 0.7292\n",
      "Epoch 387/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4779 - accuracy: 0.7691 - val_loss: 0.5463 - val_accuracy: 0.7292\n",
      "Epoch 388/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4778 - accuracy: 0.7691 - val_loss: 0.5462 - val_accuracy: 0.7292\n",
      "Epoch 389/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4776 - accuracy: 0.7691 - val_loss: 0.5461 - val_accuracy: 0.7292\n",
      "Epoch 390/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4775 - accuracy: 0.7691 - val_loss: 0.5460 - val_accuracy: 0.7292\n",
      "Epoch 391/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4773 - accuracy: 0.7691 - val_loss: 0.5460 - val_accuracy: 0.7292\n",
      "Epoch 392/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4772 - accuracy: 0.7691 - val_loss: 0.5459 - val_accuracy: 0.7292\n",
      "Epoch 393/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4770 - accuracy: 0.7691 - val_loss: 0.5458 - val_accuracy: 0.7292\n",
      "Epoch 394/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4769 - accuracy: 0.7691 - val_loss: 0.5458 - val_accuracy: 0.7292\n",
      "Epoch 395/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4767 - accuracy: 0.7674 - val_loss: 0.5457 - val_accuracy: 0.7292\n",
      "Epoch 396/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4766 - accuracy: 0.7691 - val_loss: 0.5456 - val_accuracy: 0.7240\n",
      "Epoch 397/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4764 - accuracy: 0.7674 - val_loss: 0.5455 - val_accuracy: 0.7240\n",
      "Epoch 398/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4763 - accuracy: 0.7674 - val_loss: 0.5455 - val_accuracy: 0.7240\n",
      "Epoch 399/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4761 - accuracy: 0.7674 - val_loss: 0.5454 - val_accuracy: 0.7240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4760 - accuracy: 0.7708 - val_loss: 0.5453 - val_accuracy: 0.7240\n",
      "Epoch 401/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4758 - accuracy: 0.7674 - val_loss: 0.5452 - val_accuracy: 0.7240\n",
      "Epoch 402/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4757 - accuracy: 0.7674 - val_loss: 0.5451 - val_accuracy: 0.7240\n",
      "Epoch 403/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4755 - accuracy: 0.7708 - val_loss: 0.5451 - val_accuracy: 0.7240\n",
      "Epoch 404/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4754 - accuracy: 0.7708 - val_loss: 0.5450 - val_accuracy: 0.7240\n",
      "Epoch 405/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4752 - accuracy: 0.7691 - val_loss: 0.5449 - val_accuracy: 0.7240\n",
      "Epoch 406/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4751 - accuracy: 0.7691 - val_loss: 0.5449 - val_accuracy: 0.7240\n",
      "Epoch 407/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4750 - accuracy: 0.7691 - val_loss: 0.5448 - val_accuracy: 0.7240\n",
      "Epoch 408/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4748 - accuracy: 0.7708 - val_loss: 0.5447 - val_accuracy: 0.7240\n",
      "Epoch 409/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4746 - accuracy: 0.7691 - val_loss: 0.5446 - val_accuracy: 0.7240\n",
      "Epoch 410/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4746 - accuracy: 0.7691 - val_loss: 0.5446 - val_accuracy: 0.7188\n",
      "Epoch 411/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4744 - accuracy: 0.7691 - val_loss: 0.5445 - val_accuracy: 0.7188\n",
      "Epoch 412/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4743 - accuracy: 0.7708 - val_loss: 0.5444 - val_accuracy: 0.7188\n",
      "Epoch 413/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4741 - accuracy: 0.7691 - val_loss: 0.5443 - val_accuracy: 0.7188\n",
      "Epoch 414/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4740 - accuracy: 0.7726 - val_loss: 0.5442 - val_accuracy: 0.7188\n",
      "Epoch 415/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4739 - accuracy: 0.7726 - val_loss: 0.5442 - val_accuracy: 0.7188\n",
      "Epoch 416/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4738 - accuracy: 0.7708 - val_loss: 0.5441 - val_accuracy: 0.7188\n",
      "Epoch 417/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4737 - accuracy: 0.7726 - val_loss: 0.5440 - val_accuracy: 0.7188\n",
      "Epoch 418/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4736 - accuracy: 0.7708 - val_loss: 0.5440 - val_accuracy: 0.7188\n",
      "Epoch 419/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4735 - accuracy: 0.7726 - val_loss: 0.5439 - val_accuracy: 0.7188\n",
      "Epoch 420/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4734 - accuracy: 0.7708 - val_loss: 0.5438 - val_accuracy: 0.7188\n",
      "Epoch 421/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4732 - accuracy: 0.7726 - val_loss: 0.5437 - val_accuracy: 0.7188\n",
      "Epoch 422/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4731 - accuracy: 0.7743 - val_loss: 0.5437 - val_accuracy: 0.7188\n",
      "Epoch 423/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4730 - accuracy: 0.7726 - val_loss: 0.5436 - val_accuracy: 0.7188\n",
      "Epoch 424/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4729 - accuracy: 0.7743 - val_loss: 0.5435 - val_accuracy: 0.7188\n",
      "Epoch 425/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4728 - accuracy: 0.7743 - val_loss: 0.5435 - val_accuracy: 0.7188\n",
      "Epoch 426/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4726 - accuracy: 0.7743 - val_loss: 0.5434 - val_accuracy: 0.7188\n",
      "Epoch 427/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4725 - accuracy: 0.7726 - val_loss: 0.5433 - val_accuracy: 0.7188\n",
      "Epoch 428/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4724 - accuracy: 0.7743 - val_loss: 0.5433 - val_accuracy: 0.7188\n",
      "Epoch 429/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4723 - accuracy: 0.7743 - val_loss: 0.5432 - val_accuracy: 0.7188\n",
      "Epoch 430/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4722 - accuracy: 0.7743 - val_loss: 0.5431 - val_accuracy: 0.7188\n",
      "Epoch 431/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4721 - accuracy: 0.7726 - val_loss: 0.5430 - val_accuracy: 0.7188\n",
      "Epoch 432/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4720 - accuracy: 0.7743 - val_loss: 0.5430 - val_accuracy: 0.7188\n",
      "Epoch 433/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4719 - accuracy: 0.7743 - val_loss: 0.5429 - val_accuracy: 0.7188\n",
      "Epoch 434/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4718 - accuracy: 0.7708 - val_loss: 0.5428 - val_accuracy: 0.7188\n",
      "Epoch 435/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4716 - accuracy: 0.7726 - val_loss: 0.5428 - val_accuracy: 0.7188\n",
      "Epoch 436/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4716 - accuracy: 0.7708 - val_loss: 0.5427 - val_accuracy: 0.7188\n",
      "Epoch 437/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4714 - accuracy: 0.7726 - val_loss: 0.5427 - val_accuracy: 0.7188\n",
      "Epoch 438/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4714 - accuracy: 0.7708 - val_loss: 0.5426 - val_accuracy: 0.7188\n",
      "Epoch 439/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4712 - accuracy: 0.7708 - val_loss: 0.5425 - val_accuracy: 0.7188\n",
      "Epoch 440/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4711 - accuracy: 0.7726 - val_loss: 0.5425 - val_accuracy: 0.7188\n",
      "Epoch 441/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4710 - accuracy: 0.7726 - val_loss: 0.5424 - val_accuracy: 0.7188\n",
      "Epoch 442/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4709 - accuracy: 0.7708 - val_loss: 0.5423 - val_accuracy: 0.7188\n",
      "Epoch 443/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4709 - accuracy: 0.7726 - val_loss: 0.5423 - val_accuracy: 0.7188\n",
      "Epoch 444/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4707 - accuracy: 0.7708 - val_loss: 0.5422 - val_accuracy: 0.7188\n",
      "Epoch 445/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4706 - accuracy: 0.7726 - val_loss: 0.5422 - val_accuracy: 0.7188\n",
      "Epoch 446/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4705 - accuracy: 0.7726 - val_loss: 0.5421 - val_accuracy: 0.7188\n",
      "Epoch 447/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4704 - accuracy: 0.7726 - val_loss: 0.5421 - val_accuracy: 0.7188\n",
      "Epoch 448/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4703 - accuracy: 0.7726 - val_loss: 0.5420 - val_accuracy: 0.7188\n",
      "Epoch 449/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4702 - accuracy: 0.7726 - val_loss: 0.5420 - val_accuracy: 0.7188\n",
      "Epoch 450/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4701 - accuracy: 0.7726 - val_loss: 0.5419 - val_accuracy: 0.7188\n",
      "Epoch 451/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4700 - accuracy: 0.7743 - val_loss: 0.5419 - val_accuracy: 0.7188\n",
      "Epoch 452/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4699 - accuracy: 0.7726 - val_loss: 0.5419 - val_accuracy: 0.7188\n",
      "Epoch 453/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4699 - accuracy: 0.7743 - val_loss: 0.5418 - val_accuracy: 0.7188\n",
      "Epoch 454/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4697 - accuracy: 0.7726 - val_loss: 0.5418 - val_accuracy: 0.7188\n",
      "Epoch 455/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4697 - accuracy: 0.7708 - val_loss: 0.5417 - val_accuracy: 0.7188\n",
      "Epoch 456/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4696 - accuracy: 0.7726 - val_loss: 0.5417 - val_accuracy: 0.7188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 457/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4695 - accuracy: 0.7726 - val_loss: 0.5416 - val_accuracy: 0.7188\n",
      "Epoch 458/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4694 - accuracy: 0.7726 - val_loss: 0.5416 - val_accuracy: 0.7188\n",
      "Epoch 459/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4693 - accuracy: 0.7708 - val_loss: 0.5415 - val_accuracy: 0.7188\n",
      "Epoch 460/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4692 - accuracy: 0.7726 - val_loss: 0.5415 - val_accuracy: 0.7188\n",
      "Epoch 461/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4691 - accuracy: 0.7726 - val_loss: 0.5415 - val_accuracy: 0.7188\n",
      "Epoch 462/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4690 - accuracy: 0.7726 - val_loss: 0.5414 - val_accuracy: 0.7188\n",
      "Epoch 463/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4689 - accuracy: 0.7726 - val_loss: 0.5414 - val_accuracy: 0.7188\n",
      "Epoch 464/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4688 - accuracy: 0.7726 - val_loss: 0.5414 - val_accuracy: 0.7188\n",
      "Epoch 465/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4687 - accuracy: 0.7743 - val_loss: 0.5413 - val_accuracy: 0.7188\n",
      "Epoch 466/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4687 - accuracy: 0.7743 - val_loss: 0.5413 - val_accuracy: 0.7188\n",
      "Epoch 467/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4686 - accuracy: 0.7743 - val_loss: 0.5413 - val_accuracy: 0.7135\n",
      "Epoch 468/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4685 - accuracy: 0.7743 - val_loss: 0.5412 - val_accuracy: 0.7135\n",
      "Epoch 469/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4684 - accuracy: 0.7743 - val_loss: 0.5412 - val_accuracy: 0.7135\n",
      "Epoch 470/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4683 - accuracy: 0.7743 - val_loss: 0.5411 - val_accuracy: 0.7135\n",
      "Epoch 471/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4682 - accuracy: 0.7726 - val_loss: 0.5411 - val_accuracy: 0.7135\n",
      "Epoch 472/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4681 - accuracy: 0.7743 - val_loss: 0.5410 - val_accuracy: 0.7135\n",
      "Epoch 473/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4680 - accuracy: 0.7743 - val_loss: 0.5410 - val_accuracy: 0.7135\n",
      "Epoch 474/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4680 - accuracy: 0.7743 - val_loss: 0.5410 - val_accuracy: 0.7135\n",
      "Epoch 475/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4679 - accuracy: 0.7743 - val_loss: 0.5409 - val_accuracy: 0.7135\n",
      "Epoch 476/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4678 - accuracy: 0.7726 - val_loss: 0.5409 - val_accuracy: 0.7135\n",
      "Epoch 477/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4677 - accuracy: 0.7743 - val_loss: 0.5408 - val_accuracy: 0.7135\n",
      "Epoch 478/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4676 - accuracy: 0.7743 - val_loss: 0.5408 - val_accuracy: 0.7135\n",
      "Epoch 479/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4675 - accuracy: 0.7743 - val_loss: 0.5408 - val_accuracy: 0.7135\n",
      "Epoch 480/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4674 - accuracy: 0.7743 - val_loss: 0.5407 - val_accuracy: 0.7135\n",
      "Epoch 481/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4674 - accuracy: 0.7743 - val_loss: 0.5407 - val_accuracy: 0.7135\n",
      "Epoch 482/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4673 - accuracy: 0.7743 - val_loss: 0.5406 - val_accuracy: 0.7135\n",
      "Epoch 483/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4672 - accuracy: 0.7743 - val_loss: 0.5406 - val_accuracy: 0.7135\n",
      "Epoch 484/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4671 - accuracy: 0.7743 - val_loss: 0.5406 - val_accuracy: 0.7135\n",
      "Epoch 485/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4671 - accuracy: 0.7743 - val_loss: 0.5405 - val_accuracy: 0.7135\n",
      "Epoch 486/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4670 - accuracy: 0.7743 - val_loss: 0.5405 - val_accuracy: 0.7135\n",
      "Epoch 487/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4669 - accuracy: 0.7743 - val_loss: 0.5404 - val_accuracy: 0.7135\n",
      "Epoch 488/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4668 - accuracy: 0.7743 - val_loss: 0.5404 - val_accuracy: 0.7135\n",
      "Epoch 489/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4667 - accuracy: 0.7743 - val_loss: 0.5403 - val_accuracy: 0.7135\n",
      "Epoch 490/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4666 - accuracy: 0.7760 - val_loss: 0.5403 - val_accuracy: 0.7135\n",
      "Epoch 491/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4666 - accuracy: 0.7743 - val_loss: 0.5403 - val_accuracy: 0.7135\n",
      "Epoch 492/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4665 - accuracy: 0.7760 - val_loss: 0.5402 - val_accuracy: 0.7135\n",
      "Epoch 493/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4664 - accuracy: 0.7760 - val_loss: 0.5402 - val_accuracy: 0.7135\n",
      "Epoch 494/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4663 - accuracy: 0.7743 - val_loss: 0.5401 - val_accuracy: 0.7135\n",
      "Epoch 495/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4663 - accuracy: 0.7760 - val_loss: 0.5401 - val_accuracy: 0.7135\n",
      "Epoch 496/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4662 - accuracy: 0.7760 - val_loss: 0.5400 - val_accuracy: 0.7135\n",
      "Epoch 497/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4661 - accuracy: 0.7760 - val_loss: 0.5400 - val_accuracy: 0.7135\n",
      "Epoch 498/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4661 - accuracy: 0.7743 - val_loss: 0.5399 - val_accuracy: 0.7188\n",
      "Epoch 499/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4660 - accuracy: 0.7743 - val_loss: 0.5399 - val_accuracy: 0.7188\n",
      "Epoch 500/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4659 - accuracy: 0.7743 - val_loss: 0.5398 - val_accuracy: 0.7188\n",
      "Epoch 501/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4658 - accuracy: 0.7743 - val_loss: 0.5398 - val_accuracy: 0.7188\n",
      "Epoch 502/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4657 - accuracy: 0.7760 - val_loss: 0.5397 - val_accuracy: 0.7188\n",
      "Epoch 503/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4656 - accuracy: 0.7778 - val_loss: 0.5397 - val_accuracy: 0.7188\n",
      "Epoch 504/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4655 - accuracy: 0.7726 - val_loss: 0.5396 - val_accuracy: 0.7188\n",
      "Epoch 505/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4655 - accuracy: 0.7743 - val_loss: 0.5396 - val_accuracy: 0.7188\n",
      "Epoch 506/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4654 - accuracy: 0.7726 - val_loss: 0.5395 - val_accuracy: 0.7240\n",
      "Epoch 507/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4654 - accuracy: 0.7726 - val_loss: 0.5395 - val_accuracy: 0.7240\n",
      "Epoch 508/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4653 - accuracy: 0.7743 - val_loss: 0.5394 - val_accuracy: 0.7240\n",
      "Epoch 509/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4652 - accuracy: 0.7743 - val_loss: 0.5394 - val_accuracy: 0.7240\n",
      "Epoch 510/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4651 - accuracy: 0.7743 - val_loss: 0.5393 - val_accuracy: 0.7240\n",
      "Epoch 511/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4650 - accuracy: 0.7743 - val_loss: 0.5393 - val_accuracy: 0.7240\n",
      "Epoch 512/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4650 - accuracy: 0.7743 - val_loss: 0.5392 - val_accuracy: 0.7240\n",
      "Epoch 513/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4649 - accuracy: 0.7743 - val_loss: 0.5392 - val_accuracy: 0.7240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 514/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4648 - accuracy: 0.7760 - val_loss: 0.5391 - val_accuracy: 0.7240\n",
      "Epoch 515/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4648 - accuracy: 0.7760 - val_loss: 0.5391 - val_accuracy: 0.7240\n",
      "Epoch 516/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4647 - accuracy: 0.7760 - val_loss: 0.5391 - val_accuracy: 0.7240\n",
      "Epoch 517/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4646 - accuracy: 0.7760 - val_loss: 0.5390 - val_accuracy: 0.7240\n",
      "Epoch 518/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4645 - accuracy: 0.7760 - val_loss: 0.5390 - val_accuracy: 0.7240\n",
      "Epoch 519/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4644 - accuracy: 0.7760 - val_loss: 0.5389 - val_accuracy: 0.7240\n",
      "Epoch 520/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4643 - accuracy: 0.7760 - val_loss: 0.5389 - val_accuracy: 0.7240\n",
      "Epoch 521/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4643 - accuracy: 0.7760 - val_loss: 0.5388 - val_accuracy: 0.7240\n",
      "Epoch 522/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4642 - accuracy: 0.7760 - val_loss: 0.5388 - val_accuracy: 0.7240\n",
      "Epoch 523/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4641 - accuracy: 0.7778 - val_loss: 0.5388 - val_accuracy: 0.7240\n",
      "Epoch 524/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4641 - accuracy: 0.7778 - val_loss: 0.5387 - val_accuracy: 0.7240\n",
      "Epoch 525/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4640 - accuracy: 0.7778 - val_loss: 0.5387 - val_accuracy: 0.7240\n",
      "Epoch 526/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4639 - accuracy: 0.7778 - val_loss: 0.5387 - val_accuracy: 0.7240\n",
      "Epoch 527/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4638 - accuracy: 0.7778 - val_loss: 0.5386 - val_accuracy: 0.7240\n",
      "Epoch 528/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4637 - accuracy: 0.7778 - val_loss: 0.5386 - val_accuracy: 0.7240\n",
      "Epoch 529/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4637 - accuracy: 0.7778 - val_loss: 0.5386 - val_accuracy: 0.7240\n",
      "Epoch 530/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4636 - accuracy: 0.7795 - val_loss: 0.5385 - val_accuracy: 0.7240\n",
      "Epoch 531/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4635 - accuracy: 0.7795 - val_loss: 0.5385 - val_accuracy: 0.7240\n",
      "Epoch 532/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4635 - accuracy: 0.7795 - val_loss: 0.5385 - val_accuracy: 0.7240\n",
      "Epoch 533/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4633 - accuracy: 0.7795 - val_loss: 0.5384 - val_accuracy: 0.7240\n",
      "Epoch 534/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4633 - accuracy: 0.7795 - val_loss: 0.5384 - val_accuracy: 0.7240\n",
      "Epoch 535/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4632 - accuracy: 0.7795 - val_loss: 0.5384 - val_accuracy: 0.7240\n",
      "Epoch 536/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4632 - accuracy: 0.7795 - val_loss: 0.5384 - val_accuracy: 0.7240\n",
      "Epoch 537/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4631 - accuracy: 0.7795 - val_loss: 0.5384 - val_accuracy: 0.7240\n",
      "Epoch 538/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4630 - accuracy: 0.7795 - val_loss: 0.5383 - val_accuracy: 0.7240\n",
      "Epoch 539/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4630 - accuracy: 0.7795 - val_loss: 0.5383 - val_accuracy: 0.7240\n",
      "Epoch 540/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4629 - accuracy: 0.7778 - val_loss: 0.5383 - val_accuracy: 0.7240\n",
      "Epoch 541/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4628 - accuracy: 0.7795 - val_loss: 0.5383 - val_accuracy: 0.7240\n",
      "Epoch 542/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4627 - accuracy: 0.7778 - val_loss: 0.5383 - val_accuracy: 0.7240\n",
      "Epoch 543/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4627 - accuracy: 0.7778 - val_loss: 0.5383 - val_accuracy: 0.7240\n",
      "Epoch 544/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4626 - accuracy: 0.7778 - val_loss: 0.5383 - val_accuracy: 0.7240\n",
      "Epoch 545/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4625 - accuracy: 0.7778 - val_loss: 0.5383 - val_accuracy: 0.7240\n",
      "Epoch 546/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4625 - accuracy: 0.7795 - val_loss: 0.5383 - val_accuracy: 0.7240\n",
      "Epoch 547/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4624 - accuracy: 0.7778 - val_loss: 0.5383 - val_accuracy: 0.7240\n",
      "Epoch 548/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4623 - accuracy: 0.7795 - val_loss: 0.5383 - val_accuracy: 0.7240\n",
      "Epoch 549/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4623 - accuracy: 0.7778 - val_loss: 0.5383 - val_accuracy: 0.7240\n",
      "Epoch 550/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4622 - accuracy: 0.7778 - val_loss: 0.5383 - val_accuracy: 0.7240\n",
      "Epoch 551/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4621 - accuracy: 0.7778 - val_loss: 0.5383 - val_accuracy: 0.7240\n",
      "Epoch 552/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4621 - accuracy: 0.7778 - val_loss: 0.5383 - val_accuracy: 0.7240\n",
      "Epoch 553/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4620 - accuracy: 0.7778 - val_loss: 0.5383 - val_accuracy: 0.7240\n",
      "Epoch 554/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4619 - accuracy: 0.7778 - val_loss: 0.5383 - val_accuracy: 0.7240\n",
      "Epoch 555/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4619 - accuracy: 0.7778 - val_loss: 0.5383 - val_accuracy: 0.7240\n",
      "Epoch 556/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4618 - accuracy: 0.7778 - val_loss: 0.5383 - val_accuracy: 0.7240\n",
      "Epoch 557/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4617 - accuracy: 0.7795 - val_loss: 0.5383 - val_accuracy: 0.7240\n",
      "Epoch 558/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4617 - accuracy: 0.7778 - val_loss: 0.5383 - val_accuracy: 0.7188\n",
      "Epoch 559/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4616 - accuracy: 0.7778 - val_loss: 0.5383 - val_accuracy: 0.7188\n",
      "Epoch 560/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4616 - accuracy: 0.7778 - val_loss: 0.5383 - val_accuracy: 0.7188\n",
      "Epoch 561/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4615 - accuracy: 0.7795 - val_loss: 0.5383 - val_accuracy: 0.7188\n",
      "Epoch 562/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4614 - accuracy: 0.7778 - val_loss: 0.5383 - val_accuracy: 0.7188\n",
      "Epoch 563/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4614 - accuracy: 0.7778 - val_loss: 0.5383 - val_accuracy: 0.7188\n",
      "Epoch 564/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4613 - accuracy: 0.7795 - val_loss: 0.5383 - val_accuracy: 0.7135\n",
      "Epoch 565/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4612 - accuracy: 0.7778 - val_loss: 0.5383 - val_accuracy: 0.7135\n",
      "Epoch 566/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4611 - accuracy: 0.7795 - val_loss: 0.5383 - val_accuracy: 0.7135\n",
      "Epoch 567/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4611 - accuracy: 0.7778 - val_loss: 0.5384 - val_accuracy: 0.7135\n",
      "Epoch 568/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4610 - accuracy: 0.7795 - val_loss: 0.5384 - val_accuracy: 0.7135\n",
      "Epoch 569/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4610 - accuracy: 0.7795 - val_loss: 0.5384 - val_accuracy: 0.7135\n",
      "Epoch 570/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4610 - accuracy: 0.7778 - val_loss: 0.5384 - val_accuracy: 0.7135\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 571/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4609 - accuracy: 0.7760 - val_loss: 0.5384 - val_accuracy: 0.7135\n",
      "Epoch 572/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4608 - accuracy: 0.7778 - val_loss: 0.5384 - val_accuracy: 0.7135\n",
      "Epoch 573/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4608 - accuracy: 0.7778 - val_loss: 0.5384 - val_accuracy: 0.7135\n",
      "Epoch 574/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4608 - accuracy: 0.7778 - val_loss: 0.5384 - val_accuracy: 0.7135\n",
      "Epoch 575/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4607 - accuracy: 0.7778 - val_loss: 0.5384 - val_accuracy: 0.7135\n",
      "Epoch 576/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4606 - accuracy: 0.7778 - val_loss: 0.5384 - val_accuracy: 0.7135\n",
      "Epoch 577/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4606 - accuracy: 0.7743 - val_loss: 0.5384 - val_accuracy: 0.7135\n",
      "Epoch 578/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4605 - accuracy: 0.7778 - val_loss: 0.5384 - val_accuracy: 0.7135\n",
      "Epoch 579/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4605 - accuracy: 0.7760 - val_loss: 0.5384 - val_accuracy: 0.7135\n",
      "Epoch 580/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4604 - accuracy: 0.7778 - val_loss: 0.5384 - val_accuracy: 0.7135\n",
      "Epoch 581/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4604 - accuracy: 0.7778 - val_loss: 0.5384 - val_accuracy: 0.7135\n",
      "Epoch 582/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4603 - accuracy: 0.7760 - val_loss: 0.5384 - val_accuracy: 0.7135\n",
      "Epoch 583/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4603 - accuracy: 0.7760 - val_loss: 0.5384 - val_accuracy: 0.7188\n",
      "Epoch 584/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4602 - accuracy: 0.7778 - val_loss: 0.5384 - val_accuracy: 0.7188\n",
      "Epoch 585/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4602 - accuracy: 0.7760 - val_loss: 0.5385 - val_accuracy: 0.7188\n",
      "Epoch 586/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4601 - accuracy: 0.7760 - val_loss: 0.5385 - val_accuracy: 0.7188\n",
      "Epoch 587/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4601 - accuracy: 0.7760 - val_loss: 0.5385 - val_accuracy: 0.7188\n",
      "Epoch 588/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4601 - accuracy: 0.7760 - val_loss: 0.5385 - val_accuracy: 0.7188\n",
      "Epoch 589/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4600 - accuracy: 0.7778 - val_loss: 0.5385 - val_accuracy: 0.7188\n",
      "Epoch 590/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4599 - accuracy: 0.7760 - val_loss: 0.5385 - val_accuracy: 0.7188\n",
      "Epoch 591/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4598 - accuracy: 0.7760 - val_loss: 0.5385 - val_accuracy: 0.7188\n",
      "Epoch 592/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4598 - accuracy: 0.7760 - val_loss: 0.5385 - val_accuracy: 0.7188\n",
      "Epoch 593/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4597 - accuracy: 0.7778 - val_loss: 0.5385 - val_accuracy: 0.7188\n",
      "Epoch 594/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4597 - accuracy: 0.7760 - val_loss: 0.5386 - val_accuracy: 0.7188\n",
      "Epoch 595/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4596 - accuracy: 0.7760 - val_loss: 0.5386 - val_accuracy: 0.7188\n",
      "Epoch 596/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4595 - accuracy: 0.7760 - val_loss: 0.5386 - val_accuracy: 0.7188\n",
      "Epoch 597/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4595 - accuracy: 0.7760 - val_loss: 0.5386 - val_accuracy: 0.7188\n",
      "Epoch 598/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4594 - accuracy: 0.7743 - val_loss: 0.5386 - val_accuracy: 0.7188\n",
      "Epoch 599/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4594 - accuracy: 0.7743 - val_loss: 0.5386 - val_accuracy: 0.7188\n",
      "Epoch 600/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4593 - accuracy: 0.7778 - val_loss: 0.5386 - val_accuracy: 0.7188\n",
      "Epoch 601/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4593 - accuracy: 0.7743 - val_loss: 0.5386 - val_accuracy: 0.7188\n",
      "Epoch 602/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4592 - accuracy: 0.7778 - val_loss: 0.5386 - val_accuracy: 0.7188\n",
      "Epoch 603/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4591 - accuracy: 0.7743 - val_loss: 0.5386 - val_accuracy: 0.7188\n",
      "Epoch 604/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4590 - accuracy: 0.7743 - val_loss: 0.5386 - val_accuracy: 0.7188\n",
      "Epoch 605/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4590 - accuracy: 0.7760 - val_loss: 0.5387 - val_accuracy: 0.7188\n",
      "Epoch 606/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4589 - accuracy: 0.7743 - val_loss: 0.5387 - val_accuracy: 0.7188\n",
      "Epoch 607/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4588 - accuracy: 0.7760 - val_loss: 0.5387 - val_accuracy: 0.7188\n",
      "Epoch 608/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4588 - accuracy: 0.7760 - val_loss: 0.5387 - val_accuracy: 0.7188\n",
      "Epoch 609/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4587 - accuracy: 0.7743 - val_loss: 0.5387 - val_accuracy: 0.7188\n",
      "Epoch 610/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4586 - accuracy: 0.7743 - val_loss: 0.5387 - val_accuracy: 0.7188\n",
      "Epoch 611/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4585 - accuracy: 0.7760 - val_loss: 0.5387 - val_accuracy: 0.7188\n",
      "Epoch 612/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4585 - accuracy: 0.7760 - val_loss: 0.5387 - val_accuracy: 0.7188\n",
      "Epoch 613/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4585 - accuracy: 0.7743 - val_loss: 0.5388 - val_accuracy: 0.7188\n",
      "Epoch 614/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4584 - accuracy: 0.7760 - val_loss: 0.5388 - val_accuracy: 0.7188\n",
      "Epoch 615/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4583 - accuracy: 0.7743 - val_loss: 0.5388 - val_accuracy: 0.7188\n",
      "Epoch 616/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4582 - accuracy: 0.7743 - val_loss: 0.5388 - val_accuracy: 0.7188\n",
      "Epoch 617/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4582 - accuracy: 0.7743 - val_loss: 0.5388 - val_accuracy: 0.7188\n",
      "Epoch 618/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4581 - accuracy: 0.7760 - val_loss: 0.5388 - val_accuracy: 0.7135\n",
      "Epoch 619/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4580 - accuracy: 0.7743 - val_loss: 0.5388 - val_accuracy: 0.7135\n",
      "Epoch 620/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4580 - accuracy: 0.7743 - val_loss: 0.5388 - val_accuracy: 0.7135\n",
      "Epoch 621/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4579 - accuracy: 0.7760 - val_loss: 0.5388 - val_accuracy: 0.7135\n",
      "Epoch 622/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4578 - accuracy: 0.7726 - val_loss: 0.5388 - val_accuracy: 0.7135\n",
      "Epoch 623/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4577 - accuracy: 0.7760 - val_loss: 0.5389 - val_accuracy: 0.7135\n",
      "Epoch 624/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4577 - accuracy: 0.7743 - val_loss: 0.5388 - val_accuracy: 0.7135\n",
      "Epoch 625/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4576 - accuracy: 0.7743 - val_loss: 0.5388 - val_accuracy: 0.7135\n",
      "Epoch 626/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4576 - accuracy: 0.7760 - val_loss: 0.5388 - val_accuracy: 0.7135\n",
      "Epoch 627/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4574 - accuracy: 0.7743 - val_loss: 0.5388 - val_accuracy: 0.7135\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 628/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4574 - accuracy: 0.7760 - val_loss: 0.5388 - val_accuracy: 0.7135\n",
      "Epoch 629/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4573 - accuracy: 0.7760 - val_loss: 0.5388 - val_accuracy: 0.7135\n",
      "Epoch 630/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4572 - accuracy: 0.7743 - val_loss: 0.5388 - val_accuracy: 0.7135\n",
      "Epoch 631/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4572 - accuracy: 0.7726 - val_loss: 0.5387 - val_accuracy: 0.7135\n",
      "Epoch 632/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4571 - accuracy: 0.7708 - val_loss: 0.5387 - val_accuracy: 0.7083\n",
      "Epoch 633/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4571 - accuracy: 0.7708 - val_loss: 0.5387 - val_accuracy: 0.7083\n",
      "Epoch 634/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4570 - accuracy: 0.7726 - val_loss: 0.5387 - val_accuracy: 0.7083\n",
      "Epoch 635/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4569 - accuracy: 0.7743 - val_loss: 0.5387 - val_accuracy: 0.7083\n",
      "Epoch 636/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4569 - accuracy: 0.7726 - val_loss: 0.5387 - val_accuracy: 0.7083\n",
      "Epoch 637/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4569 - accuracy: 0.7726 - val_loss: 0.5387 - val_accuracy: 0.7083\n",
      "Epoch 638/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4567 - accuracy: 0.7726 - val_loss: 0.5387 - val_accuracy: 0.7083\n",
      "Epoch 639/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4567 - accuracy: 0.7726 - val_loss: 0.5386 - val_accuracy: 0.7083\n",
      "Epoch 640/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4566 - accuracy: 0.7726 - val_loss: 0.5386 - val_accuracy: 0.7083\n",
      "Epoch 641/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4566 - accuracy: 0.7726 - val_loss: 0.5386 - val_accuracy: 0.7083\n",
      "Epoch 642/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4565 - accuracy: 0.7726 - val_loss: 0.5386 - val_accuracy: 0.7135\n",
      "Epoch 643/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4565 - accuracy: 0.7726 - val_loss: 0.5386 - val_accuracy: 0.7135\n",
      "Epoch 644/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4564 - accuracy: 0.7726 - val_loss: 0.5386 - val_accuracy: 0.7135\n",
      "Epoch 645/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4564 - accuracy: 0.7726 - val_loss: 0.5386 - val_accuracy: 0.7135\n",
      "Epoch 646/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4563 - accuracy: 0.7726 - val_loss: 0.5386 - val_accuracy: 0.7135\n",
      "Epoch 647/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4563 - accuracy: 0.7708 - val_loss: 0.5386 - val_accuracy: 0.7135\n",
      "Epoch 648/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4562 - accuracy: 0.7726 - val_loss: 0.5385 - val_accuracy: 0.7135\n",
      "Epoch 649/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4562 - accuracy: 0.7743 - val_loss: 0.5385 - val_accuracy: 0.7135\n",
      "Epoch 650/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4560 - accuracy: 0.7726 - val_loss: 0.5385 - val_accuracy: 0.7135\n",
      "Epoch 651/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4560 - accuracy: 0.7726 - val_loss: 0.5385 - val_accuracy: 0.7135\n",
      "Epoch 652/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4559 - accuracy: 0.7726 - val_loss: 0.5385 - val_accuracy: 0.7135\n",
      "Epoch 653/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4559 - accuracy: 0.7743 - val_loss: 0.5385 - val_accuracy: 0.7135\n",
      "Epoch 654/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4559 - accuracy: 0.7743 - val_loss: 0.5385 - val_accuracy: 0.7135\n",
      "Epoch 655/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4558 - accuracy: 0.7726 - val_loss: 0.5385 - val_accuracy: 0.7135\n",
      "Epoch 656/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4558 - accuracy: 0.7726 - val_loss: 0.5385 - val_accuracy: 0.7135\n",
      "Epoch 657/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4557 - accuracy: 0.7743 - val_loss: 0.5385 - val_accuracy: 0.7135\n",
      "Epoch 658/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4556 - accuracy: 0.7708 - val_loss: 0.5385 - val_accuracy: 0.7135\n",
      "Epoch 659/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4556 - accuracy: 0.7743 - val_loss: 0.5385 - val_accuracy: 0.7135\n",
      "Epoch 660/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4556 - accuracy: 0.7743 - val_loss: 0.5385 - val_accuracy: 0.7135\n",
      "Epoch 661/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4555 - accuracy: 0.7778 - val_loss: 0.5385 - val_accuracy: 0.7135\n",
      "Epoch 662/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4554 - accuracy: 0.7743 - val_loss: 0.5385 - val_accuracy: 0.7135\n",
      "Epoch 663/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4554 - accuracy: 0.7778 - val_loss: 0.5384 - val_accuracy: 0.7135\n",
      "Epoch 664/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4554 - accuracy: 0.7760 - val_loss: 0.5385 - val_accuracy: 0.7135\n",
      "Epoch 665/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4553 - accuracy: 0.7778 - val_loss: 0.5385 - val_accuracy: 0.7135\n",
      "Epoch 666/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4553 - accuracy: 0.7760 - val_loss: 0.5385 - val_accuracy: 0.7135\n",
      "Epoch 667/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4552 - accuracy: 0.7743 - val_loss: 0.5385 - val_accuracy: 0.7135\n",
      "Epoch 668/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4552 - accuracy: 0.7760 - val_loss: 0.5385 - val_accuracy: 0.7135\n",
      "Epoch 669/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4551 - accuracy: 0.7760 - val_loss: 0.5385 - val_accuracy: 0.7188\n",
      "Epoch 670/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4550 - accuracy: 0.7760 - val_loss: 0.5385 - val_accuracy: 0.7188\n",
      "Epoch 671/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4550 - accuracy: 0.7760 - val_loss: 0.5385 - val_accuracy: 0.7188\n",
      "Epoch 672/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4550 - accuracy: 0.7760 - val_loss: 0.5385 - val_accuracy: 0.7188\n",
      "Epoch 673/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4549 - accuracy: 0.7760 - val_loss: 0.5385 - val_accuracy: 0.7188\n",
      "Epoch 674/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4549 - accuracy: 0.7760 - val_loss: 0.5385 - val_accuracy: 0.7188\n",
      "Epoch 675/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4548 - accuracy: 0.7760 - val_loss: 0.5385 - val_accuracy: 0.7188\n",
      "Epoch 676/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4548 - accuracy: 0.7760 - val_loss: 0.5385 - val_accuracy: 0.7188\n",
      "Epoch 677/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4547 - accuracy: 0.7760 - val_loss: 0.5385 - val_accuracy: 0.7188\n",
      "Epoch 678/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4547 - accuracy: 0.7760 - val_loss: 0.5385 - val_accuracy: 0.7188\n",
      "Epoch 679/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4546 - accuracy: 0.7760 - val_loss: 0.5385 - val_accuracy: 0.7188\n",
      "Epoch 680/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4546 - accuracy: 0.7743 - val_loss: 0.5385 - val_accuracy: 0.7188\n",
      "Epoch 681/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4546 - accuracy: 0.7743 - val_loss: 0.5385 - val_accuracy: 0.7188\n",
      "Epoch 682/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4546 - accuracy: 0.7778 - val_loss: 0.5385 - val_accuracy: 0.7188\n",
      "Epoch 683/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4545 - accuracy: 0.7760 - val_loss: 0.5385 - val_accuracy: 0.7188\n",
      "Epoch 684/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4545 - accuracy: 0.7760 - val_loss: 0.5385 - val_accuracy: 0.7188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 685/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4544 - accuracy: 0.7743 - val_loss: 0.5385 - val_accuracy: 0.7188\n",
      "Epoch 686/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4543 - accuracy: 0.7778 - val_loss: 0.5384 - val_accuracy: 0.7188\n",
      "Epoch 687/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4543 - accuracy: 0.7760 - val_loss: 0.5384 - val_accuracy: 0.7188\n",
      "Epoch 688/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4543 - accuracy: 0.7778 - val_loss: 0.5384 - val_accuracy: 0.7188\n",
      "Epoch 689/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4543 - accuracy: 0.7778 - val_loss: 0.5384 - val_accuracy: 0.7188\n",
      "Epoch 690/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4542 - accuracy: 0.7778 - val_loss: 0.5384 - val_accuracy: 0.7188\n",
      "Epoch 691/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4541 - accuracy: 0.7760 - val_loss: 0.5384 - val_accuracy: 0.7188\n",
      "Epoch 692/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4541 - accuracy: 0.7760 - val_loss: 0.5384 - val_accuracy: 0.7188\n",
      "Epoch 693/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4540 - accuracy: 0.7760 - val_loss: 0.5384 - val_accuracy: 0.7188\n",
      "Epoch 694/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4540 - accuracy: 0.7778 - val_loss: 0.5384 - val_accuracy: 0.7188\n",
      "Epoch 695/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4539 - accuracy: 0.7778 - val_loss: 0.5384 - val_accuracy: 0.7188\n",
      "Epoch 696/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4539 - accuracy: 0.7778 - val_loss: 0.5383 - val_accuracy: 0.7188\n",
      "Epoch 697/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4539 - accuracy: 0.7778 - val_loss: 0.5383 - val_accuracy: 0.7188\n",
      "Epoch 698/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4538 - accuracy: 0.7778 - val_loss: 0.5383 - val_accuracy: 0.7188\n",
      "Epoch 699/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4538 - accuracy: 0.7778 - val_loss: 0.5383 - val_accuracy: 0.7188\n",
      "Epoch 700/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4537 - accuracy: 0.7778 - val_loss: 0.5383 - val_accuracy: 0.7188\n",
      "Epoch 701/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4537 - accuracy: 0.7778 - val_loss: 0.5383 - val_accuracy: 0.7188\n",
      "Epoch 702/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4537 - accuracy: 0.7778 - val_loss: 0.5383 - val_accuracy: 0.7188\n",
      "Epoch 703/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4536 - accuracy: 0.7778 - val_loss: 0.5383 - val_accuracy: 0.7188\n",
      "Epoch 704/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4536 - accuracy: 0.7778 - val_loss: 0.5383 - val_accuracy: 0.7188\n",
      "Epoch 705/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4535 - accuracy: 0.7778 - val_loss: 0.5383 - val_accuracy: 0.7188\n",
      "Epoch 706/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4535 - accuracy: 0.7778 - val_loss: 0.5383 - val_accuracy: 0.7188\n",
      "Epoch 707/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4534 - accuracy: 0.7778 - val_loss: 0.5382 - val_accuracy: 0.7188\n",
      "Epoch 708/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4534 - accuracy: 0.7778 - val_loss: 0.5382 - val_accuracy: 0.7188\n",
      "Epoch 709/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4534 - accuracy: 0.7778 - val_loss: 0.5382 - val_accuracy: 0.7188\n",
      "Epoch 710/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4533 - accuracy: 0.7778 - val_loss: 0.5382 - val_accuracy: 0.7188\n",
      "Epoch 711/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4533 - accuracy: 0.7778 - val_loss: 0.5382 - val_accuracy: 0.7188\n",
      "Epoch 712/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4533 - accuracy: 0.7778 - val_loss: 0.5382 - val_accuracy: 0.7188\n",
      "Epoch 713/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4533 - accuracy: 0.7778 - val_loss: 0.5382 - val_accuracy: 0.7188\n",
      "Epoch 714/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4532 - accuracy: 0.7778 - val_loss: 0.5382 - val_accuracy: 0.7188\n",
      "Epoch 715/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4532 - accuracy: 0.7778 - val_loss: 0.5382 - val_accuracy: 0.7188\n",
      "Epoch 716/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4531 - accuracy: 0.7778 - val_loss: 0.5381 - val_accuracy: 0.7188\n",
      "Epoch 717/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4531 - accuracy: 0.7778 - val_loss: 0.5381 - val_accuracy: 0.7188\n",
      "Epoch 718/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4531 - accuracy: 0.7778 - val_loss: 0.5381 - val_accuracy: 0.7188\n",
      "Epoch 719/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4530 - accuracy: 0.7778 - val_loss: 0.5381 - val_accuracy: 0.7188\n",
      "Epoch 720/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4530 - accuracy: 0.7778 - val_loss: 0.5381 - val_accuracy: 0.7188\n",
      "Epoch 721/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4530 - accuracy: 0.7778 - val_loss: 0.5381 - val_accuracy: 0.7188\n",
      "Epoch 722/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4530 - accuracy: 0.7778 - val_loss: 0.5381 - val_accuracy: 0.7188\n",
      "Epoch 723/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4529 - accuracy: 0.7778 - val_loss: 0.5381 - val_accuracy: 0.7188\n",
      "Epoch 724/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4529 - accuracy: 0.7778 - val_loss: 0.5380 - val_accuracy: 0.7188\n",
      "Epoch 725/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4528 - accuracy: 0.7778 - val_loss: 0.5380 - val_accuracy: 0.7188\n",
      "Epoch 726/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4528 - accuracy: 0.7778 - val_loss: 0.5380 - val_accuracy: 0.7188\n",
      "Epoch 727/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4527 - accuracy: 0.7778 - val_loss: 0.5380 - val_accuracy: 0.7188\n",
      "Epoch 728/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4527 - accuracy: 0.7778 - val_loss: 0.5380 - val_accuracy: 0.7188\n",
      "Epoch 729/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4526 - accuracy: 0.7778 - val_loss: 0.5380 - val_accuracy: 0.7188\n",
      "Epoch 730/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4526 - accuracy: 0.7778 - val_loss: 0.5380 - val_accuracy: 0.7188\n",
      "Epoch 731/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4526 - accuracy: 0.7778 - val_loss: 0.5380 - val_accuracy: 0.7188\n",
      "Epoch 732/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4525 - accuracy: 0.7778 - val_loss: 0.5380 - val_accuracy: 0.7188\n",
      "Epoch 733/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4525 - accuracy: 0.7778 - val_loss: 0.5380 - val_accuracy: 0.7188\n",
      "Epoch 734/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4524 - accuracy: 0.7778 - val_loss: 0.5380 - val_accuracy: 0.7188\n",
      "Epoch 735/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4524 - accuracy: 0.7778 - val_loss: 0.5380 - val_accuracy: 0.7188\n",
      "Epoch 736/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4523 - accuracy: 0.7778 - val_loss: 0.5380 - val_accuracy: 0.7188\n",
      "Epoch 737/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4523 - accuracy: 0.7778 - val_loss: 0.5381 - val_accuracy: 0.7188\n",
      "Epoch 738/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4523 - accuracy: 0.7778 - val_loss: 0.5380 - val_accuracy: 0.7188\n",
      "Epoch 739/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4522 - accuracy: 0.7795 - val_loss: 0.5381 - val_accuracy: 0.7188\n",
      "Epoch 740/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4522 - accuracy: 0.7778 - val_loss: 0.5381 - val_accuracy: 0.7188\n",
      "Epoch 741/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4522 - accuracy: 0.7795 - val_loss: 0.5381 - val_accuracy: 0.7188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 742/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4521 - accuracy: 0.7778 - val_loss: 0.5381 - val_accuracy: 0.7188\n",
      "Epoch 743/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4521 - accuracy: 0.7778 - val_loss: 0.5381 - val_accuracy: 0.7188\n",
      "Epoch 744/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4520 - accuracy: 0.7778 - val_loss: 0.5381 - val_accuracy: 0.7188\n",
      "Epoch 745/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4520 - accuracy: 0.7778 - val_loss: 0.5381 - val_accuracy: 0.7188\n",
      "Epoch 746/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4519 - accuracy: 0.7795 - val_loss: 0.5381 - val_accuracy: 0.7188\n",
      "Epoch 747/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4519 - accuracy: 0.7778 - val_loss: 0.5381 - val_accuracy: 0.7188\n",
      "Epoch 748/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4519 - accuracy: 0.7778 - val_loss: 0.5381 - val_accuracy: 0.7188\n",
      "Epoch 749/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4518 - accuracy: 0.7795 - val_loss: 0.5381 - val_accuracy: 0.7188\n",
      "Epoch 750/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4518 - accuracy: 0.7778 - val_loss: 0.5381 - val_accuracy: 0.7188\n",
      "Epoch 751/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4518 - accuracy: 0.7778 - val_loss: 0.5380 - val_accuracy: 0.7188\n",
      "Epoch 752/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4517 - accuracy: 0.7778 - val_loss: 0.5380 - val_accuracy: 0.7188\n",
      "Epoch 753/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4517 - accuracy: 0.7778 - val_loss: 0.5380 - val_accuracy: 0.7188\n",
      "Epoch 754/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4517 - accuracy: 0.7778 - val_loss: 0.5380 - val_accuracy: 0.7188\n",
      "Epoch 755/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4516 - accuracy: 0.7760 - val_loss: 0.5380 - val_accuracy: 0.7188\n",
      "Epoch 756/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4515 - accuracy: 0.7778 - val_loss: 0.5380 - val_accuracy: 0.7188\n",
      "Epoch 757/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4515 - accuracy: 0.7760 - val_loss: 0.5380 - val_accuracy: 0.7188\n",
      "Epoch 758/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4515 - accuracy: 0.7743 - val_loss: 0.5379 - val_accuracy: 0.7188\n",
      "Epoch 759/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4514 - accuracy: 0.7760 - val_loss: 0.5379 - val_accuracy: 0.7188\n",
      "Epoch 760/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4514 - accuracy: 0.7760 - val_loss: 0.5379 - val_accuracy: 0.7240\n",
      "Epoch 761/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4513 - accuracy: 0.7726 - val_loss: 0.5379 - val_accuracy: 0.7240\n",
      "Epoch 762/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4512 - accuracy: 0.7760 - val_loss: 0.5379 - val_accuracy: 0.7240\n",
      "Epoch 763/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4512 - accuracy: 0.7760 - val_loss: 0.5379 - val_accuracy: 0.7240\n",
      "Epoch 764/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4512 - accuracy: 0.7743 - val_loss: 0.5379 - val_accuracy: 0.7240\n",
      "Epoch 765/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4511 - accuracy: 0.7743 - val_loss: 0.5379 - val_accuracy: 0.7240\n",
      "Epoch 766/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4511 - accuracy: 0.7760 - val_loss: 0.5378 - val_accuracy: 0.7240\n",
      "Epoch 767/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4510 - accuracy: 0.7743 - val_loss: 0.5378 - val_accuracy: 0.7240\n",
      "Epoch 768/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4509 - accuracy: 0.7760 - val_loss: 0.5378 - val_accuracy: 0.7240\n",
      "Epoch 769/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4509 - accuracy: 0.7743 - val_loss: 0.5378 - val_accuracy: 0.7240\n",
      "Epoch 770/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4508 - accuracy: 0.7743 - val_loss: 0.5378 - val_accuracy: 0.7240\n",
      "Epoch 771/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4508 - accuracy: 0.7743 - val_loss: 0.5378 - val_accuracy: 0.7240\n",
      "Epoch 772/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4507 - accuracy: 0.7743 - val_loss: 0.5378 - val_accuracy: 0.7240\n",
      "Epoch 773/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4506 - accuracy: 0.7726 - val_loss: 0.5378 - val_accuracy: 0.7240\n",
      "Epoch 774/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4506 - accuracy: 0.7726 - val_loss: 0.5378 - val_accuracy: 0.7240\n",
      "Epoch 775/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4506 - accuracy: 0.7726 - val_loss: 0.5378 - val_accuracy: 0.7240\n",
      "Epoch 776/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4505 - accuracy: 0.7743 - val_loss: 0.5378 - val_accuracy: 0.7240\n",
      "Epoch 777/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4504 - accuracy: 0.7726 - val_loss: 0.5378 - val_accuracy: 0.7240\n",
      "Epoch 778/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4503 - accuracy: 0.7708 - val_loss: 0.5378 - val_accuracy: 0.7240\n",
      "Epoch 779/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4503 - accuracy: 0.7743 - val_loss: 0.5378 - val_accuracy: 0.7240\n",
      "Epoch 780/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4502 - accuracy: 0.7743 - val_loss: 0.5378 - val_accuracy: 0.7240\n",
      "Epoch 781/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4502 - accuracy: 0.7726 - val_loss: 0.5378 - val_accuracy: 0.7292\n",
      "Epoch 782/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4501 - accuracy: 0.7743 - val_loss: 0.5378 - val_accuracy: 0.7292\n",
      "Epoch 783/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4501 - accuracy: 0.7726 - val_loss: 0.5378 - val_accuracy: 0.7292\n",
      "Epoch 784/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4500 - accuracy: 0.7726 - val_loss: 0.5378 - val_accuracy: 0.7292\n",
      "Epoch 785/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4500 - accuracy: 0.7726 - val_loss: 0.5378 - val_accuracy: 0.7292\n",
      "Epoch 786/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4499 - accuracy: 0.7726 - val_loss: 0.5378 - val_accuracy: 0.7292\n",
      "Epoch 787/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4499 - accuracy: 0.7726 - val_loss: 0.5377 - val_accuracy: 0.7292\n",
      "Epoch 788/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4498 - accuracy: 0.7726 - val_loss: 0.5377 - val_accuracy: 0.7292\n",
      "Epoch 789/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4498 - accuracy: 0.7726 - val_loss: 0.5377 - val_accuracy: 0.7292\n",
      "Epoch 790/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4497 - accuracy: 0.7726 - val_loss: 0.5377 - val_accuracy: 0.7292\n",
      "Epoch 791/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4496 - accuracy: 0.7726 - val_loss: 0.5377 - val_accuracy: 0.7292\n",
      "Epoch 792/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4497 - accuracy: 0.7726 - val_loss: 0.5377 - val_accuracy: 0.7292\n",
      "Epoch 793/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4495 - accuracy: 0.7726 - val_loss: 0.5377 - val_accuracy: 0.7292\n",
      "Epoch 794/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4495 - accuracy: 0.7726 - val_loss: 0.5377 - val_accuracy: 0.7292\n",
      "Epoch 795/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4494 - accuracy: 0.7726 - val_loss: 0.5377 - val_accuracy: 0.7292\n",
      "Epoch 796/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4494 - accuracy: 0.7726 - val_loss: 0.5377 - val_accuracy: 0.7292\n",
      "Epoch 797/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4493 - accuracy: 0.7726 - val_loss: 0.5377 - val_accuracy: 0.7292\n",
      "Epoch 798/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4492 - accuracy: 0.7726 - val_loss: 0.5377 - val_accuracy: 0.7292\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 799/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4492 - accuracy: 0.7726 - val_loss: 0.5377 - val_accuracy: 0.7292\n",
      "Epoch 800/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4492 - accuracy: 0.7726 - val_loss: 0.5376 - val_accuracy: 0.7292\n",
      "Epoch 801/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4492 - accuracy: 0.7726 - val_loss: 0.5376 - val_accuracy: 0.7292\n",
      "Epoch 802/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4491 - accuracy: 0.7726 - val_loss: 0.5376 - val_accuracy: 0.7292\n",
      "Epoch 803/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4490 - accuracy: 0.7726 - val_loss: 0.5376 - val_accuracy: 0.7292\n",
      "Epoch 804/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4490 - accuracy: 0.7726 - val_loss: 0.5376 - val_accuracy: 0.7292\n",
      "Epoch 805/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4489 - accuracy: 0.7726 - val_loss: 0.5376 - val_accuracy: 0.7292\n",
      "Epoch 806/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4489 - accuracy: 0.7726 - val_loss: 0.5376 - val_accuracy: 0.7292\n",
      "Epoch 807/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4488 - accuracy: 0.7726 - val_loss: 0.5376 - val_accuracy: 0.7292\n",
      "Epoch 808/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4488 - accuracy: 0.7726 - val_loss: 0.5376 - val_accuracy: 0.7292\n",
      "Epoch 809/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4487 - accuracy: 0.7726 - val_loss: 0.5376 - val_accuracy: 0.7292\n",
      "Epoch 810/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4486 - accuracy: 0.7726 - val_loss: 0.5376 - val_accuracy: 0.7292\n",
      "Epoch 811/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4486 - accuracy: 0.7726 - val_loss: 0.5376 - val_accuracy: 0.7292\n",
      "Epoch 812/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4485 - accuracy: 0.7726 - val_loss: 0.5376 - val_accuracy: 0.7292\n",
      "Epoch 813/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4484 - accuracy: 0.7726 - val_loss: 0.5376 - val_accuracy: 0.7292\n",
      "Epoch 814/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4484 - accuracy: 0.7726 - val_loss: 0.5376 - val_accuracy: 0.7292\n",
      "Epoch 815/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4484 - accuracy: 0.7726 - val_loss: 0.5376 - val_accuracy: 0.7292\n",
      "Epoch 816/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4483 - accuracy: 0.7726 - val_loss: 0.5376 - val_accuracy: 0.7292\n",
      "Epoch 817/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4483 - accuracy: 0.7726 - val_loss: 0.5376 - val_accuracy: 0.7292\n",
      "Epoch 818/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4482 - accuracy: 0.7726 - val_loss: 0.5376 - val_accuracy: 0.7292\n",
      "Epoch 819/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4482 - accuracy: 0.7726 - val_loss: 0.5376 - val_accuracy: 0.7292\n",
      "Epoch 820/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4481 - accuracy: 0.7726 - val_loss: 0.5376 - val_accuracy: 0.7292\n",
      "Epoch 821/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4480 - accuracy: 0.7726 - val_loss: 0.5376 - val_accuracy: 0.7292\n",
      "Epoch 822/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4480 - accuracy: 0.7726 - val_loss: 0.5376 - val_accuracy: 0.7292\n",
      "Epoch 823/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4479 - accuracy: 0.7726 - val_loss: 0.5376 - val_accuracy: 0.7292\n",
      "Epoch 824/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4479 - accuracy: 0.7743 - val_loss: 0.5376 - val_accuracy: 0.7292\n",
      "Epoch 825/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4479 - accuracy: 0.7743 - val_loss: 0.5376 - val_accuracy: 0.7292\n",
      "Epoch 826/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4478 - accuracy: 0.7743 - val_loss: 0.5376 - val_accuracy: 0.7292\n",
      "Epoch 827/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4477 - accuracy: 0.7743 - val_loss: 0.5376 - val_accuracy: 0.7292\n",
      "Epoch 828/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4477 - accuracy: 0.7726 - val_loss: 0.5376 - val_accuracy: 0.7292\n",
      "Epoch 829/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4477 - accuracy: 0.7743 - val_loss: 0.5376 - val_accuracy: 0.7292\n",
      "Epoch 830/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4476 - accuracy: 0.7743 - val_loss: 0.5376 - val_accuracy: 0.7292\n",
      "Epoch 831/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4476 - accuracy: 0.7743 - val_loss: 0.5376 - val_accuracy: 0.7292\n",
      "Epoch 832/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4475 - accuracy: 0.7743 - val_loss: 0.5376 - val_accuracy: 0.7292\n",
      "Epoch 833/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4475 - accuracy: 0.7743 - val_loss: 0.5376 - val_accuracy: 0.7292\n",
      "Epoch 834/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4475 - accuracy: 0.7743 - val_loss: 0.5376 - val_accuracy: 0.7292\n",
      "Epoch 835/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4474 - accuracy: 0.7743 - val_loss: 0.5376 - val_accuracy: 0.7292\n",
      "Epoch 836/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4474 - accuracy: 0.7743 - val_loss: 0.5376 - val_accuracy: 0.7292\n",
      "Epoch 837/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4473 - accuracy: 0.7743 - val_loss: 0.5376 - val_accuracy: 0.7292\n",
      "Epoch 838/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4473 - accuracy: 0.7743 - val_loss: 0.5376 - val_accuracy: 0.7292\n",
      "Epoch 839/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4473 - accuracy: 0.7743 - val_loss: 0.5376 - val_accuracy: 0.7292\n",
      "Epoch 840/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4472 - accuracy: 0.7743 - val_loss: 0.5375 - val_accuracy: 0.7292\n",
      "Epoch 841/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4472 - accuracy: 0.7743 - val_loss: 0.5375 - val_accuracy: 0.7292\n",
      "Epoch 842/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4471 - accuracy: 0.7743 - val_loss: 0.5375 - val_accuracy: 0.7292\n",
      "Epoch 843/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4471 - accuracy: 0.7743 - val_loss: 0.5375 - val_accuracy: 0.7292\n",
      "Epoch 844/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4470 - accuracy: 0.7743 - val_loss: 0.5375 - val_accuracy: 0.7292\n",
      "Epoch 845/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4470 - accuracy: 0.7743 - val_loss: 0.5375 - val_accuracy: 0.7292\n",
      "Epoch 846/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4470 - accuracy: 0.7743 - val_loss: 0.5375 - val_accuracy: 0.7292\n",
      "Epoch 847/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4470 - accuracy: 0.7743 - val_loss: 0.5375 - val_accuracy: 0.7292\n",
      "Epoch 848/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4470 - accuracy: 0.7743 - val_loss: 0.5374 - val_accuracy: 0.7292\n",
      "Epoch 849/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4469 - accuracy: 0.7743 - val_loss: 0.5374 - val_accuracy: 0.7292\n",
      "Epoch 850/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4469 - accuracy: 0.7743 - val_loss: 0.5374 - val_accuracy: 0.7292\n",
      "Epoch 851/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4469 - accuracy: 0.7743 - val_loss: 0.5374 - val_accuracy: 0.7292\n",
      "Epoch 852/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4468 - accuracy: 0.7743 - val_loss: 0.5374 - val_accuracy: 0.7292\n",
      "Epoch 853/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4468 - accuracy: 0.7743 - val_loss: 0.5373 - val_accuracy: 0.7292\n",
      "Epoch 854/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4468 - accuracy: 0.7743 - val_loss: 0.5373 - val_accuracy: 0.7292\n",
      "Epoch 855/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4467 - accuracy: 0.7743 - val_loss: 0.5373 - val_accuracy: 0.7292\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 856/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4467 - accuracy: 0.7743 - val_loss: 0.5373 - val_accuracy: 0.7292\n",
      "Epoch 857/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4466 - accuracy: 0.7743 - val_loss: 0.5373 - val_accuracy: 0.7292\n",
      "Epoch 858/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4467 - accuracy: 0.7743 - val_loss: 0.5373 - val_accuracy: 0.7292\n",
      "Epoch 859/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4466 - accuracy: 0.7743 - val_loss: 0.5372 - val_accuracy: 0.7292\n",
      "Epoch 860/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4465 - accuracy: 0.7743 - val_loss: 0.5372 - val_accuracy: 0.7292\n",
      "Epoch 861/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4465 - accuracy: 0.7743 - val_loss: 0.5372 - val_accuracy: 0.7292\n",
      "Epoch 862/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4464 - accuracy: 0.7743 - val_loss: 0.5372 - val_accuracy: 0.7292\n",
      "Epoch 863/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4464 - accuracy: 0.7743 - val_loss: 0.5372 - val_accuracy: 0.7292\n",
      "Epoch 864/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4464 - accuracy: 0.7743 - val_loss: 0.5372 - val_accuracy: 0.7292\n",
      "Epoch 865/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4463 - accuracy: 0.7743 - val_loss: 0.5371 - val_accuracy: 0.7292\n",
      "Epoch 866/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4464 - accuracy: 0.7743 - val_loss: 0.5371 - val_accuracy: 0.7292\n",
      "Epoch 867/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4463 - accuracy: 0.7743 - val_loss: 0.5371 - val_accuracy: 0.7292\n",
      "Epoch 868/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4463 - accuracy: 0.7743 - val_loss: 0.5371 - val_accuracy: 0.7292\n",
      "Epoch 869/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4462 - accuracy: 0.7743 - val_loss: 0.5370 - val_accuracy: 0.7292\n",
      "Epoch 870/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4461 - accuracy: 0.7743 - val_loss: 0.5370 - val_accuracy: 0.7292\n",
      "Epoch 871/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4462 - accuracy: 0.7743 - val_loss: 0.5370 - val_accuracy: 0.7292\n",
      "Epoch 872/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4461 - accuracy: 0.7743 - val_loss: 0.5369 - val_accuracy: 0.7292\n",
      "Epoch 873/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4461 - accuracy: 0.7743 - val_loss: 0.5369 - val_accuracy: 0.7292\n",
      "Epoch 874/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4460 - accuracy: 0.7743 - val_loss: 0.5369 - val_accuracy: 0.7292\n",
      "Epoch 875/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4460 - accuracy: 0.7743 - val_loss: 0.5369 - val_accuracy: 0.7292\n",
      "Epoch 876/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4459 - accuracy: 0.7743 - val_loss: 0.5369 - val_accuracy: 0.7292\n",
      "Epoch 877/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4459 - accuracy: 0.7743 - val_loss: 0.5368 - val_accuracy: 0.7292\n",
      "Epoch 878/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4459 - accuracy: 0.7743 - val_loss: 0.5368 - val_accuracy: 0.7292\n",
      "Epoch 879/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4459 - accuracy: 0.7743 - val_loss: 0.5368 - val_accuracy: 0.7292\n",
      "Epoch 880/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4458 - accuracy: 0.7743 - val_loss: 0.5367 - val_accuracy: 0.7292\n",
      "Epoch 881/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4458 - accuracy: 0.7743 - val_loss: 0.5367 - val_accuracy: 0.7292\n",
      "Epoch 882/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4457 - accuracy: 0.7760 - val_loss: 0.5367 - val_accuracy: 0.7292\n",
      "Epoch 883/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4457 - accuracy: 0.7778 - val_loss: 0.5367 - val_accuracy: 0.7292\n",
      "Epoch 884/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4457 - accuracy: 0.7760 - val_loss: 0.5366 - val_accuracy: 0.7292\n",
      "Epoch 885/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4456 - accuracy: 0.7760 - val_loss: 0.5366 - val_accuracy: 0.7292\n",
      "Epoch 886/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4456 - accuracy: 0.7795 - val_loss: 0.5366 - val_accuracy: 0.7292\n",
      "Epoch 887/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4456 - accuracy: 0.7795 - val_loss: 0.5365 - val_accuracy: 0.7292\n",
      "Epoch 888/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4455 - accuracy: 0.7795 - val_loss: 0.5365 - val_accuracy: 0.7292\n",
      "Epoch 889/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4455 - accuracy: 0.7795 - val_loss: 0.5365 - val_accuracy: 0.7292\n",
      "Epoch 890/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4455 - accuracy: 0.7795 - val_loss: 0.5365 - val_accuracy: 0.7292\n",
      "Epoch 891/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4454 - accuracy: 0.7812 - val_loss: 0.5364 - val_accuracy: 0.7292\n",
      "Epoch 892/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4454 - accuracy: 0.7795 - val_loss: 0.5364 - val_accuracy: 0.7292\n",
      "Epoch 893/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4453 - accuracy: 0.7795 - val_loss: 0.5364 - val_accuracy: 0.7292\n",
      "Epoch 894/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4453 - accuracy: 0.7812 - val_loss: 0.5364 - val_accuracy: 0.7292\n",
      "Epoch 895/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4453 - accuracy: 0.7812 - val_loss: 0.5363 - val_accuracy: 0.7292\n",
      "Epoch 896/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4453 - accuracy: 0.7812 - val_loss: 0.5363 - val_accuracy: 0.7292\n",
      "Epoch 897/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4452 - accuracy: 0.7812 - val_loss: 0.5363 - val_accuracy: 0.7292\n",
      "Epoch 898/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4452 - accuracy: 0.7795 - val_loss: 0.5363 - val_accuracy: 0.7292\n",
      "Epoch 899/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4451 - accuracy: 0.7795 - val_loss: 0.5362 - val_accuracy: 0.7292\n",
      "Epoch 900/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4451 - accuracy: 0.7812 - val_loss: 0.5362 - val_accuracy: 0.7292\n",
      "Epoch 901/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4451 - accuracy: 0.7812 - val_loss: 0.5362 - val_accuracy: 0.7292\n",
      "Epoch 902/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4451 - accuracy: 0.7812 - val_loss: 0.5362 - val_accuracy: 0.7292\n",
      "Epoch 903/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4450 - accuracy: 0.7812 - val_loss: 0.5362 - val_accuracy: 0.7292\n",
      "Epoch 904/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4450 - accuracy: 0.7795 - val_loss: 0.5361 - val_accuracy: 0.7292\n",
      "Epoch 905/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4450 - accuracy: 0.7812 - val_loss: 0.5361 - val_accuracy: 0.7292\n",
      "Epoch 906/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4449 - accuracy: 0.7812 - val_loss: 0.5361 - val_accuracy: 0.7292\n",
      "Epoch 907/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4449 - accuracy: 0.7812 - val_loss: 0.5361 - val_accuracy: 0.7292\n",
      "Epoch 908/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4449 - accuracy: 0.7812 - val_loss: 0.5360 - val_accuracy: 0.7292\n",
      "Epoch 909/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4449 - accuracy: 0.7812 - val_loss: 0.5360 - val_accuracy: 0.7292\n",
      "Epoch 910/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4448 - accuracy: 0.7812 - val_loss: 0.5360 - val_accuracy: 0.7292\n",
      "Epoch 911/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4448 - accuracy: 0.7812 - val_loss: 0.5360 - val_accuracy: 0.7292\n",
      "Epoch 912/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4448 - accuracy: 0.7812 - val_loss: 0.5360 - val_accuracy: 0.7292\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 913/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4447 - accuracy: 0.7812 - val_loss: 0.5360 - val_accuracy: 0.7292\n",
      "Epoch 914/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4447 - accuracy: 0.7812 - val_loss: 0.5359 - val_accuracy: 0.7292\n",
      "Epoch 915/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4447 - accuracy: 0.7812 - val_loss: 0.5359 - val_accuracy: 0.7292\n",
      "Epoch 916/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4447 - accuracy: 0.7812 - val_loss: 0.5359 - val_accuracy: 0.7292\n",
      "Epoch 917/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4446 - accuracy: 0.7812 - val_loss: 0.5359 - val_accuracy: 0.7292\n",
      "Epoch 918/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4446 - accuracy: 0.7812 - val_loss: 0.5358 - val_accuracy: 0.7292\n",
      "Epoch 919/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4446 - accuracy: 0.7812 - val_loss: 0.5358 - val_accuracy: 0.7292\n",
      "Epoch 920/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4445 - accuracy: 0.7812 - val_loss: 0.5358 - val_accuracy: 0.7292\n",
      "Epoch 921/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4445 - accuracy: 0.7812 - val_loss: 0.5358 - val_accuracy: 0.7292\n",
      "Epoch 922/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4445 - accuracy: 0.7812 - val_loss: 0.5358 - val_accuracy: 0.7292\n",
      "Epoch 923/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4445 - accuracy: 0.7812 - val_loss: 0.5358 - val_accuracy: 0.7292\n",
      "Epoch 924/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4444 - accuracy: 0.7812 - val_loss: 0.5357 - val_accuracy: 0.7292\n",
      "Epoch 925/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4444 - accuracy: 0.7812 - val_loss: 0.5357 - val_accuracy: 0.7292\n",
      "Epoch 926/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4443 - accuracy: 0.7812 - val_loss: 0.5357 - val_accuracy: 0.7292\n",
      "Epoch 927/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4443 - accuracy: 0.7812 - val_loss: 0.5357 - val_accuracy: 0.7292\n",
      "Epoch 928/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4443 - accuracy: 0.7812 - val_loss: 0.5357 - val_accuracy: 0.7292\n",
      "Epoch 929/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4443 - accuracy: 0.7812 - val_loss: 0.5357 - val_accuracy: 0.7292\n",
      "Epoch 930/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4443 - accuracy: 0.7812 - val_loss: 0.5357 - val_accuracy: 0.7292\n",
      "Epoch 931/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4442 - accuracy: 0.7830 - val_loss: 0.5357 - val_accuracy: 0.7292\n",
      "Epoch 932/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4442 - accuracy: 0.7812 - val_loss: 0.5356 - val_accuracy: 0.7292\n",
      "Epoch 933/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4442 - accuracy: 0.7812 - val_loss: 0.5356 - val_accuracy: 0.7292\n",
      "Epoch 934/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4442 - accuracy: 0.7812 - val_loss: 0.5356 - val_accuracy: 0.7292\n",
      "Epoch 935/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4441 - accuracy: 0.7830 - val_loss: 0.5356 - val_accuracy: 0.7292\n",
      "Epoch 936/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4441 - accuracy: 0.7812 - val_loss: 0.5356 - val_accuracy: 0.7292\n",
      "Epoch 937/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4441 - accuracy: 0.7812 - val_loss: 0.5356 - val_accuracy: 0.7292\n",
      "Epoch 938/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4441 - accuracy: 0.7812 - val_loss: 0.5355 - val_accuracy: 0.7292\n",
      "Epoch 939/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4440 - accuracy: 0.7830 - val_loss: 0.5355 - val_accuracy: 0.7292\n",
      "Epoch 940/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4440 - accuracy: 0.7812 - val_loss: 0.5355 - val_accuracy: 0.7292\n",
      "Epoch 941/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4440 - accuracy: 0.7830 - val_loss: 0.5355 - val_accuracy: 0.7292\n",
      "Epoch 942/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4440 - accuracy: 0.7812 - val_loss: 0.5355 - val_accuracy: 0.7292\n",
      "Epoch 943/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4439 - accuracy: 0.7830 - val_loss: 0.5355 - val_accuracy: 0.7292\n",
      "Epoch 944/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4439 - accuracy: 0.7830 - val_loss: 0.5355 - val_accuracy: 0.7292\n",
      "Epoch 945/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4439 - accuracy: 0.7830 - val_loss: 0.5354 - val_accuracy: 0.7292\n",
      "Epoch 946/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4438 - accuracy: 0.7812 - val_loss: 0.5354 - val_accuracy: 0.7292\n",
      "Epoch 947/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4438 - accuracy: 0.7812 - val_loss: 0.5354 - val_accuracy: 0.7292\n",
      "Epoch 948/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4438 - accuracy: 0.7830 - val_loss: 0.5354 - val_accuracy: 0.7292\n",
      "Epoch 949/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4438 - accuracy: 0.7812 - val_loss: 0.5354 - val_accuracy: 0.7292\n",
      "Epoch 950/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4437 - accuracy: 0.7812 - val_loss: 0.5353 - val_accuracy: 0.7292\n",
      "Epoch 951/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4438 - accuracy: 0.7812 - val_loss: 0.5353 - val_accuracy: 0.7292\n",
      "Epoch 952/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4437 - accuracy: 0.7812 - val_loss: 0.5353 - val_accuracy: 0.7292\n",
      "Epoch 953/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4437 - accuracy: 0.7812 - val_loss: 0.5353 - val_accuracy: 0.7292\n",
      "Epoch 954/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4436 - accuracy: 0.7812 - val_loss: 0.5353 - val_accuracy: 0.7292\n",
      "Epoch 955/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4436 - accuracy: 0.7830 - val_loss: 0.5353 - val_accuracy: 0.7292\n",
      "Epoch 956/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4436 - accuracy: 0.7812 - val_loss: 0.5352 - val_accuracy: 0.7292\n",
      "Epoch 957/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4435 - accuracy: 0.7812 - val_loss: 0.5352 - val_accuracy: 0.7292\n",
      "Epoch 958/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4435 - accuracy: 0.7812 - val_loss: 0.5352 - val_accuracy: 0.7292\n",
      "Epoch 959/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4435 - accuracy: 0.7812 - val_loss: 0.5352 - val_accuracy: 0.7292\n",
      "Epoch 960/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4435 - accuracy: 0.7812 - val_loss: 0.5351 - val_accuracy: 0.7292\n",
      "Epoch 961/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4434 - accuracy: 0.7812 - val_loss: 0.5351 - val_accuracy: 0.7292\n",
      "Epoch 962/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4434 - accuracy: 0.7812 - val_loss: 0.5351 - val_accuracy: 0.7292\n",
      "Epoch 963/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4434 - accuracy: 0.7812 - val_loss: 0.5351 - val_accuracy: 0.7292\n",
      "Epoch 964/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4434 - accuracy: 0.7812 - val_loss: 0.5350 - val_accuracy: 0.7292\n",
      "Epoch 965/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4434 - accuracy: 0.7812 - val_loss: 0.5350 - val_accuracy: 0.7292\n",
      "Epoch 966/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4433 - accuracy: 0.7795 - val_loss: 0.5350 - val_accuracy: 0.7292\n",
      "Epoch 967/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4433 - accuracy: 0.7812 - val_loss: 0.5350 - val_accuracy: 0.7292\n",
      "Epoch 968/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4433 - accuracy: 0.7812 - val_loss: 0.5350 - val_accuracy: 0.7292\n",
      "Epoch 969/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4432 - accuracy: 0.7812 - val_loss: 0.5350 - val_accuracy: 0.7292\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 970/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4432 - accuracy: 0.7812 - val_loss: 0.5349 - val_accuracy: 0.7292\n",
      "Epoch 971/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4432 - accuracy: 0.7812 - val_loss: 0.5349 - val_accuracy: 0.7292\n",
      "Epoch 972/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4432 - accuracy: 0.7812 - val_loss: 0.5349 - val_accuracy: 0.7292\n",
      "Epoch 973/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4432 - accuracy: 0.7812 - val_loss: 0.5349 - val_accuracy: 0.7292\n",
      "Epoch 974/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4431 - accuracy: 0.7812 - val_loss: 0.5348 - val_accuracy: 0.7292\n",
      "Epoch 975/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4431 - accuracy: 0.7812 - val_loss: 0.5348 - val_accuracy: 0.7292\n",
      "Epoch 976/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4430 - accuracy: 0.7812 - val_loss: 0.5348 - val_accuracy: 0.7292\n",
      "Epoch 977/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4430 - accuracy: 0.7812 - val_loss: 0.5348 - val_accuracy: 0.7292\n",
      "Epoch 978/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4430 - accuracy: 0.7812 - val_loss: 0.5348 - val_accuracy: 0.7292\n",
      "Epoch 979/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4430 - accuracy: 0.7830 - val_loss: 0.5348 - val_accuracy: 0.7292\n",
      "Epoch 980/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4429 - accuracy: 0.7812 - val_loss: 0.5347 - val_accuracy: 0.7292\n",
      "Epoch 981/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4429 - accuracy: 0.7830 - val_loss: 0.5347 - val_accuracy: 0.7292\n",
      "Epoch 982/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4428 - accuracy: 0.7830 - val_loss: 0.5347 - val_accuracy: 0.7292\n",
      "Epoch 983/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4428 - accuracy: 0.7812 - val_loss: 0.5347 - val_accuracy: 0.7292\n",
      "Epoch 984/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4428 - accuracy: 0.7830 - val_loss: 0.5347 - val_accuracy: 0.7292\n",
      "Epoch 985/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4428 - accuracy: 0.7830 - val_loss: 0.5347 - val_accuracy: 0.7292\n",
      "Epoch 986/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4428 - accuracy: 0.7830 - val_loss: 0.5346 - val_accuracy: 0.7292\n",
      "Epoch 987/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4427 - accuracy: 0.7830 - val_loss: 0.5346 - val_accuracy: 0.7292\n",
      "Epoch 988/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4427 - accuracy: 0.7830 - val_loss: 0.5346 - val_accuracy: 0.7292\n",
      "Epoch 989/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4427 - accuracy: 0.7830 - val_loss: 0.5346 - val_accuracy: 0.7292\n",
      "Epoch 990/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4427 - accuracy: 0.7830 - val_loss: 0.5346 - val_accuracy: 0.7292\n",
      "Epoch 991/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4427 - accuracy: 0.7830 - val_loss: 0.5346 - val_accuracy: 0.7292\n",
      "Epoch 992/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4426 - accuracy: 0.7830 - val_loss: 0.5346 - val_accuracy: 0.7292\n",
      "Epoch 993/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4426 - accuracy: 0.7830 - val_loss: 0.5346 - val_accuracy: 0.7292\n",
      "Epoch 994/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4425 - accuracy: 0.7830 - val_loss: 0.5345 - val_accuracy: 0.7292\n",
      "Epoch 995/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4425 - accuracy: 0.7830 - val_loss: 0.5345 - val_accuracy: 0.7292\n",
      "Epoch 996/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4425 - accuracy: 0.7830 - val_loss: 0.5345 - val_accuracy: 0.7292\n",
      "Epoch 997/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4424 - accuracy: 0.7830 - val_loss: 0.5345 - val_accuracy: 0.7292\n",
      "Epoch 998/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4424 - accuracy: 0.7830 - val_loss: 0.5345 - val_accuracy: 0.7344\n",
      "Epoch 999/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4424 - accuracy: 0.7830 - val_loss: 0.5345 - val_accuracy: 0.7344\n",
      "Epoch 1000/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4423 - accuracy: 0.7830 - val_loss: 0.5345 - val_accuracy: 0.7344\n",
      "Epoch 1001/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4423 - accuracy: 0.7830 - val_loss: 0.5345 - val_accuracy: 0.7344\n",
      "Epoch 1002/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4423 - accuracy: 0.7830 - val_loss: 0.5345 - val_accuracy: 0.7344\n",
      "Epoch 1003/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4422 - accuracy: 0.7812 - val_loss: 0.5345 - val_accuracy: 0.7344\n",
      "Epoch 1004/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4422 - accuracy: 0.7830 - val_loss: 0.5345 - val_accuracy: 0.7344\n",
      "Epoch 1005/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4422 - accuracy: 0.7830 - val_loss: 0.5345 - val_accuracy: 0.7344\n",
      "Epoch 1006/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4422 - accuracy: 0.7812 - val_loss: 0.5345 - val_accuracy: 0.7344\n",
      "Epoch 1007/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4421 - accuracy: 0.7830 - val_loss: 0.5344 - val_accuracy: 0.7344\n",
      "Epoch 1008/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4421 - accuracy: 0.7830 - val_loss: 0.5344 - val_accuracy: 0.7344\n",
      "Epoch 1009/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4421 - accuracy: 0.7830 - val_loss: 0.5344 - val_accuracy: 0.7344\n",
      "Epoch 1010/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4420 - accuracy: 0.7830 - val_loss: 0.5344 - val_accuracy: 0.7344\n",
      "Epoch 1011/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4420 - accuracy: 0.7830 - val_loss: 0.5344 - val_accuracy: 0.7344\n",
      "Epoch 1012/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4419 - accuracy: 0.7830 - val_loss: 0.5344 - val_accuracy: 0.7344\n",
      "Epoch 1013/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4419 - accuracy: 0.7812 - val_loss: 0.5344 - val_accuracy: 0.7344\n",
      "Epoch 1014/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4419 - accuracy: 0.7830 - val_loss: 0.5344 - val_accuracy: 0.7344\n",
      "Epoch 1015/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4419 - accuracy: 0.7830 - val_loss: 0.5344 - val_accuracy: 0.7344\n",
      "Epoch 1016/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4418 - accuracy: 0.7812 - val_loss: 0.5343 - val_accuracy: 0.7344\n",
      "Epoch 1017/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4418 - accuracy: 0.7830 - val_loss: 0.5343 - val_accuracy: 0.7344\n",
      "Epoch 1018/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4417 - accuracy: 0.7830 - val_loss: 0.5343 - val_accuracy: 0.7344\n",
      "Epoch 1019/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4418 - accuracy: 0.7830 - val_loss: 0.5343 - val_accuracy: 0.7344\n",
      "Epoch 1020/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4418 - accuracy: 0.7830 - val_loss: 0.5343 - val_accuracy: 0.7344\n",
      "Epoch 1021/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4417 - accuracy: 0.7830 - val_loss: 0.5343 - val_accuracy: 0.7344\n",
      "Epoch 1022/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4417 - accuracy: 0.7830 - val_loss: 0.5343 - val_accuracy: 0.7344\n",
      "Epoch 1023/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4416 - accuracy: 0.7830 - val_loss: 0.5343 - val_accuracy: 0.7344\n",
      "Epoch 1024/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4416 - accuracy: 0.7812 - val_loss: 0.5343 - val_accuracy: 0.7344\n",
      "Epoch 1025/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4416 - accuracy: 0.7812 - val_loss: 0.5343 - val_accuracy: 0.7344\n",
      "Epoch 1026/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4415 - accuracy: 0.7830 - val_loss: 0.5343 - val_accuracy: 0.7344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1027/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4415 - accuracy: 0.7812 - val_loss: 0.5342 - val_accuracy: 0.7344\n",
      "Epoch 1028/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4415 - accuracy: 0.7812 - val_loss: 0.5342 - val_accuracy: 0.7344\n",
      "Epoch 1029/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4415 - accuracy: 0.7812 - val_loss: 0.5342 - val_accuracy: 0.7344\n",
      "Epoch 1030/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4415 - accuracy: 0.7812 - val_loss: 0.5342 - val_accuracy: 0.7344\n",
      "Epoch 1031/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4414 - accuracy: 0.7812 - val_loss: 0.5342 - val_accuracy: 0.7344\n",
      "Epoch 1032/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4414 - accuracy: 0.7812 - val_loss: 0.5341 - val_accuracy: 0.7344\n",
      "Epoch 1033/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4413 - accuracy: 0.7830 - val_loss: 0.5341 - val_accuracy: 0.7344\n",
      "Epoch 1034/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4413 - accuracy: 0.7830 - val_loss: 0.5341 - val_accuracy: 0.7344\n",
      "Epoch 1035/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4413 - accuracy: 0.7812 - val_loss: 0.5341 - val_accuracy: 0.7344\n",
      "Epoch 1036/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4413 - accuracy: 0.7812 - val_loss: 0.5340 - val_accuracy: 0.7344\n",
      "Epoch 1037/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4412 - accuracy: 0.7812 - val_loss: 0.5340 - val_accuracy: 0.7344\n",
      "Epoch 1038/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4412 - accuracy: 0.7830 - val_loss: 0.5340 - val_accuracy: 0.7344\n",
      "Epoch 1039/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4412 - accuracy: 0.7812 - val_loss: 0.5340 - val_accuracy: 0.7344\n",
      "Epoch 1040/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4411 - accuracy: 0.7830 - val_loss: 0.5339 - val_accuracy: 0.7344\n",
      "Epoch 1041/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4411 - accuracy: 0.7830 - val_loss: 0.5339 - val_accuracy: 0.7344\n",
      "Epoch 1042/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4411 - accuracy: 0.7812 - val_loss: 0.5338 - val_accuracy: 0.7344\n",
      "Epoch 1043/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4411 - accuracy: 0.7812 - val_loss: 0.5338 - val_accuracy: 0.7344\n",
      "Epoch 1044/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4410 - accuracy: 0.7795 - val_loss: 0.5337 - val_accuracy: 0.7344\n",
      "Epoch 1045/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4410 - accuracy: 0.7812 - val_loss: 0.5337 - val_accuracy: 0.7344\n",
      "Epoch 1046/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4409 - accuracy: 0.7812 - val_loss: 0.5337 - val_accuracy: 0.7344\n",
      "Epoch 1047/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4409 - accuracy: 0.7830 - val_loss: 0.5336 - val_accuracy: 0.7344\n",
      "Epoch 1048/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4409 - accuracy: 0.7812 - val_loss: 0.5336 - val_accuracy: 0.7344\n",
      "Epoch 1049/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4408 - accuracy: 0.7812 - val_loss: 0.5335 - val_accuracy: 0.7344\n",
      "Epoch 1050/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4408 - accuracy: 0.7830 - val_loss: 0.5335 - val_accuracy: 0.7344\n",
      "Epoch 1051/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4407 - accuracy: 0.7812 - val_loss: 0.5335 - val_accuracy: 0.7396\n",
      "Epoch 1052/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4407 - accuracy: 0.7830 - val_loss: 0.5334 - val_accuracy: 0.7396\n",
      "Epoch 1053/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4406 - accuracy: 0.7847 - val_loss: 0.5334 - val_accuracy: 0.7396\n",
      "Epoch 1054/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4407 - accuracy: 0.7830 - val_loss: 0.5333 - val_accuracy: 0.7396\n",
      "Epoch 1055/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4405 - accuracy: 0.7847 - val_loss: 0.5333 - val_accuracy: 0.7396\n",
      "Epoch 1056/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4406 - accuracy: 0.7847 - val_loss: 0.5333 - val_accuracy: 0.7396\n",
      "Epoch 1057/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4405 - accuracy: 0.7847 - val_loss: 0.5332 - val_accuracy: 0.7396\n",
      "Epoch 1058/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4405 - accuracy: 0.7847 - val_loss: 0.5332 - val_accuracy: 0.7396\n",
      "Epoch 1059/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4404 - accuracy: 0.7847 - val_loss: 0.5331 - val_accuracy: 0.7396\n",
      "Epoch 1060/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4404 - accuracy: 0.7865 - val_loss: 0.5331 - val_accuracy: 0.7396\n",
      "Epoch 1061/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4403 - accuracy: 0.7847 - val_loss: 0.5331 - val_accuracy: 0.7396\n",
      "Epoch 1062/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4403 - accuracy: 0.7847 - val_loss: 0.5330 - val_accuracy: 0.7396\n",
      "Epoch 1063/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4402 - accuracy: 0.7847 - val_loss: 0.5329 - val_accuracy: 0.7396\n",
      "Epoch 1064/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4402 - accuracy: 0.7865 - val_loss: 0.5329 - val_accuracy: 0.7396\n",
      "Epoch 1065/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4402 - accuracy: 0.7865 - val_loss: 0.5328 - val_accuracy: 0.7396\n",
      "Epoch 1066/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4401 - accuracy: 0.7865 - val_loss: 0.5328 - val_accuracy: 0.7396\n",
      "Epoch 1067/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4400 - accuracy: 0.7865 - val_loss: 0.5327 - val_accuracy: 0.7396\n",
      "Epoch 1068/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4400 - accuracy: 0.7865 - val_loss: 0.5327 - val_accuracy: 0.7396\n",
      "Epoch 1069/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4400 - accuracy: 0.7865 - val_loss: 0.5326 - val_accuracy: 0.7396\n",
      "Epoch 1070/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4399 - accuracy: 0.7865 - val_loss: 0.5326 - val_accuracy: 0.7396\n",
      "Epoch 1071/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4399 - accuracy: 0.7865 - val_loss: 0.5325 - val_accuracy: 0.7396\n",
      "Epoch 1072/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4399 - accuracy: 0.7865 - val_loss: 0.5325 - val_accuracy: 0.7396\n",
      "Epoch 1073/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4398 - accuracy: 0.7865 - val_loss: 0.5324 - val_accuracy: 0.7396\n",
      "Epoch 1074/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4398 - accuracy: 0.7865 - val_loss: 0.5324 - val_accuracy: 0.7396\n",
      "Epoch 1075/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4397 - accuracy: 0.7865 - val_loss: 0.5323 - val_accuracy: 0.7396\n",
      "Epoch 1076/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4397 - accuracy: 0.7865 - val_loss: 0.5323 - val_accuracy: 0.7396\n",
      "Epoch 1077/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4396 - accuracy: 0.7865 - val_loss: 0.5323 - val_accuracy: 0.7396\n",
      "Epoch 1078/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4396 - accuracy: 0.7865 - val_loss: 0.5322 - val_accuracy: 0.7396\n",
      "Epoch 1079/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4396 - accuracy: 0.7865 - val_loss: 0.5322 - val_accuracy: 0.7396\n",
      "Epoch 1080/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4395 - accuracy: 0.7865 - val_loss: 0.5321 - val_accuracy: 0.7396\n",
      "Epoch 1081/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4395 - accuracy: 0.7865 - val_loss: 0.5321 - val_accuracy: 0.7396\n",
      "Epoch 1082/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4395 - accuracy: 0.7865 - val_loss: 0.5320 - val_accuracy: 0.7396\n",
      "Epoch 1083/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4394 - accuracy: 0.7865 - val_loss: 0.5320 - val_accuracy: 0.7396\n",
      "Epoch 1084/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4394 - accuracy: 0.7865 - val_loss: 0.5319 - val_accuracy: 0.7396\n",
      "Epoch 1085/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4394 - accuracy: 0.7865 - val_loss: 0.5319 - val_accuracy: 0.7396\n",
      "Epoch 1086/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4393 - accuracy: 0.7865 - val_loss: 0.5318 - val_accuracy: 0.7448\n",
      "Epoch 1087/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4393 - accuracy: 0.7865 - val_loss: 0.5318 - val_accuracy: 0.7448\n",
      "Epoch 1088/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4392 - accuracy: 0.7865 - val_loss: 0.5317 - val_accuracy: 0.7448\n",
      "Epoch 1089/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4392 - accuracy: 0.7865 - val_loss: 0.5317 - val_accuracy: 0.7448\n",
      "Epoch 1090/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4391 - accuracy: 0.7865 - val_loss: 0.5316 - val_accuracy: 0.7448\n",
      "Epoch 1091/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4391 - accuracy: 0.7865 - val_loss: 0.5316 - val_accuracy: 0.7448\n",
      "Epoch 1092/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4390 - accuracy: 0.7865 - val_loss: 0.5315 - val_accuracy: 0.7448\n",
      "Epoch 1093/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4390 - accuracy: 0.7865 - val_loss: 0.5315 - val_accuracy: 0.7448\n",
      "Epoch 1094/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4390 - accuracy: 0.7865 - val_loss: 0.5315 - val_accuracy: 0.7448\n",
      "Epoch 1095/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4390 - accuracy: 0.7847 - val_loss: 0.5314 - val_accuracy: 0.7448\n",
      "Epoch 1096/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4389 - accuracy: 0.7847 - val_loss: 0.5314 - val_accuracy: 0.7448\n",
      "Epoch 1097/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4389 - accuracy: 0.7865 - val_loss: 0.5314 - val_accuracy: 0.7448\n",
      "Epoch 1098/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4388 - accuracy: 0.7847 - val_loss: 0.5313 - val_accuracy: 0.7448\n",
      "Epoch 1099/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4387 - accuracy: 0.7847 - val_loss: 0.5313 - val_accuracy: 0.7448\n",
      "Epoch 1100/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4386 - accuracy: 0.7847 - val_loss: 0.5312 - val_accuracy: 0.7500\n",
      "Epoch 1101/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4386 - accuracy: 0.7847 - val_loss: 0.5312 - val_accuracy: 0.7500\n",
      "Epoch 1102/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4386 - accuracy: 0.7847 - val_loss: 0.5311 - val_accuracy: 0.7500\n",
      "Epoch 1103/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4386 - accuracy: 0.7847 - val_loss: 0.5311 - val_accuracy: 0.7500\n",
      "Epoch 1104/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4385 - accuracy: 0.7847 - val_loss: 0.5311 - val_accuracy: 0.7500\n",
      "Epoch 1105/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4384 - accuracy: 0.7847 - val_loss: 0.5311 - val_accuracy: 0.7500\n",
      "Epoch 1106/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4384 - accuracy: 0.7847 - val_loss: 0.5310 - val_accuracy: 0.7500\n",
      "Epoch 1107/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4384 - accuracy: 0.7830 - val_loss: 0.5310 - val_accuracy: 0.7500\n",
      "Epoch 1108/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4383 - accuracy: 0.7830 - val_loss: 0.5309 - val_accuracy: 0.7448\n",
      "Epoch 1109/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4383 - accuracy: 0.7830 - val_loss: 0.5309 - val_accuracy: 0.7448\n",
      "Epoch 1110/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4382 - accuracy: 0.7830 - val_loss: 0.5309 - val_accuracy: 0.7448\n",
      "Epoch 1111/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4382 - accuracy: 0.7830 - val_loss: 0.5308 - val_accuracy: 0.7448\n",
      "Epoch 1112/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4382 - accuracy: 0.7830 - val_loss: 0.5308 - val_accuracy: 0.7500\n",
      "Epoch 1113/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4382 - accuracy: 0.7830 - val_loss: 0.5307 - val_accuracy: 0.7500\n",
      "Epoch 1114/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4381 - accuracy: 0.7847 - val_loss: 0.5307 - val_accuracy: 0.7500\n",
      "Epoch 1115/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4380 - accuracy: 0.7847 - val_loss: 0.5306 - val_accuracy: 0.7500\n",
      "Epoch 1116/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4380 - accuracy: 0.7830 - val_loss: 0.5306 - val_accuracy: 0.7500\n",
      "Epoch 1117/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4379 - accuracy: 0.7847 - val_loss: 0.5306 - val_accuracy: 0.7500\n",
      "Epoch 1118/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4379 - accuracy: 0.7830 - val_loss: 0.5306 - val_accuracy: 0.7500\n",
      "Epoch 1119/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4379 - accuracy: 0.7830 - val_loss: 0.5306 - val_accuracy: 0.7500\n",
      "Epoch 1120/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4378 - accuracy: 0.7830 - val_loss: 0.5305 - val_accuracy: 0.7500\n",
      "Epoch 1121/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4377 - accuracy: 0.7830 - val_loss: 0.5305 - val_accuracy: 0.7500\n",
      "Epoch 1122/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4377 - accuracy: 0.7830 - val_loss: 0.5304 - val_accuracy: 0.7500\n",
      "Epoch 1123/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4377 - accuracy: 0.7812 - val_loss: 0.5304 - val_accuracy: 0.7500\n",
      "Epoch 1124/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4376 - accuracy: 0.7812 - val_loss: 0.5304 - val_accuracy: 0.7500\n",
      "Epoch 1125/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4376 - accuracy: 0.7830 - val_loss: 0.5303 - val_accuracy: 0.7500\n",
      "Epoch 1126/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4375 - accuracy: 0.7812 - val_loss: 0.5303 - val_accuracy: 0.7500\n",
      "Epoch 1127/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4375 - accuracy: 0.7847 - val_loss: 0.5302 - val_accuracy: 0.7500\n",
      "Epoch 1128/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4375 - accuracy: 0.7847 - val_loss: 0.5302 - val_accuracy: 0.7500\n",
      "Epoch 1129/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4374 - accuracy: 0.7847 - val_loss: 0.5302 - val_accuracy: 0.7448\n",
      "Epoch 1130/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4374 - accuracy: 0.7830 - val_loss: 0.5302 - val_accuracy: 0.7448\n",
      "Epoch 1131/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4374 - accuracy: 0.7830 - val_loss: 0.5301 - val_accuracy: 0.7448\n",
      "Epoch 1132/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4373 - accuracy: 0.7847 - val_loss: 0.5301 - val_accuracy: 0.7448\n",
      "Epoch 1133/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4373 - accuracy: 0.7830 - val_loss: 0.5301 - val_accuracy: 0.7448\n",
      "Epoch 1134/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4372 - accuracy: 0.7847 - val_loss: 0.5300 - val_accuracy: 0.7500\n",
      "Epoch 1135/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4373 - accuracy: 0.7847 - val_loss: 0.5300 - val_accuracy: 0.7500\n",
      "Epoch 1136/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4372 - accuracy: 0.7847 - val_loss: 0.5300 - val_accuracy: 0.7500\n",
      "Epoch 1137/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4372 - accuracy: 0.7847 - val_loss: 0.5299 - val_accuracy: 0.7500\n",
      "Epoch 1138/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4371 - accuracy: 0.7847 - val_loss: 0.5299 - val_accuracy: 0.7500\n",
      "Epoch 1139/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4371 - accuracy: 0.7847 - val_loss: 0.5298 - val_accuracy: 0.7500\n",
      "Epoch 1140/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4371 - accuracy: 0.7847 - val_loss: 0.5298 - val_accuracy: 0.7500\n",
      "Epoch 1141/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4370 - accuracy: 0.7830 - val_loss: 0.5298 - val_accuracy: 0.7500\n",
      "Epoch 1142/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4370 - accuracy: 0.7830 - val_loss: 0.5298 - val_accuracy: 0.7500\n",
      "Epoch 1143/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4370 - accuracy: 0.7865 - val_loss: 0.5298 - val_accuracy: 0.7500\n",
      "Epoch 1144/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4370 - accuracy: 0.7865 - val_loss: 0.5297 - val_accuracy: 0.7500\n",
      "Epoch 1145/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4369 - accuracy: 0.7865 - val_loss: 0.5297 - val_accuracy: 0.7500\n",
      "Epoch 1146/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4370 - accuracy: 0.7830 - val_loss: 0.5297 - val_accuracy: 0.7500\n",
      "Epoch 1147/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4369 - accuracy: 0.7865 - val_loss: 0.5297 - val_accuracy: 0.7552\n",
      "Epoch 1148/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4368 - accuracy: 0.7865 - val_loss: 0.5296 - val_accuracy: 0.7552\n",
      "Epoch 1149/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4368 - accuracy: 0.7847 - val_loss: 0.5296 - val_accuracy: 0.7552\n",
      "Epoch 1150/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4368 - accuracy: 0.7865 - val_loss: 0.5296 - val_accuracy: 0.7552\n",
      "Epoch 1151/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4367 - accuracy: 0.7865 - val_loss: 0.5296 - val_accuracy: 0.7552\n",
      "Epoch 1152/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4367 - accuracy: 0.7865 - val_loss: 0.5296 - val_accuracy: 0.7552\n",
      "Epoch 1153/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4367 - accuracy: 0.7847 - val_loss: 0.5295 - val_accuracy: 0.7500\n",
      "Epoch 1154/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4366 - accuracy: 0.7865 - val_loss: 0.5295 - val_accuracy: 0.7500\n",
      "Epoch 1155/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4366 - accuracy: 0.7865 - val_loss: 0.5295 - val_accuracy: 0.7500\n",
      "Epoch 1156/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4366 - accuracy: 0.7865 - val_loss: 0.5295 - val_accuracy: 0.7500\n",
      "Epoch 1157/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4365 - accuracy: 0.7865 - val_loss: 0.5294 - val_accuracy: 0.7500\n",
      "Epoch 1158/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4365 - accuracy: 0.7865 - val_loss: 0.5294 - val_accuracy: 0.7500\n",
      "Epoch 1159/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4365 - accuracy: 0.7865 - val_loss: 0.5294 - val_accuracy: 0.7500\n",
      "Epoch 1160/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4364 - accuracy: 0.7865 - val_loss: 0.5293 - val_accuracy: 0.7500\n",
      "Epoch 1161/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4365 - accuracy: 0.7865 - val_loss: 0.5293 - val_accuracy: 0.7500\n",
      "Epoch 1162/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4363 - accuracy: 0.7865 - val_loss: 0.5293 - val_accuracy: 0.7500\n",
      "Epoch 1163/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4364 - accuracy: 0.7865 - val_loss: 0.5293 - val_accuracy: 0.7500\n",
      "Epoch 1164/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4363 - accuracy: 0.7865 - val_loss: 0.5293 - val_accuracy: 0.7500\n",
      "Epoch 1165/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4362 - accuracy: 0.7865 - val_loss: 0.5293 - val_accuracy: 0.7500\n",
      "Epoch 1166/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4363 - accuracy: 0.7865 - val_loss: 0.5292 - val_accuracy: 0.7552\n",
      "Epoch 1167/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4362 - accuracy: 0.7865 - val_loss: 0.5292 - val_accuracy: 0.7552\n",
      "Epoch 1168/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4361 - accuracy: 0.7865 - val_loss: 0.5292 - val_accuracy: 0.7552\n",
      "Epoch 1169/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4361 - accuracy: 0.7865 - val_loss: 0.5292 - val_accuracy: 0.7552\n",
      "Epoch 1170/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4361 - accuracy: 0.7865 - val_loss: 0.5292 - val_accuracy: 0.7552\n",
      "Epoch 1171/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4360 - accuracy: 0.7847 - val_loss: 0.5292 - val_accuracy: 0.7552\n",
      "Epoch 1172/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4361 - accuracy: 0.7847 - val_loss: 0.5291 - val_accuracy: 0.7552\n",
      "Epoch 1173/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4360 - accuracy: 0.7847 - val_loss: 0.5291 - val_accuracy: 0.7552\n",
      "Epoch 1174/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4360 - accuracy: 0.7865 - val_loss: 0.5291 - val_accuracy: 0.7552\n",
      "Epoch 1175/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4360 - accuracy: 0.7847 - val_loss: 0.5291 - val_accuracy: 0.7552\n",
      "Epoch 1176/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4359 - accuracy: 0.7847 - val_loss: 0.5291 - val_accuracy: 0.7552\n",
      "Epoch 1177/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4359 - accuracy: 0.7847 - val_loss: 0.5291 - val_accuracy: 0.7552\n",
      "Epoch 1178/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4358 - accuracy: 0.7847 - val_loss: 0.5290 - val_accuracy: 0.7552\n",
      "Epoch 1179/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4358 - accuracy: 0.7865 - val_loss: 0.5290 - val_accuracy: 0.7552\n",
      "Epoch 1180/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4358 - accuracy: 0.7830 - val_loss: 0.5290 - val_accuracy: 0.7552\n",
      "Epoch 1181/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4357 - accuracy: 0.7865 - val_loss: 0.5290 - val_accuracy: 0.7552\n",
      "Epoch 1182/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4357 - accuracy: 0.7865 - val_loss: 0.5290 - val_accuracy: 0.7552\n",
      "Epoch 1183/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4357 - accuracy: 0.7847 - val_loss: 0.5289 - val_accuracy: 0.7552\n",
      "Epoch 1184/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4356 - accuracy: 0.7865 - val_loss: 0.5289 - val_accuracy: 0.7552\n",
      "Epoch 1185/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4356 - accuracy: 0.7865 - val_loss: 0.5289 - val_accuracy: 0.7552\n",
      "Epoch 1186/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4356 - accuracy: 0.7865 - val_loss: 0.5289 - val_accuracy: 0.7552\n",
      "Epoch 1187/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4356 - accuracy: 0.7865 - val_loss: 0.5288 - val_accuracy: 0.7552\n",
      "Epoch 1188/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4355 - accuracy: 0.7865 - val_loss: 0.5289 - val_accuracy: 0.7552\n",
      "Epoch 1189/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4355 - accuracy: 0.7865 - val_loss: 0.5289 - val_accuracy: 0.7552\n",
      "Epoch 1190/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4355 - accuracy: 0.7865 - val_loss: 0.5289 - val_accuracy: 0.7552\n",
      "Epoch 1191/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4354 - accuracy: 0.7847 - val_loss: 0.5289 - val_accuracy: 0.7552\n",
      "Epoch 1192/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4354 - accuracy: 0.7865 - val_loss: 0.5288 - val_accuracy: 0.7552\n",
      "Epoch 1193/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4354 - accuracy: 0.7847 - val_loss: 0.5288 - val_accuracy: 0.7552\n",
      "Epoch 1194/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4354 - accuracy: 0.7847 - val_loss: 0.5288 - val_accuracy: 0.7552\n",
      "Epoch 1195/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4353 - accuracy: 0.7847 - val_loss: 0.5288 - val_accuracy: 0.7552\n",
      "Epoch 1196/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4353 - accuracy: 0.7847 - val_loss: 0.5288 - val_accuracy: 0.7552\n",
      "Epoch 1197/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4353 - accuracy: 0.7830 - val_loss: 0.5288 - val_accuracy: 0.7552\n",
      "Epoch 1198/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4353 - accuracy: 0.7812 - val_loss: 0.5288 - val_accuracy: 0.7500\n",
      "Epoch 1199/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4352 - accuracy: 0.7830 - val_loss: 0.5288 - val_accuracy: 0.7500\n",
      "Epoch 1200/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4352 - accuracy: 0.7830 - val_loss: 0.5287 - val_accuracy: 0.7500\n",
      "Epoch 1201/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4352 - accuracy: 0.7847 - val_loss: 0.5287 - val_accuracy: 0.7500\n",
      "Epoch 1202/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4351 - accuracy: 0.7830 - val_loss: 0.5287 - val_accuracy: 0.7500\n",
      "Epoch 1203/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4351 - accuracy: 0.7847 - val_loss: 0.5287 - val_accuracy: 0.7500\n",
      "Epoch 1204/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4351 - accuracy: 0.7847 - val_loss: 0.5286 - val_accuracy: 0.7500\n",
      "Epoch 1205/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4350 - accuracy: 0.7830 - val_loss: 0.5286 - val_accuracy: 0.7500\n",
      "Epoch 1206/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4350 - accuracy: 0.7830 - val_loss: 0.5286 - val_accuracy: 0.7500\n",
      "Epoch 1207/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4350 - accuracy: 0.7830 - val_loss: 0.5286 - val_accuracy: 0.7500\n",
      "Epoch 1208/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4349 - accuracy: 0.7812 - val_loss: 0.5286 - val_accuracy: 0.7500\n",
      "Epoch 1209/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4349 - accuracy: 0.7830 - val_loss: 0.5286 - val_accuracy: 0.7500\n",
      "Epoch 1210/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4349 - accuracy: 0.7830 - val_loss: 0.5286 - val_accuracy: 0.7500\n",
      "Epoch 1211/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4348 - accuracy: 0.7830 - val_loss: 0.5286 - val_accuracy: 0.7500\n",
      "Epoch 1212/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4348 - accuracy: 0.7812 - val_loss: 0.5285 - val_accuracy: 0.7500\n",
      "Epoch 1213/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4348 - accuracy: 0.7830 - val_loss: 0.5285 - val_accuracy: 0.7500\n",
      "Epoch 1214/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4348 - accuracy: 0.7847 - val_loss: 0.5285 - val_accuracy: 0.7500\n",
      "Epoch 1215/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4347 - accuracy: 0.7830 - val_loss: 0.5285 - val_accuracy: 0.7500\n",
      "Epoch 1216/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4347 - accuracy: 0.7812 - val_loss: 0.5285 - val_accuracy: 0.7500\n",
      "Epoch 1217/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4347 - accuracy: 0.7830 - val_loss: 0.5285 - val_accuracy: 0.7500\n",
      "Epoch 1218/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4347 - accuracy: 0.7830 - val_loss: 0.5285 - val_accuracy: 0.7500\n",
      "Epoch 1219/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4347 - accuracy: 0.7830 - val_loss: 0.5284 - val_accuracy: 0.7500\n",
      "Epoch 1220/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4346 - accuracy: 0.7830 - val_loss: 0.5284 - val_accuracy: 0.7500\n",
      "Epoch 1221/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4346 - accuracy: 0.7865 - val_loss: 0.5284 - val_accuracy: 0.7552\n",
      "Epoch 1222/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4346 - accuracy: 0.7812 - val_loss: 0.5284 - val_accuracy: 0.7552\n",
      "Epoch 1223/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4346 - accuracy: 0.7830 - val_loss: 0.5284 - val_accuracy: 0.7552\n",
      "Epoch 1224/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4346 - accuracy: 0.7847 - val_loss: 0.5284 - val_accuracy: 0.7552\n",
      "Epoch 1225/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4345 - accuracy: 0.7847 - val_loss: 0.5284 - val_accuracy: 0.7552\n",
      "Epoch 1226/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4345 - accuracy: 0.7830 - val_loss: 0.5284 - val_accuracy: 0.7552\n",
      "Epoch 1227/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4345 - accuracy: 0.7847 - val_loss: 0.5284 - val_accuracy: 0.7552\n",
      "Epoch 1228/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4344 - accuracy: 0.7847 - val_loss: 0.5284 - val_accuracy: 0.7552\n",
      "Epoch 1229/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4344 - accuracy: 0.7830 - val_loss: 0.5283 - val_accuracy: 0.7552\n",
      "Epoch 1230/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4344 - accuracy: 0.7865 - val_loss: 0.5283 - val_accuracy: 0.7552\n",
      "Epoch 1231/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4343 - accuracy: 0.7847 - val_loss: 0.5283 - val_accuracy: 0.7552\n",
      "Epoch 1232/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4343 - accuracy: 0.7847 - val_loss: 0.5283 - val_accuracy: 0.7552\n",
      "Epoch 1233/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4343 - accuracy: 0.7847 - val_loss: 0.5283 - val_accuracy: 0.7552\n",
      "Epoch 1234/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4343 - accuracy: 0.7847 - val_loss: 0.5283 - val_accuracy: 0.7552\n",
      "Epoch 1235/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4342 - accuracy: 0.7847 - val_loss: 0.5283 - val_accuracy: 0.7552\n",
      "Epoch 1236/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4343 - accuracy: 0.7847 - val_loss: 0.5283 - val_accuracy: 0.7552\n",
      "Epoch 1237/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4342 - accuracy: 0.7847 - val_loss: 0.5283 - val_accuracy: 0.7552\n",
      "Epoch 1238/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4342 - accuracy: 0.7847 - val_loss: 0.5283 - val_accuracy: 0.7552\n",
      "Epoch 1239/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4342 - accuracy: 0.7830 - val_loss: 0.5283 - val_accuracy: 0.7552\n",
      "Epoch 1240/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4341 - accuracy: 0.7847 - val_loss: 0.5283 - val_accuracy: 0.7552\n",
      "Epoch 1241/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4340 - accuracy: 0.7847 - val_loss: 0.5283 - val_accuracy: 0.7552\n",
      "Epoch 1242/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4340 - accuracy: 0.7847 - val_loss: 0.5283 - val_accuracy: 0.7552\n",
      "Epoch 1243/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4341 - accuracy: 0.7847 - val_loss: 0.5283 - val_accuracy: 0.7552\n",
      "Epoch 1244/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4340 - accuracy: 0.7847 - val_loss: 0.5283 - val_accuracy: 0.7552\n",
      "Epoch 1245/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4340 - accuracy: 0.7847 - val_loss: 0.5282 - val_accuracy: 0.7552\n",
      "Epoch 1246/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4339 - accuracy: 0.7830 - val_loss: 0.5282 - val_accuracy: 0.7552\n",
      "Epoch 1247/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4339 - accuracy: 0.7830 - val_loss: 0.5282 - val_accuracy: 0.7552\n",
      "Epoch 1248/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4339 - accuracy: 0.7847 - val_loss: 0.5282 - val_accuracy: 0.7552\n",
      "Epoch 1249/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4339 - accuracy: 0.7847 - val_loss: 0.5282 - val_accuracy: 0.7552\n",
      "Epoch 1250/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4338 - accuracy: 0.7847 - val_loss: 0.5282 - val_accuracy: 0.7552\n",
      "Epoch 1251/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4338 - accuracy: 0.7847 - val_loss: 0.5282 - val_accuracy: 0.7552\n",
      "Epoch 1252/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4338 - accuracy: 0.7847 - val_loss: 0.5282 - val_accuracy: 0.7552\n",
      "Epoch 1253/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4337 - accuracy: 0.7847 - val_loss: 0.5282 - val_accuracy: 0.7552\n",
      "Epoch 1254/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4337 - accuracy: 0.7847 - val_loss: 0.5282 - val_accuracy: 0.7552\n",
      "Epoch 1255/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4337 - accuracy: 0.7865 - val_loss: 0.5282 - val_accuracy: 0.7552\n",
      "Epoch 1256/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4336 - accuracy: 0.7847 - val_loss: 0.5282 - val_accuracy: 0.7552\n",
      "Epoch 1257/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4336 - accuracy: 0.7847 - val_loss: 0.5282 - val_accuracy: 0.7552\n",
      "Epoch 1258/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4336 - accuracy: 0.7847 - val_loss: 0.5281 - val_accuracy: 0.7552\n",
      "Epoch 1259/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4335 - accuracy: 0.7865 - val_loss: 0.5281 - val_accuracy: 0.7552\n",
      "Epoch 1260/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4336 - accuracy: 0.7847 - val_loss: 0.5281 - val_accuracy: 0.7552\n",
      "Epoch 1261/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4335 - accuracy: 0.7847 - val_loss: 0.5281 - val_accuracy: 0.7552\n",
      "Epoch 1262/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4335 - accuracy: 0.7865 - val_loss: 0.5281 - val_accuracy: 0.7552\n",
      "Epoch 1263/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4334 - accuracy: 0.7865 - val_loss: 0.5281 - val_accuracy: 0.7552\n",
      "Epoch 1264/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4334 - accuracy: 0.7865 - val_loss: 0.5281 - val_accuracy: 0.7552\n",
      "Epoch 1265/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4334 - accuracy: 0.7865 - val_loss: 0.5281 - val_accuracy: 0.7552\n",
      "Epoch 1266/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4333 - accuracy: 0.7865 - val_loss: 0.5280 - val_accuracy: 0.7552\n",
      "Epoch 1267/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4333 - accuracy: 0.7865 - val_loss: 0.5280 - val_accuracy: 0.7552\n",
      "Epoch 1268/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4333 - accuracy: 0.7882 - val_loss: 0.5280 - val_accuracy: 0.7552\n",
      "Epoch 1269/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4332 - accuracy: 0.7882 - val_loss: 0.5280 - val_accuracy: 0.7552\n",
      "Epoch 1270/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4332 - accuracy: 0.7865 - val_loss: 0.5280 - val_accuracy: 0.7552\n",
      "Epoch 1271/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4331 - accuracy: 0.7882 - val_loss: 0.5280 - val_accuracy: 0.7552\n",
      "Epoch 1272/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4331 - accuracy: 0.7882 - val_loss: 0.5280 - val_accuracy: 0.7552\n",
      "Epoch 1273/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4331 - accuracy: 0.7882 - val_loss: 0.5280 - val_accuracy: 0.7552\n",
      "Epoch 1274/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4331 - accuracy: 0.7882 - val_loss: 0.5279 - val_accuracy: 0.7552\n",
      "Epoch 1275/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4330 - accuracy: 0.7882 - val_loss: 0.5279 - val_accuracy: 0.7552\n",
      "Epoch 1276/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4330 - accuracy: 0.7882 - val_loss: 0.5279 - val_accuracy: 0.7552\n",
      "Epoch 1277/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4329 - accuracy: 0.7882 - val_loss: 0.5279 - val_accuracy: 0.7552\n",
      "Epoch 1278/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4329 - accuracy: 0.7882 - val_loss: 0.5279 - val_accuracy: 0.7552\n",
      "Epoch 1279/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4329 - accuracy: 0.7882 - val_loss: 0.5279 - val_accuracy: 0.7552\n",
      "Epoch 1280/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4328 - accuracy: 0.7865 - val_loss: 0.5278 - val_accuracy: 0.7500\n",
      "Epoch 1281/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4328 - accuracy: 0.7882 - val_loss: 0.5278 - val_accuracy: 0.7500\n",
      "Epoch 1282/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4328 - accuracy: 0.7865 - val_loss: 0.5278 - val_accuracy: 0.7500\n",
      "Epoch 1283/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4327 - accuracy: 0.7882 - val_loss: 0.5277 - val_accuracy: 0.7500\n",
      "Epoch 1284/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4326 - accuracy: 0.7882 - val_loss: 0.5277 - val_accuracy: 0.7500\n",
      "Epoch 1285/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4326 - accuracy: 0.7882 - val_loss: 0.5277 - val_accuracy: 0.7500\n",
      "Epoch 1286/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4326 - accuracy: 0.7882 - val_loss: 0.5277 - val_accuracy: 0.7500\n",
      "Epoch 1287/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4326 - accuracy: 0.7882 - val_loss: 0.5277 - val_accuracy: 0.7500\n",
      "Epoch 1288/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4325 - accuracy: 0.7882 - val_loss: 0.5277 - val_accuracy: 0.7500\n",
      "Epoch 1289/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4325 - accuracy: 0.7882 - val_loss: 0.5277 - val_accuracy: 0.7500\n",
      "Epoch 1290/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4325 - accuracy: 0.7865 - val_loss: 0.5277 - val_accuracy: 0.7500\n",
      "Epoch 1291/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4324 - accuracy: 0.7865 - val_loss: 0.5277 - val_accuracy: 0.7500\n",
      "Epoch 1292/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4324 - accuracy: 0.7899 - val_loss: 0.5277 - val_accuracy: 0.7500\n",
      "Epoch 1293/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4323 - accuracy: 0.7865 - val_loss: 0.5277 - val_accuracy: 0.7448\n",
      "Epoch 1294/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4323 - accuracy: 0.7882 - val_loss: 0.5276 - val_accuracy: 0.7448\n",
      "Epoch 1295/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4323 - accuracy: 0.7882 - val_loss: 0.5276 - val_accuracy: 0.7448\n",
      "Epoch 1296/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4322 - accuracy: 0.7899 - val_loss: 0.5276 - val_accuracy: 0.7448\n",
      "Epoch 1297/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4322 - accuracy: 0.7899 - val_loss: 0.5276 - val_accuracy: 0.7448\n",
      "Epoch 1298/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4322 - accuracy: 0.7882 - val_loss: 0.5276 - val_accuracy: 0.7448\n",
      "Epoch 1299/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4322 - accuracy: 0.7882 - val_loss: 0.5275 - val_accuracy: 0.7448\n",
      "Epoch 1300/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4322 - accuracy: 0.7882 - val_loss: 0.5275 - val_accuracy: 0.7448\n",
      "Epoch 1301/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4321 - accuracy: 0.7882 - val_loss: 0.5275 - val_accuracy: 0.7448\n",
      "Epoch 1302/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4321 - accuracy: 0.7899 - val_loss: 0.5275 - val_accuracy: 0.7448\n",
      "Epoch 1303/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4321 - accuracy: 0.7882 - val_loss: 0.5275 - val_accuracy: 0.7448\n",
      "Epoch 1304/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4320 - accuracy: 0.7882 - val_loss: 0.5275 - val_accuracy: 0.7448\n",
      "Epoch 1305/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4320 - accuracy: 0.7865 - val_loss: 0.5275 - val_accuracy: 0.7448\n",
      "Epoch 1306/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4320 - accuracy: 0.7899 - val_loss: 0.5275 - val_accuracy: 0.7448\n",
      "Epoch 1307/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4319 - accuracy: 0.7882 - val_loss: 0.5275 - val_accuracy: 0.7448\n",
      "Epoch 1308/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4319 - accuracy: 0.7882 - val_loss: 0.5275 - val_accuracy: 0.7448\n",
      "Epoch 1309/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4318 - accuracy: 0.7865 - val_loss: 0.5274 - val_accuracy: 0.7448\n",
      "Epoch 1310/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4318 - accuracy: 0.7882 - val_loss: 0.5274 - val_accuracy: 0.7448\n",
      "Epoch 1311/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4317 - accuracy: 0.7882 - val_loss: 0.5274 - val_accuracy: 0.7448\n",
      "Epoch 1312/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4317 - accuracy: 0.7899 - val_loss: 0.5274 - val_accuracy: 0.7448\n",
      "Epoch 1313/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4317 - accuracy: 0.7882 - val_loss: 0.5274 - val_accuracy: 0.7448\n",
      "Epoch 1314/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4317 - accuracy: 0.7899 - val_loss: 0.5274 - val_accuracy: 0.7500\n",
      "Epoch 1315/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4316 - accuracy: 0.7865 - val_loss: 0.5274 - val_accuracy: 0.7500\n",
      "Epoch 1316/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4316 - accuracy: 0.7882 - val_loss: 0.5273 - val_accuracy: 0.7500\n",
      "Epoch 1317/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4316 - accuracy: 0.7865 - val_loss: 0.5273 - val_accuracy: 0.7500\n",
      "Epoch 1318/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4315 - accuracy: 0.7882 - val_loss: 0.5273 - val_accuracy: 0.7500\n",
      "Epoch 1319/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4315 - accuracy: 0.7899 - val_loss: 0.5273 - val_accuracy: 0.7500\n",
      "Epoch 1320/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4315 - accuracy: 0.7899 - val_loss: 0.5273 - val_accuracy: 0.7500\n",
      "Epoch 1321/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4314 - accuracy: 0.7899 - val_loss: 0.5273 - val_accuracy: 0.7500\n",
      "Epoch 1322/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4314 - accuracy: 0.7882 - val_loss: 0.5273 - val_accuracy: 0.7500\n",
      "Epoch 1323/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4314 - accuracy: 0.7882 - val_loss: 0.5273 - val_accuracy: 0.7500\n",
      "Epoch 1324/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4313 - accuracy: 0.7882 - val_loss: 0.5273 - val_accuracy: 0.7500\n",
      "Epoch 1325/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4313 - accuracy: 0.7882 - val_loss: 0.5272 - val_accuracy: 0.7500\n",
      "Epoch 1326/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4312 - accuracy: 0.7865 - val_loss: 0.5272 - val_accuracy: 0.7500\n",
      "Epoch 1327/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4313 - accuracy: 0.7865 - val_loss: 0.5272 - val_accuracy: 0.7500\n",
      "Epoch 1328/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4312 - accuracy: 0.7865 - val_loss: 0.5272 - val_accuracy: 0.7500\n",
      "Epoch 1329/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4312 - accuracy: 0.7865 - val_loss: 0.5272 - val_accuracy: 0.7500\n",
      "Epoch 1330/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4311 - accuracy: 0.7865 - val_loss: 0.5272 - val_accuracy: 0.7500\n",
      "Epoch 1331/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4311 - accuracy: 0.7865 - val_loss: 0.5272 - val_accuracy: 0.7500\n",
      "Epoch 1332/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4311 - accuracy: 0.7865 - val_loss: 0.5272 - val_accuracy: 0.7500\n",
      "Epoch 1333/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4311 - accuracy: 0.7865 - val_loss: 0.5271 - val_accuracy: 0.7500\n",
      "Epoch 1334/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4310 - accuracy: 0.7865 - val_loss: 0.5271 - val_accuracy: 0.7500\n",
      "Epoch 1335/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4309 - accuracy: 0.7865 - val_loss: 0.5271 - val_accuracy: 0.7500\n",
      "Epoch 1336/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4309 - accuracy: 0.7865 - val_loss: 0.5271 - val_accuracy: 0.7500\n",
      "Epoch 1337/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4309 - accuracy: 0.7865 - val_loss: 0.5271 - val_accuracy: 0.7500\n",
      "Epoch 1338/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4309 - accuracy: 0.7865 - val_loss: 0.5271 - val_accuracy: 0.7500\n",
      "Epoch 1339/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4308 - accuracy: 0.7865 - val_loss: 0.5271 - val_accuracy: 0.7500\n",
      "Epoch 1340/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4308 - accuracy: 0.7865 - val_loss: 0.5270 - val_accuracy: 0.7500\n",
      "Epoch 1341/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4308 - accuracy: 0.7865 - val_loss: 0.5270 - val_accuracy: 0.7500\n",
      "Epoch 1342/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4308 - accuracy: 0.7865 - val_loss: 0.5270 - val_accuracy: 0.7500\n",
      "Epoch 1343/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4308 - accuracy: 0.7865 - val_loss: 0.5270 - val_accuracy: 0.7500\n",
      "Epoch 1344/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4306 - accuracy: 0.7865 - val_loss: 0.5270 - val_accuracy: 0.7500\n",
      "Epoch 1345/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4306 - accuracy: 0.7865 - val_loss: 0.5270 - val_accuracy: 0.7500\n",
      "Epoch 1346/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4306 - accuracy: 0.7865 - val_loss: 0.5270 - val_accuracy: 0.7500\n",
      "Epoch 1347/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4306 - accuracy: 0.7865 - val_loss: 0.5270 - val_accuracy: 0.7500\n",
      "Epoch 1348/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4306 - accuracy: 0.7865 - val_loss: 0.5269 - val_accuracy: 0.7500\n",
      "Epoch 1349/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4306 - accuracy: 0.7865 - val_loss: 0.5269 - val_accuracy: 0.7500\n",
      "Epoch 1350/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4305 - accuracy: 0.7865 - val_loss: 0.5269 - val_accuracy: 0.7500\n",
      "Epoch 1351/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4305 - accuracy: 0.7882 - val_loss: 0.5269 - val_accuracy: 0.7500\n",
      "Epoch 1352/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4304 - accuracy: 0.7865 - val_loss: 0.5269 - val_accuracy: 0.7500\n",
      "Epoch 1353/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4304 - accuracy: 0.7865 - val_loss: 0.5269 - val_accuracy: 0.7500\n",
      "Epoch 1354/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4304 - accuracy: 0.7865 - val_loss: 0.5269 - val_accuracy: 0.7500\n",
      "Epoch 1355/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4304 - accuracy: 0.7865 - val_loss: 0.5269 - val_accuracy: 0.7552\n",
      "Epoch 1356/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4304 - accuracy: 0.7865 - val_loss: 0.5269 - val_accuracy: 0.7552\n",
      "Epoch 1357/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4303 - accuracy: 0.7882 - val_loss: 0.5269 - val_accuracy: 0.7552\n",
      "Epoch 1358/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4303 - accuracy: 0.7865 - val_loss: 0.5269 - val_accuracy: 0.7552\n",
      "Epoch 1359/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4303 - accuracy: 0.7882 - val_loss: 0.5269 - val_accuracy: 0.7552\n",
      "Epoch 1360/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4302 - accuracy: 0.7882 - val_loss: 0.5268 - val_accuracy: 0.7552\n",
      "Epoch 1361/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4302 - accuracy: 0.7882 - val_loss: 0.5268 - val_accuracy: 0.7552\n",
      "Epoch 1362/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4302 - accuracy: 0.7882 - val_loss: 0.5268 - val_accuracy: 0.7552\n",
      "Epoch 1363/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4301 - accuracy: 0.7882 - val_loss: 0.5268 - val_accuracy: 0.7552\n",
      "Epoch 1364/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4301 - accuracy: 0.7882 - val_loss: 0.5268 - val_accuracy: 0.7552\n",
      "Epoch 1365/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4301 - accuracy: 0.7882 - val_loss: 0.5268 - val_accuracy: 0.7552\n",
      "Epoch 1366/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4300 - accuracy: 0.7882 - val_loss: 0.5268 - val_accuracy: 0.7552\n",
      "Epoch 1367/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4300 - accuracy: 0.7882 - val_loss: 0.5268 - val_accuracy: 0.7552\n",
      "Epoch 1368/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4300 - accuracy: 0.7882 - val_loss: 0.5267 - val_accuracy: 0.7552\n",
      "Epoch 1369/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4299 - accuracy: 0.7882 - val_loss: 0.5267 - val_accuracy: 0.7552\n",
      "Epoch 1370/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4299 - accuracy: 0.7882 - val_loss: 0.5267 - val_accuracy: 0.7552\n",
      "Epoch 1371/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4299 - accuracy: 0.7882 - val_loss: 0.5267 - val_accuracy: 0.7552\n",
      "Epoch 1372/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4299 - accuracy: 0.7882 - val_loss: 0.5267 - val_accuracy: 0.7552\n",
      "Epoch 1373/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4299 - accuracy: 0.7882 - val_loss: 0.5267 - val_accuracy: 0.7552\n",
      "Epoch 1374/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4298 - accuracy: 0.7882 - val_loss: 0.5267 - val_accuracy: 0.7552\n",
      "Epoch 1375/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4298 - accuracy: 0.7882 - val_loss: 0.5267 - val_accuracy: 0.7552\n",
      "Epoch 1376/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4298 - accuracy: 0.7882 - val_loss: 0.5267 - val_accuracy: 0.7552\n",
      "Epoch 1377/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4298 - accuracy: 0.7882 - val_loss: 0.5267 - val_accuracy: 0.7552\n",
      "Epoch 1378/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4297 - accuracy: 0.7882 - val_loss: 0.5266 - val_accuracy: 0.7552\n",
      "Epoch 1379/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4297 - accuracy: 0.7882 - val_loss: 0.5267 - val_accuracy: 0.7552\n",
      "Epoch 1380/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4297 - accuracy: 0.7882 - val_loss: 0.5266 - val_accuracy: 0.7552\n",
      "Epoch 1381/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4296 - accuracy: 0.7882 - val_loss: 0.5266 - val_accuracy: 0.7552\n",
      "Epoch 1382/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4296 - accuracy: 0.7882 - val_loss: 0.5266 - val_accuracy: 0.7552\n",
      "Epoch 1383/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4296 - accuracy: 0.7882 - val_loss: 0.5266 - val_accuracy: 0.7552\n",
      "Epoch 1384/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4295 - accuracy: 0.7882 - val_loss: 0.5266 - val_accuracy: 0.7552\n",
      "Epoch 1385/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4296 - accuracy: 0.7882 - val_loss: 0.5266 - val_accuracy: 0.7552\n",
      "Epoch 1386/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4295 - accuracy: 0.7882 - val_loss: 0.5266 - val_accuracy: 0.7552\n",
      "Epoch 1387/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4295 - accuracy: 0.7882 - val_loss: 0.5266 - val_accuracy: 0.7552\n",
      "Epoch 1388/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4294 - accuracy: 0.7882 - val_loss: 0.5265 - val_accuracy: 0.7552\n",
      "Epoch 1389/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4294 - accuracy: 0.7882 - val_loss: 0.5265 - val_accuracy: 0.7552\n",
      "Epoch 1390/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4293 - accuracy: 0.7882 - val_loss: 0.5265 - val_accuracy: 0.7552\n",
      "Epoch 1391/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4293 - accuracy: 0.7882 - val_loss: 0.5265 - val_accuracy: 0.7552\n",
      "Epoch 1392/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4293 - accuracy: 0.7882 - val_loss: 0.5265 - val_accuracy: 0.7552\n",
      "Epoch 1393/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4293 - accuracy: 0.7882 - val_loss: 0.5265 - val_accuracy: 0.7552\n",
      "Epoch 1394/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4293 - accuracy: 0.7882 - val_loss: 0.5265 - val_accuracy: 0.7552\n",
      "Epoch 1395/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4292 - accuracy: 0.7882 - val_loss: 0.5266 - val_accuracy: 0.7552\n",
      "Epoch 1396/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4292 - accuracy: 0.7882 - val_loss: 0.5266 - val_accuracy: 0.7552\n",
      "Epoch 1397/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4291 - accuracy: 0.7882 - val_loss: 0.5266 - val_accuracy: 0.7552\n",
      "Epoch 1398/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4292 - accuracy: 0.7882 - val_loss: 0.5265 - val_accuracy: 0.7552\n",
      "Epoch 1399/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4291 - accuracy: 0.7882 - val_loss: 0.5265 - val_accuracy: 0.7552\n",
      "Epoch 1400/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4291 - accuracy: 0.7882 - val_loss: 0.5265 - val_accuracy: 0.7552\n",
      "Epoch 1401/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4291 - accuracy: 0.7882 - val_loss: 0.5265 - val_accuracy: 0.7552\n",
      "Epoch 1402/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4290 - accuracy: 0.7882 - val_loss: 0.5265 - val_accuracy: 0.7552\n",
      "Epoch 1403/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4291 - accuracy: 0.7882 - val_loss: 0.5265 - val_accuracy: 0.7552\n",
      "Epoch 1404/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4290 - accuracy: 0.7882 - val_loss: 0.5265 - val_accuracy: 0.7552\n",
      "Epoch 1405/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4290 - accuracy: 0.7882 - val_loss: 0.5265 - val_accuracy: 0.7552\n",
      "Epoch 1406/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4290 - accuracy: 0.7882 - val_loss: 0.5265 - val_accuracy: 0.7552\n",
      "Epoch 1407/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4289 - accuracy: 0.7882 - val_loss: 0.5265 - val_accuracy: 0.7552\n",
      "Epoch 1408/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4289 - accuracy: 0.7882 - val_loss: 0.5265 - val_accuracy: 0.7552\n",
      "Epoch 1409/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4289 - accuracy: 0.7882 - val_loss: 0.5265 - val_accuracy: 0.7552\n",
      "Epoch 1410/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4288 - accuracy: 0.7882 - val_loss: 0.5265 - val_accuracy: 0.7552\n",
      "Epoch 1411/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4288 - accuracy: 0.7882 - val_loss: 0.5265 - val_accuracy: 0.7552\n",
      "Epoch 1412/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4288 - accuracy: 0.7882 - val_loss: 0.5265 - val_accuracy: 0.7552\n",
      "Epoch 1413/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4287 - accuracy: 0.7882 - val_loss: 0.5265 - val_accuracy: 0.7552\n",
      "Epoch 1414/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4287 - accuracy: 0.7882 - val_loss: 0.5265 - val_accuracy: 0.7552\n",
      "Epoch 1415/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4287 - accuracy: 0.7882 - val_loss: 0.5265 - val_accuracy: 0.7552\n",
      "Epoch 1416/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4287 - accuracy: 0.7882 - val_loss: 0.5265 - val_accuracy: 0.7552\n",
      "Epoch 1417/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4286 - accuracy: 0.7882 - val_loss: 0.5265 - val_accuracy: 0.7552\n",
      "Epoch 1418/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4286 - accuracy: 0.7882 - val_loss: 0.5265 - val_accuracy: 0.7552\n",
      "Epoch 1419/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4286 - accuracy: 0.7882 - val_loss: 0.5265 - val_accuracy: 0.7552\n",
      "Epoch 1420/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4286 - accuracy: 0.7882 - val_loss: 0.5265 - val_accuracy: 0.7552\n",
      "Epoch 1421/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4286 - accuracy: 0.7882 - val_loss: 0.5265 - val_accuracy: 0.7552\n",
      "Epoch 1422/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4285 - accuracy: 0.7882 - val_loss: 0.5265 - val_accuracy: 0.7604\n",
      "Epoch 1423/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4285 - accuracy: 0.7882 - val_loss: 0.5265 - val_accuracy: 0.7604\n",
      "Epoch 1424/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4285 - accuracy: 0.7882 - val_loss: 0.5265 - val_accuracy: 0.7604\n",
      "Epoch 1425/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4284 - accuracy: 0.7882 - val_loss: 0.5264 - val_accuracy: 0.7604\n",
      "Epoch 1426/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4284 - accuracy: 0.7882 - val_loss: 0.5264 - val_accuracy: 0.7604\n",
      "Epoch 1427/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4284 - accuracy: 0.7882 - val_loss: 0.5264 - val_accuracy: 0.7604\n",
      "Epoch 1428/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4284 - accuracy: 0.7882 - val_loss: 0.5264 - val_accuracy: 0.7604\n",
      "Epoch 1429/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4283 - accuracy: 0.7882 - val_loss: 0.5264 - val_accuracy: 0.7604\n",
      "Epoch 1430/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4283 - accuracy: 0.7882 - val_loss: 0.5264 - val_accuracy: 0.7604\n",
      "Epoch 1431/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4283 - accuracy: 0.7882 - val_loss: 0.5264 - val_accuracy: 0.7604\n",
      "Epoch 1432/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4283 - accuracy: 0.7882 - val_loss: 0.5265 - val_accuracy: 0.7604\n",
      "Epoch 1433/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4282 - accuracy: 0.7899 - val_loss: 0.5264 - val_accuracy: 0.7604\n",
      "Epoch 1434/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4282 - accuracy: 0.7882 - val_loss: 0.5265 - val_accuracy: 0.7604\n",
      "Epoch 1435/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4282 - accuracy: 0.7882 - val_loss: 0.5265 - val_accuracy: 0.7604\n",
      "Epoch 1436/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4282 - accuracy: 0.7882 - val_loss: 0.5264 - val_accuracy: 0.7604\n",
      "Epoch 1437/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4281 - accuracy: 0.7882 - val_loss: 0.5265 - val_accuracy: 0.7604\n",
      "Epoch 1438/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4281 - accuracy: 0.7882 - val_loss: 0.5265 - val_accuracy: 0.7604\n",
      "Epoch 1439/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4280 - accuracy: 0.7899 - val_loss: 0.5265 - val_accuracy: 0.7604\n",
      "Epoch 1440/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4280 - accuracy: 0.7899 - val_loss: 0.5264 - val_accuracy: 0.7604\n",
      "Epoch 1441/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4280 - accuracy: 0.7882 - val_loss: 0.5264 - val_accuracy: 0.7604\n",
      "Epoch 1442/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4280 - accuracy: 0.7882 - val_loss: 0.5264 - val_accuracy: 0.7604\n",
      "Epoch 1443/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4279 - accuracy: 0.7899 - val_loss: 0.5264 - val_accuracy: 0.7604\n",
      "Epoch 1444/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4280 - accuracy: 0.7882 - val_loss: 0.5265 - val_accuracy: 0.7604\n",
      "Epoch 1445/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4279 - accuracy: 0.7899 - val_loss: 0.5265 - val_accuracy: 0.7604\n",
      "Epoch 1446/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4278 - accuracy: 0.7899 - val_loss: 0.5264 - val_accuracy: 0.7604\n",
      "Epoch 1447/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4278 - accuracy: 0.7882 - val_loss: 0.5265 - val_accuracy: 0.7604\n",
      "Epoch 1448/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4279 - accuracy: 0.7899 - val_loss: 0.5265 - val_accuracy: 0.7604\n",
      "Epoch 1449/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4278 - accuracy: 0.7899 - val_loss: 0.5265 - val_accuracy: 0.7604\n",
      "Epoch 1450/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4278 - accuracy: 0.7882 - val_loss: 0.5264 - val_accuracy: 0.7604\n",
      "Epoch 1451/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4278 - accuracy: 0.7899 - val_loss: 0.5264 - val_accuracy: 0.7604\n",
      "Epoch 1452/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4277 - accuracy: 0.7882 - val_loss: 0.5265 - val_accuracy: 0.7604\n",
      "Epoch 1453/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4277 - accuracy: 0.7899 - val_loss: 0.5265 - val_accuracy: 0.7604\n",
      "Epoch 1454/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4277 - accuracy: 0.7899 - val_loss: 0.5265 - val_accuracy: 0.7604\n",
      "Epoch 1455/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4276 - accuracy: 0.7899 - val_loss: 0.5264 - val_accuracy: 0.7604\n",
      "Epoch 1456/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4276 - accuracy: 0.7899 - val_loss: 0.5264 - val_accuracy: 0.7604\n",
      "Epoch 1457/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4276 - accuracy: 0.7899 - val_loss: 0.5264 - val_accuracy: 0.7604\n",
      "Epoch 1458/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4276 - accuracy: 0.7899 - val_loss: 0.5264 - val_accuracy: 0.7604\n",
      "Epoch 1459/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4276 - accuracy: 0.7899 - val_loss: 0.5264 - val_accuracy: 0.7604\n",
      "Epoch 1460/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4276 - accuracy: 0.7899 - val_loss: 0.5264 - val_accuracy: 0.7604\n",
      "Epoch 1461/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4276 - accuracy: 0.7899 - val_loss: 0.5264 - val_accuracy: 0.7604\n",
      "Epoch 1462/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4276 - accuracy: 0.7899 - val_loss: 0.5264 - val_accuracy: 0.7604\n",
      "Epoch 1463/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4275 - accuracy: 0.7882 - val_loss: 0.5264 - val_accuracy: 0.7604\n",
      "Epoch 1464/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4275 - accuracy: 0.7899 - val_loss: 0.5263 - val_accuracy: 0.7604\n",
      "Epoch 1465/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4274 - accuracy: 0.7899 - val_loss: 0.5264 - val_accuracy: 0.7604\n",
      "Epoch 1466/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4274 - accuracy: 0.7882 - val_loss: 0.5264 - val_accuracy: 0.7604\n",
      "Epoch 1467/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4274 - accuracy: 0.7882 - val_loss: 0.5264 - val_accuracy: 0.7604\n",
      "Epoch 1468/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4274 - accuracy: 0.7899 - val_loss: 0.5264 - val_accuracy: 0.7604\n",
      "Epoch 1469/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4273 - accuracy: 0.7899 - val_loss: 0.5264 - val_accuracy: 0.7604\n",
      "Epoch 1470/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4273 - accuracy: 0.7882 - val_loss: 0.5264 - val_accuracy: 0.7604\n",
      "Epoch 1471/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4273 - accuracy: 0.7882 - val_loss: 0.5264 - val_accuracy: 0.7604\n",
      "Epoch 1472/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4273 - accuracy: 0.7882 - val_loss: 0.5264 - val_accuracy: 0.7604\n",
      "Epoch 1473/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4273 - accuracy: 0.7899 - val_loss: 0.5264 - val_accuracy: 0.7604\n",
      "Epoch 1474/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4272 - accuracy: 0.7899 - val_loss: 0.5264 - val_accuracy: 0.7604\n",
      "Epoch 1475/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4272 - accuracy: 0.7882 - val_loss: 0.5263 - val_accuracy: 0.7604\n",
      "Epoch 1476/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4272 - accuracy: 0.7882 - val_loss: 0.5263 - val_accuracy: 0.7604\n",
      "Epoch 1477/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4271 - accuracy: 0.7899 - val_loss: 0.5263 - val_accuracy: 0.7604\n",
      "Epoch 1478/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4271 - accuracy: 0.7882 - val_loss: 0.5263 - val_accuracy: 0.7604\n",
      "Epoch 1479/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4271 - accuracy: 0.7882 - val_loss: 0.5263 - val_accuracy: 0.7604\n",
      "Epoch 1480/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4271 - accuracy: 0.7882 - val_loss: 0.5263 - val_accuracy: 0.7604\n",
      "Epoch 1481/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4270 - accuracy: 0.7882 - val_loss: 0.5263 - val_accuracy: 0.7604\n",
      "Epoch 1482/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4270 - accuracy: 0.7882 - val_loss: 0.5263 - val_accuracy: 0.7604\n",
      "Epoch 1483/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4270 - accuracy: 0.7882 - val_loss: 0.5263 - val_accuracy: 0.7604\n",
      "Epoch 1484/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4270 - accuracy: 0.7882 - val_loss: 0.5263 - val_accuracy: 0.7604\n",
      "Epoch 1485/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4269 - accuracy: 0.7882 - val_loss: 0.5264 - val_accuracy: 0.7604\n",
      "Epoch 1486/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4270 - accuracy: 0.7882 - val_loss: 0.5264 - val_accuracy: 0.7604\n",
      "Epoch 1487/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4269 - accuracy: 0.7865 - val_loss: 0.5264 - val_accuracy: 0.7604\n",
      "Epoch 1488/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4269 - accuracy: 0.7882 - val_loss: 0.5264 - val_accuracy: 0.7604\n",
      "Epoch 1489/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4269 - accuracy: 0.7865 - val_loss: 0.5264 - val_accuracy: 0.7604\n",
      "Epoch 1490/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4269 - accuracy: 0.7882 - val_loss: 0.5264 - val_accuracy: 0.7604\n",
      "Epoch 1491/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4269 - accuracy: 0.7882 - val_loss: 0.5264 - val_accuracy: 0.7604\n",
      "Epoch 1492/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4268 - accuracy: 0.7865 - val_loss: 0.5264 - val_accuracy: 0.7604\n",
      "Epoch 1493/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4268 - accuracy: 0.7882 - val_loss: 0.5264 - val_accuracy: 0.7604\n",
      "Epoch 1494/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4268 - accuracy: 0.7865 - val_loss: 0.5264 - val_accuracy: 0.7552\n",
      "Epoch 1495/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4268 - accuracy: 0.7865 - val_loss: 0.5264 - val_accuracy: 0.7552\n",
      "Epoch 1496/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4268 - accuracy: 0.7847 - val_loss: 0.5264 - val_accuracy: 0.7552\n",
      "Epoch 1497/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4268 - accuracy: 0.7865 - val_loss: 0.5264 - val_accuracy: 0.7552\n",
      "Epoch 1498/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4268 - accuracy: 0.7865 - val_loss: 0.5264 - val_accuracy: 0.7552\n",
      "Epoch 1499/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4267 - accuracy: 0.7865 - val_loss: 0.5264 - val_accuracy: 0.7552\n",
      "Epoch 1500/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4266 - accuracy: 0.7865 - val_loss: 0.5264 - val_accuracy: 0.7552\n"
     ]
    }
   ],
   "source": [
    "model_2.compile(SGD(lr=.003), \"binary_crossentropy\", \n",
    "                 metrics=[\"accuracy\"])\n",
    "run_hist_2=model_2.fit(X_train_norm, y_train, \n",
    "                       validation_data=(X_test_norm, y_test),\n",
    "                      epochs=1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_hist_2.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Accuracy over iterations')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAsIAAAF1CAYAAADiNYyJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdf5yUVd3/8ddnZ1l+KIisFCoKKmigCCpK4w8YwyTNzKT8BYFZrWaZ1q0g3lkmKYLdxW1ZsrepcUN6axhZafh1bQRjFPFXKviDFARNg0UUFdhf5/vHuWZ3dnZmd3bZ3Zlr9/18POYxM9d1zXWdWfTMZ858zueYcw4RERERke6mKN8NEBERERHJBwXCIiIiItItKRAWERERkW5JgbCIiIiIdEsKhEVERESkW1IgLCIiIiLdkgJh6fLM7EMzOziP1z/JzF7J1/VFRLoDM7vNzK7NcxteMrNYPtsgrWOqI9y9mNl64BvOuUfy3ZZ8MLO7gE3OuR904DUcMNw5t66jriEi4WRmcWA0MMg5tyvPzemygmB0kXNucAde4y46+PNEOp5GhKXLMLPirnANEemazGwocBLggDM7+dpdqu/q6PfT1f5ekp0CYQHAzHqa2Xwzezu4zTeznsG+fczsz2a2zcy2mtkKMysK9s00s7fMbLuZvWJmE7Ocfy8zW2hmm81sg5n9wMyKgutuM7MjUo4daGY7zOwTwfMzzOy54LiVZnZkyrHrgzb8A/goU+dlZs7MhplZGTAFmBGkS/wp2L+fmS0J2vaGmX035bXXmdnvzWyRmX0AXGhmx5lZImjPv8zsl2ZWEhy/PHjp88E1zjWzmJltSjnnCDOLB69/yczOTNl3l5ndamZ/Cf6mT5rZIcE+M7Ofm9m/zex9M/tH6t9NRAreNOAJ4C5geuoOMzvAzO4P+qFKM/tlyr5vmtnaoE9YY2ZHB9udmQ1LOe4uM/tJ8DhmZpuC/vEd4E4z2zvoyzeb2XvB48Eprx9gZncGnwHvmdnSYPuLZvaFlON6mNkWMxuT6U0G7V0XfF48YGb7BdtvM7Ofph37RzP7fvC4VX1xhuveZWY/MbM9gIeA/YJ++MPg3EVmdrWZ/TP4G99rZgOC1w4N/p5fN7M3gUeD7feZ2TtBn7vczA4Ptmf7PFlvZqcEj5v7XE3++/xH0Kf/y8y+lvJeTg/+rbeb/4y9MtPfWtqBc063bnQD1gOnZNh+Pb6D/gQwEFgJzA72zQFuA3oEt5MAAw4DNgL7BccNBQ7Jct2FwB+BvsFxrwJfD/bdAdyQcuy3gb8Gj48G/g2MAyL4D4/1QM+U9/MccADQO8u1HTAseHwX8JOUfUXA08APgRLgYOB1YFKw/zqgGjgrOLY3cAzwaaA4eC9rgSsyXS94HsP/fEbw91sHXBNc7zPAduCwlPZtBY4Lzr8YuCfYNyloa//g7z8C2Dff/03ppptuud2C//cvDfqQauCTwfYI8Dzwc2APoBdwYrDvK8BbwLHB//fDgCHBvvS+pr5/C/qdGmAu0DPou0qByUCfoC++D1ia8vq/AP8H7B30VROC7TOA/0s57ovAC1ne42eALUHf3RP4BbA82Dce/5mRTMvcG9gB7NeWvjjDtdPf/6a0/VfgP+cGB21bANwd7Bsa/D0XBv8GvYPtFwV/q57AfOC5TNdL2bae4DOW5j9Xk/8+1wd/69OBj4G9g/3/Ak5K+Tsdne//frvqLe8N0K2T/8GzB8L/BE5PeT4JWB88vh4fxA5Le80wfJB6CtCjmWtGgF3AyJRtFwPx4PEpwOsp+/4OTAse/zrZcaTsf4WGDno9cFEL77m5QHgc8Gba8bOAO4PH1xF04s2c/wrgD5muFzyv75DxXyLeAYpS9t8NXJfSvttT9p0OvBw8/gz+C8SnU1+vm266Ff4NOBEfyO0TPH8Z+F7wOApsBoozvG4ZcHmWc7YUCFcBvZpp0xjgveDxvkBdMhBLO24//Bf2fsHz3wMzspzzN8C8lOd7Bu97KD6QfxMYH+z7JvBo8Lg9+uL0958eCK8FJqY83zdoW3JQwwEHN3P+/sExe6VfL+WY9TQEws19rsbwXwKKU/b/G/h08PhN/Odkv3z/t9vVb0qNkKT9gA0pzzcE2wBuxo9kPGxmr5vZ1QDOTwa7At9B/dvM7kn+BJZmH/w3/PTz7x88fhTobWbjzGwIvnP+Q7BvCPAfQRrBNjPbhh/9Tb3Oxra84ZTz75d2/muAT2Y7v5kdGvyk+E7wE92NwXvMxX7ARudcXcq21L8F+EA56WP8BwnOuUeBXwK3Au+aWbmZ9cvxuiKSX9OBh51zW4Lnv6MhPeIAYINzribD6w7AB1Rtsdk5tzP5xMz6mNkC8+lpHwDLgf5mFgmus9U59176SZxzb+MHKCabWX/gNPyvVZk0+ixxzn0IVAL7Ox/h3QOcH+y+IOU8re6L22AI8IeU868FarNdw8wiZnZTkErxAT7Ihdb199k+VwEq0/7N6/t7/Mj96cAGM3vMzKI5XlNaSYGwJL2N7ySSDgy24Zzb7pz7D+fcwcAXgO9bkAvsnPudc+7E4LUO/zNcui34b93p538rOEcdcC++c7wA+LNzbntw3EZ82kT/lFsf59zdKedqTemT9GM3Am+knb+vc+70Zl7za/xoznDnXD98Z205Xv9t4AALcqwD9X+LFhvv3C3OuWOAw4FDgatyvK6I5ImZ9QbOASYEX6DfAb4HjDaz0fh+6EDLPEFrI3BIllN/jE9zSBqUtj+97/oPfErbuKDvGp9sYnCdAUGgm8lvgan4VI2Ecy5bn9XosyTI1y2loY+7G/hyMOgxDlgSbG9LX9ycTMduBE5Lu0avtPeS+roL8GkgpwB74UeNoaG/b6k9WT9XW2y8c085576IT6tYiv+MlA6gQLh76mFmvVJuxfjO6QfmJ6rtg8/TWgT1k9WGmZkBH+C/Qdea2WFm9pkg+X8n/mee2vSLOedq8f8T32BmfYMO8PvJ8wd+B5yLn3zwu5Tt/wNcEowWm5ntYWafN7O+bXzv7+Jzz5JWAR+Yn1DSOxgBOMLMjm3mHH3xf4cPzexTwLdauEaqJ4GP8BMsepgv8fMF/ChJs8zs2ODv0CM4x04y/L1FpOCchf9/dST+F68x+Bz/FfgJdKvwOaE3BX1cLzM7IXjt7cCVZnZM0AcOC/pQ8PMjLgj6rc8BE1poR198P70tmCT2o+QO59y/8BPMfmV+Ul0PMxuf8tql+Lzfy/F5tNn8DviamY0JPhtuBJ50zq0PrvMsPg3kdmCZc25b8Lq29MXNeRcoNbO9Urbdhv8cGgL1E7O/2Mw5+uLT+irxXzhuzHCN5mrUZ/1cbY6ZlZjZFDPbyzlXTcPnrnQABcLd04P4zjB5uw74CbAa+AfwAvBMsA1gOPAI8CGQAH7lnIvjJw/chB/xfQf/zfWaLNe8DB+8vQ48ju8s70judM4lA8T98J1xcvtqfB7ZL4H38CkaF7b1jePz10YGP40tDYL0L+A/mN4I3svt+G//2VyJHynYjg/U/y9t/3XAb4NrnJO6wzlXhS+bdFpwrV/h86FfzqHt/YLrvYf/ia0S+GmzrxCRQjAdn+v6pnPuneQN369NwY8wfgE/7+JNYBN+YADn3H3ADfg+czs+IB0QnPfy4HXbgvMsbaEd8/GT5rbgJ3H9NW3/V/G/3r2Mz1e9IrnDObcDP3p7EHB/tgs45yqAa4Nj/4UfzT4v7bC78aOsv0t5XVv64qyCPvVu4PWgL94P+G/gAXya33b832BcM6dZiO9r3wLWBMenavR5kuH1zX2utuSrwPogJeMS/Gi8dAAtqCEiIiItMrMfAoc65xSUSZehgtEiIiLSrCCV4uv4kUqRLkOpESIiIpKVmX0TP9HsIefc8paOFwkTpUaIiIiISLekEWERERER6ZYUCIuIiIhIt5TTZLmgPuF/45fKvd05d1Pa/r3xpbAOwdc2vcg592Jz59xnn33c0KFD29JmEZG8e/rpp7c45wbmux2dRX22iIRZtj67xUA4WHrxVuCz+NqGT5nZA865NSmHXQM855z7UrDAwK3AxObOO3ToUFavXt2a9yAiUjDMbEPLR3Ud6rNFJMyy9dm5pEYcB6xzzr0eLAZwD37JwVQjgQqoL2I91Mw+iYiIiIhIgcolEN4fXzYlaVOwLdXzwNkAZnYcfm3twe3RQBERERGRjpBLIGwZtqXXXLsJ2NvMnsMvpfssUNPkRGZlZrbazFZv3ry51Y0VEREREWkvuUyW2wQckPJ8MPB26gHOuQ+ArwGYmeHXCX8j/UTOuXKgHGDs2LEqYCzdSnV1NZs2bWLnzp35boq0Qq9evRg8eDA9evTId1NylsME572ARcCB+M+Bnzrn7uz0hoqI5FkugfBTwHAzOwh4CzgPuCD1ADPrD3wc5BB/A1geBMciEti0aRN9+/Zl6NCh+O+LUuicc1RWVrJp0yYOOuigfDcnJzlOcP42sMY59wUzGwi8YmaLgz5cRKTbaDE1wjlXA3wHWAasBe51zr1kZpeY2SXBYSOAl8zsZeA04PKOarBIWO3cuZPS0lIFwSFiZpSWloZtFD+XCc4O6Bv8grcnsJUM6WwiIl1dTnWEnXMPAg+mbbst5XECGN6+TRPpehQEh08I/80yTXAel3bML4EH8GlufYFznXN16ScyszKgDODAAw/skMaKiOSTVpYT6SYqKysZM2YMY8aMYdCgQey///71z6uqmv9FfPXq1Xz3u99t1fWGDh3Kli1bdqfJ0ja5THCeBDwH7AeMAX5pZv2avMi5cufcWOfc2IEDu83aISLSjeQ0Iiwi4VdaWspzzz0HwHXXXceee+7JlVdeWb+/pqaG4uLMXcLYsWMZO3Zsp7RTdluLE5zxk5tvcs45YJ2ZvQF8CljVOU0UESkMGhEWKWSJBMyZ4+87wIUXXsj3v/99Tj75ZGbOnMmqVas4/vjjOeqoozj++ON55ZVXAIjH45xxxhmAD6IvuugiYrEYBx98MLfcckvO19uwYQMTJ07kyCOPZOLEibz55psA3HfffRxxxBGMHj2a8ePHA/DSSy9x3HHHMWbMGI488khee+21dn73XVb9BGczK8FPcH4g7Zg3CVb/DBY/Ogx4vVNbKSJSAMI1IpxIQDwOsRhEo/lujUjHSiRg4kSoqoKSEqio6JD/7l999VUeeeQRIpEIH3zwAcuXL6e4uJhHHnmEa665hiVLljR5zcsvv8zf/vY3tm/fzmGHHca3vvWtnMqLfec732HatGlMnz6dO+64g+9+97ssXbqU66+/nmXLlrH//vuzbds2AG677TYuv/xypkyZQlVVFbW1te3+3rsi51yNmSUnOEeAO5ITnIP9twGzgbvM7AV8KsVM55zyWETEmzkTFi+GgQNh6FC/bf162LIFLrgA5s5tn+skEnD11fDMM7BzJ9TWgnNgBj16wIAB8OlPw4wZHRb3hScQ7qSgQKRgxOP+v/faWn8fj3fIf/Nf+cpXiEQiALz//vtMnz6d1157DTOjuro642s+//nP07NnT3r27MknPvEJ3n33XQYPbnkxyUQiwf333w/AV7/6VWbMmAHACSecwIUXXsg555zD2WefDUA0GuWGG25g06ZNnH322Qwfrvm4ucphgvPbwKmd3S4RCYGZM2HePP/4rbcgSKmrl9y3u8FwIgEnneQ/49I55z/33nkHli6Fv/wFHnusQz4Dw5MakSkoEOnKYjH/pS8S8fexWIdcZo899qh/fO2113LyySfz4osv8qc//Slr2bCePXvWP45EItTUtK3yVrIiw2233cZPfvITNm7cyJgxY6isrOSCCy7ggQceoHfv3kyaNIlHH320TdcQEZFmlJdDaakfhTVrCHSbs3ixv0+m740bB0VFDefI5Xb88ZmD4Eyqq33QPGFCu6cKhicQ7qSgQKRgRKP+l4/ZszvtF5D333+f/fffH4C77rqr3c9//PHHc8899wCwePFiTjzxRAD++c9/Mm7cOK6//nr22WcfNm7cyOuvv87BBx/Md7/7Xc4880z+8Y9/tHt7REQ6TXrAmXorKWk+yJs5E/r3h+Lipq874ADo2dMHon36+GOTkoFqeXnT+SbJ9lx8MWzd2rr38tZbDcHsNdfAqlV+FLcj1dbC8uX+mlOntttpw5MakQwKlCMs3Uk02qn/rc+YMYPp06fzs5/9jM985jO7fb4jjzySoiL/ffucc87hlltu4aKLLuLmm29m4MCB3HmnX9X3qquu4rXXXsM5x8SJExk9ejQ33XQTixYtokePHgwaNIgf/vCHu90eEZFOl0jAOefApk3Zj6mubgjyBg2CPff0+bGvv+6D1LomZb4bXpd63h07/IjuL37hR1D/9jd/TFezeDHsv3+75Cqb6+gIPouxY8e61atX5+XaIvmwdu1aRowYke9mSBtk+rczs6edc92mppz6bOnyEgkfRD7xBHz0EeyxR9OJWjNnwi23+Ild2ZSUwJgx8O67Pojdvr1z2t/dDBsGragmlK3PDs+IsIiIiMjumDoVfv97qKlpOT91+3Y/UWvp0tZdo6rKpwpIbpIVIvbc04+Gn3GG/zLyzDN+hDvbv1MwsXp3KRAWERHpyqZOhXvu8T+v9+7ty2GdcQa8+qoPOOrq4MIL268kVq4SCVi4ENas8SOsX/86lJV13PX23ddXIZDM9t8fjj3Wj2Jv3gyHHQannQbPPtvwbwTw9NNNg1MzOOQQ/+/ZEel8U6c2TNADmDKl3f57VSAsIiLSVaTX208P/j7+2Ac1a9Y0ft28efBf/wWjRvlAeevW3IPT8nL4zW9gv/18GgHApZfC2rW5jbwmrVoFP/gB/PGP7R9MjRtXOEHwqafCsmUNz8vLYdas3CesmcFtQTXE1rwum0GD4Mc/7tgvIbtr0SL49rc7ZJ6YcoRFOolyhMNLOcLqswte8if/Xbv886Ki7BOsWqukBIYM8akC6aPH5eW+6kB7Gz0afv3r9gl4Egk/Ca0QTJnig7pMEgmYPh3WrWtagWHECOjbt+HLRurfJfnlp7QUvvOd7JPjzOCqq/wvAW+/3fEj8AVGOcIiIiJhkBwh3LbNl8yaM8eP1C5c6Pe//rqvBlBTk71kVXsFweBzXlMnJc2b58tnffvbjUt1tafnn/fBa//+PljL9DN4a0dSc1Vc7IP/Xbsyj2b36eNHdZOj3wsXNow2b93qUwk+/NAHnqn/Ds0FweCD21df9Y+TE/dyCVhTqwuNGtUQFD/7bEO7Bg2CadNUcSsDjQiLdBKNCIeXRoTVZ3eaceM00aozDB3qKzvksnRverpJa+zOa6VdZeuzw7OghojsllgsxrLUvDRg/vz5XHrppc2+Jhn8nH766Wzbtq3JMddddx0//elPm7320qVLWZOSk/jDH/6QRx55pDXNzygej3PGGWfs9nlE8qq8HEaO9OW6OioIjkT8KOYee/iRyu5syBB44w34wx9yC06jUT/y3JZAdndeK51CgbBIN3H++efXr+qWdM8993D++efn9PoHH3yQ/v37t+na6YHw9ddfzymnnNKmc4l0Kckc27Vr/US2jjBkiE+jWLbM/2RfV+dTKpyDlSvhkkt8+aqOMmVKw/Wy3RYs6Ljrp7vmms67lhQ8BcIiBSy5OmZ7LK3+5S9/mT//+c/sCibTrF+/nrfffpsTTzyRb33rW4wdO5bDDz+cH/3oRxlfP3ToULZs2QLADTfcwGGHHcYpp5zCK6+8Un/M//zP/3DssccyevRoJk+ezMcff8zKlSt54IEHuOqqqxgzZgz//Oc/ufDCC/n9738PQEVFBUcddRSjRo3ioosuqm/f0KFD+dGPfsTRRx/NqFGjePnll3N+r3fffTejRo3iiCOOYGaQw1hbW8uFF17IEUccwahRo/j5z38OwC233MLIkSM58sgjOe+881r5VxVphalT/chsUZFPgRg3rn0nmkUiTbfNmAHr12d/TTTqJ6U99hjceKMPjFeuhPHjfV3X3r398r25uuQSH9QedxycdZY/V3N5sUllZf51RR0YlgwY4K/RjSaISQ6cc3m5HXPMMU6kO1mzZk2rjl+50rnevZ2LRPz9ypW734bTTz/dLV261Dnn3Jw5c9yVV17pnHOusrLSOedcTU2NmzBhgnv++eedc85NmDDBPfXUU84554YMGeI2b97sVq9e7Y444gj30Ucfuffff98dcsgh7uabb3bOObdly5b6a/3nf/6nu+WWW5xzzk2fPt3dd9999fuSz3fs2OEGDx7sXnnlFeecc1/96lfdz3/+8/rrJV9/6623uq9//etN3s/f/vY39/nPf77RtrfeessdcMAB7t///rerrq52J598svvDH/7gVq9e7U455ZT649577z3nnHP77ruv27lzZ6Nt6TL92wGrXZ76z3zc1GfvphEjWhoTbf1tzBjnLrmkceewYIFzxx3n3FlntU+nkbRypT9ntraYtU9HtXKlczfe6Nypp+b2N+jRw7nx49v3vUqXlK3P1oiwSIGKx/1k7dpafx+P7/45U9MjUtMi7r33Xo4++miOOuooXnrppUZpDOlWrFjBl770Jfr06UO/fv0488wz6/e9+OKLnHTSSYwaNYrFixfz0ksvNdueV155hYMOOohDDz0UgOnTp7N8+fL6/WcHKwcdc8wxrG9uVCvFU089RSwWY+DAgRQXFzNlyhSWL1/OwQcfzOuvv85ll13GX//6V/r16wfAkUceyZQpU1i0aBHFxSqkIx1g5kyf+tAaPXr40cvx433lhKFD/ejuJZf428qVvipAeomxsjJ48snc819zFY36cy5Y4HONFyzwbbjxRv/4hhugomL3r5nMqV22rOH8K1dmD4WrqvxotnJwpY3C1etr9qV0I7GYr+BTVeXvY7HdP+dZZ53F97//fZ555hl27NjB0UcfzRtvvMFPf/pTnnrqKfbee28uvPBCdiZXEMrCsky2ufDCC1m6dCmjR4/mrrvuIt5C9O6/pGfXM/hJNhKJUFNT0+yxLZ1z77335vnnn2fZsmXceuut3Hvvvdxxxx385S9/Yfny5TzwwAPMnj2bl156SQGxtK9f/KL1rznnHB/UFtrP+Olt6sjP4tSyYCIdJDwjwokETJwI117r79sjaVKkgEWjfoBl9uz2GWgB2HPPPYnFYlx00UX1o8EffPABe+yxB3vttRfvvvsuDz30ULPnGD9+PH/4wx/YsWMH27dv509/+lP9vu3bt7PvvvtSXV3N4pTlMPv27cv27dubnOtTn/oU69evZ926dQD87//+LxMmTNit9zhu3Dgee+wxtmzZQm1tLXfffTcTJkxgy5Yt1NXVMXnyZGbPns0zzzxDXV0dGzdu5OSTT2bevHls27aNDz/8cLeuL1IvkYBDD4UdO3J/TVFRy/VmRaTdhGfYI9PvxPqmKF1cRwyInH/++Zx99tn1KRKjR4/mqKOO4vDDD+fggw/mhBNOaPb1Rx99NOeeey5jxoxhyJAhnHTSSfX7Zs+ezbhx4xgyZAijRo2qD37PO+88vvnNb3LLLbfUT5ID6NWrF3feeSdf+cpXqKmp4dhjj+WSSy5p1fupqKhg8ODB9c/vu+8+5syZw8knn4xzjtNPP50vfvGLPP/883zta1+jLihwP2fOHGpra5k6dSrvv/8+zjm+973vtbkyhki9RMKP6G7alHl/nz4+ODaDww6D997zq7addZYCYOkW2loue/BguPfe9v1cDM+CGskR4eTvxO01RCbSSbSgRnhpQQ0tqJGzXD7hVblAurHdXTOmqAgef7z1IWD4l1hO/k6sHGERESlE/fr5kd3mzJihIFi6tWee2b3X19W1b1JAeHKEQSu0iIhIYRo5suUgePhwmDu3c9ojXc7UqX5hwH339Y9LS312TfqtVy9fqAQa0tQzHZfpVlzsz90a5eX+O2Cu18hx3nOzWihI1CrhGREWEREpROXlLZdHM4Pf/rZz2iNdztSpkJx//PHHDY8z2bUL5s2Dt96C3/3OV5nLVW1tw7lzSVdPLozY2RYvhv33b5/vleEaERYJuXzl5Evb6d9MmjVpUvZIYMSIhhXW/v53/ZopbdZCMZ+sr2lr95Xr9ZYsadv5k3r3zm31mAEDmr72/vt379pJCoRFOkmvXr2orKxUYBUizjkqKyvp1atXvpsihWjqVHj44abbe/Twn95r1nTM4hbS7Zx2Wttek6Xke7tdb/Lktp0/KaXoULMytSdYb2m3KTVCpJMMHjyYTZs2sXnz5nw3RVqhV69ejcqzidRbujTz9mHDOrcdEnrl5XDllfDhhxCJNOTRmkHPntDCGkcZNZc+kctrn3wSFi703+EmTcr8na+tzOCzn/ULCOYimabx+9/775mXXtp+6fYKhEU6SY8ePTjooIPy3QwRaQ8zZ8JHH2Xed8UVndsWCbX0PNvUyWTOtRwEJ9dfaSlf99RTsweeiQQcf3zjbevWwYknwtixuZc7mzGj4+aDLlrUMWW2lRohIiKSi0QCDjjAD2fNm5f5mLPOUnk0aZXdzbNN5vO2dJ4VK7Lvi8czb6+ra125s/bK2+1MCoRFRERakhwyy7ZaHPjfbGfM6Lw2SeiNG7f7KQfJ/NmW8nWby8eNxbLva025s/bK2+1MCoRFRERakm3ILGnYMHjsMU2Kk5y1ZYW13r39ymrga/4m0yLA/xCxYEHTCgtFRc2nRYD/z3blSr+EcVv07NmxaREdKVw5womEVpYTEZHOt21b9n1DhsBrr3VeW6RLaO0KawMGQGVl88eUlbU9MycahY0boU8f2LEj8zHFxVBd3bbzF6rwjAgnEiRis5jznx+SiM3yQbGIiEhHSyTg5psz7xsxAtav79TmSLjMnOlHcnd3hbW2lFBri+ZSKI4+unPa0JlCEwgnFr7GxKoHudb9mIlVD5JYqG/fIiLSCRYubLoywR57+N+h16zJT5skFGbO9PMqcyl/1ru3/141YIBPeVi5EsaM8csXp6ZAdLRly3wqRWoNYjO/NsyTT3ZOGzpTaFIj4kygihJqKaYKR5wJKDlCREQ63BNPNN322c+qOoS0KNcqCr17+6WT0z37bPu2J1e51vftCkIzIhybNoSSnkbEainpWURs2pB8N0lERDW5lswAACAASURBVLqDTKkPqg7R7ZWXQ2lp05SH1Nu6dbmdK9cV1qT9hWZEOBqFir9FNFdOREQ6T3l504lyU6boQ6iba2nxily1doU1aX+hCYTB9zvqe0REpNP85jeNnw8a1HnJmlKw2roIxrBhKjBSaEKTGiEiItLp9tuv8fNPfzo/7ZCC0tLiFdmEccGJrk6BsIiISDaHHtrkeSIBc+bkXsWzpVzSXr18dQFpLJcc3HzdWpsW0bt3eBec6OpClRohIiLSoWbO9FP9zz7bRy3PPddodyK+i4m/gKoqKCmBiormU/ZyySXdtcuX2AIFSkntlYPbWTqzvJm0L40Ii4iIgF/zdt48P9V/3jyYOrXJRLl4r0lUVUFtrQ+GW1p5uTW5pLmW2uoO2pqDmy8PPZTvFkhbKRAWERGZORNWrWq8bfHiRtvK+QY/WfkZamv989pauOYaGD48e5pEcyszp1u3rvlz5SKR8Nkcufy836dPYaVkJBJwwAG+bQ8/nO/WtE5nrfom7S98gXBrk7NERERa0sJwbDnf4GLK+bimpMm+devgxBObfixNndo0tm5JtnPlIpGAE07IvSrBjh1+4LsQguFEAo4/HjZtyndLWqe4WGkRYReuQDiRgIkT4dpr/b2CYRERaQ8tTOdfQrJMgGXcX1fXNE0i28/lN97oV2w+9dTM+zOdKxfxeNOVoHNRCCkZLb3fAQP8eyu0W3W1guCwC1cgHI/TquQsERGRXJx1Fowf74f4MphMy0mr8bj/wbK83KcnbN3a9JjiYr8oFDRfguuaa5pPa+jRw484p3rppRabmNGAAf5+0iQoKmp7GsW4cW2vwnDNNc2fW6kH0lFCVTUiUXoGcdtBrOhRoiXPNPQmIiIibTV1qs8HbkYZt8OMq7ny14ewfXvmYx5+uPnc1mHDYOHChioTZWX+/soryXrObGpqGpq8aJEPUlt4C1mtWgVDh8KGDdmPSaZRQObKFuPGtT4NJBfFxXDuuRp1lY5jri2/o7SDsWPHutWrV+d8fDIromqXoyRSQ8UvXyZaNqoDWygikp2ZPe2cG5vvdnSW1vbZodFSBJjUsyfs3NloU58+PkDM1amnZl9Kt7Q08whySwYMgMpKP8lu3brG+3r3ho8/bvqaTMea5ZZWkW1ltB49fHDeXpLvS6S9ZOuzQ5MaUZ8VUWdU1fUgXqkgWEREdsOkSRmD4Kn8ln5sZQxPk8CvJDfz4Hvp3x/23rshReCkk1p3ueZSIdr60//WrT6ITQ9sIXv7MqVD5zomlqxskZ4G0Z5BMCgVQjpPaFIjYjFfvDxZxFxZESIisltWrGiyaSq/ZTFfBeB5juIkVnBejyUsXntm/THJFIFly2DkSFi7tvnLDBjgc4eTqRCZJH/6v/tuP1lud40YkX30OblOSFtLlGUKuttLJALnnadUCOk8oRkRjkb9Cj6zZ7e8ko+IiEiLMgyZPkRyKNIAo5YID5Wc2eS4ZKWFAw5o/hK9e/uf+JsLgpMWLfJzwZurUpCt0kS6ltrVkpYqWzSnd++2V2GoqVEQLJ0rNIEw+OB31iwFwSIi0g4mT4a+ff3jnj1h5EhOO24rPgh2gCNS5DjtrN5NXppML2gu3QFanz7Rkpaul+txze0vKsqtskU27f2eRTpSqAJhERGRdMnV1EpKoH9/PxraXKmvRALmjPk/Zl5cyaTt91LON6CujsTl9/DY24cFRwUjwnVFjaox9O4NM2Y0VE4oK4MFCxpKkCUVFTU/Oa6tsl0vqV8/v7+lEejkeZLfA8Dn+g4bBo8/3riyRfpx2Zh1zHsW6Ug5VY0ws88B/w1EgNudczel7d8LWAQciM87/qlz7s7mztllZyCLSLegqhGFIbmaWqaPstSANfX4iRNq2FkNjkjDsdzEPK4il6kzuQSaXdGkSU3zihX4Sli0uWqEmUWAW4HTgJHA+WY2Mu2wbwNrnHOjgRjwX2bWdB3K9qAllkVEJNDcamqZVkyLx6Gq2nD1Aa9fKe5+JkNKYNycJS2vrdElZZhbmHGbSJjkkhpxHLDOOfe6c64KuAf4YtoxDuhrZgbsCWwF2rmYClpiWUQkB2b2OTN7xczWmdnVGfZfZWbPBbcXzazWzLL82F7YmqsgdPbZfq2M4uLGK5jVUoT/2KL+fh0Hk2355HRtyZvtCjLl/iofWMIul0B4f2BjyvNNwbZUvwRGAG8DLwCXO+faoQBMGi2xLCLSrFx+xXPO3eycG+OcGwPMAh5zzrVhOYf8W7o0+7543K+2Vlub3OJoCIDTNR4NLinxgXOqXPNvu6ply3wqhFnH5UCLdLZc6ghn+oqc3pNMAp4DPgMcAvw/M1vhnPug0YnMyoAygAMPPLD1rVUxYRGRltT/igdgZslf8dZkOf584O5Oalu7y5T+kPTMM+lbso34uib7rrvOVymSxhT4SleTy4jwJiC1IuFg/Mhvqq8B9ztvHfAG8Kn0Eznnyp1zY51zYwcOHNjqxiaIMmf6WhLfvEPFhEVEMsvlVzwAzKwP8DkgtFmvBx+cbY+jX91WGkaBm7s1ZqZxFpHuIpcR4aeA4WZ2EPAWcB5wQdoxbwITgRVm9kngMOD19mxoMj24qmoIJSXTqJgGCoNFRJrI5Ve8pC8Af8+WFrHbv+J1sPLyTKujNbzVrXV7A7U0jPkk96WPATX+k/Xo0W5NFJEC1+KIsHOuBvgOsAxYC9zrnHvJzC4xs0uCw2YDx5vZC0AFMNM5t6U9G6r0YBGRnOTyK17SeTSTFrG7v+J1tKbVG5IjvEZDcBsBiohQy438gFP5f8F2SzuuQW2tPmNEuotcRoRxzj0IPJi27baUx28DbViIMXdKDxYRyUkuv+Il679PAKZ2bvPaz+TJqSPCydHeOlKD2wi1gKOEamLEKWULDzOJTHnBRUU+LUKfMSLdR2hWlotGfVrw7NlKDxYRySbHX/EAvgQ87Jz7KB/tbA+jRsHw4RCJwAAqWUAZKzmJ4byKUQvUUgfsxTbmczlRnqCM21lw6hJGjDAGDfIrKxcVwXHHwZVXwkEHwWWX6TNGpLvIaWW5jlCoqxSJiORCK8vlVyLha9j60mj+c2wGN3EWD3Aiy6lL+8GziDoe50Sip/bLWPqgvBwuvrjheXcukybSFbV5ZbmCo5XlRES6vXg8tT5ww+pwcWLUEaFxDrBRRxFxYlnPl55v3F1XjxPpbnLKES4YDaUjfBKXciRERLqlWMynRKSOCJ/NEmLEKaKWuvT8X+qIEYfJX8t4vsb5xt139TiR7iZcI8IqHSEiIvgxkBUrYPx4GNzjXWZwE3O5hihPcCU/a3TswD0/5vHj/oPogq9lzXcoK/PpEKeeqrQIke4kXCPCKh0hIiKB6NKZPPb8Aqh+v9H254Z9BdY1jAgfdfweRJfNb/F8ZWUKgEW6m3CNCKt0hIhIqM2c6Ss9zJy5+yeaOu9wSt9/jan8tmG7GZPPbjwJXGkOIpJNuEaE8cssx4kSQyvLiYiEycyZMG+ef5y8nzu3beea+vOjWcw5ACzmqwAsYjrsvTdlcw+BQ/yEt8mTNcorItmFKhDWXDkRkfC6//6mz9saCD9UfUrwyADHQ5zmn37yk4DSHEQkN6FKjdBcORGR8Dr77Oaf56K8HEYO/Yjt9Am2+DSI03jIP73iirY3UES6nVAFwsm5cpGI5sqJiITNWWdBcfA7ZHGxf94ayUUv1m7oQzW9UvbU8u0B96rcg4i0WqhSI6JRqJj/AvEllcQmlxKNjsp3k0REJEfxOCQXM3XOP29NelvDIheWtidC/Mo/E1UMLCKtFKpAmESC6BUTiVZVwYoSGKUkYRGRsNjdCpgNi140rgpRbLXEYuH6OBORwhCq1AglCYuIhFc0CpddBoMGwbHHtnz81Kk+Fc7M3y6+GKCu/mbUMoxXWX7VnzUmIiJtEq5AWEnCIiKhVV7uy6a99RYsXw4TJvhqQJlMnQqLF0NdXepWh0+LKAKKcERYx6G88GpJh7ddRLqmcAXCWlBDRCS0GnJ8verq7D/sPfRQpq2W4QZL3tZngYi0TbgCYfyCGnOYRULLaYiIhMqYMY2fRyLZf9gbNix9i8tyg8lf37sdWyki3UmoZhdoQQ0RkXBKJOAXv2i8rTjLJ1B5OaxalbrFpR1RSwlV7Mc7zDrrZcrKTm/HlopIdxKqEWHNlRMRCadk/52qpqqW+BVLmyQKp6dQeA2pEKfyCLvYgzdsGGUzNBosIm0XqkBYc+VERMIpFoOi+k8cRxE1lLhdxFbNhZNO8sHwzJkwfDgDN67OcIaUVAiCSPm22/SzoIjsllClRmhBDRGRcHrhBT85LulMHmAGNxPlCagFTjwR6uoo5xss5hga0iGMU3svp8+OSt5mP77Obyjb4274fysVBIvIbgtVIKwFNUREwik93eFj+vggOCmok7aEycGG5Opxjtd37MtrxBqO/exZ6vtFpF2EKjVCScIiIuE0ORnfBiO9j3MiffiQPXifIqoxajBqeJjPphznjz2btCh60KDOaLKIdAPhCoSVJCwiEkplZbBgAQzZcwsAH7MHO+jDx/TFESG5SEb6x9IIXmAu1zRsMINp0zqt3SLStYUrENaCGiIioVVWBj367xk8y7Q4RtPFMt5l38YnOekk9f0i0m7CFQijBTVERMLs7At6B4+yLZDReLGM00hbYm7kyM5pqIh0C6GaLKcFNUREwiuRgP4fbGCKreA+dzZVlNAw+lsE1JEMgIup4Vz+j0VMbzhBSYnSIkSkXYUqEG40V25nLfGFm4hGh+S7WSIi0oL6gYydg8GdQy09UvYaxcWwfHkR0aUz4Y47YPt2qKmBg4bBVVdBZaWfF6LRDxFpR6EKhGMxKCmupaq2jhJXTeyO6TBtjjpGEZECF49D1S5HrYvQUBrN6vfX1PhjonPnwty5eWihiHRHocoRjkah4muLmW3XUcFEorWPq4SaiEgIlJYCrg6jjiJqg60NucDFxSoEJCKdL1SBMEB02nBm9fo50chTKqEmIhICiQRcdhnUuiIcRoQ6pvC/7MVW9izewfjxsHy5ftwTkc4XqtQIoKGEWjyufDERkRCIx5PLK/tUiBqKOZy1LIpcBMtXqB8XkbwJXSCcSEA8HiUWi6rvFBEJgVgMevSAqiqfBlFCNTFbDr/6lYJgEcmrUAXCKp8mIhI+0agfFV54xbPw1Cqmud8SLXoKKs/Id9NEpJsLVSCs8mkiIuEUjUJ0/i6Y+P2G0QzN8RCRPAvVZLlk+bQI1ZS4Xb58WiKR72aJiEguolGYP9//tDd/vn7SE5G8C9WIcLJ8WnzBK8Tco0RrnwoKT6ozFREpeIkEXHGFHxFesQJGjVL/LSJ5FaoRYVD5NBGR0GqU31alOvAiknehGhEGVD5NRCSsYjE/gKEcYREpEKELhFU+TUQkfOr77vlPEq38swYyRKQghCoQri+ftstREqmh4pcvEy0ble9miYhIMxqXvhxFRcUoxcAiUhBClSMcj/sguLbOqKqG+LfvU9UIEZECp9RgESlUoQqEYzEoidT48mlUE6t7VD2qiEiBS6YGRyJKDRaRwhKq1IhoFCp++TLxb99HrO5Roj2fgdjN+W6WiIg0o9Ec59IXiMb/DMSUIywieReqQBggWjaK6KgPId7bB8HqSEVECl40ClEaJQv76Fh9uIjkUahSI5ISL+zJnHiUxAt75rspIiKSg0QC5ly3i8Suo5UsLCIFI3QjwonyF5h48SFUMYKSh6uo4AVVjhARKWD1VSN2jqfEPUyFfZZoybNKFhaRvAvdiHB8SSVVlFBLMVX0IL6kMt9NEhGRZtRX/HFFvt8mBvPnKy1CRPIudIFwbHIpJVQ1VI6YXJrvJomISDNiMSix6oZ+2z0Kzz6b72aJiIQvNSJaNooKXiC+pJLY5FKlRYiIFLhoFOafcC9Llu/DZJYQ5QlgTL6bJSISvkAYgsoRZfluhYiI5CKRgCuePJ8qHCsYz6jIy0SnTct3s0REwpcaAX7C3JxJcRLlL+S7KSIi0oJ4HKqqixrmdjAh300SEQFCOCKsqhEiIuGSXBW0qo4gRzgO8T00WU5E8i50I8KqGiEiEi7JVUFnF8+moujUYFXQWL6bJSISvhHh2ORSSh6uogqnqhEiIiGhVUFFpBCFLhCOlo2i4p9Lid+/ldjZA4iWnZXvJomISC6iUQXAIlJQckqNMLPPmdkrZrbOzK7OsP8qM3suuL1oZrVmNqD9m4uffjx/Pvzzn/4+keiQy4iIhFVLfXZwTCzos18ys8c6pWGJBMyZo35bRApGiyPCZhYBbgU+C2wCnjKzB5xza5LHOOduBm4Ojv8C8D3n3NaOaHBi4WtMrHqQKkooqaqiYuHviWqEQUQEyK3PNrP+wK+Azznn3jSzT3R4w+rXWa6CkhKoqNDosIjkXS4jwscB65xzrzvnqoB7gC82c/z5wN3t0bhM4kxoPFlOZXhERFLl0mdfANzvnHsTwDn37w5vVTzug+DaWn8fj3f4JUVEWpJLILw/sDHl+aZgWxNm1gf4HLBk95uWWWzaEEp6GhGrpaRnEbFpQzrqUiIiYZRLn30osLeZxc3saTPr+NUtYjE/EhyJ+HtVjRCRApDLZDnLsM1lOfYLwN+zpUWYWRlQBnDggQfm1MB00SjMvyXCkt+8x+T9EkTZG9DPayIigVz67GLgGGAi0BtImNkTzrlXG52oHfrsetGoT4eIx30QrLQIESkAuYwIbwIOSHk+GHg7y7Hn0UxahHOu3Dk31jk3duDAgbm3MkUiAVd8t5aKVX25YmmMRGyWJl6IiDTIpc/eBPzVOfeRc24LsBwYnX6i9uizRUQKWS6B8FPAcDM7yMxK8MHuA+kHmdlewATgj+3bxMZ8mpk15AhXn6BcMxGRBrn02X8ETjKz4iClbRywtkNblZwsd+21/l4DGCJSAFoMhJ1zNcB3gGX4jvJe59xLZnaJmV2ScuiXgIedcx91TFM9n2bmiFDtF9To8XflmomIBHLps51za4G/Av8AVgG3O+de7NCGabKciBSgnBbUcM49CDyYtu22tOd3AXe1V8Oyqc8R/u+3meyWEL3iAuWaiYikyLHPri972SmSk+WS5dM0gCEiBSB0K8slc4Srdu3LCsoYddnpREeNUjAsIlLINFlORApQ6ALhhhzhCFU44tUnEI3H1amKiBQ6LbEsIgUmpyWWC0mTHOHICv3EJiIiIiKtFrpAOBqF+ZevZ6LFmc8VRCOr8t0kERFpQSIBc+aoWISIFJbQpUYkEnDFzw+kyg1hBScwqnqNUiNERApYsnJacp5cRYW6bBEpDKEbEY7Hoaq2uKGOcNFnlBohIlLAVDlNRApV6ALhWAxKehpFVocZlJ47UUMLIiIFLFk5LRJR5TQRKSyhC4SjUZh/2T+JuBrqnHHF4mNJlL+Q72aJiEgWycpps2crLUJECkvocoQBKp/bSB1DqKPYl1BbUkm0LN+tEhGRbFQ5TUQKUehGhAFik0uJUIOvJlxLbHJpvpskIiIiIiETykAYwNLuRUSkMKl0mogUqlCmRsSXVFLDCBwRaqhTaoSISIFS6TQRKWShHBFukhoxZlu+myQiIhmodJqIFLJQBsKMGoUV+8FsA5g/X7+5iYgUoPrSaUWOkqJqYqWq8iMihSOUgXA8DtU1RTgiVFNMvPp4DTOIiBSgaBQq5r/A7KIfUVF7MtErxmngQkQKRihzhEtLoQ4DHHVEKHWboXRovpslIiIZRCv/TNTdCHW1UBXxAxdKFBaRAhDKEeHKSigyBxhF1FJpA/1GEREpPFpaTkQKVChHhGMxKC52VFfXUkwNscjjEJub72aJiEgmyaXl4nHfgWs0WEQKRChHhAEsqCBsAKZqwiIiIiLSOqEcEY7HoaYGHBGqgIXV5xFVzpmISGFSMWERKVChHBGOxSBSVAc4HEXcyddIbBuR72aJiEgGiYWvMWfn90jUHqtiwiJSUEIZCEejcNEx/wDqAPMl1J7rn+9miYhImkQCJt45hWvdj5lIBYnIiZosJyIFI5SBMMBRw7fjmx+UUBuoPGERkUITj0NVTYRaiqmynsQv+q3SIkSkYIQ2EH72tb7BI0t7LiIihaJR5bReEWLThuS7SSIi9UI5WQ6AXj2bfy4iInmnymkiUshCGwgfNWADMBJw/jnPAofns0kiIpJBNKoAWEQKU3hTIzgqeBSkRjz+sdavFxEREZGchTYQZtC+jZ/X1akkj4iIiIjkLLSB8FHJAeEgNaIf70Fpad7aIyIiIiLhEtpAuLISDEcyNeK/uJLEs73y2ygRERERCY3QBsKxGBSZgyAYrqWYhWvG5rlVIiIiIhIWoQ2Eo1E44ZPrGm17581deWqNiIiIiIRNaANhgAG9Ps53E0REJBeJBMyZo+o+IlJQQltHGID+ezV6urW6X54aIiIiWSUSMHEiVFX5ZeYqKlRYWEQKQqhHhAeVbGv0/PG3hpAofyFPrRERkYzicR8E19b6e5W6FJECEepAeNrXe1BELckJc3VEWDh/a76bJSIiqWIxKC4GM38fi+W7RSIiQMgD4WjZKI7st6HRtjXvDcpTa0REJCvnGt+LiBSAUAfCALv67N3o+YaqfbMcKSIieRGP+7QI5/y9UiNEpECEPhAeyOZGzzds3VOTkkVECkks5ifJRSL+XqkRIlIgQh8Ij+z1RsozA4x58/LVGhERSZcgypzpa0l88w5VjBCRghLu8mnAtAPj3Lb+s/iY3i+3/OyzeW2SiIgEGiqnDaGkZBoV00BhsIgUitCPCEdHvs8Ynm+0bcMGp/QIEZECoMppIlLIQh8IM20an2ZVygY/Knz11flpjoiINFB6sIgUsvAHwtEo08b8A6jD1xP2li/XSp4iIvkWjfq04NmzlR4sIoUn/IEwEB36L4aSWk/Yjwpr0pyISP5FozBrloJgESk8XSIQBpjFnOBR41FhEREREZFMukYgPGgQZdzOALakbHRs3Qrl5XlrlYiIiIgUsK4RCE+bBkVFjGdFykafHjFrVn6aJCIiIiKFrWsEwtEoHHkkM7gZnxrRkB6hUWERERERyaRrBMIAu3YR5QmmsCjY0BAMa1RYRERERNJ1nUD4sMMAWMR0StjRaJdGhUVEREQkXdcJhGfMqH/YeIEN78orO7MxIiIiIlLouk4gHI3C0KEA3MQs0nOFt2+HqVPz0jIRkW4tkYA539pA4lsLtdKRiBSUrhMIAxx4IEBarnCDxYvVB4uIdKZEAiaeXMu1t+3PxNu+TCI2Sx2xiBSMrhUIDxhQ/3AR0+nHNlJHhQEuvbST2yQi0snM7HNm9oqZrTOzqzPsj5nZ+2b2XHD7YUe1JR6HqiqjlmKq6EG8+gS/UUSkAHStQHjQoEZPb2ZGk0Oee06DESLSdZlZBLgVOA0YCZxvZiMzHLrCOTcmuF3fUe2JxaCkxBGhmhKqifX4u98oIlIAcgqEWxpdCI6JBSMLL5nZY+3bzBxNm9boaRm3MyCyrclhX/xiZzVIRKTTHQesc8697pyrAu4B8tbrRaNQ8bcIsy95m4pLfk80PsdvFBEpAC0GwrmMLphZf+BXwJnOucOBr3RAW1uWMmEuaU7tDNLTIzZv1sQ5Eemy9gc2pjzfFGxLFzWz583sITM7vCMbFI3CrF8PIfrraQqCRaSg5DIinMvowgXA/c65NwGcc/9u32a2wpgxjZ6WcTvHDXy9yWGaOCciXZRl2ObSnj8DDHHOjQZ+ASzNeCKzMjNbbWarN2/e3M7NFBHJv1wC4VxGFw4F9jazuJk9bWbTyKBTOtUZTfOCnxxxET16ND30nHM6pgkiInm0CTgg5flg4O3UA5xzHzjnPgwePwj0MLN90k/knCt3zo11zo0dOHBgR7ZZRCQvcgmEcxldKAaOAT4PTAKuNbNDm7yoMzrVaLTJpDlefZXvfa/poZs2KUVCRLqcp4DhZnaQmZUA5wEPpB5gZoPMzILHx+E/Cyo7vaUiInmWSyDc4uhCcMxfnXMfOee2AMuB0e3TxDZIKaMGwDvvMPesBIMHNz1UKRIi0pU452qA7wDLgLXAvc65l8zsEjO7JDjsy8CLZvY8cAtwnnMufYBDRKTLyyUQbnF0AfgjcJKZFZtZH2AcvgPOj8svb7pt3jzuvTfz4aef3rHNERHpTM65B51zhzrnDnHO3RBsu805d1vw+JfOucOdc6Odc592zq3Mb4tFRPKjxUA4l9EF59xa4K/AP4BVwO3OuRc7rtktKCtrOir8xBNEozBlStPDt22DkZmqbIqIiIhIl5VTHeGWRheC5zc750Y6545wzs3vqAbnLD1P+J13IJFg0SIYMaLp4WvXKl9YRKRDJBIwZ47y0ESk4HStleVSZUmPAFizBvr3b7p78WIoL+/gdomIdCeJBEycCNde6+8VDItIAem6gXCm9Ijly+sfPvhg5pddfLH6aRGRdhOPQ1UV1Nb6+3g83y0SEanXdQNhaJoesXVr/ZBvtnxh0OQ5EZF2E4tBSQlEIv4+Fst3i0RE6nXtQDhTesT8hvTlbPnC27Y1WalZRETaIhqFigqYPdvfa4llESkgXTsQLiuDvn0bb9u0qdHTbPnCGzbAvvt2YNtERLqLaBRmzVIQLCIFp2sHwgAHHND4+fbtTWbEZcsXfucdKC3toHaJiHQXqhohIgWq6wfCmdIjbryx0dNoFBYsyPzyrVuhX78OaJeISHegqhEiUsC6fiCcqXrEhg1NOuOysuzB8Pbt0LOn+m8RkVZT1QgRKWBdPxAGGD++6bagpnCq5oLhqio4/njVGRYRaRVVjRCRAtY9AuEZM5pue+KJjIeWlcHKlb6/zuTii2HSpHZsm4hIV6aqESJSwLpHIByNZl1yOdvhu3Y1LTiR9PDDmkQnIpKrBFHmMIsECoJFpLB0j0AY4NOfbrrt6qubfckHHzRNL07auhWKimDmzHZom4hIF6W5ciJSyLpP3CoUeAAAH4pJREFUIJwpPWL58hZ75crKpoPJSc75VOPevZU7LCKSiebKiUgh6z6BcDSaebm4DJPm0v3rX3Dqqdn379zpc4dHjmx780REuiLNlRORQtZ9AmHwKxulW748p5cuW9b8JDqAtWt9Z690CRERT3PlRKSQda9AOFNN4a1bc85rSE6iGzIk+zF1dUqXEBFJpRWWRaRQda9AGDLXFE5baa4l69f7lONIJPsxSpcQERERKWzdLxDONGkuw0pzLZk7F2pqYMqU5o9buxbMVHtYREREpNB0v0A4Gs08KnzppW063aJFPne4f//mj3v4YQXEIiIiIoWk+wXCADfd1HTbc8+1ucBlNArvvecHm4ta+IsmA+Lhw1VPU0RERCSfumcgHI3C6NFNt7ewwEZL5s71tTJbSpcAWLcOjj/eB84aJRYRERHpfN0zEAb49a+bbnviiXY59aJFfrGN445r+VjnGkaJ99pLlSZEREREOkv3DYSj0aZLxlVVwdSp7XaJJ5/0+cODB+d2/Acf+EoTGiUWERER6XjdNxAG+PGPm25bvLhdk3ejUdi40QfEw4fn9prUUeJx49qtKSIieZFIwJw5mhchIoWnewfCmRbYgDZXkGhONAqvvuqD3OaWa063apUPiHv0aNfBahGRTpFIwMSJcO21/l7BsIgUku4dCIMfpki3GxUkcrFsmQ+IWzNKXFPjB6vNVHVCRMIjHvdZZ7W1/j4ez3eLREQaKBDONio8fXqHXzp1lHjGDCgpyf21yaoTZlBaqkl2IlKYYjHft0Ui/j4Wy3eLREQaKBCGzKPCr73WqdHl3Lmwa1frRomTtm71k+xUeUJECk00ChUVMHu2v49G890iEZEGCoTBjwoPG9Z0+5VXdnpT2ppLnJSsPJFModBosYjkW5QEs5hDFOVziUhhUSCctHBh023bt8PMmZ3flkAyl3jBgszZG7lIHS1WbrGIdDrNlhORAqZAOCkazbwk3M9+1vltSVNWBpWVPihOjhSbte1cqbnFyVskorrFItJBNFtORAqYAuFUixZBz56Nt9XUFFwx32XLoK7OB8VTpvhAdnfU1TXULU6/qWybiOwWzZYTkQKmQDjd5Zc33bZqVcEm2i5a5GP1tlSeyEV62bZCuGkEWyRENFtORAqYOefycuGxY8e61atX5+XaLfrEJ2Dz5sbb+vb1M9FCZOpUuOce/4uktK/iYjj3XP9FRLonM3vaOTc23+3oLAXdZ4uItCBbn60R4Uz++Mem27ZvD12OQOpocTKNokj/4u2irSPlGs0WEREpHAqLMolGYfToptsXLw71jOdFi/zocDIwbu3qdrL7msvHzvWmkngiIiLtQ4FwNr/+debtnbDiXGdKrVucflu5EgYPzncLJV16SbzkrVevvFb7ExERCR0FwtlEo372WbpOXnEun6JR2Lgxc5Ccr5tGsLPbtQvmzcs8iqwgWUREpCkFws2ZOzfzShbf+17nt0WA5kewO+u2Owuc5EtzQbJK5kmHSyT8UvYhTi0Tka5JgXBL5sxpuu3jj2HkyM5vixSE9AVOutpodkeXzNPqht2MVpYTkQKmQLglZWV+Kbd0a9fqt2ZplfYYzW6PBVTyLdPqhvm8afJhB9PKciJSwBQI52LZMhg4sOn2Alh+WbqX9JJ4qekaffvmu3XhlJx8qGC4g2hlOREpYAqEc5WptnBNjVIkpCCUlfn1XrpKTnM+LFmS7xZ0UVpZTkQKmALhXEWj/nfpdGvXaoUEKWityWnuzkHz5Mn5bkHXlEjAnHiURGyWgmARKTgKhFtj0aLMKRIPP6x8YekS2joRMNfbqaf6vNxCMmCA/wJQVpbvlnQ9micnIoWuON8NCJ0//tHP9Ek3bx4ccog+TUWasWxZvlsgnSnTPDkNCotIIdGIcGtlS5EAP+NGQx4iIoDmyYlI4dOIcFssWuRXmFu1qum+00+H997r/DaJiBSY5Dy5eNwHwRoNFpFCo0C4rZ580leMWLu28fZt22DffeFf/8pPu0RECkg0qgBYRAqXUiN2x5o10L9/0+3vvOODYRER0RLLIlKwNCK8ux58MPPkuWQwrJFhEenOkqUjqqp8orBqCYtIAdGI8O6KRn3tpUw0Miwi3Z2WWBaRAqZAuD2UlSkYFpGCYWafM7NXzGydmV3dzHHHmlmtmX25wxqj0hEiUsCUGtFekvWDL7646b533oF+/f5/e/ceHXV9/3n8+c6EJAZBJehqiSVIqUWMCWmEHcQSF1YtelBAfsKx3VJ2mx90V62elks9qCs/1gN6ziKnv2OlYlmVhrqgOeIByQKm+CtZLnITBPyBxDVeKA2/QiyXkOSzf3wnMYRJMklm5juTvB7nzMnM9/ud77xy++Sd73wu3hq4IiIxZGYB4J+B/whUATvM7G3n3EdhjlsExHZ2Z00dISIJTFeEo6mtK8M1NZCersEiIhJrI4AjzrlPnHO1wCrgvjDHPQysAf4Sz3AiIolEhXC0tVUM19Z6A+u0HLOIxM4A4LNmj6tC25qY2QBgIvDbtk5kZsVmttPMdp44caJzabTOsogksIgK4fb6m5lZkZmdMrM9oduT0Y+aRIqLYetWrz9cOIsXw113xTeTiPQUFmaba/F4CTDHOVff1omcc8ucc4XOucKrr766c2k0WE5EEli7fYQj7W8GvO+cuzcGGZNTMAjnz3t9g2tqLt1fVgY5OVBZGe9kItK9VQHXN3ucDXzR4phCYJWZAfQHxptZnXOuNOppsrIgJQWc02A5EUk4kVwRjrS/mYRz+jT06xd+36efen8kRESiZwcwxMwGmVkaMBV4u/kBzrlBzrkc51wOsBr4eUyK4IoK+MUvvKvBKSmwZIkGy4lIQomkEG63v1lI0Mz2mtl6MxsW7kRR6W+WjKqrYeDA8PtOntQgOhGJGudcHfDf8GaDOAi84Zw7YGYzzWxmXMOUl1NxvoBnG2ZT0TDSawtFRBJIJNOnRdLfbBcw0Dn3tZmNB0qBIZc8ybllwDKAwsLClufo3iorvX7BZWWX7mscRHfnnbAhtjMZiUj355xbB6xrsS3swDjn3PRY5ajIupexDY9SSxppDbVsyjqKrgeLSCKJ5Ipwu/3NnHOnnXNfh+6vA3qZWf+opewuNmyA2bNb319WpsU3RKTbKK/OpTblMupJpTblMsqrc/2OJCJykUgK4Xb7m5nZtRYadWFmI0Ln1Xtg4Sxa1PaMEl99Bb16wbJl8c0lIhJlRUWQlm7eonLppnFyIpJw2i2EI+xv9gCw38z2AkuBqc65ntX1oSMaZ5RobRBdXZ23Qt3IkfHNJSISRY2Lyi1Y4H3UODkRSTQRLbHcXn8z59xvgN9EN1oPUF3tFbvbt4ffv307ZGbqL4iIJK0gFQQpB4pAPYRFJMFoZTm/bdvmrUQXCITff/asN5DuRz+Kby4Rka7SqnIikuBUCCeC4mKvO8S117Z+zMqV0KeP/pCISPLQqnIikuBUCCeSL7/0plBrzddfe1eH1XdYRJJBUZE3MDgQ0KpyIpKQVAgnmg0bvFklLrus9WO2b/f+sMyZE79cIiIdpdFyIpLgVAgnomAQzpyBESNaP6ahARYvhpycuMUSEemwYBDmzVMRLCIJSYVwImtvIB3Ap59CSooG04mIiIh0kArhRNc4kK6tvsPOeYPp0tO1EIeIiIhIhFQIJ4vGvsNXXtn6MbW13kIcl1+uglhEEkLFsg959q5yKpZ96HcUEZFLqBBOJsEg/Nu/wezZ4K1oHd7f/+4VxNdco+nWRMQ3Fcs+ZOw/DmZ+2WjG/uNgFcMiknBUCCejRYu8wXJDh7Z93IkT3nRrukIsIj4oX36UWtKoJ5VaelG+/KjfkURELqJCOJl99JE3mK5Xr7aPa7xCnJICd90Vn2wi0uMVfetj0qglwAXSuEDRtz72O5KIyEVUCCe74mKvb/BDD7V/rHNQVuZ1q0hN1UwTIhJTwdm3syn1bhbwFJtS7yY4+3a/I4mIXESFcHfx+uteoRtJQQzekqcrV3pFca9eKopFJPqCQYJbFjHvf/QhuGWR5hIWkYSjQri76WhBDN70bI1FcUqKlnAWkejRghoiksBUCHdXjQXx7NmQlhb585zzlnA2826ZmVrKWUQ6raICnn1WE9iISGJSIdzdLVoE5897BW5bi3K05uxZbynnxsL4iis0A4WIRKSiAsaOhfnzvY8qhkUk0agQ7kk2bPAK4q1bITu7c+c4fdqbgaKxG8WQIfrrJiJhlZd7Y3nr672P5eV+JxIRuZgK4Z4oGITPPvOK4pdegn79Once5+DIEW+uYnWlEJEWioogLbWegNWTllpPUZHfiURELqZCuKcrLobqaq+o7Wz3ieZadqXQrBQiPVaQCja5sSzgSTa5sQTRu0ciklhS/Q4gCWbDhm/uL1sGv/wl1NR07ZyNs1KsXPnNtu98B159VSPJRbqz8nKC9f9C0P0J6gNe3wj9zkuSunDhAlVVVZw7d87vKNKGjIwMsrOz6dXeYmMhKoSldcXF3q3RnDmwZInX2a+rGrtUNEpPh0cf9Qb3iUj3UFRERWA05Q23URT4M0H1jZAkVlVVRZ8+fcjJycHM/I4jYTjnqK6upqqqikGDBkX0HHWNkMg1n4GisRtFtBqD8+fVpUKkm6n48HLG1pcxn2cYa5uoQFeDJXmdO3eOrKwsFcEJzMzIysrq0FV7FcLSeRs2QEPDN4XxSy9Bnz7RO3/zhT5a3jSNm0hiq6ig/L/+b2rrU6h3AWovpGjWCEl6KoITX0e/RyqEJXqKi73p1RoL467OStGW5tO4tbylpupKsojfysspathMGrUEuEBaoE6zRoh0QXV1Nfn5+eTn53PttdcyYMCApse17XRZ3LlzJ4888kiHX3P37t2YGRuajx/qZlQIS2y1nJUi2l0qwqmvD38lWV0tROKnqIhg+i42pdzJgtQFbPrNIY2TE+mCrKws9uzZw549e5g5cyaPPfZY0+O0tDTq6upafW5hYSFLly7t8GuWlJQwevRoSkpKuhI9oakQlviLdZeK1oTrahEIwF13xf61RXqaYBA2bSL4T/cwb8sPCRbn+p1IJP5ivMb49OnTefzxx7njjjuYM2cO27dvZ9SoUQwfPpxRo0Zx+PBhAMrLy7n33nsBePrpp5kxYwZFRUXccMMNrRbIzjlWr17NihUrKCsru6jf7eLFi8nNzSUvL4+5c+cCcOTIEcaNG0deXh4FBQUcPXo0Jp9ztGnWCPFfy9kpwGs0/uEfoKoqtq/d0ABlZZdeoe7bF5577tJcIiIikWhcY7y2FtLSYNOmmEwf+PHHH7Nx40YCgQCnT59my5YtpKamsnHjRn7961+zZs2aS55z6NAh3nvvPWpqarjxxhuZNWvWJdON/fnPf2bQoEEMHjyYoqIi1q1bx6RJk1i/fj2lpaVs27aNzMxMTp48CcBDDz3E3LlzmThxIufOnaOhoSHqn2ss6IqwJKbmq9+1vM2e7TUqsdRWH2StoCfSvsYiYP5876OWYpeeJk5rjE+ZMoVAIADAqVOnmDJlCjfffDOPPfYYBw4cCPuce+65h/T0dPr3788111zD8ePHLzmmpKSEqVOnAjB16tSm7hEbN27kpz/9KZmZmQD069ePmpoaPv/8cyZOnAh4c/k27k90KoQl+bScxq35betWyM6OfYZwK+i1vGVlaWYL6bniVASIJKyiIu+iTSDgfYzRaNHevXs33Z8/fz533HEH+/fvZ+3ata1OI5aent50PxAIXNK/uL6+njVr1vDMM8+Qk5PDww8/zPr166mpqcE5d8nMDM65KH5G8aVCWLqX1q4kx2r2iracPNn2VeXGW0oKjBwZ32wisRanIkAkYYX6ybNgQcy6RbR06tQpBgwYAMCKFSs6fZ6NGzeSl5fHZ599RmVlJZ9++imTJ0+mtLSUO++8k1deeYUzZ84AcPLkSfr27Ut2djalpaUAnD9/vml/olMhLD1DuNkrtm6FIUP8TuZl2b69/YJZA/skmfhQBIgknGAQ5s2L28//7NmzmTdvHrfddhv19fWdPk9JSUlTN4dGkydP5g9/+AN33303EyZMoLCwkPz8fJ5//nkAXnvtNZYuXcott9zCqFGj+Oqrr7r0ucSL+XU5u7Cw0O3cudOX1xZpUzSXko6XlBQYN86bkUPiwsw+cM4V+p0jXtRmS0938OBBhg4d6ncMiUC471VrbbauCIu01FYf5MbBehkZfqe8WPPZLzR/soiISERUCIt01KJF3mC51grleM1sEam2lqo284p6zYAhMRDjKVRFRLpMhbBILLR3VTmeK+215/x5zYAhUafZ00QkGagQFvFby5X2WpsWzs+BfZHOgKEBfRKi2dNEJBmoEBZJBsEgfPxxYhbJzbXVV7nxNmSILg/2AJo9TUSSgQphkWTXVpHsx/zJ7TlyBEaNar1QTk3V4L5uQLOniUgyUCEs0p2Fmz850Qvl+vq2B/c1X4hE3TASWpynUBXp1oqKitjQYorMJUuW8POf/7zN5zROezh+/Hj+9re/XXLM008/3TQXcGtKS0v56KOPmh4/+eSTbNy4sSPx2/Too48yYMAAGhoaonbOSKkQFunJ2iuUnYOHHvLe3040zrXfDaN50awuGSKSxKZNm8aqVasu2rZq1SqmTZsW0fPXrVvHlVde2anXblkIP/PMM4wbN65T52qpoaGBt956i+uvv54tW7ZE5ZwdoUJYRNr2+uveFGztzX6RSH2VW3Ku9S4ZmhEjZjR9mvR00fwdeOCBB3jnnXc4f/48AJWVlXzxxReMHj2aWbNmUVhYyLBhw3jqqafCPj8nJ4e//vWvACxcuJAbb7yRcePGcfjw4aZjfve733HrrbeSl5fH5MmTOXPmDFu3buXtt9/mV7/6Ffn5+Rw9epTp06ezevVqADZt2sTw4cPJzc1lxowZTflycnJ46qmnKCgoIDc3l0OHDoXN9d5773HzzTcza9YsSkpKmrYfP36ciRMnkpeXR15eHlu3bgXg1Vdf5ZZbbiEvL48f//jHXfyqqhAWkWhpq69yokwVF07jjBgqhqNK06dJTxft34GsrCxGjBjBu+++C3hXgx988EHMjIULF7Jz50727dvHn/70J/bt29fqeT744ANWrVrF7t27efPNN9mxY0fTvkmTJrFjxw727t3L0KFDWb58OaNGjWLChAk899xz7Nmzh8GDBzcdf+7cOaZPn84f//hHPvzwQ+rq6njxxReb9vfv359du3Yxa9asVrtflJSUMG3aNCZOnMg777zDhQsXAHjkkUcYM2YMe/fuZdeuXQwbNowDBw6wcOFCNm/ezN69e3nhhRe69DUFFcIiEk/tTRXn51XlNWv8ed1uStOnSU8Xi9+B5t0jmneLeOONNygoKGD48OEcOHDgom4MLb3//vtMnDiRzMxM+vbty4QJE5r27d+/n9tvv53c3FxWrlzJgQMH2sxz+PBhBg0axHe/+10AfvKTn1zUvWHSpEkAfP/736eysvKS59fW1rJu3Truv/9++vbty8iRIykrKwNg8+bNzJo1C4BAIMAVV1zB5s2beeCBB+jfvz8A/aIwxiW1y2cQEYmWxqvKkRg5ErZvj95rT54cvXNJ0/RptbWaPk16plj8Dtx///08/vjj7Nq1i7Nnz1JQUMCxY8d4/vnn2bFjB1dddRXTp0/n3LlzbZ7HWnlnbvr06ZSWlpKXl8eKFSsob6d6d861uT89PR3wCtm6urpL9r/77rucOnWK3NxcAM6cOUNmZib33HNPq6/XWvbO0hVhEUlO27ZFtnLf1q2Qn996l4x+/bzZM4qL45u/m9P0adLTxeJ34PLLL6eoqIgZM2Y0XQ0+ffo0vXv35oorruD48eOsX7++zXP84Ac/4K233uLs2bPU1NSwdu3apn01NTVcd911XLhwgZUrVzZt79OnDzU1NZec63vf+x6VlZUcOXIEgNdee40xY8ZE/PmUlJTw8ssvU1lZSWVlJceOHaOsrIwzZ84wduzYpm4W9fX1nD59mrFjx/LGG29QXV0NwMmTJyN+rdboirCIdG/BIOze7XeKHikYVAEsPVssfgemTZvGpEmTmrpI5OXlMXz4cIYNG8YNN9zAbbfd1ubzCwoKePDBB8nPz2fgwIHcfvvtTfsWLFjAyJEjGThwILm5uU3F79SpU/nZz37G0qVLmwbJAWRkZPD73/+eKVOmUFdXx6233srMmTMj+jzOnDnDhg0beOmll5q29e7dm9GjR7N27VpeeOEFiouLWb58OYFAgBdffJFgMMgTTzzBmDFjCAQCDB8+nBUrVkT6pQvL2rusHSuFhYWucW47EZFkY2YfOOcK/c4RL2qzpac7ePAgQ4cO9TuGRCDc96q1NltdI0RERESkR1IhLCIiIiI9kgphEREREemRVAiLiHQzZna3mR02syNmNjfM/vvMbJ+Z7TGznWY22o+cIsnGr3FVErmOfo9UCIuIdCNmFgD+GfghcBMwzcxuanHYJiDPOZcPzABejm9KkeSTkZFBdXW1iuEE5pyjurqajIyMiJ+j6dNERLqXEcAR59wnAGa2CrgPaFpqyjn3dbPjewP6yy7SjuzsbKqqqjhx4oTfUaQNGRkZZGdnR3y8CmERke5lAPBZs8dVwMiWB5nZROBZ4Bog7DJOZlYMFAN8+9vfjnpQkWTSq1cvBg0a5HcMiTJ1jRAR6V7CLaF3yRVf59xbzrnvAfcDC8KdyDm3zDlX6JwrvPrqq6McU0TEfyqERUS6lyrg+maPs4EvWjvYObcFGGxm/WMdTEQk0agQFhHpXnYAQ8xskJmlAVOBt5sfYGbfMTML3S8A0oDquCcVEfGZb0ssm9kJ4NNOPLU/8Ncox+kqZYqMMkVGmdqXCHkGOucSsr+AmY0HlgAB4BXn3EIzmwngnPutmc0B/hNwATgL/Mo59y/tnFNtdmwpU2SUKTLKdKmwbbZvhXBnmdnOcGtF+0mZIqNMkVGm9iVaHmldIn6vlCkyyhQZZYpMImYCdY0QERERkR5KhbCIiIiI9EjJWAgv8ztAGMoUGWWKjDK1L9HySOsS8XulTJFRpsgoU2QSMVPy9REWEREREYmGZLwiLCIiIiLSZUlTCJvZ3WZ22MyOmNncOL7u9Wb2npkdNLMDZvZoaHs/M/s/ZvavoY9XNXvOvFDOw2Z2VwyzBcxst5m9kwiZzOxKM1ttZodCX69gAmR6LPR9229mJWaWEe9MZvaKmf3FzPY329bhDGb2fTP7MLRvaeM8sFHM9Fzoe7fPzN4ysyv9ztRs3y/NzDVf9CEemaRr/Gi31WZ3KI/a7PAZ1GZ3MlOzfcnTZjvnEv6GNxfmUeAGvInf9wI3xem1rwMKQvf7AB8DNwGLgbmh7XOBRaH7N4XypQODQrkDMcr2OPAH4J3QY18zAf8L+C+h+2nAlX5mAgYAx4DLQo/fAKbHOxPwA6AA2N9sW4czANuBIN4SuuuBH0Y5051Aauj+okTIFNp+PbABbw7b/vHMpFuXfu59abdRm92RPGqzw+dQm93JTKHtSdVmJ8sV4RHAEefcJ865WmAVcF88Xtg596Vzblfofg1wEO+X9T68RoTQx/tD9+8DVjnnzjvnjgFHQvmjysyygXuAl5tt9i2TmfXF+6VYDuCcq3XO/c3PTCGpwGVmlgpk4i01G9dMzlvC9mSLzR3KYGbXAX2dcxXOazlebfacqGRyzpU55+pCD/8v3tK8vmYK+Z/AbKD5gIa4ZJIu8aXdVpsdcR612a1Qm935TCFJ1WYnSyE8APis2eOq0La4MrMcYDiwDfh3zrkvwWt4gWtCh8Ur6xK8H7SGZtv8zHQDcAL4feitv5fNrLefmZxznwPPA/8P+BI45Zwr8zNTMx3NMCB0Px7ZAGbg/WfuayYzmwB87pzb22JXonydpHW+t9tqs9ukNrtj1GZHIBnb7GQphMP1F4nrdBdmdjmwBviFc+50W4eG2RbVrGZ2L/AX59wHkT4lzLZof/1S8d4iedE5Nxz4O97bR75lCvXhug/vbZhvAb3N7Ed+ZopAaxnils3MngDqgJV+ZjKzTOAJ4Mlwu/3IJB3i6/dCbXa71GZHh+9tkdrsrkmWQrgKr89Jo2y8t0viwsx64TWoK51zb4Y2Hw9d0if08S9xzHobMMHMKvHebvwPZva6z5mqgCrn3LbQ49V4jayfmcYBx5xzJ5xzF4A3gVE+Z2rU0QxVfPO2V8yymdlPgHuBh0JvU/mZaTDeH8S9oZ/1bGCXmV3rYyaJnG/tttrsiKjN7hi12e1Lzja7o52K/bjh/ef6Cd4XuHHQxbA4vbbh9VlZ0mL7c1zccX5x6P4wLu4Q/gkxGngRer0ivhl44Wsm4H3gxtD9p0N5fMsEjAQO4PUzM7x+XQ/7kQnI4eJBDh3OAOwA/j3fDCgYH+VMdwMfAVe3OM63TC32VfLNwIu4ZdKt099LX9pt1GZ3JIva7NaztGwf1WZHkKnFvkqSoM2O2wtF4YdyPN7o36PAE3F83dF4l+n3AXtCt/FAFrAJ+NfQx37NnvNEKOdhYjz6kYsbVV8zAfnAztDXqhS4KgEy/XfgELAfeC30SxjXTEAJXn+3C3j//f7nzmQACkOfx1HgN4QWxIlipiN4fbgaf85/63emFvsrCTWq8cqkW5d/9uPebqM2uyNZ1GaHz6A2u5OZWuyvJAnabK0sJyIiIiI9UrL0ERYRERERiSoVwiIiIiLSI6kQFhEREZEeSYWwiIiIiPRIKoRFREREpEdSISwiIiIiPZIKYRERERHpkVQIi4iIiEiP9P8BPqrUSYo2VM8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 864x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = len(run_hist_2.history[\"loss\"])\n",
    "\n",
    "fig = plt.figure(figsize=(12, 6))\n",
    "ax = fig.add_subplot(1, 2, 1)\n",
    "ax.plot(range(n), (run_hist_2.history[\"loss\"]),'r.', label=\"Train Loss\")\n",
    "ax.plot(range(n), (run_hist_2.history[\"val_loss\"]),'b.', label=\"Validation Loss\")\n",
    "ax.legend()\n",
    "ax.set_title('Loss over iterations')\n",
    "\n",
    "ax = fig.add_subplot(1, 2, 2)\n",
    "ax.plot(range(n), (run_hist_2.history[\"accuracy\"]),'r.', label=\"Train Acc\")\n",
    "ax.plot(range(n), (run_hist_2.history[\"val_accuracy\"]),'b.', label=\"Validation Acc\")\n",
    "ax.legend(loc='lower right')\n",
    "ax.set_title('Accuracy over iterations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "accuracy is 0.755\n",
      "roc-auc is 0.814\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred_class_nn_2 = model_2.predict_classes(X_test_norm)\n",
    "y_pred_prob_nn_2 = model_2.predict(X_test_norm)\n",
    "print('')\n",
    "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_nn_2)))\n",
    "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_nn_2)))\n",
    "\n",
    "plot_roc(y_test, y_pred_prob_nn_2, 'NN-2')\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
